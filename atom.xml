<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Fre5h1nd&#39;s Blog</title>
  
  
  <link href="https://freshwlnd.github.io/atom.xml" rel="self"/>
  
  <link href="https://freshwlnd.github.io/"/>
  <updated>2025-09-18T07:27:36.954Z</updated>
  <id>https://freshwlnd.github.io/</id>
  
  <author>
    <name>Fre5h1nd</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【集群】云原生批调度实战：Go 项目解析与并发编程实践</title>
    <link href="https://freshwlnd.github.io/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/"/>
    <id>https://freshwlnd.github.io/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/</id>
    <published>2025-09-09T15:38:48.000Z</published>
    <updated>2025-09-18T07:27:36.954Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p><ol><li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li><li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li><li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li><li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li><li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li><li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li><li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li><li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li><li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li><li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li><li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li><li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li><li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li><li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a></li></ol></blockquote><p>前期在 <a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a> 中我们深入解析了 <strong>审计日志 → Exporter → Prometheus+Grafana</strong> 的端到端链路，但仅关注 <code>kube-scheduling-performance</code> 项目本身（只负责开展测试、部署 Exporter 工具）。本篇将聚焦于实现了 Exporter 逻辑的 <code>kube-apiserver-audit-exporter</code> 项目细节，顺便以此为例介绍从 Go 语言项目结构到并发编程实践，帮助读者全面掌握云原生监控工具的开发模式。</p><p>下图给出了本篇的核心内容结构：</p><pre class="mermaid">graph TD  subgraph Go 项目解析    A[项目结构] --&gt; B[包结构]    B --&gt; C[文件结构]    C --&gt; D[函数/方法/类型]  end    subgraph 并发编程实践    E[Goroutine] --&gt; F[Channel]    F --&gt; G[操作符 &lt;-]    G --&gt; H[WaitGroup 同步]  end    subgraph 实际应用    I[审计日志处理] --&gt; J[指标收集]    J --&gt; K[监控数据暴露]  end</pre><hr><h1 id="1️⃣-kube-apiserver-audit-exporter-项目解析"><a href="#1️⃣-kube-apiserver-audit-exporter-项目解析" class="headerlink" title="1️⃣ kube-apiserver-audit-exporter 项目解析"></a>1️⃣ kube-apiserver-audit-exporter 项目解析</h1><h2 id="项目背景介绍"><a href="#项目背景介绍" class="headerlink" title="项目背景介绍"></a>项目背景介绍</h2><p><code>kube-apiserver-audit-exporter</code> 是一个专门用于将 Kubernetes API Server 审计日志转换为 Prometheus 指标的工具。在云原生环境中，监控和可观测性是至关重要的，而审计日志包含了所有 API 请求的详细信息，是分析系统行为的重要数据源。</p><p><strong>核心功能</strong>：</p><ul><li><strong>并发处理</strong>：为每个审计日志文件创建独立的 Exporter 协程，实现并行处理</li><li><strong>重放控制</strong>：支持历史审计日志的时间间隔重放，用于性能回归测试</li><li><strong>指标转换</strong>：将 JSON 格式的审计事件转换为 Prometheus 指标</li><li><strong>多维度标签</strong>：提取集群、命名空间、用户、资源等维度信息</li><li><strong>实时监控</strong>：持续读取审计日志文件，实时处理新增内容并更新指标</li></ul><h2 id="项目目录结构介绍"><a href="#项目目录结构介绍" class="headerlink" title="项目目录结构介绍"></a>项目目录结构介绍</h2><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">kube-apiserver-audit-exporter/</span><br><span class="line">├── cmd/                           # 可执行程序入口</span><br><span class="line">│   └── kube-apiserver-audit-exporter/</span><br><span class="line">│       └── main.go               # 主程序入口</span><br><span class="line">├── exporter/                      # 核心业务逻辑包</span><br><span class="line">│   ├── exporter.go               # 导出器核心逻辑</span><br><span class="line">│   ├── metrics.go                # Prometheus 指标定义</span><br><span class="line">│   ├── model.go                  # 数据模型定义</span><br><span class="line">│   └── utils.go                  # 工具函数</span><br><span class="line">├── go.mod                        # Go 模块定义文件</span><br><span class="line">├── go.sum                        # 依赖版本锁定文件</span><br><span class="line">├── audit-policy.yaml            # 审计策略配置</span><br><span class="line">└── README.md                     # 项目说明</span><br></pre></td></tr></table></figure></div><p><strong>目录结构特点</strong>：</p><ul><li><strong>cmd/</strong>: 遵循 Go 项目标准布局，存放可执行程序入口</li><li><strong>exporter/</strong>: 核心业务逻辑，采用包级别的模块化设计</li><li><strong>根目录</strong>: 包含项目配置文件和依赖管理文件</li></ul><h2 id="项目关键点介绍"><a href="#项目关键点介绍" class="headerlink" title="项目关键点介绍"></a>项目关键点介绍</h2><h3 id="1-并发处理架构"><a href="#1-并发处理架构" class="headerlink" title="1. 并发处理架构"></a>1. 并发处理架构</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main.go 中的并发启动</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> {</span><br><span class="line">    <span class="keyword">go</span> monitorAndStartExporters()  <span class="comment">// 异步启动监控器</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> err := exporter.ListenAndServe(address); err != <span class="literal">nil</span> {</span><br><span class="line">        slog.Error(<span class="string">"Failed to start metrics server"</span>, <span class="string">"err"</span>, err)</span><br><span class="line">        os.Exit(<span class="number">1</span>)</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// main.go 中为每个日志文件创建 Exporter</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">monitorAndStartExporters</span><span class="params">()</span></span> {</span><br><span class="line">    <span class="keyword">for</span> i, path := <span class="keyword">range</span> paths {</span><br><span class="line">        e := exporter.NewExporter(  <span class="comment">// 创建 Exporter 实例</span></span><br><span class="line">            exporter.WithReplay(replay),</span><br><span class="line">            exporter.WithFile(path),</span><br><span class="line">            exporter.WithClusterLabel(labels[i]),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">go</span> e.Run()  <span class="comment">// 启动 Exporter 协程</span></span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p><strong>设计亮点</strong>：</p><ul><li><strong>主线程</strong>：运行 HTTP 服务器，提供 <code>/metrics</code> 端点</li><li><strong>工作协程</strong>：每个日志文件对应一个独立的 Exporter 协程</li><li><strong>并发处理</strong>：多个 Exporter 协程并行处理不同的日志文件</li><li><strong>独立运行</strong>：每个协程独立监控自己的日志文件，互不干扰</li></ul><h3 id="2-重放控制机制"><a href="#2-重放控制机制" class="headerlink" title="2. 重放控制机制"></a>2. 重放控制机制</h3><p>重放控制是该项目的一个重要特性，用于按照原始时间间隔重放历史审计日志，支持性能回归测试。</p><h4 id="重放控制原理"><a href="#重放控制原理" class="headerlink" title="重放控制原理"></a>重放控制原理</h4><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// exporter.go 中的重放控制逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Exporter)</span></span> processFileUpdate(path <span class="type">string</span>) <span class="type">error</span> {</span><br><span class="line">    <span class="comment">// ... 文件读取逻辑 ...</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">var</span> event auditv1.Event</span><br><span class="line">    <span class="keyword">if</span> err := json.Unmarshal(line, &amp;event); err != <span class="literal">nil</span> {</span><br><span class="line">        <span class="keyword">return</span> fmt.Errorf(<span class="string">"json decode error: %w"</span>, err)</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 重放控制：如果启用重放模式，控制时间差</span></span><br><span class="line">    <span class="keyword">if</span> p.replay {</span><br><span class="line">        <span class="keyword">if</span> p.timeDiff == <span class="number">0</span> {</span><br><span class="line">            <span class="comment">// 第一次事件：记录当前时间与事件时间戳的差值作为基准</span></span><br><span class="line">            p.timeDiff = time.Since(event.StageTimestamp.Time)</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            <span class="comment">// 后续事件：如果当前时间与事件时间戳的差值小于基准，跳过该事件</span></span><br><span class="line">            <span class="keyword">if</span> time.Since(event.StageTimestamp.Time) &lt; p.timeDiff {</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">nil</span>  <span class="comment">// 跳过，等待时间到达</span></span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    p.updateMetrics(p.clusterLabel, event)</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h4 id="重放控制工作流程"><a href="#重放控制工作流程" class="headerlink" title="重放控制工作流程"></a>重放控制工作流程</h4><ol><li><p><strong>基准时间计算</strong>：</p><ul><li>当 <code>p.timeDiff == 0</code> 时，表示这是第一个事件</li><li>计算 <code>time.Since(event.StageTimestamp.Time)</code> 作为基准时间差</li><li>这个差值表示从事件发生到当前处理的时间间隔</li></ul></li><li><p><strong>时间间隔控制</strong>：</p><ul><li>对于后续事件，计算当前时间与事件时间戳的差值</li><li>如果差值小于基准时间差，说明还没到处理这个事件的时间</li><li>直接 <code>return nil</code> 跳过该事件，等待下次循环</li></ul></li><li><p><strong>重放效果</strong>：</p><ul><li>事件会按照原始的时间间隔被处理</li><li>如果原始日志中两个事件间隔 1 秒，重放时也会间隔 1 秒</li><li>实现了真实的时间模拟，而不是快速连续处理</li></ul></li></ol><h4 id="重放控制示例"><a href="#重放控制示例" class="headerlink" title="重放控制示例"></a>重放控制示例</h4><p>假设审计日志中有以下事件：</p><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">事件1: 2024-01-01 10:00:00 (处理时间: 10:00:05) → timeDiff = 5秒</span><br><span class="line">事件2: 2024-01-01 10:00:02 (处理时间: 10:00:05) → 5秒 &lt; 5秒? 否，处理</span><br><span class="line">事件3: 2024-01-01 10:00:03 (处理时间: 10:00:05) → 5秒 &lt; 5秒? 否，处理</span><br><span class="line">事件4: 2024-01-01 10:00:10 (处理时间: 10:00:05) → 5秒 &lt; 5秒? 否，处理</span><br></pre></td></tr></table></figure></div><p><strong>重放控制特点</strong>：</p><ul><li><strong>时间差计算</strong>：记录第一个事件的时间差作为基准</li><li><strong>重放模拟</strong>：按照原始时间间隔重放审计事件</li><li><strong>性能测试</strong>：支持历史数据的性能回归测试</li><li><strong>真实模拟</strong>：保持原始事件的时间关系，而不是快速连续处理</li></ul><h3 id="3-指标标签提取"><a href="#3-指标标签提取" class="headerlink" title="3. 指标标签提取"></a>3. 指标标签提取</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// metrics.go 中的标签提取逻辑</span></span><br><span class="line">labels := []<span class="type">string</span>{</span><br><span class="line">    clusterLabel,                           <span class="comment">// 集群标识</span></span><br><span class="line">    ns,                                     <span class="comment">// 命名空间</span></span><br><span class="line">    extractUserAgent(event.UserAgent),      <span class="comment">// 用户代理</span></span><br><span class="line">    event.Verb,                            <span class="comment">// HTTP 方法</span></span><br><span class="line">    extractResourceName(event),            <span class="comment">// 资源名称</span></span><br><span class="line">    strconv.Itoa(<span class="type">int</span>(event.ResponseStatus.Code)), <span class="comment">// 状态码</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p><strong>数据丰富性</strong>：</p><ul><li><strong>多维度标签</strong>：支持按集群、命名空间、用户等维度聚合</li><li><strong>状态码过滤</strong>：只处理成功的 API 调用（200-299）</li><li><strong>资源类型识别</strong>：自动识别 Pod、Job 等不同资源类型</li></ul><h2 id="关键点调用关系与数据流向"><a href="#关键点调用关系与数据流向" class="headerlink" title="关键点调用关系与数据流向"></a>关键点调用关系与数据流向</h2><h3 id="1-程序启动流程"><a href="#1-程序启动流程" class="headerlink" title="1. 程序启动流程"></a>1. 程序启动流程</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main.go - 程序入口</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> {</span><br><span class="line">    <span class="keyword">go</span> monitorAndStartExporters()  <span class="comment">// 启动监控器协程</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> err := exporter.ListenAndServe(address); err != <span class="literal">nil</span> {  <span class="comment">// 启动HTTP服务</span></span><br><span class="line">        slog.Error(<span class="string">"Failed to start metrics server"</span>, <span class="string">"err"</span>, err)</span><br><span class="line">        os.Exit(<span class="number">1</span>)</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h3 id="2-Exporter-创建与启动"><a href="#2-Exporter-创建与启动" class="headerlink" title="2. Exporter 创建与启动"></a>2. Exporter 创建与启动</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main.go - 为每个日志文件创建 Exporter</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">monitorAndStartExporters</span><span class="params">()</span></span> {</span><br><span class="line">    <span class="keyword">for</span> i, path := <span class="keyword">range</span> paths {</span><br><span class="line">        e := exporter.NewExporter(  <span class="comment">// 创建 Exporter 实例</span></span><br><span class="line">            exporter.WithReplay(replay),</span><br><span class="line">            exporter.WithFile(path),</span><br><span class="line">            exporter.WithClusterLabel(labels[i]),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">go</span> e.Run()  <span class="comment">// 启动 Exporter 协程</span></span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h3 id="3-文件监控与事件处理"><a href="#3-文件监控与事件处理" class="headerlink" title="3. 文件监控与事件处理"></a>3. 文件监控与事件处理</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// exporter.go - Exporter 运行循环</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Exporter)</span></span> Run() {</span><br><span class="line">    ticker := time.NewTicker(time.Second)</span><br><span class="line">    <span class="keyword">defer</span> ticker.Stop()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">range</span> ticker.C {</span><br><span class="line">        p.handleFileEvent(p.file)  <span class="comment">// 处理文件事件</span></span><br><span class="line">        ticker.Reset(time.Second)</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// exporter.go - 文件事件处理</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Exporter)</span></span> handleFileEvent(path <span class="type">string</span>) {</span><br><span class="line">    <span class="keyword">if</span> err := p.processFileUpdate(path); err != <span class="literal">nil</span> {  <span class="comment">// 处理文件更新</span></span><br><span class="line">        slog.Error(<span class="string">"Error processing file"</span>, <span class="string">"cluster"</span>, p.clusterLabel, <span class="string">"error"</span>, err)</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h3 id="4-日志解析与重放控制"><a href="#4-日志解析与重放控制" class="headerlink" title="4. 日志解析与重放控制"></a>4. 日志解析与重放控制</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// exporter.go - 文件更新处理</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Exporter)</span></span> processFileUpdate(path <span class="type">string</span>) <span class="type">error</span> {</span><br><span class="line">    <span class="comment">// ... 文件读取逻辑 ...</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">var</span> event auditv1.Event</span><br><span class="line">    <span class="keyword">if</span> err := json.Unmarshal(line, &amp;event); err != <span class="literal">nil</span> {  <span class="comment">// JSON 解析</span></span><br><span class="line">        <span class="keyword">return</span> fmt.Errorf(<span class="string">"json decode error: %w"</span>, err)</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 重放控制</span></span><br><span class="line">    <span class="keyword">if</span> p.replay {</span><br><span class="line">        <span class="keyword">if</span> p.timeDiff == <span class="number">0</span> {</span><br><span class="line">            p.timeDiff = time.Since(event.StageTimestamp.Time)</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            <span class="keyword">if</span> time.Since(event.StageTimestamp.Time) &lt; p.timeDiff {</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    p.updateMetrics(p.clusterLabel, event)  <span class="comment">// 更新指标</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h3 id="5-指标处理与标签提取"><a href="#5-指标处理与标签提取" class="headerlink" title="5. 指标处理与标签提取"></a>5. 指标处理与标签提取</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// metrics.go - 指标更新入口</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Exporter)</span></span> updateMetrics(clusterLabel <span class="type">string</span>, event auditv1.Event) {</span><br><span class="line">    <span class="comment">// 状态码过滤</span></span><br><span class="line">    <span class="keyword">if</span> event.ResponseStatus == <span class="literal">nil</span> ||</span><br><span class="line">        (event.ResponseStatus.Code &lt; <span class="number">200</span> || event.ResponseStatus.Code &gt;= <span class="number">300</span>) {</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 标签提取</span></span><br><span class="line">    labels := []<span class="type">string</span>{</span><br><span class="line">        clusterLabel,</span><br><span class="line">        ns,</span><br><span class="line">        extractUserAgent(event.UserAgent),      <span class="comment">// 提取用户代理</span></span><br><span class="line">        event.Verb,</span><br><span class="line">        extractResourceName(event),            <span class="comment">// 提取资源名称</span></span><br><span class="line">        strconv.Itoa(<span class="type">int</span>(event.ResponseStatus.Code)),</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    apiRequests.WithLabelValues(labels...).Inc()  <span class="comment">// 更新指标</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h3 id="6-HTTP-服务与指标暴露"><a href="#6-HTTP-服务与指标暴露" class="headerlink" title="6. HTTP 服务与指标暴露"></a>6. HTTP 服务与指标暴露</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// exporter.go - HTTP 服务启动</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ListenAndServe</span><span class="params">(addr <span class="type">string</span>)</span></span> <span class="type">error</span> {</span><br><span class="line">    mux := http.NewServeMux()</span><br><span class="line">    handler := promhttp.HandlerFor(registry, promhttp.HandlerOpts{</span><br><span class="line">        EnableOpenMetrics: <span class="literal">true</span>,</span><br><span class="line">    })</span><br><span class="line">    mux.Handle(<span class="string">"/metrics"</span>, handler)  <span class="comment">// 注册指标端点</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> http.ListenAndServe(addr, mux)  <span class="comment">// 启动 HTTP 服务</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h3 id="数据流向总结"><a href="#数据流向总结" class="headerlink" title="数据流向总结"></a>数据流向总结</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">审计日志文件 → processFileUpdate() → JSON解析 → 重放控制 → updateMetrics() → Prometheus指标 → /metrics端点 → 外部监控系统</span><br></pre></td></tr></table></figure></div><hr><h1 id="2️⃣-Go-项目解析"><a href="#2️⃣-Go-项目解析" class="headerlink" title="2️⃣ Go 项目解析"></a>2️⃣ Go 项目解析</h1><p>以该项目为例，我们可以看到一个 Go 语言项目的组成。</p><h2 id="项目结构层级"><a href="#项目结构层级" class="headerlink" title="项目结构层级"></a>项目结构层级</h2><p>Go 语言有清晰的层级结构，从大到小排列：</p><h3 id="项目-Project-Module"><a href="#项目-Project-Module" class="headerlink" title="项目 (Project/Module)"></a>项目 (Project/Module)</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kube-apiserver-audit-exporter/          # 项目根目录</span><br><span class="line">├── go.mod                              # 模块定义</span><br><span class="line">└── go.sum                              # 依赖锁定</span><br></pre></td></tr></table></figure></div><h3 id="包-Package"><a href="#包-Package" class="headerlink" title="包 (Package)"></a>包 (Package)</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">exporter/                               # 包目录</span><br><span class="line">├── exporter.go                         # package exporter</span><br><span class="line">├── metrics.go                          # package exporter  </span><br><span class="line">├── model.go                            # package exporter</span><br><span class="line">└── utils.go                            # package exporter</span><br><span class="line"></span><br><span class="line">cmd/kube-apiserver-audit-exporter/     # 另一个包</span><br><span class="line">└── main.go                             # package main</span><br></pre></td></tr></table></figure></div><h3 id="文件-File"><a href="#文件-File" class="headerlink" title="文件 (File)"></a>文件 (File)</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">exporter.go                             # 单个 .go 文件</span><br><span class="line">├── package exporter                    # 包声明</span><br><span class="line">├── import (...)                        # 导入语句</span><br><span class="line">├── type Exporter struct {...}          # 类型定义</span><br><span class="line">├── func NewExporter(...) {...}         # 函数定义</span><br><span class="line">└── func (e *Exporter) Run() {...}      # 方法定义</span><br></pre></td></tr></table></figure></div><h3 id="函数-方法-Function-Method"><a href="#函数-方法-Function-Method" class="headerlink" title="函数/方法 (Function/Method)"></a>函数/方法 (Function/Method)</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewExporter</span><span class="params">(opts ...Option)</span></span> *Exporter {  <span class="comment">// 函数</span></span><br><span class="line">    <span class="comment">// 函数体</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *Exporter)</span></span> Run() {                    <span class="comment">// 方法</span></span><br><span class="line">    <span class="comment">// 方法体</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h2 id="包结构详解"><a href="#包结构详解" class="headerlink" title="包结构详解"></a>包结构详解</h2><h3 id="1-包的作用域机制"><a href="#1-包的作用域机制" class="headerlink" title="1. 包的作用域机制"></a>1. 包的作用域机制</h3><p><strong>在 <code>exporter</code> 包中</strong>：</p><ul><li><code>exporter.go</code> 声明：<code>package exporter</code></li><li><code>metrics.go</code> 声明：<code>package exporter</code></li><li><code>model.go</code> 声明：<code>package exporter</code></li><li><code>utils.go</code> 声明：<code>package exporter</code></li></ul><p><strong>关键特点</strong>：</p><ul><li><strong>同一个包内的所有文件共享命名空间</strong></li><li><strong>不需要显式 import</strong>：同一个包内的文件可以直接访问彼此的公开标识符</li><li><strong>公开标识符</strong>：首字母大写的函数、变量、类型可以被外部包访问</li></ul><h3 id="2-包间调用关系"><a href="#2-包间调用关系" class="headerlink" title="2. 包间调用关系"></a>2. 包间调用关系</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在 main.go 中调用 exporter 包</span></span><br><span class="line"><span class="keyword">import</span> <span class="string">"github.com/wzshiming/kube-apiserver-audit-exporter/exporter"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> {</span><br><span class="line">    exporter.NewExporter(...)  <span class="comment">// 通过包名访问</span></span><br><span class="line">    exporter.ListenAndServe(address)  <span class="comment">// 通过包名访问</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h2 id="文件结构详解"><a href="#文件结构详解" class="headerlink" title="文件结构详解"></a>文件结构详解</h2><h3 id="1-Go-文件的基本组成"><a href="#1-Go-文件的基本组成" class="headerlink" title="1. Go 文件的基本组成"></a>1. Go 文件的基本组成</h3><p>一个典型的 Go 文件包含以下部分（按顺序）：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> declaration    <span class="comment">// 包声明</span></span><br><span class="line"><span class="keyword">import</span> statements     <span class="comment">// 导入语句</span></span><br><span class="line"><span class="keyword">type</span> declarations     <span class="comment">// 类型声明</span></span><br><span class="line"><span class="keyword">var</span> declarations      <span class="comment">// 变量声明</span></span><br><span class="line"><span class="keyword">const</span> declarations    <span class="comment">// 常量声明</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">declarations</span>     // 函数声明</span></span><br></pre></td></tr></table></figure></div><h3 id="2-关键概念解析"><a href="#2-关键概念解析" class="headerlink" title="2. 关键概念解析"></a>2. 关键概念解析</h3><h4 id="package-main-和-main-函数"><a href="#package-main-和-main-函数" class="headerlink" title="package main 和 main 函数"></a><code>package main</code> 和 <code>main</code> 函数</h4><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main  <span class="comment">// 可执行包，只有 main 包才能编译成可执行文件</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> {  <span class="comment">// 程序入口点，必须存在且唯一</span></span><br><span class="line">    <span class="comment">// 程序逻辑</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h4 id="import-语句"><a href="#import-语句" class="headerlink" title="import 语句"></a><code>import</code> 语句</h4><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">"log/slog"</span>    <span class="comment">// 标准库 - 结构化日志</span></span><br><span class="line">    <span class="string">"os"</span>          <span class="comment">// 标准库 - 操作系统接口</span></span><br><span class="line">    <span class="string">"strings"</span>     <span class="comment">// 标准库 - 字符串处理</span></span><br><span class="line">    <span class="string">"time"</span>        <span class="comment">// 标准库 - 时间处理</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">"github.com/spf13/pflag"</span>  <span class="comment">// 第三方库 - 命令行参数解析</span></span><br><span class="line">    <span class="string">"github.com/wzshiming/kube-apiserver-audit-exporter/exporter"</span>  <span class="comment">// 本地包</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></div><h4 id="var-变量声明"><a href="#var-变量声明" class="headerlink" title="var 变量声明"></a><code>var</code> 变量声明</h4><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">    auditLogPath = []<span class="type">string</span>{<span class="string">"./audit.log"</span>}  <span class="comment">// 审计日志路径，默认值</span></span><br><span class="line">    address      = <span class="string">":8080"</span>                  <span class="comment">// HTTP 服务地址，默认值</span></span><br><span class="line">    cluster      = <span class="string">""</span>                       <span class="comment">// 集群标签，默认值</span></span><br><span class="line">    replay       = <span class="literal">false</span>                    <span class="comment">// 是否重放日志，默认值</span></span><br><span class="line">    delay        time.Duration              <span class="comment">// 启动延迟，默认值</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></div><h4 id="init-函数"><a href="#init-函数" class="headerlink" title="init 函数"></a><code>init</code> 函数</h4><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> {</span><br><span class="line">    pflag.StringArrayVar(&amp;auditLogPath, <span class="string">"audit-log-path"</span>, auditLogPath, <span class="string">"Path to audit log files"</span>)</span><br><span class="line">    pflag.StringVar(&amp;address, <span class="string">"address"</span>, address, <span class="string">"Address to listen on"</span>)</span><br><span class="line">    pflag.StringVar(&amp;cluster, <span class="string">"cluster-label"</span>, cluster, <span class="string">"Default cluster label of metrics"</span>)</span><br><span class="line">    pflag.BoolVar(&amp;replay, <span class="string">"replay"</span>, replay, <span class="string">"replay the audit log"</span>)</span><br><span class="line">    pflag.DurationVar(&amp;delay, <span class="string">"delay"</span>, <span class="number">0</span>, <span class="string">"delay to start"</span>)</span><br><span class="line">    pflag.Parse()</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p><strong>执行顺序</strong>：</p><ol><li><strong>包级别变量初始化</strong>：先执行 <code>var</code> 声明</li><li><strong>init 函数执行</strong>：然后执行所有 <code>init</code> 函数</li><li><strong>main 函数执行</strong>：最后执行 <code>main</code> 函数</li></ol><h2 id="函数-方法-类型结构"><a href="#函数-方法-类型结构" class="headerlink" title="函数/方法/类型结构"></a>函数/方法/类型结构</h2><h3 id="1-选项模式-Option-Pattern"><a href="#1-选项模式-Option-Pattern" class="headerlink" title="1. 选项模式 (Option Pattern)"></a>1. 选项模式 (Option Pattern)</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Option <span class="function"><span class="keyword">func</span><span class="params">(e *Exporter)</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithFile</span><span class="params">(file <span class="type">string</span>)</span></span> Option {</span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(e *Exporter)</span></span> {</span><br><span class="line">        e.file = file</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithReplay</span><span class="params">(replay <span class="type">bool</span>)</span></span> Option {</span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(e *Exporter)</span></span> {</span><br><span class="line">        e.replay = replay</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewExporter</span><span class="params">(opts ...Option)</span></span> *Exporter {</span><br><span class="line">    e := &amp;Exporter{</span><br><span class="line">        podCreationTimes:      <span class="keyword">map</span>[target]*time.Time{},</span><br><span class="line">        batchJobCreationTimes: <span class="keyword">map</span>[target]*time.Time{},</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> _, opt := <span class="keyword">range</span> opts {</span><br><span class="line">        opt(e)  <span class="comment">// 应用每个选项</span></span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> e</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p><strong>选项模式的优势</strong>：</p><ul><li><strong>灵活配置</strong>：可以传递任意数量的选项</li><li><strong>可选参数</strong>：不需要的参数可以不传递</li><li><strong>可扩展性</strong>：添加新选项不需要修改构造函数签名</li><li><strong>可读性</strong>：调用时意图清晰明确</li></ul><h3 id="2-结构体方法"><a href="#2-结构体方法" class="headerlink" title="2. 结构体方法"></a>2. 结构体方法</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Exporter <span class="keyword">struct</span> {</span><br><span class="line">    file   <span class="type">string</span></span><br><span class="line">    offset <span class="type">int64</span></span><br><span class="line">    clusterLabel <span class="type">string</span></span><br><span class="line">    replay       <span class="type">bool</span></span><br><span class="line">    timeDiff     time.Duration</span><br><span class="line">    podCreationTimes      <span class="keyword">map</span>[target]*time.Time</span><br><span class="line">    batchJobCreationTimes <span class="keyword">map</span>[target]*time.Time</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Exporter)</span></span> Run() {</span><br><span class="line">    ticker := time.NewTicker(time.Second)</span><br><span class="line">    <span class="keyword">defer</span> ticker.Stop()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">range</span> ticker.C {</span><br><span class="line">        p.handleFileEvent(p.file)</span><br><span class="line">        ticker.Reset(time.Second)</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><hr><h1 id="3️⃣-Go-并发编程实践"><a href="#3️⃣-Go-并发编程实践" class="headerlink" title="3️⃣ Go 并发编程实践"></a>3️⃣ Go 并发编程实践</h1><h2 id="并发编程核心概念"><a href="#并发编程核心概念" class="headerlink" title="并发编程核心概念"></a>并发编程核心概念</h2><h3 id="1-Goroutine-vs-线程"><a href="#1-Goroutine-vs-线程" class="headerlink" title="1. Goroutine vs 线程"></a>1. Goroutine vs 线程</h3><table><thead><tr><th>特性</th><th>Goroutine</th><th>线程</th></tr></thead><tbody><tr><td><strong>内存占用</strong></td><td>2KB 初始栈，可动态增长</td><td>通常 1-2MB</td></tr><tr><td><strong>创建成本</strong></td><td>极低</td><td>较高</td></tr><tr><td><strong>调度方式</strong></td><td>M:N 模型（用户态调度）</td><td>1:1 模型（内核调度）</td></tr><tr><td><strong>并发数量</strong></td><td>可创建数百万个</td><td>通常几千个</td></tr></tbody></table><h3 id="2-Channel-通信机制"><a href="#2-Channel-通信机制" class="headerlink" title="2. Channel 通信机制"></a>2. Channel 通信机制</h3><p>Channel 是 Go 协程间通信的管道，遵循”通过通信共享内存”的设计哲学。</p><blockquote><p>在Effective Go 中对并发的描述中有这样一句话：<br>“Do not communicate by sharing memory; instead, share memory by communicating.</p></blockquote><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建 channel</span></span><br><span class="line">tasks := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, <span class="number">100</span>)  <span class="comment">// 带缓冲的 channel</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 发送数据</span></span><br><span class="line">tasks &lt;- i  <span class="comment">// 将数据发送到 channel</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 接收数据</span></span><br><span class="line">task := &lt;-tasks  <span class="comment">// 从 channel 接收数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 关闭 channel</span></span><br><span class="line"><span class="built_in">close</span>(tasks)  <span class="comment">// 通知接收方没有更多数据</span></span><br></pre></td></tr></table></figure></div><h3 id="3-WaitGroup-同步机制"><a href="#3-WaitGroup-同步机制" class="headerlink" title="3. WaitGroup 同步机制"></a>3. WaitGroup 同步机制</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line"></span><br><span class="line">wg.Add(<span class="number">1</span>)    <span class="comment">// 增加等待计数</span></span><br><span class="line"><span class="keyword">defer</span> wg.Done()  <span class="comment">// 协程结束时减少计数</span></span><br><span class="line">wg.Wait()    <span class="comment">// 等待所有协程完成</span></span><br></pre></td></tr></table></figure></div><h2 id="实战示例：5个协程并行输出数字1-100"><a href="#实战示例：5个协程并行输出数字1-100" class="headerlink" title="实战示例：5个协程并行输出数字1-100"></a>实战示例：5个协程并行输出数字1-100</h2><h3 id="方案1：Channel-WaitGroup（推荐）"><a href="#方案1：Channel-WaitGroup（推荐）" class="headerlink" title="方案1：Channel + WaitGroup（推荐）"></a>方案1：Channel + WaitGroup（推荐）</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">"fmt"</span></span><br><span class="line">    <span class="string">"sync"</span></span><br><span class="line">    <span class="string">"time"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> {</span><br><span class="line">    fmt.Println(<span class="string">"5个协程并行输出数字1-100（无重复）"</span>)</span><br><span class="line">    fmt.Println(<span class="string">"====================================="</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 创建任务 channel</span></span><br><span class="line">    tasks := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, <span class="number">100</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 使用 WaitGroup 等待所有协程完成</span></span><br><span class="line">    <span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 启动 5 个 worker 协程</span></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ {</span><br><span class="line">        wg.Add(<span class="number">1</span>) <span class="comment">// 增加等待计数</span></span><br><span class="line">        <span class="keyword">go</span> worker(i, tasks, &amp;wg)</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 发送任务到 channel</span></span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> {</span><br><span class="line">        <span class="keyword">for</span> i := <span class="number">1</span>; i &lt;= <span class="number">100</span>; i++ {</span><br><span class="line">            tasks &lt;- i</span><br><span class="line">        }</span><br><span class="line">        <span class="built_in">close</span>(tasks) <span class="comment">// 关闭 channel，通知 workers 没有更多任务</span></span><br><span class="line">    }()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 等待所有协程完成</span></span><br><span class="line">    wg.Wait()</span><br><span class="line">    fmt.Println(<span class="string">"\n所有任务完成！"</span>)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// worker 函数：处理任务的协程</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">worker</span><span class="params">(workerID <span class="type">int</span>, tasks &lt;-<span class="keyword">chan</span> <span class="type">int</span>, wg *sync.WaitGroup)</span></span> {</span><br><span class="line">    <span class="keyword">defer</span> wg.Done() <span class="comment">// 协程结束时减少等待计数</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> task := <span class="keyword">range</span> tasks {</span><br><span class="line">        fmt.Printf(<span class="string">"协程 %d 处理数字: %d\n"</span>, workerID, task)</span><br><span class="line">        <span class="comment">// 模拟一些处理时间</span></span><br><span class="line">        time.Sleep(<span class="number">10</span> * time.Millisecond)</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p><strong>运行结果</strong>：</p><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">5个协程并行输出数字1-100（无重复）</span><br><span class="line">=====================================</span><br><span class="line">协程 1 处理数字: 1</span><br><span class="line">协程 2 处理数字: 2</span><br><span class="line">协程 3 处理数字: 3</span><br><span class="line">协程 4 处理数字: 4</span><br><span class="line">协程 0 处理数字: 5</span><br><span class="line">协程 0 处理数字: 6</span><br><span class="line">协程 4 处理数字: 7</span><br><span class="line">协程 1 处理数字: 8</span><br><span class="line">协程 2 处理数字: 9</span><br><span class="line">协程 3 处理数字: 10</span><br><span class="line">...</span><br><span class="line">协程 2 处理数字: 99</span><br><span class="line">协程 3 处理数字: 100</span><br><span class="line"></span><br><span class="line">所有任务完成！</span><br></pre></td></tr></table></figure></div><h3 id="方案2：互斥锁（不推荐，性能较差）"><a href="#方案2：互斥锁（不推荐，性能较差）" class="headerlink" title="方案2：互斥锁（不推荐，性能较差）"></a>方案2：互斥锁（不推荐，性能较差）</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mutexApproach</span><span class="params">()</span></span> {</span><br><span class="line">    <span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">    <span class="keyword">var</span> mu sync.Mutex</span><br><span class="line">    counter := <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ {</span><br><span class="line">        wg.Add(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(workerID <span class="type">int</span>)</span></span> {</span><br><span class="line">            <span class="keyword">defer</span> wg.Done()</span><br><span class="line">            <span class="keyword">for</span> {</span><br><span class="line">                mu.Lock()</span><br><span class="line">                <span class="keyword">if</span> counter &gt; <span class="number">100</span> {</span><br><span class="line">                    mu.Unlock()</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                }</span><br><span class="line">                current := counter</span><br><span class="line">                counter++</span><br><span class="line">                mu.Unlock()</span><br><span class="line">                </span><br><span class="line">                fmt.Printf(<span class="string">"Worker %d: %d\n"</span>, workerID, current)</span><br><span class="line">            }</span><br><span class="line">        }(i)</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    wg.Wait()</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h3 id="方案3：原子操作（高性能）"><a href="#方案3：原子操作（高性能）" class="headerlink" title="方案3：原子操作（高性能）"></a>方案3：原子操作（高性能）</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">atomicApproach</span><span class="params">()</span></span> {</span><br><span class="line">    <span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">    <span class="keyword">var</span> counter <span class="type">int64</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ {</span><br><span class="line">        wg.Add(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(workerID <span class="type">int</span>)</span></span> {</span><br><span class="line">            <span class="keyword">defer</span> wg.Done()</span><br><span class="line">            <span class="keyword">for</span> {</span><br><span class="line">                current := atomic.AddInt64(&amp;counter, <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">if</span> current &gt; <span class="number">100</span> {</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                }</span><br><span class="line">                fmt.Printf(<span class="string">"Worker %d: %d\n"</span>, workerID, current)</span><br><span class="line">            }</span><br><span class="line">        }(i)</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    wg.Wait()</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h2 id="操作符-lt-详解"><a href="#操作符-lt-详解" class="headerlink" title="操作符 <- 详解"></a>操作符 <code>&lt;-</code> 详解</h2><h3 id="1-Channel-操作符"><a href="#1-Channel-操作符" class="headerlink" title="1. Channel 操作符"></a>1. Channel 操作符</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 发送操作</span></span><br><span class="line">ch &lt;- value  <span class="comment">// 将 value 发送到 channel ch</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 接收操作</span></span><br><span class="line">value := &lt;-ch  <span class="comment">// 从 channel ch 接收值</span></span><br><span class="line">value, ok := &lt;-ch  <span class="comment">// 接收值并检查 channel 是否关闭</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 关闭操作</span></span><br><span class="line"><span class="built_in">close</span>(ch)  <span class="comment">// 关闭 channel</span></span><br></pre></td></tr></table></figure></div><h3 id="2-方向性-Channel"><a href="#2-方向性-Channel" class="headerlink" title="2. 方向性 Channel"></a>2. 方向性 Channel</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 只发送</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">sendOnly</span><span class="params">(ch <span class="keyword">chan</span>&lt;- <span class="type">int</span>)</span></span> {</span><br><span class="line">    ch &lt;- <span class="number">42</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只接收</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">receiveOnly</span><span class="params">(ch &lt;-<span class="keyword">chan</span> <span class="type">int</span>)</span></span> {</span><br><span class="line">    value := &lt;-ch</span><br><span class="line">    fmt.Println(value)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 双向（默认）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">bidirectional</span><span class="params">(ch <span class="keyword">chan</span> <span class="type">int</span>)</span></span> {</span><br><span class="line">    ch &lt;- <span class="number">42</span></span><br><span class="line">    value := &lt;-ch</span><br><span class="line">    fmt.Println(value)</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h3 id="3-Select-语句"><a href="#3-Select-语句" class="headerlink" title="3. Select 语句"></a>3. Select 语句</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> {</span><br><span class="line"><span class="keyword">case</span> msg1 := &lt;-ch1:</span><br><span class="line">    fmt.Println(<span class="string">"收到消息1:"</span>, msg1)</span><br><span class="line"><span class="keyword">case</span> msg2 := &lt;-ch2:</span><br><span class="line">    fmt.Println(<span class="string">"收到消息2:"</span>, msg2)</span><br><span class="line"><span class="keyword">case</span> &lt;-time.After(<span class="number">1</span> * time.Second):</span><br><span class="line">    fmt.Println(<span class="string">"超时"</span>)</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">    fmt.Println(<span class="string">"没有消息"</span>)</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h2 id="并发编程最佳实践"><a href="#并发编程最佳实践" class="headerlink" title="并发编程最佳实践"></a>并发编程最佳实践</h2><h3 id="1-推荐方案：Channel-WaitGroup"><a href="#1-推荐方案：Channel-WaitGroup" class="headerlink" title="1. 推荐方案：Channel + WaitGroup"></a>1. 推荐方案：Channel + WaitGroup</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 优点：</span></span><br><span class="line"><span class="comment">// - 代码清晰易读</span></span><br><span class="line"><span class="comment">// - 符合 Go 的"通过通信共享内存"理念</span></span><br><span class="line"><span class="comment">// - 自动处理协程同步</span></span><br><span class="line"><span class="comment">// - 避免竞态条件</span></span><br><span class="line"></span><br><span class="line">tasks := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, <span class="number">100</span>)</span><br><span class="line"><span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ {</span><br><span class="line">    wg.Add(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(workerID <span class="type">int</span>)</span></span> {</span><br><span class="line">        <span class="keyword">defer</span> wg.Done()</span><br><span class="line">        <span class="keyword">for</span> task := <span class="keyword">range</span> tasks {</span><br><span class="line">            <span class="comment">// 处理任务</span></span><br><span class="line">        }</span><br><span class="line">    }(i)</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h3 id="2-Go-并发设计哲学"><a href="#2-Go-并发设计哲学" class="headerlink" title="2. Go 并发设计哲学"></a>2. Go 并发设计哲学</h3><blockquote><p><strong>“Don’t communicate by sharing memory; share memory by communicating.”</strong></p><p><strong>“不要通过共享内存来通信；要通过通信来共享内存。”</strong></p></blockquote><p>简单解析：</p><blockquote><p>多个goroutine同时操作同一个变量（communicate by sharing memory），会有数据竞争的问题，尽量不要用这种方式；而推荐用传递共享方式，一个goroutine处理完了以后传递给另一个goroutine继续处理（share memory by communicating）</p><p>作者：水慕华<br>链接：<a class="link" href="https://www.zhihu.com/question/27596075/answer/593672097">https://www.zhihu.com/question/27596075/answer/593672097<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>来源：知乎</p></blockquote><p>这就是为什么 Channel 是 Go 并发编程的首选方案！</p><h3 id="3-实际应用场景"><a href="#3-实际应用场景" class="headerlink" title="3. 实际应用场景"></a>3. 实际应用场景</h3><p>这种模式在实际项目中非常常见：</p><ul><li><strong>Web 服务器</strong>：每个请求一个协程</li><li><strong>数据处理</strong>：批量处理文件、数据库操作</li><li><strong>微服务</strong>：并发调用多个服务</li><li><strong>爬虫</strong>：并发抓取网页</li></ul><hr><p><em>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</em><br><em>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</em></p><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><p><a class="link" href="https://github.com/wzshiming/kube-apiserver-audit-exporter">[1] Github - kube-apiserver-audit-exporter<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://golang.org/doc/effective_go.html#concurrency">[2] Go 官方文档 - 并发编程<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://golang.org/ref/spec#Channel_types">[3] Go 官方文档 - Channel<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/audit/">[4] Kubernetes官方文档 - 审计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">深入解析 kube-apiserver-audit-exporter 项目架构，从 Go 语言项目结构到并发编程实践，全面掌握云原生监控工具的开发模式。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="K8s" scheme="https://freshwlnd.github.io/tags/K8s/"/>
    
    <category term="Go" scheme="https://freshwlnd.github.io/tags/Go/"/>
    
    <category term="并发编程" scheme="https://freshwlnd.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
    <category term="监控" scheme="https://freshwlnd.github.io/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>【集群】云原生批调度实战：Volcano 深度解析（五）：CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验</title>
    <link href="https://freshwlnd.github.io/2025/09/04/k8s/k8s-volcano-create-schedule-contention-analysis/"/>
    <id>https://freshwlnd.github.io/2025/09/04/k8s/k8s-volcano-create-schedule-contention-analysis/</id>
    <published>2025-09-04T15:44:55.000Z</published>
    <updated>2025-09-18T12:37:35.911Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列《云原生批调度实战：Volcano 深度解析》计划分为以下几篇，点击查看其它内容。</p><ol><li><a href="/2025/05/26/k8s/k8s-volcano-1/" title="云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点">云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点</a></li><li><a href="/2025/05/27/k8s/k8s-volcano-2/" title="云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态">云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态</a></li><li><a href="/2025/06/22/k8s/k8s-volcano-install/" title="云原生批调度实战：Volcano 安装与初试">云原生批调度实战：Volcano 安装与初试</a></li><li><a href="/2025/08/25/k8s/k8s-volcano-core-flow/" title="云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计">云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计</a></li><li><a href="/2025/08/26/k8s/k8s-volcano-create-analysis/" title="云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析">云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析</a></li><li><a href="/2025/09/04/k8s/k8s-volcano-create-schedule-contention-analysis/" title="云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验">云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验</a></li></ol></blockquote><p>本文承接《CREATE 阶段瓶颈追踪与优化思考》，基于大量实验数据和源码深度分析，重新梳理 <strong>CREATE/SCHEDULE 卡顿现象</strong> 的根本原因。上篇博客中我们推测协程数不足是导致卡顿的主要原因，但实验结果却呈现了一些反直觉的现象，本文将结合源码分析给出更准确的解释。</p><h1 id="0️⃣-引言"><a href="#0️⃣-引言" class="headerlink" title="0️⃣ 引言"></a>0️⃣ 引言</h1><p>在上一篇博客 <a href="/2025/08/26/k8s/k8s-volcano-create-analysis/" title="CREATE 阶段瓶颈追踪">CREATE 阶段瓶颈追踪</a> 中，我们通过代码分析推测，Controller 的 worker 协程数不足可能是导致 <code>CREATE</code>/<code>SCHEDULE</code> 阶段出现卡顿（表现为“突增、突停”）现象的原因。然而，后续大量的性能测试揭示了一些反直觉的现象，挑战了这一初步结论。</p><ul><li><strong>协程数增加并不总是提升性能</strong>：在某些配置下，增加协程数反而会降低性能</li></ul><p>这些现象促使我们重新审视问题的根本原因。<br>本次，我们将结合最新的实验结果以及对 Volcano 源码的进一步分析，重新梳理 <code>CREATE</code>/<code>SCHEDULE</code> 卡顿现象的深层原因，并探讨其背后的 K8s API-Server 争用机制。</p><h1 id="1️⃣-背景回顾"><a href="#1️⃣-背景回顾" class="headerlink" title="1️⃣ 背景回顾"></a>1️⃣ 背景回顾</h1><h2 id="1-1-卡顿现象描述"><a href="#1-1-卡顿现象描述" class="headerlink" title="1.1 卡顿现象描述"></a>1.1 卡顿现象描述</h2><p>根据前期测试（无论是 KubeCon 的分享还是我们本地的复现），我们发现 Volcano 在处理大量 Pod 的 <code>CREATE</code> 和 <code>SCHEDULE</code> 过程中，性能曲线并非平滑上升，而是会出现卡顿现象，具体体现为：</p><ul><li><strong>“完成 <code>CREATE</code> 的 Pod 数量”</strong> 和 <strong>“完成 <code>SCHEDULE</code> 的 Pod 数量”</strong> 指标各自出现持续增长一段时间后突停一段时间</li><li>然后再持续增长一段时间后又突停一段时间，循环往复</li></ul><p><figure class="image-caption"><img src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/b.NoGang-500Job-no/output/panel-5.png?raw=true" alt="CREATE/SCHEDULE 卡顿现象示意图1"><figcaption>CREATE/SCHEDULE 卡顿现象示意图1</figcaption></figure></p><p><figure class="image-caption"><img src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/5-more-worker-threads/only-volcano/worker_threads_100/3.NoGang-2KJob/output/panel-5.png?raw=true" alt="CREATE/SCHEDULE 卡顿现象示意图2"><figcaption>CREATE/SCHEDULE 卡顿现象示意图2</figcaption></figure></p><p>这种现象引起了我们的担忧：这些停顿的平台期是否意味着时间的浪费？如果我们能消除这些停顿，把这些时间段用起来，是不是我们就能够达到更高的效率呢？</p><h2 id="1-2-测试环境说明"><a href="#1-2-测试环境说明" class="headerlink" title="1.2 测试环境说明"></a>1.2 测试环境说明</h2><p>前期我们保持 Node 数量和 Pod 数量不变，调整 Job 数量（以及对应的每 Job 内 Pod 数量）进行测试。测试配置如下：</p><table><thead><tr><th>Benchmark</th><th>Job×Pod</th><th>总 Pod 数</th><th>现象特征</th></tr></thead><tbody><tr><td>benchmark-1</td><td>10K×1</td><td>10,000</td><td><code>CREATE</code> 与 <code>SCHEDULE</code> 几乎重叠，整体速度最慢</td></tr><tr><td>benchmark-2</td><td>500×20</td><td>10,000</td><td>阶梯最清晰，<code>CREATE</code>/<code>SCHEDULE</code> 交替性卡顿</td></tr><tr><td>benchmark-3</td><td>200×50</td><td>10,000</td><td><code>CREATE</code> 有阶梯但速度明显快于 <code>SCHEDULE</code></td></tr><tr><td>benchmark-4</td><td>20×500</td><td>10,000</td><td><code>CREATE</code> 有阶梯，且与 <code>SCHEDULE</code> 有交点</td></tr><tr><td>benchmark-5</td><td>1×10K</td><td>10,000</td><td><code>CREATE</code> 快速完成，<code>SCHEDULE</code> 成为瓶颈</td></tr></tbody></table><h1 id="2️⃣-现象观察：三个层次的卡顿模式"><a href="#2️⃣-现象观察：三个层次的卡顿模式" class="headerlink" title="2️⃣ 现象观察：三个层次的卡顿模式"></a>2️⃣ 现象观察：三个层次的卡顿模式</h1><p>仔细观察后，我们发现卡顿现象随 Job 数量有三个层次：</p><h2 id="2-1-不卡顿：Job-数量少，每-Job-内-Pod-数量多"><a href="#2-1-不卡顿：Job-数量少，每-Job-内-Pod-数量多" class="headerlink" title="2.1 不卡顿：Job 数量少，每 Job 内 Pod 数量多"></a>2.1 不卡顿：Job 数量少，每 Job 内 Pod 数量多</h2><p><strong>典型场景</strong>：benchmark-4（20×500）、benchmark-5（1×10K）</p><p><strong>现象特征</strong>：</p><ul><li><code>CREATE</code> 快速完成，<code>SCHEDULE</code> 慢慢完成</li><li>两条曲线基本平滑，无明显卡顿</li><li><code>CREATE</code> 始终比 <code>SCHEDULE</code> 更快</li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/c.NoGang-20Job-no/output/panel-5.png?raw=true" alt="不卡顿现象示例"><figcaption>不卡顿现象示例</figcaption></figure></p><h2 id="2-2-卡顿但互不影响：Job-数量较多，每-Job-内-Pod-数量较少"><a href="#2-2-卡顿但互不影响：Job-数量较多，每-Job-内-Pod-数量较少" class="headerlink" title="2.2 卡顿但互不影响：Job 数量较多，每 Job 内 Pod 数量较少"></a>2.2 卡顿但互不影响：Job 数量较多，每 Job 内 Pod 数量较少</h2><p><strong>典型场景</strong>：benchmark-3（200×50）</p><p><strong>现象特征</strong>：</p><ul><li><code>CREATE</code>/<code>SCHEDULE</code> 交替性卡顿</li><li><code>CREATE</code> 始终比 <code>SCHEDULE</code> 更快，两条曲线没有交点</li><li>卡顿期间，另一条曲线仍在工作</li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/e.NoGang-200Job/output/panel-5.png?raw=true" alt="卡顿但互不影响示例"><figcaption>卡顿但互不影响示例</figcaption></figure></p><h2 id="2-3-卡顿且相互影响：Job-数量极多，每-Job-内-Pod-数量极少"><a href="#2-3-卡顿且相互影响：Job-数量极多，每-Job-内-Pod-数量极少" class="headerlink" title="2.3 卡顿且相互影响：Job 数量极多，每 Job 内 Pod 数量极少"></a>2.3 卡顿且相互影响：Job 数量极多，每 Job 内 Pod 数量极少</h2><p><strong>典型场景</strong>：benchmark-2（500×20）、benchmark-1（10K×1）</p><p><strong>现象特征</strong>：</p><ul><li><code>CREATE</code>/<code>SCHEDULE</code> 交替性卡顿</li><li><code>CREATE</code> 有时会阻塞 <code>SCHEDULE</code>，两条曲线存在交点</li><li>整体性能最差</li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/b.NoGang-500Job-no/output/panel-5.png?raw=true" alt="卡顿且相互影响示例1"><figcaption>卡顿且相互影响示例1</figcaption></figure></p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="卡顿且相互影响示例2"><figcaption>卡顿且相互影响示例2</figcaption></figure></p><h2 id="2-4-关键发现：CREATE-和-SCHEDULE-不会同时卡顿"><a href="#2-4-关键发现：CREATE-和-SCHEDULE-不会同时卡顿" class="headerlink" title="2.4 关键发现：CREATE 和 SCHEDULE 不会同时卡顿"></a>2.4 关键发现：CREATE 和 SCHEDULE 不会同时卡顿</h2><p>仔细观察后，我们发现了一个非常有意思且关键的现象：<code>CREATE</code> 和 <code>SCHEDULE</code> <strong>不会同时出现卡顿</strong>（即从图中看不会同时斜率为 0，而斜率代表着每秒完成对应操作的 Pod 数量）。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/5-more-worker-threads/only-volcano/worker_threads_100/3.NoGang-2KJob/output/panel-5.png?raw=true" alt="CREATE 和 SCHEDULE 不会同时卡顿示意图1：完成 CREATE 和 SCHEDULE 的 Pod 总数数量图"><figcaption>CREATE 和 SCHEDULE 不会同时卡顿示意图1：完成 CREATE 和 SCHEDULE 的 Pod 总数数量图</figcaption></figure></p><p>对照事件趋势图也会发现，<code>CREATE</code>（图中红色虚线）和<code>SCHEDULE</code>（图中亮绿色实线）的波峰和波谷恰恰好重合。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/5-more-worker-threads/only-volcano/worker_threads_100/3.NoGang-2KJob/output/panel-11.png?raw=true" alt="CREATE 和 SCHEDULE 不会同时卡顿示意图2：完成 CREATE 和 SCHEDULE 的 Pod 每秒吞吐图"><figcaption>CREATE 和 SCHEDULE 不会同时卡顿示意图2：完成 CREATE 和 SCHEDULE 的 Pod 每秒吞吐图</figcaption></figure></p><p>即使是在上述第 3 种层次下，两条曲线的交点也是一交即分。这也就意味着，<code>CREATE</code> 和 <code>SCHEDULE</code> 两种操作始终是在工作的，但是似乎存在一种严重的“争用”，导致某些时候只有一类操作能够顺利进行。</p><h2 id="2-5-Api-Server-日志分析"><a href="#2-5-Api-Server-日志分析" class="headerlink" title="2.5 Api-Server 日志分析"></a>2.5 Api-Server 日志分析</h2><p>进一步仔细排查后发现，<code>kube-apiserver</code> 日志中出现大量（超过 3000 次）<code>409 Conflict</code> 错误。<br>典型错误日志如下：<br>    <div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">事件类型: default_vc-controller-manager/v0.0.0 (linux/amd64) kubernetes/$Format_create_pods</span><br><span class="line">发生次数: 1575</span><br><span class="line">事件特征:</span><br><span class="line">    namespace: default</span><br><span class="line">    userAgent: vc-controller-manager/v0.0.0 (linux/amd64) kubernetes/$Format</span><br><span class="line">    verb: create</span><br><span class="line">    resource: pods</span><br><span class="line">    code: 409</span><br><span class="line">    reason: AlreadyExists</span><br><span class="line"></span><br><span class="line">------------------------------</span><br><span class="line"></span><br><span class="line">事件类型: default_vc-controller-manager/v0.0.0 (linux/amd64) kubernetes/$Format_update_jobs/status</span><br><span class="line">发生次数: 705</span><br><span class="line">事件特征:</span><br><span class="line">    namespace: default</span><br><span class="line">    userAgent: vc-controller-manager/v0.0.0 (linux/amd64) kubernetes/$Format</span><br><span class="line">    verb: update</span><br><span class="line">    resource: jobs/status</span><br><span class="line">    code: 409</span><br><span class="line">    reason: Conflict</span><br><span class="line"></span><br><span class="line">------------------------------</span><br><span class="line"></span><br><span class="line">事件类型: default_vc-controller-manager/v0.0.0 (linux/amd64) kubernetes/$Format_create_podgroups</span><br><span class="line">发生次数: 623</span><br><span class="line">事件特征:</span><br><span class="line">    namespace: default</span><br><span class="line">    userAgent: vc-controller-manager/v0.0.0 (linux/amd64) kubernetes/$Format</span><br><span class="line">    verb: create</span><br><span class="line">    resource: podgroups</span><br><span class="line">    code: 409</span><br><span class="line">    reason: AlreadyExists</span><br><span class="line"></span><br><span class="line">------------------------------</span><br><span class="line"></span><br><span class="line">事件类型: default_vc-scheduler/v0.0.0 (linux/amd64) kubernetes/$Format_update_podgroups</span><br><span class="line">发生次数: 477</span><br><span class="line">事件特征:</span><br><span class="line">    namespace: default</span><br><span class="line">    userAgent: vc-scheduler/v0.0.0 (linux/amd64) kubernetes/$Format</span><br><span class="line">    verb: update</span><br><span class="line">    resource: podgroups</span><br><span class="line">    code: 409</span><br><span class="line">    reason: Conflict</span><br><span class="line"></span><br><span class="line">------------------------------</span><br><span class="line"></span><br></pre></td></tr></table></figure></div></p><h1 id="3️⃣-原因分析：API-Server-请求排队争用"><a href="#3️⃣-原因分析：API-Server-请求排队争用" class="headerlink" title="3️⃣ 原因分析：API-Server 请求排队争用"></a>3️⃣ 原因分析：API-Server 请求排队争用</h1><h2 id="3-1-初步分析：CREATE-和-SCHEDULE-的独立性"><a href="#3-1-初步分析：CREATE-和-SCHEDULE-的独立性" class="headerlink" title="3.1 初步分析：CREATE 和 SCHEDULE 的独立性"></a>3.1 初步分析：<code>CREATE</code> 和 <code>SCHEDULE</code> 的独立性</h2><p>根据上述关键现象，我们猜测造成“卡顿”的原因很可能是 <code>CREATE</code> 和 <code>SCHEDULE</code> 两种操作之间的“争用”。</p><p>然而，经过对 Volcano 源码的仔细分析，我们发现 <code>CREATE</code> 功能属于 Controller 组件，而 <code>SCHEDULE</code> 功能属于 Scheduler 组件，两者在代码层面并没有直接的调用、依赖或其它影响关系。</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller_actions.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *jobcontroller)</span></span> syncJob(jobInfo *apis.JobInfo, updateStatus state.UpdateStatusFn) <span class="type">error</span> {</span><br><span class="line">    <span class="comment">// Controller 负责 Pod 创建</span></span><br><span class="line">    <span class="keyword">for</span> _, pod := <span class="keyword">range</span> podToCreateEachTask {</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(pod *v1.Pod)</span></span> {</span><br><span class="line">            <span class="keyword">defer</span> waitCreationGroup.Done()</span><br><span class="line">            newPod, err := cc.kubeClient.CoreV1().Pods(pod.Namespace).Create(context.TODO(), pod, metav1.CreateOptions{})</span><br><span class="line">            <span class="comment">// ...</span></span><br><span class="line">        }(pod)</span><br><span class="line">    }</span><br><span class="line">    waitCreationGroup.Wait()</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// pkg/scheduler/actions/allocate/allocate.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(alloc *Action)</span></span> Execute(ssn *framework.Session) {</span><br><span class="line">    <span class="comment">// Scheduler 负责 Pod 调度</span></span><br><span class="line">    <span class="keyword">for</span> _, task := <span class="keyword">range</span> tasks {</span><br><span class="line">        <span class="comment">// 调度决策和绑定</span></span><br><span class="line">        ssn.Bind(task, node)</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h2 id="3-2-深入分析：API-Server-层面的争用"><a href="#3-2-深入分析：API-Server-层面的争用" class="headerlink" title="3.2 深入分析：API-Server 层面的争用"></a>3.2 深入分析：API-Server 层面的争用</h2><p>那么争用发生在哪里？进一步分析会发现，这两个组件在完成各自的操作后，都需要将结果（创建 Pod / 更新 Pod 状态）提交到 <strong>K8s API-Server</strong>，并由其完成后续的 etcd 写入等操作。当两者同时操作一个 Pod 对象时，就会触发 K8s 的乐观锁机制。一个组件的写请求会因为 <code>resourceVersion</code> 不匹配而失败，返回 <code>409 Conflict</code> 错误，进而必须重试。大量的并发、冲突与重试，最终在宏观上表现为“一个工作、另一个等待”的交替执行现象。<strong>真正的争用就发生在这里</strong>。</p><p>换言之，我们观察到的卡顿，是两大批对 K8s API-Server 的请求（<code>CREATE</code> 请求和 <code>SCHEDULE</code> 更新请求）排队与失败并重试导致的宏观表现。</p><h3 id="3-2-1-CREATE-请求流"><a href="#3-2-1-CREATE-请求流" class="headerlink" title="3.2.1 CREATE 请求流"></a>3.2.1 CREATE 请求流</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Controller 创建 Pod 的请求流</span></span><br><span class="line">JobController.syncJob() </span><br><span class="line">  → kubeClient.CoreV1().Pods().Create() </span><br><span class="line">    → kube-apiserver </span><br><span class="line">      → etcd write</span><br></pre></td></tr></table></figure></div><h3 id="3-2-2-SCHEDULE-请求流"><a href="#3-2-2-SCHEDULE-请求流" class="headerlink" title="3.2.2 SCHEDULE 请求流"></a>3.2.2 SCHEDULE 请求流</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Scheduler 调度 Pod 的请求流</span></span><br><span class="line">VolcanoScheduler.allocate() </span><br><span class="line">  → ssn.Bind() </span><br><span class="line">    → kubeClient.CoreV1().Pods().Update() </span><br><span class="line">      → kube-apiserver </span><br><span class="line">        → etcd write</span><br></pre></td></tr></table></figure></div><h2 id="3-3-排队与重试机制分析"><a href="#3-3-排队与重试机制分析" class="headerlink" title="3.3 排队与重试机制分析"></a>3.3 排队与重试机制分析</h2><p>那排队与重试为什么会导致如此泾渭分明的“交替卡顿”呢？这就需要结合我们在上一篇博客中分析的<strong>协程阻塞模型</strong>。</p><h3 id="3-3-1-Job-数量对请求模式的影响"><a href="#3-3-1-Job-数量对请求模式的影响" class="headerlink" title="3.3.1 Job 数量对请求模式的影响"></a>3.3.1 Job 数量对请求模式的影响</h3><p>仔细分析上述三种层次的现象，其间唯一的区别是 Job 数量。Job 数量多时，会导致：</p><ol><li><strong>请求碎片化</strong>：当 Job 数量多时，原本一次性的 10000 个 Pod <code>CREATE</code> 请求，被切割成了许多个小批次的请求段；</li><li><strong>争用与插队</strong>：在这些 <code>CREATE</code> 请求的小段之间，存在着时间空隙。Scheduler 发送的 <code>SCHEDULE</code>（Pod Update）请求就会“见缝插针”，填满这些空隙。这就导致了 API-Server 的请求队列中，呈现出一段 <code>CREATE</code>、一段 <code>SCHEDULE</code> 交替进行的局面。当 <code>SCHEDULE</code> 请求占据队列时，<code>CREATE</code> 请求就会排队阻塞，反之亦然。</li></ol><p>因此，在不同 Job 数量下会有不同的请求模式</p><p><strong>Job 数量少时</strong>：</p><ul><li>所有 Pod 的 <code>CREATE</code> 请求（共 10K）可以在很短时间内同时被发送到 API-Server</li><li>由于 <code>SCHEDULE</code> 需要的时间比 <code>CREATE</code> 更多，因此后续 <code>SCHEDULE</code> 请求陆陆续续被发送到 API-Server 时 <code>CREATE</code> 已经几乎完成</li><li>不会产生二者间的争用</li></ul><p><strong>Job 数量多时</strong>：</p><ul><li>Pod 的 <code>CREATE</code> 请求断断续续被发送到 API-Server</li><li>此后 <code>SCHEDULE</code> 请求也陆陆续续被发送到 API-Server</li><li>由于 Pod 的多批 <code>CREATE</code> 请求间存在时间空隙，导致出现某些时刻 <code>SCHEDULE</code> 占满而使得 <code>CREATE</code> 排队阻塞</li></ul><h3 id="3-3-2-协程阻塞的放大效应"><a href="#3-3-2-协程阻塞的放大效应" class="headerlink" title="3.3.2 协程阻塞的放大效应"></a>3.3.2 协程阻塞的放大效应</h3><p>简单回顾一下：</p><blockquote><p>Controller 是以 Job 为粒度进行处理的，一个 worker 协程会等待一个 Job 内的所有 Pod 创建完成后，才会开始处理下一个 Job。</p></blockquote><p>在此过程中，由于 Controller 每个协程会等待一个 Job 完成后再进行下一个 Job 的处理，因此一旦一个 Job 中某些 Pod 被阻塞，就会产生放大效应导致整个协程阻塞，使得阻塞现象更加严重。</p><p>而一系列同属一个 Job 的 Pod 资源变更后将会对同一个 PodGroup 甚至 Job 进行资源更新，导致 <code>409 Conflict</code> 错误也会在一段时间内连续出现，使得表现出“突停”现象。</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller_actions.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *jobcontroller)</span></span> syncJob(jobInfo *apis.JobInfo, updateStatus state.UpdateStatusFn) <span class="type">error</span> {</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    waitCreationGroup := sync.WaitGroup{}</span><br><span class="line">    <span class="comment">// 收集所有需要创建的 Pod</span></span><br><span class="line">    <span class="keyword">for</span> _, ts := <span class="keyword">range</span> job.Spec.Tasks {</span><br><span class="line">        <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="type">int</span>(ts.Replicas); i++ {</span><br><span class="line">            <span class="comment">// ...</span></span><br><span class="line">            waitCreationGroup.Add(<span class="number">1</span>)</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 并发创建 Pod</span></span><br><span class="line">    <span class="keyword">for</span> taskName, podToCreateEachTask := <span class="keyword">range</span> podToCreate {</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(taskName <span class="type">string</span>, podToCreateEachTask []*v1.Pod)</span></span> {</span><br><span class="line">            <span class="keyword">for</span> _, pod := <span class="keyword">range</span> podToCreateEachTask {</span><br><span class="line">                <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(pod *v1.Pod)</span></span> {</span><br><span class="line">                    <span class="keyword">defer</span> waitCreationGroup.Done()</span><br><span class="line">                    <span class="comment">// API-Server 调用</span></span><br><span class="line">                    newPod, err := cc.kubeClient.CoreV1().Pods(pod.Namespace).Create(context.TODO(), pod, metav1.CreateOptions{})</span><br><span class="line">                }(pod)</span><br><span class="line">            }</span><br><span class="line">        }(taskName, podToCreateEachTask)</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ⚠️ 关键阻塞点：等待所有 Pod 创建完成</span></span><br><span class="line">    waitCreationGroup.Wait()</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h2 id="3-4-CREATE-本身成为瓶颈的情况"><a href="#3-4-CREATE-本身成为瓶颈的情况" class="headerlink" title="3.4 CREATE 本身成为瓶颈的情况"></a>3.4 CREATE 本身成为瓶颈的情况</h2><p>此外还有一个因素，随着 Job 数量变多，<code>CREATE</code> 过程中 Controller 用于处理 Job 的计算量越来越大，速度也会变得越来越慢并成为瓶颈，这种情况下则无需争用分析，<code>CREATE</code> 本身就是瓶颈，对应上述benchmark-1（10K×1）。</p><h2 id="3-5-小结"><a href="#3-5-小结" class="headerlink" title="3.5 小结"></a>3.5 小结</h2><p>目前根据 “关键发现： <code>CREATE</code> 和 <code>SCHEDULE</code> 不会同时卡顿” 推断 vc-controller-manager 和 vc-scheduler 之间存在某种类型资源的争用，但暂未有更直接的证据，后续还将进一步分析。</p><p>但在此之外，有一个更根本的问题值得我们继续思考：“卡顿”问题如果能够被解决（即 <code>CREATE</code> 效率更高、不会“阻塞” <code>SCHEDULE</code>），整体效率就能更高吗？从后续实验会发现，并不一定。</p><h1 id="4️⃣-协程数优化实验：反直觉的结果"><a href="#4️⃣-协程数优化实验：反直觉的结果" class="headerlink" title="4️⃣ 协程数优化实验：反直觉的结果"></a>4️⃣ 协程数优化实验：反直觉的结果</h1><p>前期我们猜想协程数<code>--worker-threads</code> 是很重要的参数，并且猜想协程越多越能够并行、效率越高，但实验发现并非如此。</p><ol><li>“协程数” 与 “<code>CREATE</code> 效率” 非线性相关关系，也就是不是“协程越多越好”。</li><li>“<code>CREATE</code> 效率” 与 “整体效率” 非线性相关关系，也就是不是“<code>CERATE</code> 效率越快越好”。</li></ol><h2 id="4-1-实验设计"><a href="#4-1-实验设计" class="headerlink" title="4.1 实验设计"></a>4.1 实验设计</h2><p><strong>实验环境说明</strong>：</p><ul><li>协程数分别为：1、5、10、25、50、100、150、200、400、600</li><li>Job 和 Pod 组合分别为：10000×1、5000×2、2000×5、1000×10、500×20、200×50、100×100、50×200、20×500、1×10000</li><li>统计从测试开始到最后一个 <code>CREATE</code> 和 <code>SCHEDULE</code> 完成时间</li><li>计划每种配置下都重复执行 3 次，但由于时间问题目前某些配置还只有 2 或 1 次</li></ul><h2 id="4-2-实验结果分析"><a href="#4-2-实验结果分析" class="headerlink" title="4.2 实验结果分析"></a>4.2 实验结果分析</h2><p>实验得出了两个关键结论：</p><ul><li>在相同协程数下，随着 Job 数的增加，<code>CREATE</code> 用时整体提高。</li><li>在相同 Job 数下，随着 Controller 协程的增加，<code>CREATE</code> 用时呈现出明显的类似 <strong>“V”字型</strong>：先下降，后提高。</li></ul><h3 id="4-2-1-相同协程数下，Job-数增加的影响"><a href="#4-2-1-相同协程数下，Job-数增加的影响" class="headerlink" title="4.2.1 相同协程数下，Job 数增加的影响"></a>4.2.1 相同协程数下，Job 数增加的影响</h3><p>在相同协程数下，随着 Job 数的增加，<code>CREATE</code> 用时整体提高。这验证了我们前面的分析：</p><ol><li>Job 数量越多，Controller 用于处理 Job 的计算量越来越大</li><li>Job 数量越多，<code>CREATE</code> 请求被切割得越细，与 <code>SCHEDULE</code> 请求的争用越严重。</li></ol><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/5-more-worker-threads/summary/scale_performance_trends.png?raw=true" alt="在相同协程数下，不同 Job 数结果"><figcaption>在相同协程数下，不同 Job 数结果</figcaption></figure></p><h3 id="4-2-2-相同-Job-数下，协程数增加的影响"><a href="#4-2-2-相同-Job-数下，协程数增加的影响" class="headerlink" title="4.2.2 相同 Job 数下，协程数增加的影响"></a>4.2.2 相同 Job 数下，协程数增加的影响</h3><p>在相同 Job 数下，随着 Controller 协程的增加，<code>CREATE</code> 用时先下降后提高（类似 V 字型）。</p><p><strong>用时“先下降”（V 型左侧）的原因</strong>：</p><ul><li>协程数过少时，瓶颈在 API-Server 通信和远程 etcd 的 IO</li><li>计算资源未被充分利用，少量协程快速完成计算后发送 <code>CREATE</code> 请求、此后协程阻塞</li><li>此时协程数增加可以充分利用计算资源，消除等待通信/IO 的气泡时间</li></ul><p><strong>用时“后提高”（V 型右侧）的原因</strong>：</p><ul><li>协程数过多时，瓶颈在计算资源本身 + 加剧跨 Job 的 Pod 排队阻塞</li><li>大量协程已充分利用所有计算资源，此时跨 Job 的 Pod 排队竞争且公平地依次创建</li><li>一个 Job 内最后几个 Pod 阻塞整个 Job，导致突变情况更为严重</li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/5-more-worker-threads/summary/worker_threads_trends.png?raw=true" alt="在相同 Job 数下，不同协程数结果"><figcaption>在相同 Job 数下，不同协程数结果</figcaption></figure></p><h2 id="4-3-实验结论"><a href="#4-3-实验结论" class="headerlink" title="4.3 实验结论"></a>4.3 实验结论</h2><p>协程数优化存在一个<strong>最优值</strong>，既不能太少（无法充分利用计算资源），也不能太多（加剧 API-Server 争用）。这个最优值需要根据具体的 Job 数量和 Pod 数量来动态调整。</p><h1 id="5️⃣-解决思路：从争用角度思考"><a href="#5️⃣-解决思路：从争用角度思考" class="headerlink" title="5️⃣ 解决思路：从争用角度思考"></a>5️⃣ 解决思路：从争用角度思考</h1><h2 id="5-1-问题本质重新认识"><a href="#5-1-问题本质重新认识" class="headerlink" title="5.1 问题本质重新认识"></a>5.1 问题本质重新认识</h2><p>基于以上分析我们会发现，减小卡顿其实并不是”治本”。<br>即使我们通过调优让 <code>CREATE</code> 阶段飞速完成，这些 Pod 依然要等待缓慢的 <code>SCHEDULE</code> 阶段，总时间相差无几，甚至可能因为前期资源占用过猛而变得更长。（例如下图<code>100x100</code>、<code>500x20</code>，调整协程后 <code>CREATE</code> 更快完成，但<code>SCHEDULE</code>完成时间反而更长）</p><ul><li>从全局最优的角度看，<strong>让 <code>CREATE</code> 和 <code>SCHEDULE</code> 的速率接近，实现一种动态平衡，可能是更好的选择</strong>。</li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/5-more-worker-threads/summary/create_vs_schedule_comparison.png?raw=true" alt="在相同 Job 数下，不同协程数结果2"><figcaption>在相同 Job 数下，不同协程数结果2</figcaption></figure></p><h2 id="5-2-根本解决方案"><a href="#5-2-根本解决方案" class="headerlink" title="5.2 根本解决方案"></a>5.2 根本解决方案</h2><p>如果想要彻底解决这个问题，可能需要对 Volcano 的整个架构进行比较大的修改，实现 <code>CREATE</code> 和 <code>SCHEDULE</code> 的合理配比、速率接近。可能需要：</p><ol><li><strong>调整 API-Server 的策略</strong>：实现更智能的请求排队和优先级机制</li><li><strong>调整 Controller 和 Scheduler 之间的联动速率调整</strong>：实现动态的速率匹配</li><li><strong>引入异步处理机制</strong>：将同步的批处理改为异步处理</li></ol><h2 id="5-3-短期优化方案"><a href="#5-3-短期优化方案" class="headerlink" title="5.3 短期优化方案"></a>5.3 短期优化方案</h2><p>在有限时间内，可以考虑以下优化方向：（囊括前期总结的几项内容）</p><ol><li><strong>调整协程数</strong>：根据 Job 数量和 Pod 数量动态调整最优协程数</li><li><strong>设置合适的 webhook timeout</strong>：避免超时导致的请求重试和性能下降</li><li><strong>优化 webhook 效率</strong>：参考 <a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="前面的分析">前面的分析</a>，将必要的校验功能转移到 Controller 或 K8s CRD（使用 CEL） 中。</li></ol><h1 id="6️⃣-小结"><a href="#6️⃣-小结" class="headerlink" title="6️⃣ 小结"></a>6️⃣ 小结</h1><p>截至目前，我们已经分析了几项特定的结论，并提出了一些解决方案（解决方案如上所述）。</p><p>【结论】</p><ol><li>Job数量对性能影响极大，Jobs数量越多性能越差。</li><li>Jobs多时，CREATE/SCHEDULE 存在“卡顿”现象。但卡顿只是表象，本质很可能是资源争用导致的轮替；除此之外，不一定要把卡顿消除、而是应该让CREATE和SCHEDULE的卡顿速率保持一致。</li><li>除此之外，webhook本身对性能的影响仍然比较大，需要优化。</li></ol><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://github.com/volcano-sh/volcano">[1] Volcano GitHub 仓库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://volcano.sh/zh/">[2] Volcano 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/">[3] Kubernetes API Server 设计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/architecture/controller/">[4] Kubernetes 控制器模式<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://volcano.sh/zh/docs/actions/">[5] Volcano 调度器 Actions<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/kube-scheduler/">[6] Kubernetes 调度器<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://volcano.sh/zh/docs/architecture/">[7] Volcano 架构设计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/">[8] Kubernetes Webhook 机制<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">基于大量实验数据和源码分析，重新梳理Volcano中CREATE和SCHEDULE卡顿现象的根本原因：两大批对K8s API-Server的请求排队导致的争用，而非简单的协程数不足问题。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="Kubernetes" scheme="https://freshwlnd.github.io/tags/Kubernetes/"/>
    
    <category term="调度器" scheme="https://freshwlnd.github.io/tags/%E8%B0%83%E5%BA%A6%E5%99%A8/"/>
    
    <category term="性能优化" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    
    <category term="Volcano" scheme="https://freshwlnd.github.io/tags/Volcano/"/>
    
    <category term="批处理" scheme="https://freshwlnd.github.io/tags/%E6%89%B9%E5%A4%84%E7%90%86/"/>
    
    <category term="API-Server" scheme="https://freshwlnd.github.io/tags/API-Server/"/>
    
    <category term="争用分析" scheme="https://freshwlnd.github.io/tags/%E4%BA%89%E7%94%A8%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>【AI】AI-Infra框架初识：从vLLM到SGLang、Aibrix与Mooncake的性能革命</title>
    <link href="https://freshwlnd.github.io/2025/09/03/ai/ai-infra-frameworks-introduction/"/>
    <id>https://freshwlnd.github.io/2025/09/03/ai/ai-infra-frameworks-introduction/</id>
    <published>2025-09-03T06:44:55.000Z</published>
    <updated>2025-09-05T02:58:47.467Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景简介：为何需要AI-Infra框架？从大模型推理的痛点说起"><a href="#背景简介：为何需要AI-Infra框架？从大模型推理的痛点说起" class="headerlink" title="背景简介：为何需要AI-Infra框架？从大模型推理的痛点说起"></a>背景简介：<strong>为何需要AI-Infra框架？从大模型推理的痛点说起</strong></h1><p>大语言模型（LLM）的兴起使其从科研领域走向了实际应用。这些强大的模型在实际部署和应用中，需要专门的“AI基础设施框架”（AI-Infra）来保障其高效、稳定地运行。这些框架是LLM从研究走向工业级应用的关键。</p><blockquote><p>上个月sglang-v0.3.0和vllm-v0.6.0前后脚发布之后（注：该文章发布时间为2024.10），就一直想总结梳理一下现在主流的大模型推理引擎。因为我觉得这也算是一个有意义的节点吧，从此开源大模型推理引擎总算是由”非常粗糙，但是能用”的阶段迈入到了”好用，稍微有那么点粗糙”的阶段。</p><p>大模型的推理引擎实际也就是近一两年才开始飞速发展，从最开始的tgi和vllm并驾齐驱到如今sglang、lmdeply的异军突起，整个开源社区都是非常有活力的。</p><p>但是正如之前所说，从长远的一个视角看如今的开源引擎实际上都还是比较粗糙的，大家都是在摸索中前进。另一方面也是因为现在全世界的目光都聚焦在llm这里，新技术的更新换代太快了，做好一个大模型的推理引擎要做的事情实在是太太太太多了。除了要支持日新月异的<strong>新模型和新硬件</strong>，还要不断关心学术界最新的paper并且想方设法落地实现。而这些新的想法可能涉及到<strong>模型结构、计算策略、调度策略、存储策略、cuda内核、硬件加速</strong>等各个层级，这就需要开发者有非常广泛的知识范围和过硬的工程能力。</p><p>我一直认为大模型推理引擎最难的地方就在于：对模型和硬件的广泛支持以及如何将各种角度的不同优化方法兼容实现。因为写paper的人可以只关心他自己的idea，在transformer库的基础上写个简单demo就行，但是在推理引擎里落地的时候往往就会与其它模块有冲突，需要想办法去做各种兼容。退一步说，即使没有冲突的情况，你也需要对其他基础的优化比较熟悉，你才能在这些的基础上完成新功能的开发。</p><p>——开源大模型推理引擎现状及常见推理优化方法 - 齐夏的文章 - 知乎 <a class="link"   href="https://zhuanlan.zhihu.com/p/755874470" >https://zhuanlan.zhihu.com/p/755874470<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p></blockquote><p>在AI-Infra框架出现之前，大语言模型的实际部署和应用，尤其是推理环节，面临着一系列严峻的挑战。这些挑战不仅关乎性能，也关乎成本和效率，它们是催生AI-Infra框架的根本原因。</p><h2 id="1-1-GPU显存挑战：显存占用与内存碎片化"><a href="#1-1-GPU显存挑战：显存占用与内存碎片化" class="headerlink" title="1.1 GPU显存挑战：显存占用与内存碎片化"></a><strong>1.1 GPU显存挑战：显存占用与内存碎片化</strong></h2><p>大语言模型的核心是Transformer架构，其推理过程大致分为两个阶段：预填充（Prefill）和解码（Decode）。在解码阶段，模型需要逐个生成新的词元（token），而每一次生成，都需要访问前面所有词元的“键值缓存”（KV Cache），这部分数据占据了大量的GPU显存<a href="#refer-anchor-1"><sup>[1]</sup></a>。随着模型规模和用户请求数量的增加，GPU的显存常常爆满<a href="#refer-anchor-1"><sup>[1]</sup></a>。</p><p>更棘手的问题是内存碎片化。传统的推理方法在为每个用户会话分配KV Cache时，会预留一个连续的、固定的内存块。然而，用户请求的文本长度是动态的，当会话结束或内容比预分配的短时，就会产生大量无法被其他请求利用的零散显存碎片。这导致了显存资源的巨大浪费，严重影响了GPU的利用率。</p><h2 id="1-2-吞吐量挑战：处理大规模并发请求的挑战"><a href="#1-2-吞吐量挑战：处理大规模并发请求的挑战" class="headerlink" title="1.2 吞吐量挑战：处理大规模并发请求的挑战"></a><strong>1.2 吞吐量挑战：处理大规模并发请求的挑战</strong></h2><p>除了显存问题，另一个核心挑战是吞吐量瓶颈，即单位时间内能够处理的请求数量。传统的推理架构在处理并发请求时效率低下。例如，串行批处理（static batching）会等待一组请求全部完成输入后，再一起进行推理计算。如果批处理中的某个请求很长，其他所有请求都必须等待它完成，这导致了GPU计算资源在大部分时间内处于闲置状态，整体吞吐量无法有效提升<a href="#refer-anchor-1"><sup>[2]</sup></a>。</p><p>此外，传统的无状态推理架构在处理LLM应用时面临性能瓶颈：每次请求被随机路由到不同的计算实例，导致KV Cache无法有效复用、多轮对话上下文频繁重建、系统提示词重复处理，这严重影响了用户体验和系统效率<a href="#refer-anchor-1"><sup>[3]</sup></a>。这表明，通用的云计算架构在LLM这种特定工作负载面前，不再是最优解。</p><h2 id="1-3-复杂应用场景挑战：从简单对话到程序化调用"><a href="#1-3-复杂应用场景挑战：从简单对话到程序化调用" class="headerlink" title="1.3 复杂应用场景挑战：从简单对话到程序化调用"></a><strong>1.3 复杂应用场景挑战：从简单对话到程序化调用</strong></h2><p>早期的大模型应用以简单的单轮对话为主。但随着应用的发展，LLM的使用方式变得更加复杂，例如LLM参与多轮规划、推理以及与外部环境的交互等场景<a href="#refer-anchor-1"><sup>[4]</sup></a>。这些新的使用模式不再是简单的单轮对话形式，而是需要包含多个LLM调用，这些调用之间穿插着控制流，并且需要接收和产生结构化的输入和输出（比如JSON格式）<a href="#refer-anchor-1"><sup>[4]</sup></a>。</p><p>传统的推理引擎主要针对单次、无状态的推理进行优化，难以高效地处理这种复杂的“程序化调用”（LM Programs）范式。开发者必须在外部手动管理状态、编排调用顺序，这不仅繁琐，而且难以实现端到端的性能优化<a href="#refer-anchor-1"><sup>[4]</sup></a>。</p><h1 id="脉络梳理：AI-Infra框架的演进脉络与核心解法"><a href="#脉络梳理：AI-Infra框架的演进脉络与核心解法" class="headerlink" title="脉络梳理：AI-Infra框架的演进脉络与核心解法"></a>脉络梳理：<strong>AI-Infra框架的演进脉络与核心解法</strong></h1><p>针对前面提到的三大痛点，AI-Infra框架领域出现了一系列解决方案。</p><h2 id="2-1-vLLM：内存管理上的创新"><a href="#2-1-vLLM：内存管理上的创新" class="headerlink" title="2.1 vLLM：内存管理上的创新"></a><strong>2.1 vLLM：内存管理上的创新</strong></h2><blockquote><p>vllm原本只是作为PagedAttention的一个开源实现，但发展到今天已经成为llm推理引擎的标杆了。</p></blockquote><p>vLLM是AI-Infra框架中一个代表性的框架<a href="#refer-anchor-1"><sup>[5]</sup></a>，团队来自UC Berkeley。</p><ul><li><p><strong>技术：</strong>&#x5B83;率先对底层推理效率进行了优化。vLLM的核心贡献在于其独创的  <strong>PagedAttention</strong>技术，这一技术旨在高效管理注意力键和值的内存<a href="#refer-anchor-1"><sup>[6]</sup></a>。vLLM将KV Cache分割成多个离散的“块”（block），这些“块”可以根据需要动态地分配和管理。通过这种方式，vLLM解决了KV Cache显存碎片化的问题，显著提高了显存的利用率，使得GPU能够同时处理更多的并发请求，从而大幅提升了整体吞吐量<a href="#refer-anchor-1"><sup>[6]</sup></a>。</p></li><li><p><strong>优势：</strong>&#x76;LLM有着大量且稳定的开发者，Github上Contributors已经1500+人了，相比于SGLang的663人、Aibrix的75人、TensorRT的79人、Mooncake的84人，vLLM的开发人员投入是最高的。因此vLLM对模型的支持和对硬件的支持都是最完善的，以及各种功能也往往是最齐全的。<a href="#refer-anchor-1"><sup>[14]</sup></a></p></li></ul><p>vLLM的出现，让大模型的在线服务效率达到了一个全新的高度，也为后续的框架发展奠定了基础<a href="#refer-anchor-1"><sup>[7]</sup></a>。目前，vLLM的社区活跃度是最高的，github上issue和pr都很多，且大量paper都是以vLLM作为baseline来开发demo。</p><h2 id="2-2-SGLang：面向复杂应用场景的编程范式"><a href="#2-2-SGLang：面向复杂应用场景的编程范式" class="headerlink" title="2.2 SGLang：面向复杂应用场景的编程范式"></a><strong>2.2 SGLang：面向复杂应用场景的编程范式</strong></h2><p>SGLang也来自UC Berkeley，但是跟vLLM是不同的一拨人，核心团队基本都是交大的<a href="#refer-anchor-1"><sup>[14]</sup></a>（另有说法为：很多人都是vLLM的作者<a href="#refer-anchor-1"><sup>[4]</sup></a>）。</p><p>当vLLM解决了底层的显存和吞吐量问题后，SGLang将关注点提升到了更高层面的应用场景<a href="#refer-anchor-1"><sup>[4]</sup></a>。它专注于解决前文提到的“复杂应用场景：程序化调用”挑战，即如何让开发者能够像编写传统软件一样，编排复杂的LLM应用逻辑<a href="#refer-anchor-1"><sup>[4]</sup></a>。</p><ul><li><p><strong>技术：</strong>&#x53;GLang的核心思想是采用一种<strong>编译器设计</strong>的理念。它引入了一个“前端语言”和“后端运行时”协同设计的模式，允许开发者在框架内直接编写多步LLM调用和控制流，例如循环和条件判断<a href="#refer-anchor-1"><sup>[8]</sup></a>。这使得LLM能够更高效地处理工具使用、多轮推理和结构化生成等任务<a href="#refer-anchor-1"><sup>[8]</sup></a>。SGLang的这种设计，可以从根本上优化多对多的输入输出，并进行端到端的性能优化<a href="#refer-anchor-1"><sup>[4]</sup></a>。SGLang通过其RadixAttention技术，实现了对KV Cache的高效复用<a href="#refer-anchor-1"><sup>[8]</sup></a>。</p></li><li><p><strong>优势：</strong>&#x53;GLang的代码可拓展性很高，主流功能都有支持的情况下，代码比vLLM清晰简单很多，这对于二次开发来说是很重要的。社区活跃度虽然比不上vLLM，但是作者都很积极地回复issue。<a href="#refer-anchor-1"><sup>[14]</sup></a></p></li></ul><p>SGLang的出现，标志着AI-Infra框架开始从单纯的“性能优化”走向“应用范式创新”，它让LLM成为了一个可以被深度集成到复杂软件系统中的“计算单元”<a href="#refer-anchor-1"><sup>[4]</sup></a>。</p><h2 id="2-3-Aibrix与Mooncake：面向大规模部署的系统级创新"><a href="#2-3-Aibrix与Mooncake：面向大规模部署的系统级创新" class="headerlink" title="2.3 Aibrix与Mooncake：面向大规模部署的系统级创新"></a><strong>2.3 Aibrix与Mooncake：面向大规模部署的系统级创新</strong></h2><p>当LLM的应用从单机走向大规模集群部署时，新的挑战随之出现。vLLM和SGLang主要解决了单机或少量GPU环境下的效率问题，但面对大规模集群，就需要新的系统级解决方案。Aibrix和Mooncake的出现正是为了解决这一问题，它们将关注点从“引擎内部”转移到了“集群系统层面”<a href="#refer-anchor-1"><sup>[10]</sup></a>。</p><p><strong>Aibrix（来自字节跳动）</strong>&#x662F;一个云原生的开源框架，其核心使命是简化和优化大规模LLM在云环境中的部署<a href="#refer-anchor-1"><sup>[11]</sup></a>。它并非一个全新的推理引擎，而是一个协同vLLM等引擎运行的“控制平面”（Control Plane）<a href="#refer-anchor-1"><sup>[5]</sup></a>。Aibrix负责集群层面的资源调度、自适应扩缩容、负载均衡以及智能路由等任务<a href="#refer-anchor-1"><sup>[11]</sup></a>。根据一项实验数据，Aibrix的扩缩容响应时间可加速82%<a href="#refer-anchor-1"><sup>[5]</sup></a>。此外，Aibrix还引入了针对低秩适配（LoRA）模型的高密度管理，支持动态调度和加载LoRA适配器<a href="#refer-anchor-1"><sup>[11]</sup></a>。</p><p><strong>Mooncake（为Kimi服务的平台，由MoonshotAI提供，论文获FAST’25最佳论文奖）</strong>&#x5219;是一个专门为LLM推理场景设计的<strong>分布式KV Cache存储系统</strong><a href="#refer-anchor-1"><sup>[10]</sup></a>。它解决了在集群环境中，KV Cache无法在不同计算节点之间高效共享和复用的问题。Mooncake的核心是其“全局缓存+分离式推理架构”（KVCache-centric disaggregated architecture），它将预填充和解码的计算集群与KV Cache的存储集群分离<a href="#refer-anchor-1"><sup>[12]</sup></a>。通过聚合集群中未被充分利用的CPU、DRAM甚至SSD资源，Mooncake形成了一个统一的分布式内存池，供所有节点共享KV Cache<a href="#refer-anchor-1"><sup>[10]</sup></a>。这种设计使得计算资源可以根据负载动态增减，而KV Cache则可以在独立的存储池中持久化，并被所有节点复用，这对于长上下文、多轮对话场景尤其重要，能显著提升吞吐量和资源利用率<a href="#refer-anchor-1"><sup>[12]</sup></a>。</p><p>Aibrix和Mooncake的出现，反映了LLM应用已经进入大规模工业化生产阶段，关注点从单纯的性能，扩展到了成本、可扩展性和服务质量。</p><p><figure class="image-caption"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://pic1.zhimg.com/v2-9c4fc47e5c35538026efc1d247d5ea4c_1440w.jpg"                      alt="图1：Airbrix"                ><figcaption>图1：Airbrix</figcaption></figure></p><p><figure class="image-caption"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://pic2.zhimg.com/v2-6b57ab25c4f74cabe76ce186d7f630a9_1440w.jpg"                      alt="图2：Mooncake"                ><figcaption>图2：Mooncake</figcaption></figure></p><h1 id="框架横向对比：各自的定位与优劣"><a href="#框架横向对比：各自的定位与优劣" class="headerlink" title="框架横向对比：各自的定位与优劣"></a><strong>框架横向对比：各自的定位与优劣</strong></h1><p>通过以上分析，我们可以看到AI-Infra框架的主要生态系统。为了更清晰地理解它们的定位和特点，本节将通过表格形式对几个主要框架进行对比。同时，我们还引入一个来自硬件厂商的代表——NVIDIA的TensorRT-LLM，来展示不同的技术路径。</p><h2 id="主流AI-Infra框架能力对比"><a href="#主流AI-Infra框架能力对比" class="headerlink" title="主流AI-Infra框架能力对比"></a><strong>主流AI-Infra框架能力对比</strong></h2><table><thead><tr><th><strong>框架名称</strong></th><th><strong>核心解决问题</strong></th><th><strong>关键技术</strong></th><th><strong>典型应用场景</strong></th><th><strong>优点</strong></th><th><strong>局限性</strong></th></tr></thead><tbody><tr><td><strong>vLLM</strong></td><td>单机显存管理</td><td>PagedAttention，连续批处理</td><td>高性能API服务，单机部署</td><td>吞吐量高，易用性强，社区活跃<a href="#refer-anchor-1"><sup>[6]</sup></a></td><td>主要为单机引擎，集群扩展能力有限</td></tr><tr><td><strong>SGLang</strong></td><td>复杂应用编程与结构化生成</td><td>编译器设计，RadixAttention</td><td>复杂Agent，工具调用，多轮对话</td><td>支持复杂逻辑编排，编程范式友好<a href="#refer-anchor-1"><sup>[8]</sup></a></td><td>相对vLLM，底层性能优化空间可能略小</td></tr><tr><td><strong>Aibrix</strong></td><td>大规模集群资源管理与扩展</td><td>LLM专用自适应扩缩容，高效LoRA管理</td><td>大规模企业级生产环境部署</td><td>系统级优化，弹性高，降低成本<a href="#refer-anchor-1"><sup>[5]</sup></a></td><td>非核心推理引擎，需与vLLM等配合使用<a href="#refer-anchor-1"><sup>[5]</sup></a></td></tr><tr><td><strong>Mooncake</strong></td><td>分布式KV Cache与长上下文</td><td>KVCache分离式架构</td><td>长上下文场景，多机KV Cache共享</td><td>高效利用集群资源，支持超长上下文<a href="#refer-anchor-1"><sup>[12]</sup></a></td><td>纯缓存系统，需与引擎配合使用<a href="#refer-anchor-1"><sup>[10]</sup></a></td></tr><tr><td><strong>TensorRT-LLM</strong></td><td>极致单机性能与低延迟</td><td>量化，层/张量融合，CUDA内核优化</td><td>实时交互应用，边缘设备部署</td><td>性能高，延迟低，针对NVIDIA硬件深度优化<a href="#refer-anchor-1"><sup>[13]</sup></a></td><td>强硬件（NVIDIA）依赖性，通用性差<a href="#refer-anchor-1"><sup>[13]</sup></a></td></tr></tbody></table><p>从上表可以看出，这些框架并非相互替代，而是在不同层级上进行互补。</p><ul><li><p>vLLM和SGLang是“引擎层”的框架，专注于模型执行效率和应用逻辑；</p></li><li><p>而Aibrix和Mooncake则是“系统层”的框架，专注于集群管理和资源调度；</p></li><li><p>TensorRT-LLM则代表了一种由硬件厂商主导的、从底层进行优化的路径，它通过对NVIDIA硬件的深度适配，实现了超高的性能，但代价是牺牲了通用性和跨硬件的兼容性<a href="#refer-anchor-1"><sup>[13]</sup></a>。</p></li></ul><p>这种分层发展的趋势，反映了AI-Infra领域发展的成熟度。当底层引擎的性能问题得到解决后，开发者们会将目光投向更高层面的应用编程和大规模部署，而这些新挑战又催生了新一轮的框架创新。</p><hr><hr><ul><li>希望这篇博客对你了解AI-Infra框架有所帮助！如果你有任何问题或需要进一步的讨论，欢迎随时交流。</li><li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="🗺️参考文献"><a href="#🗺️参考文献" class="headerlink" title="🗺️参考文献"></a>🗺️参考文献</h1><div id="refer-anchor-1"></div><p><a class="link"   href="https://ppio.com/blogs/post/da-mo-xing-tui-li-cheng-ben-mei-nian-jiang-di-10bei-de-mi-mi-yi-wen-liao-jie-vllm-sglangdeng-zhu-liu-tui-li-yin-qing" >[1] 大模型推理成本每年降低10倍的秘密：一文了解vLLM、SGLang等主流推理引擎 - PPIO<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://blog.csdn.net/lqfarmer/article/details/140906949" >[2] 从vLLM到大模型推理的最新进展_vllm复现-CSDN博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://aws.amazon.com/cn/blogs/china/accelerating-inference-on-llm-with-amazon-sagemaker-sticky-sessions/" >[3] 利用Amazon SageMaker Sticky Session 实现大语言模型推理加速 | 亚马逊AWS官方博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://aijishu.com/a/1060000000476318" >[4] SGLang：LLM推理引擎发展新方向- 极术社区- 连接开发者与智能计算 …<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://www.infoq.cn/article/ncbudc3vvp8kignttiof" >[5] 字节跳动开源AIBrix：填补云原生大模型推理“系统层”空白 - InfoQ<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://vllm.hyper.ai/docs/" >[6] 欢迎来到vLLM！ | vLLM 中文站<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://www.high-flyer.cn/blog/continuous-batching/" >[7] Continuous Batching：一种提升LLM 部署吞吐量的利器 - 幻方<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://blog.csdn.net/2401_85280106/article/details/147835433" >[8] 学习笔记：主流大模型框架对比分析（Ollama、vLLM、SGlang …,  <i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://qwen.readthedocs.io/zh-cn/latest/deployment/sglang.html" >[9] SGLang - Qwen - Read the Docs<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://docs.lmcache.ai/kv_cache/mooncake.html" >[10] Mooncake | LMCache<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://arxiv.org/html/2504.03648v1" >[11] AIBrix: Towards Scalable, Cost-Effective Large Language Model Inference Infrastructure<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://github.com/kvcache-ai/Mooncake" >[12] Mooncake is the serving platform for Kimi, a leading LLM service provided by Moonshot AI. - GitHub<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://developer.nvidia.cn/tensorrt" >[13] NVIDIA TensorRT - NVIDIA 开发者<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://zhuanlan.zhihu.com/p/755874470" >[14] 2024年-开源大模型推理引擎现状及常见推理优化方法 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://aibrix.readthedocs.io/latest/community/research.html" >[15] Research Collaboration - AIBrix - Read the Docs<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://doi.org/10.1145/3600006.3613165" >[16] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient Memory Management for Large Language Model Serving with PagedAttention. In Proceedings of the 29th Symposium on Operating Systems Principles (SOSP ‘23). Association for Computing Machinery, New York, NY, USA, 611–626.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://zhuanlan.zhihu.com/p/27872556474" >[17] 【深度解读FAST’25最佳论文Mooncake】：存储为中心的大语言模型推理架构 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link"   href="https://zhuanlan.zhihu.com/p/25874756271" >[18] 字节跳动开源AIBrix：一个可扩展、经济高效的vLLM控制平面 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">介绍AI推理基础设施框架的发展历程</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="人工智能" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
    <category term="AI基础设施" scheme="https://freshwlnd.github.io/tags/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="推理优化" scheme="https://freshwlnd.github.io/tags/%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/"/>
    
    <category term="vLLM" scheme="https://freshwlnd.github.io/tags/vLLM/"/>
    
    <category term="SGLang" scheme="https://freshwlnd.github.io/tags/SGLang/"/>
    
  </entry>
  
  <entry>
    <title>【论文】略读笔记87-经典-vLLM</title>
    <link href="https://freshwlnd.github.io/2025/09/02/literature/literatureNotes87/"/>
    <id>https://freshwlnd.github.io/2025/09/02/literature/literatureNotes87/</id>
    <published>2025-09-02T03:29:58.000Z</published>
    <updated>2025-09-02T06:49:33.970Z</updated>
    
    <content type="html"><![CDATA[<h1 id="x1f4d6-《Efficient-Memory-Management-for-Large-Language-Model-Serving-with-PagedAttention》"><a href="#x1f4d6-《Efficient-Memory-Management-for-Large-Language-Model-Serving-with-PagedAttention》" class="headerlink" title="📖《Efficient Memory Management for Large Language Model Serving with PagedAttention》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Efficient Memory Management for Large Language Model Serving with PagedAttention》</h1><p>2023 年 UC Berkeley 大学、斯坦福大学、UC San Diego 大学团队 发表于 CCF-A 类会议 SOSP。</p><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul><li>高吞吐量服务大型语言模型（LLMs）需要同时批量处理足够多的请求。<ul><li>大型语言模型（LLMs）如 GPT 和 PaLM 的出现，使得编程助手和通用聊天机器人等新应用成为可能，这些应用正开始深刻影响我们的工作和日常生活。</li><li>许多云公司正在竞相提供这些作为托管服务。然而，运行这些应用非常昂贵，需要大量的硬件加速器，如GPU。根据最新的估计，处理LLM请求的成本可能比传统的关键词查询高10倍。</li><li>鉴于这些高昂的成本，提高LLM服务系统的吞吐量——从而降低每请求的成本——变得越来越重要。</li></ul></li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05/1-Figure1-1.png" alt="图1：左侧：在NVIDIA A100上为具有130亿参数的LLM提供服务时的内存布局。参数（灰色）在整个服务过程中持续存在于GPU内存中。KV缓存内存（红色）根据服务请求进行（分配）和（释放）。一小部分内存（黄色）用于暂时的激活。右侧：vLLM平滑了现有系统中观察到的KV缓存内存的快速增长曲线，从而显著提高了服务吞吐量。"><figcaption>图1：左侧：在NVIDIA A100上为具有130亿参数的LLM提供服务时的内存布局。参数（灰色）在整个服务过程中持续存在于GPU内存中。KV缓存内存（红色）根据服务请求进行（分配）和（释放）。一小部分内存（黄色）用于暂时的激活。右侧：vLLM平滑了现有系统中观察到的KV缓存内存的快速增长曲线，从而显著提高了服务吞吐量。</figcaption></figure></p><h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul><li>然而，现有系统存在困难，因为每个请求的关键值缓存（KV缓存）内存巨大，且动态增长和收缩。<ul><li>LLMs的核心是一个自回归Transformer模型。该模型根据输入（提示）和之前生成的输出token序列，逐个生成单词（token）。对于每个请求，这个过程会重复进行，直到模型输出终止token。这种顺序生成过程使得工作负载受<strong>内存限制</strong>，未能充分利用GPU的计算能力，限制了服务吞吐量。</li><li>通过将多个请求一起批处理，可以提高吞吐量。然而，为了批量处理许多请求，每个请求的内存空间应该得到有效管理。例如，<ul><li>图1（左）展示了在配备40GB RAM的NVIDIA A100 GPU上运行13B参数的LLM的内存分布。<ul><li>大约65%的内存分配给模型权重，在服务期间保持静态。</li><li>接近30%的内存用于存储请求的动态状态。对于Transformer，这些状态包括与注意力机制相关的键和值张量，通常称为KV缓存，它们代表从早期标记到生成新输出标记的上下文。</li><li>剩余的小部分内存用于其他数据，包括激活——在评估LLM时创建的短暂张量。</li></ul></li></ul></li></ul></li><li>当管理效率低下时，这种内存可能会因碎片化和冗余重复而造成显著浪费，限制批量大小。<ul><li>由于模型权重是恒定的，而激活只占用GPU内存的一小部分，因此KV缓存的内存管理方式对于确定最大批量大小至关重要。管理不当时，KV缓存内存可以显著限制批量大小，从而降低LLM的吞吐量，如图1（右）所示。</li><li>在这篇论文中，我们观察到现有的LLM服务系统在高效管理KV缓存内存方面存在不足。这主要是因为它们将请求的KV缓存<strong>存储在连续的内存空间中</strong>，因为大多数<strong>深度学习框架</strong>要求张量存储在连续的内存中。<ul><li>然而，与传统的深度学习工作负载中的张量不同，KV缓存具有独特的特性：随着时间的推移，随着模型生成新的tokens，它动态地增长和缩小，其生命周期和长度事先并不知道。这些特性使得现有系统的方法在两个方面都显著低效：<ul><li>首先，现有的系统存在<strong>内部和外部内存碎片化</strong>问题。<ul><li>为了在连续空间中存储请求的KV缓存，它们预先分配一个与请求最大长度连续的内存块（例如，2048个标记）。这可能导致严重的<strong>内部碎片化</strong>，因为请求的实际长度可能远短于其最大长度（例如，图11）。</li><li>此外，即使事先知道实际长度，预分配仍然效率低下：在整个请求生命周期中，整个块（chunk）被预留（reserved），其他较短的请求无法利用当前未使用的任何部分。</li><li>此外，<strong>外部内存碎片化</strong>也可能很大，因为预分配的大小对每个请求可能不同。</li><li>实际上，我们图2中的分析结果显示，在现有系统中，只有20.4% - 38.2%的KV缓存内存用于存储实际标记状态。</li></ul></li><li>其次，现有系统无法利用<strong>内存共享</strong>的机会。<ul><li>LLM服务通常使用先进的<strong>解码算法</strong>，如并行采样和束搜索（parallel sampling and beam search），每个请求生成多个输出。在这些场景中，请求（request）由多个序列（sequences）组成，这些序列可以部分共享它们的KV缓存。然而，由于序列的KV缓存存储在各自连续的空间中，现有系统中无法实现内存共享。</li></ul></li></ul></li></ul></li></ul></li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05/2-Figure2-1.png" alt="图2：第6.2节实验中不同LLM服务系统中内存浪费的平均百分比。"><figcaption>图2：第6.2节实验中不同LLM服务系统中内存浪费的平均百分比。</figcaption></figure></p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05/9-Figure11-1.png" alt="图11：输入和输出长度分布的（a）ShareGPT和（b）Alpaca数据集。"><figcaption>图11：输入和输出长度分布的（a）ShareGPT和（b）Alpaca数据集。</figcaption></figure></p><h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul><li><p>为了解决这个问题，我们提出了PagedAttention，这是一种受操作系统中的解决内存碎片化和共享方案（经典虚拟内存和分页）启发的注意力算法。</p><ul><li>PagedAttention将请求的KV缓存划分为块（blocks），每个块可以包含一定数量的标记的注意力键K和值V。</li><li>在PagedAttention中，KV缓存的块不一定存储在连续的空间中。因此，我们可以像操作系统中的虚拟内存一样以更灵活的方式管理KV缓存：可以将块视为页面，将tokens视为字节（bytes），将请求（requests）视为进程（processes）。这种设计通过使用相对较小的块并在需要时分配它们来缓解内部碎片。</li><li>此外，它消除了外部碎片，因为所有块的大小都相同。</li><li>最后，它允许在块粒度上实现内存共享，跨越与同一请求相关联的不同序列（sequences），甚至跨越不同的请求。</li></ul></li><li><p>在此基础上，我们构建了vLLM，一个基于PagedAttention的高吞吐量分布式LLM服务引擎，在KV缓存内存中实现了近乎零浪费。实现了（1）KV缓存内存接近零浪费和（2）在请求之间灵活共享KV缓存，以进一步减少内存使用。</p><ul><li>vLLM使用与PagedAttention协同设计的<strong>块级内存管理</strong>和<strong>抢占式请求调度</strong>。</li><li>vLLM支持各种大小的流行LLM，如GPT、OPT和LLaMA，包括超出单个GPU内存容量的那些LLM。</li></ul></li><li><p>总结来说，我们做出了以下贡献：</p><ul><li>• 我们确定了在为LLM提供服务中的内存分配挑战，并量化了它们对服务性能的影响。</li><li>• 我们提出了PagedAttention，这是一种在非连续分页内存中存储的KV缓存上运行的注意力算法，灵感来源于操作系统的虚拟内存和分页。</li><li>• 我们设计和实现了vLLM，这是一个基于PagedAttention的分布式LLM服务引擎。</li><li>• 我们在各种场景下评估了vLLM，并证明它在性能上显著优于之前的先进解决方案，如 FasterTransformer 和 Orca。</li></ul></li></ul><h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul><li>我们的评估表明，与最先进的系统（如FasterTransformer和Orca）相比，vLLM在相同延迟水平下将流行LLMs的吞吐量提高了2-4倍，而且完全没有影响模型精度。随着序列变长、模型变大和解码算法更复杂，这种改进更为明显。</li><li>vLLM的源代码在<a class="link" href="https://github.com/vllm-project/vllm%E4%B8%8A%E5%85%AC%E5%BC%80%E3%80%82">https://github.com/vllm-project/vllm上公开。<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li></ul><h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul><li>将虚拟内存和分页技术应用于<strong>其他GPU工作负载</strong>。<ul><li>虚拟内存和分页的想法对于管理LLM服务中的KV缓存是有效的，因为工作负载需要动态内存分配（因为输出长度事先未知）并且其性能受限于GPU内存容量。</li><li>然而，这并不适用于每个GPU工作负载。例如，在DNN训练中，张量形状通常是<strong>静态</strong>的，因此可以在事先优化内存分配。另一个例子是在服务不是LLM的DNN时，提高内存效率可能不会带来任何性能提升，因为性能<strong>主要受计算限制</strong>。在这种情况下，引入vLLM的技术可能会因为内存间接和非连续块内存的额外开销而降低性能。</li><li>然而，我们很期待看到vLLM的技术被应用于具有类似LLM服务特性的其他工作负载。</li></ul></li><li>在应用虚拟内存和分页时<strong>对LLM特定的优化</strong>。<ul><li>vLLM通过利用应用特定的语义重新解释和增强虚拟内存和分页的概念。</li><li>一个例子是vLLM的全或无交换策略（all-or-nothing swap-out policy），它利用了处理请求需要存储所有相应标记状态在GPU内存中的事实。</li><li>另一个例子是恢复被驱逐块的重计算方法，这在操作系统中是不可行的。</li><li>此外，vLLM通过融合用于内存访问操作的GPU内核与其他操作（如注意力）的内核来减轻分页中内存间接的开销。</li></ul></li></ul><hr><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://dl.acm.org/doi/10.1145/3600006.3613165">[1] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient Memory Management for Large Language Model Serving with PagedAttention. In Proceedings of the 29th Symposium on Operating Systems Principles (SOSP ‘23). Association for Computing Machinery, New York, NY, USA, 611–626. https://doi.org/10.1145/3600006.3613165<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">《Efficient Memory Management for Large Language Model Serving with PagedAttention》，针对大型语言模型服务的分页注意力高效内存管理</summary>
    
    
    
    <category term="论文" scheme="https://freshwlnd.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    <category term="略读" scheme="https://freshwlnd.github.io/categories/%E8%AE%BA%E6%96%87/%E7%95%A5%E8%AF%BB/"/>
    
    <category term="AI-infra" scheme="https://freshwlnd.github.io/categories/%E8%AE%BA%E6%96%87/%E7%95%A5%E8%AF%BB/AI-infra/"/>
    
    
    <category term="大模型,推理优化,vLLM" scheme="https://freshwlnd.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96-vLLM/"/>
    
  </entry>
  
  <entry>
    <title>【集群】云原生批调度实战：Volcano 深度解析（四）：CREATE 阶段瓶颈追踪与优化思考</title>
    <link href="https://freshwlnd.github.io/2025/08/26/k8s/k8s-volcano-create-analysis/"/>
    <id>https://freshwlnd.github.io/2025/08/26/k8s/k8s-volcano-create-analysis/</id>
    <published>2025-08-26T11:45:21.000Z</published>
    <updated>2025-09-05T01:47:02.092Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列《云原生批调度实战：Volcano 深度解析》计划分为以下几篇，点击查看其它内容。</p><ol><li><a href="/2025/05/26/k8s/k8s-volcano-1/" title="云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点">云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点</a></li><li><a href="/2025/05/27/k8s/k8s-volcano-2/" title="云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态">云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态</a></li><li><a href="/2025/06/22/k8s/k8s-volcano-install/" title="云原生批调度实战：Volcano 安装与初试">云原生批调度实战：Volcano 安装与初试</a></li><li><a href="/2025/08/25/k8s/k8s-volcano-core-flow/" title="云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计">云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计</a></li><li><a href="/2025/08/26/k8s/k8s-volcano-create-analysis/" title="云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析">云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析</a></li><li><a href="/2025/09/04/k8s/k8s-volcano-create-schedule-contention-analysis/" title="云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验">云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验</a></li></ol></blockquote><p>本文承接《Volcano 深度解析（三）：核心流程解析与架构设计》，聚焦 <strong>CREATED 阶段</strong> 的性能瓶颈。实验环境及测试方法延续前文，不再赘述。</p><h1 id="0️⃣-背景回顾"><a href="#0️⃣-背景回顾" class="headerlink" title="0️⃣ 背景回顾"></a>0️⃣ 背景回顾</h1><p>在 <a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="Webhook 禁用实验">Webhook 禁用实验</a> 中，我们已确认：即使禁用 Webhook，<strong>CREATED 曲线仍呈阶梯式“突增 / 突停”</strong>。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="CREATED 阶梯示例 Benchmark-1：10K Jobs × 1 Pod"><figcaption>CREATED 阶梯示例 Benchmark-1：10K Jobs × 1 Pod</figcaption></figure><br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/kube-scheduling-perf-image/4-disable-webhook/b.NoGang-500Job-no/output/panel-5.png" alt="CREATED 阶梯示例 Benchmark-2：500 Jobs × 20 Pods"><figcaption>CREATED 阶梯示例 Benchmark-2：500 Jobs × 20 Pods</figcaption></figure></p><p>本文尝试回答两个问题：</p><ol><li>阶梯为何产生？</li><li>有哪些“调得动”的参数能够缓解？</li></ol><h1 id="1️⃣-实验现象重现"><a href="#1️⃣-实验现象重现" class="headerlink" title="1️⃣ 实验现象重现"></a>1️⃣ 实验现象重现</h1><table><thead><tr><th>Benchmark</th><th>Job×Pod</th><th>现象</th><th>备注</th></tr></thead><tbody><tr><td>benchmark-1</td><td>10K×1</td><td>CREATE 与 SCHEDULE 几乎重叠，整体速度四组中最慢</td><td><strong>CREATE = 主要瓶颈</strong></td></tr><tr><td>benchmark-2</td><td>500×20</td><td>阶梯最清晰，阶段性出现 CREATE 阻塞 → SCHEDULE 停顿</td><td>CREATE &amp; SCHEDULE 交替受阻</td></tr><tr><td>benchmark-3</td><td>20×500</td><td>CREATE 有阶梯但速度明显快于 SCHEDULE</td><td>SCHEDULE 成瓶颈</td></tr><tr><td>benchmark-4</td><td>1×10K</td><td>同上，CREATE 不是主瓶颈</td><td></td></tr></tbody></table><p><strong>猜想</strong>：JobController 对 Pod 的“批量同步创建”导致单批全部结束前无法进入下一批，从而表现为突停；批量完成后瞬时放量，表现为突增。</p><h1 id="2️⃣-代码走读：JobController-批量创建逻辑"><a href="#2️⃣-代码走读：JobController-批量创建逻辑" class="headerlink" title="2️⃣ 代码走读：JobController 批量创建逻辑"></a>2️⃣ 代码走读：JobController 批量创建逻辑</h1><h2 id="2-1-Worker-协程来源"><a href="#2-1-Worker-协程来源" class="headerlink" title="2.1 Worker 协程来源"></a>2.1 Worker 协程来源</h2><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// cmd/controller-manager/app/server.go:134-139</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">startControllers</span><span class="params">(config *rest.Config, opt *options.ServerOption)</span></span> <span class="function"><span class="keyword">func</span><span class="params">(ctx context.Context)</span></span> {</span><br><span class="line">    ...</span><br><span class="line">    controllerOpt.WorkerNum = opt.WorkerThreads</span><br><span class="line">    ...</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p><code>--worker-threads</code> 默认为 <strong>50</strong>（不指定则使用该值），决定 JobController 并发消费 <strong>Job 请求</strong> 的 goroutine 数。</p><blockquote><p>⚠️ <strong>注意</strong>：这里的协程只决定 <em>Job</em> 并行数，跟 <em>Pod</em> 并行数并非一回事。</p></blockquote><h2 id="2-2-哈希分片与队列"><a href="#2-2-哈希分片与队列" class="headerlink" title="2.2 哈希分片与队列"></a>2.2 哈希分片与队列</h2><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller.go:318-333</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *jobcontroller)</span></span> belongsToThisRoutine(key <span class="type">string</span>, count <span class="type">uint32</span>) <span class="type">bool</span> {</span><br><span class="line">    val := cc.genHash(key)</span><br><span class="line">    <span class="keyword">return</span> val % cc.workers == count</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *jobcontroller)</span></span> getWorkerQueue(key <span class="type">string</span>) workqueue.TypedRateLimitingInterface[any] {</span><br><span class="line">val := cc.genHash(key)</span><br><span class="line">queue := cc.queueList[val%cc.workers]</span><br><span class="line"><span class="keyword">return</span> queue</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// genHash 源码</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *jobcontroller)</span></span> genHash(key <span class="type">string</span>) <span class="type">uint32</span> {</span><br><span class="line">    hashVal := fnv.New32() <span class="comment">// FNV-1a 非加密散列</span></span><br><span class="line">    hashVal.Write([]<span class="type">byte</span>(key))</span><br><span class="line">    <span class="keyword">return</span> hashVal.Sum32()</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p>FNV（Fowler–Noll–Vo）是一种速度快、冲突率低的非加密散列函数，它在 Volcano 中承担 <strong>一致分片</strong> 的角色：</p><ol><li><strong>单 Job 串行化</strong>：保证相同的 JobKey 永远路由到同一 worker，避免多协程并发修改同一 Job 状态导致的竞态（如版本冲突、重复创建 Pod 等）。</li><li><strong>负载均衡</strong>：不同 Job 均匀散落到 <code>workers</code> 个队列，提升并行度。</li></ol><blockquote><p>❓ 如果不保证“同一Job → 同一协程”？</p><ul><li>多协程可能同时进入同一 Job 的状态机，导致 <strong>Status 冲突</strong>（ResourceVersion 不匹配重试、乐观锁失败）。</li><li>重复创建 Pod / PodGroup，产生 <strong>资源泄漏</strong> 与 <strong>Gang 调度失败</strong>。</li><li>如不使用该机制，则需要加全局锁或精细乐观重试，得不偿失。</li></ul></blockquote><h2 id="3️⃣-CREATE-批量创建流程"><a href="#3️⃣-CREATE-批量创建流程" class="headerlink" title="3️⃣ CREATE 批量创建流程"></a>3️⃣ CREATE 批量创建流程</h2><h3 id="PodGroup-创建"><a href="#PodGroup-创建" class="headerlink" title="PodGroup 创建"></a>PodGroup 创建</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller_actions.go:190-214</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *jobcontroller)</span></span> createOrUpdatePodGroup(job *batch.Job) <span class="type">error</span> {</span><br><span class="line">    ...</span><br><span class="line">    pg := &amp;scheduling.PodGroup{ ... }</span><br><span class="line">    vcClient.SchedulingV1beta1().PodGroups(...).Create(..., pg, ...)</span><br><span class="line">    ...</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p>一次 API 调用即可完成，且一个 Job 只建一个 PodGroup；创建本身比较简单（仅是逻辑单元），可能不是主要瓶颈：</p><ul><li>PodGroup 本质是一个 CRD 对象（仅几十字节的 Spec &amp; Metadata，见<code>pkg/controllers/job/job_controller_actions.go</code>定义部分），创建过程只是 kube-apiserver → etcd 的一次写操作。</li><li>不涉及调度决策、节点通信或资源计算；成功后即可返回，无后续长耗时流程。</li></ul><p>但需注意：若 <code>MinMember</code> 设置过大或 Queue 资源不足，调度器在 <strong>后续阶段</strong> 仍可能因 PodGroup 不满足条件而阻塞 Job 启动，这属于调度环节而非 CREATE 环节。</p><h3 id="Pod-创建"><a href="#Pod-创建" class="headerlink" title="Pod 创建"></a>Pod 创建</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller_actions.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *jobcontroller)</span></span> syncJob(jobInfo *apis.JobInfo, updateStatus state.UpdateStatusFn) <span class="type">error</span> {</span><br><span class="line">    ...</span><br><span class="line">    waitCreationGroup := sync.WaitGroup{}</span><br><span class="line">    ...</span><br><span class="line"><span class="keyword">var</span> podToCreateEachTask []*v1.Pod</span><br><span class="line"><span class="keyword">for</span> _, ts := <span class="keyword">range</span> job.Spec.Tasks {</span><br><span class="line">        <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="type">int</span>(ts.Replicas); i++ {           <span class="comment">// 收集待建 Pod</span></span><br><span class="line">            ...</span><br><span class="line">            newPod := createJobPod(job, tc, ts.TopologyPolicy, i, jobForwarding)</span><br><span class="line">            ...</span><br><span class="line">            podToCreateEachTask = <span class="built_in">append</span>(podToCreateEachTask, newPod)</span><br><span class="line">            waitCreationGroup.Add(<span class="number">1</span>)</span><br><span class="line">            ...</span><br><span class="line">        }</span><br><span class="line">        podToCreate[ts.Name] = podToCreateEachTask</span><br><span class="line">    }</span><br><span class="line">    ...</span><br><span class="line"><span class="keyword">for</span> taskName, podToCreateEachTask := <span class="keyword">range</span> podToCreate {</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(taskName <span class="type">string</span>, podToCreateEachTask []*v1.Pod)</span></span> {</span><br><span class="line">            ...</span><br><span class="line">            <span class="keyword">for</span> _, pod := <span class="keyword">range</span> podToCreateEachTask {</span><br><span class="line">                <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(pod *v1.Pod)</span></span> {</span><br><span class="line">                    <span class="keyword">defer</span> waitCreationGroup.Done()</span><br><span class="line">                    kubeClient.CoreV1().Pods(...).Create(...)</span><br><span class="line">                }(pod)</span><br><span class="line">            }</span><br><span class="line">            ...</span><br><span class="line">        }(taskName, podToCreateEachTask)</span><br><span class="line">    }</span><br><span class="line">    ...</span><br><span class="line">    waitCreationGroup.Wait()  <span class="comment">// ⬅ 阻塞：一批全部完成前不返回</span></span><br><span class="line">    ...</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><blockquote><p><strong>观察</strong>：每个 Job 中的所有 Pod 都必须在同一批完成，<code>Wait()</code> 阻塞期间该 worker 协程无法服务其他 Job，形成“突停”。</p></blockquote><p>与上述PodGroup有所差异，由于Pod是K8s原生对象，涉及到的字段极多且复杂，既需要默认填充大量字段、也需要花更多时间写入etcd，因此更容易成为瓶颈。</p><h2 id="4️⃣-CREATE-阶段可能的瓶颈链路"><a href="#4️⃣-CREATE-阶段可能的瓶颈链路" class="headerlink" title="4️⃣  CREATE 阶段可能的瓶颈链路"></a>4️⃣  CREATE 阶段可能的瓶颈链路</h2><ol><li><strong>ControllerManager – PodGroup 创建</strong>：单请求，理论影响小；仅在 CRD 校验或 etcd 压力大时显现。</li><li><strong>ControllerManager – Pod 创建并发</strong>：瞬时并发高且字段复杂，容易受 kube-apiserver QPS/TPS 限流影响。</li><li><strong>kube-apiserver – etcd 写入</strong>：大批量对象持久化；etcd IOPS 饱和时延长请求时长。</li><li><strong>网络 / TLS 握手</strong>：每 Pod 一次 HTTPS；高并发下握手耗时占比提升。</li><li><strong>Webhook</strong>（若开启）：Mutating/Validating 延时或超时。</li><li><strong>Worker 协程饱和</strong>：<code>--worker-threads</code> 阈值被占满后，新 Job 无法 dequeue，外部观察即“突停”。</li></ol><blockquote><p>在四组 Benchmark 中，总 Pod 数一致（10K），但 <strong>Job 数量越多，Worker 越容易饱和</strong>，因此出现瓶颈的并非 “单 Job 内 Pod 数” 而是 “Cluster 同时活跃的 Job 数”。</p></blockquote><h2 id="5️⃣-关键对象关系"><a href="#5️⃣-关键对象关系" class="headerlink" title="5️⃣ 关键对象关系"></a>5️⃣ 关键对象关系</h2><table><thead><tr><th>对象</th><th>层级</th><th>作用</th><th>与其他对象关系</th></tr></thead><tbody><tr><td><strong>Job</strong></td><td>Volcano CRD</td><td>用户提交的批处理作业</td><td>一个 Job <strong>拥有</strong> 1 PodGroup &amp; N Tasks</td></tr><tr><td><strong>PodGroup</strong></td><td>Volcano CRD</td><td>Gang 调度边界，决定最小可运行成员数</td><td>Job 创建时同步生成；Scheduler 以 PG 维度做满足性判断</td></tr><tr><td><strong>Task</strong></td><td>Job 内部元素</td><td>Job 的逻辑分片，可用不同镜像/参数</td><td>Task <strong>生成</strong> 多个 Pod(Replicas)</td></tr><tr><td><strong>Pod</strong></td><td>K8s 原生</td><td>实际运行单元</td><td>由 Task 模板实例化，归属同一 PodGroup</td></tr></tbody></table><blockquote><p>PodGroup ≠ Task：个人理解前者是 Job 的化身，后者是 Job 内的子对象。<br>层级关系为：1 Job（PodGroup） → n Task → n*m Pod。</p></blockquote><h2 id="6️⃣-相关参数与理论影响"><a href="#6️⃣-相关参数与理论影响" class="headerlink" title="6️⃣ 相关参数与理论影响"></a>6️⃣ 相关参数与理论影响</h2><table><thead><tr><th>参数</th><th>默认</th><th>预期影响</th><th>实测结论</th></tr></thead><tbody><tr><td><code>--worker-threads</code></td><td>50</td><td>决定可同时被处理的 Job 数</td><td>✅ 提高可缩短突停时长，但系统整体压力增大</td></tr><tr><td><code>task.replicas</code></td><td>用户输入</td><td>决定单 Job 内批量大小</td><td>⚠️ 非根因；更改只影响单 batch 时长</td></tr><tr><td>新增参数</td><td>N/A</td><td>控制每次并发 Pod 数（而非局限于一个 Job 内的 Pod 数）</td><td>🚧 需进一步设计</td></tr></tbody></table><blockquote><p>结论：</p><ul><li><strong>Job 数</strong> → Worker 饱和度 → 是否突停。</li><li><strong>Replica 数</strong> → 单 worker 持续时间 → 阶梯宽度。</li></ul></blockquote><h2 id="7️⃣-优化方向"><a href="#7️⃣-优化方向" class="headerlink" title="7️⃣ 优化方向"></a>7️⃣ 优化方向</h2><table><thead><tr><th>方向</th><th>复杂度</th><th>收益</th><th>说明</th></tr></thead><tbody><tr><td>智能调整 <code>--worker-threads</code></td><td>低</td><td>高</td><td>观察到出现瓶颈（或观察到 replicas 普遍较小）时，自动提高并行协程数，削弱同步阻塞</td></tr><tr><td>引入新参数，或调整协程Wait阻塞逻辑</td><td>中</td><td>高</td><td>分片提交 Pods（支持跨Job并行），削弱同步阻塞</td></tr></tbody></table><hr><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://github.com/volcano-sh/volcano">[1] Volcano GitHub 仓库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://volcano.sh/zh/">[2] Volcano 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/kube-scheduler/">[3] Kubernetes 调度器设计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://volcano.sh/zh/docs/architecture/">[4] Volcano 架构设计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/">[5] Kubernetes Webhook 机制<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://volcano.sh/zh/docs/actions/">[6] Volcano 调度器 Actions<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/architecture/controller/">[7] Kubernetes 控制器<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://volcano.sh/zh/docs/schduler_introduction/">[8] Volcano 调度器<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">深入剖析禁用 Webhook 后仍旧存在的 CREATED 阶段性能瓶颈，通过代码略读定位 JobController 中的批量创建逻辑，分析关键相关参数影响并提出可行的优化方向。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="Kubernetes" scheme="https://freshwlnd.github.io/tags/Kubernetes/"/>
    
    <category term="调度器" scheme="https://freshwlnd.github.io/tags/%E8%B0%83%E5%BA%A6%E5%99%A8/"/>
    
    <category term="性能优化" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    
    <category term="Volcano" scheme="https://freshwlnd.github.io/tags/Volcano/"/>
    
    <category term="批处理" scheme="https://freshwlnd.github.io/tags/%E6%89%B9%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>【集群】云原生批调度实战：Volcano 深度解析（三）：核心流程解析与架构设计</title>
    <link href="https://freshwlnd.github.io/2025/08/25/k8s/k8s-volcano-core-flow/"/>
    <id>https://freshwlnd.github.io/2025/08/25/k8s/k8s-volcano-core-flow/</id>
    <published>2025-08-25T12:39:54.000Z</published>
    <updated>2025-09-18T07:27:36.932Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列《云原生批调度实战：Volcano 深度解析》计划分为以下几篇，点击查看其它内容。</p><ol><li><a href="/2025/05/26/k8s/k8s-volcano-1/" title="云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点">云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点</a></li><li><a href="/2025/05/27/k8s/k8s-volcano-2/" title="云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态">云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态</a></li><li><a href="/2025/06/22/k8s/k8s-volcano-install/" title="云原生批调度实战：Volcano 安装与初试">云原生批调度实战：Volcano 安装与初试</a></li><li><a href="/2025/08/25/k8s/k8s-volcano-core-flow/" title="云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计">云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计</a></li><li><a href="/2025/08/26/k8s/k8s-volcano-create-analysis/" title="云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析">云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析</a></li><li><a href="/2025/09/04/k8s/k8s-volcano-create-schedule-contention-analysis/" title="云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验">云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验</a></li></ol></blockquote><h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="调度器性能对比分析">调度器性能对比分析</a>中，我们发现Volcano在大规模Job创建时存在性能瓶颈，特别是与Webhook相关的限制。为了深入理解这一现象并提供有效的优化方案，我们需要从代码层面深入分析Volcano的核心流程。</p><p>本文将从Volcano的整体架构出发，详细解析从Job创建到Pod调度的完整流程，通过代码分析揭示Volcano如何实现高效的批处理调度，以及与原生Kubernetes调度器的关键差异。</p><h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>在性能测试中，我们发现Volcano在以下场景下存在性能瓶颈：</p><ol><li><strong>大规模Job创建</strong>：同时创建大量Job时，会出现阶段性阻塞</li><li><strong>Webhook QPS限制</strong>：Webhook的QPS限制可能影响Job创建速度</li><li><strong>批量处理机制</strong>：可能存在批量处理策略，按批创建，导致创建成为瓶颈</li></ol><p>为了理解这些问题的根本原因，我们需要深入分析Volcano的核心流程。在这篇博客中，我们对代码进行初步分析，从Job创建到Pod调度的完整流程开始，初步了解各组件的作用和交互关系。</p><h1 id="🏗️Volcano整体架构概览"><a href="#🏗️Volcano整体架构概览" class="headerlink" title="🏗️Volcano整体架构概览"></a>🏗️Volcano整体架构概览</h1><h2 id="核心组件架构"><a href="#核心组件架构" class="headerlink" title="核心组件架构"></a>核心组件架构</h2><p>Volcano作为Kubernetes的批处理调度系统，主要由以下几个核心组件组成：</p><pre class="mermaid">graph TB    A[用户] --&gt; B[kube-apiserver]    B --&gt; C[Volcano Controller Manager]    B --&gt; D[Volcano Scheduler]    B --&gt; E[Volcano Webhook Manager]        C --&gt; F[Job Controller]    C --&gt; G[PodGroup Controller]    C --&gt; H[Queue Controller]        D --&gt; I[Cache]    D --&gt; J[Actions]    D --&gt; K[Plugins]        E --&gt; L[Admission Webhooks]    E --&gt; M[Validating Webhooks]    E --&gt; N[Mutating Webhooks]        F --&gt; O[Pod Creation]    G --&gt; P[PodGroup Management]    H --&gt; Q[Queue Management]        I --&gt; R[Node Cache]    I --&gt; S[Pod Cache]    I --&gt; T[Job Cache]        J --&gt; U[Enqueue]    J --&gt; V[Allocate]    J --&gt; W[Preempt]    J --&gt; X[Reclaim]    J --&gt; Y[Backfill]</pre><h2 id="组件职责分析"><a href="#组件职责分析" class="headerlink" title="组件职责分析"></a>组件职责分析</h2><h3 id="1-Controller-Manager"><a href="#1-Controller-Manager" class="headerlink" title="1. Controller Manager"></a>1. Controller Manager</h3><ul><li><strong>Job Controller</strong>：管理Volcano Job的生命周期</li><li><strong>PodGroup Controller</strong>：管理PodGroup的创建和状态</li><li><strong>Queue Controller</strong>：管理队列资源和配额</li></ul><h3 id="2-Scheduler"><a href="#2-Scheduler" class="headerlink" title="2. Scheduler"></a>2. Scheduler</h3><ul><li><strong>Cache</strong>：维护集群状态快照</li><li><strong>Actions</strong>：执行调度操作（入队、分配、抢占等）</li><li><strong>Plugins</strong>：提供调度算法和策略</li></ul><h3 id="3-Webhook-Manager"><a href="#3-Webhook-Manager" class="headerlink" title="3. Webhook Manager"></a>3. Webhook Manager</h3><ul><li><strong>Admission Webhooks</strong>：准入控制</li><li><strong>Validating Webhooks</strong>：验证资源</li><li><strong>Mutating Webhooks</strong>：修改资源</li></ul><h1 id="🔄Job创建到Pod调度的完整流程"><a href="#🔄Job创建到Pod调度的完整流程" class="headerlink" title="🔄Job创建到Pod调度的完整流程"></a>🔄Job创建到Pod调度的完整流程</h1><h2 id="流程概览"><a href="#流程概览" class="headerlink" title="流程概览"></a>流程概览</h2><pre class="mermaid">sequenceDiagram    participant User as 用户    participant API as kube-apiserver    participant Webhook as Webhook Manager    participant Controller as Controller Manager    participant Scheduler as Volcano Scheduler    participant Cache as Scheduler Cache        User-&gt;&gt;API: 创建Volcano Job    API-&gt;&gt;Webhook: 调用准入Webhook    Webhook-&gt;&gt;API: 验证/修改Job    API-&gt;&gt;Controller: 触发Job Controller    Controller-&gt;&gt;API: 创建PodGroup    API-&gt;&gt;Webhook: 调用PodGroup Webhook    Webhook-&gt;&gt;API: 验证PodGroup    Controller-&gt;&gt;API: 创建Pod    API-&gt;&gt;Webhook: 调用Pod Webhook    Webhook-&gt;&gt;API: 验证Pod    API-&gt;&gt;Scheduler: 触发调度    Scheduler-&gt;&gt;Cache: 获取集群快照    Scheduler-&gt;&gt;Scheduler: 执行调度算法    Scheduler-&gt;&gt;API: 绑定Pod到节点</pre><h2 id="详细流程分析"><a href="#详细流程分析" class="headerlink" title="详细流程分析"></a>详细流程分析</h2><h3 id="阶段1：Job创建与验证"><a href="#阶段1：Job创建与验证" class="headerlink" title="阶段1：Job创建与验证"></a>阶段1：Job创建与验证</h3><h4 id="1-1-用户提交Job"><a href="#1-1-用户提交Job" class="headerlink" title="1.1 用户提交Job"></a>1.1 用户提交Job</h4><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch.volcano.sh/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-job</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">minAvailable:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">schedulerName:</span> <span class="string">volcano</span></span><br><span class="line">  <span class="attr">queue:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">task-1</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">container-1</span></span><br><span class="line">              <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">              <span class="attr">command:</span> [<span class="string">"sleep"</span>, <span class="string">"100"</span>]</span><br></pre></td></tr></table></figure></div><h4 id="1-2-Webhook验证"><a href="#1-2-Webhook验证" class="headerlink" title="1.2 Webhook验证"></a>1.2 Webhook验证</h4><p>当用户提交Job时，kube-apiserver会调用Volcano的Webhook进行验证。AdmitJobs函数通过HTTP路由系统被kube-apiserver调用，而不是直接的函数调用：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/webhooks/admission/jobs/validate/admit_job.go</span></span><br><span class="line"><span class="keyword">var</span> service = &amp;router.AdmissionService{</span><br><span class="line">    Path: <span class="string">"/jobs/validate"</span>,</span><br><span class="line">    Func: AdmitJobs,  <span class="comment">// 注册到HTTP路由</span></span><br><span class="line">    ValidatingConfig: &amp;whv1.ValidatingWebhookConfiguration{...},</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">AdmitJobs</span><span class="params">(ar admissionv1.AdmissionReview)</span></span> *admissionv1.AdmissionResponse {</span><br><span class="line">    <span class="keyword">switch</span> ar.Request.Operation {</span><br><span class="line">    <span class="keyword">case</span> admissionv1.Create:</span><br><span class="line">        msg = validateJobCreate(job, &amp;reviewResponse)</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p><strong>实际验证内容</strong>：根据代码分析，<code>validateJobCreate</code>函数主要验证：</p><ul><li><strong>基础参数校验</strong>：minAvailable、maxRetry、replicas等参数范围</li><li><strong>任务模板验证</strong>：Pod模板的合法性和K8s资源规范</li><li><strong>MPI依赖检查</strong>：验证master/worker任务配置</li><li><strong>任务间依赖</strong>：检查依赖关系是否形成有向无环图(DAG)</li><li><strong>队列状态验证</strong>：检查Queue是否存在、状态是否为Open、是否为叶子队列</li><li><strong>插件配置验证</strong>：验证Job插件是否存在</li></ul><p><strong>调用机制</strong>：Webhook通过以下机制被调用：</p><ol><li>webhook-manager启动时注册HTTP路由 (<code>http.HandleFunc(service.Path, service.Handler)</code>)</li><li>kube-apiserver根据ValidatingWebhookConfiguration向Volcano发送HTTP POST请求</li><li>请求路径为 <code>/jobs/validate</code>，由router.Serve处理并调用AdmitJobs函数</li></ol><h4 id="1-3-Job-Controller处理"><a href="#1-3-Job-Controller处理" class="headerlink" title="1.3 Job Controller处理"></a>1.3 Job Controller处理</h4><p>Job Controller监听到Job创建事件后，开始处理：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(jc *jobcontroller)</span></span> syncJob(job *vcbatch.Job) <span class="type">error</span> {</span><br><span class="line">    <span class="comment">// 1. 创建PodGroup</span></span><br><span class="line">    <span class="comment">// 2. 创建Pod</span></span><br><span class="line">    <span class="comment">// 3. 更新Job状态</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h3 id="阶段2：PodGroup创建"><a href="#阶段2：PodGroup创建" class="headerlink" title="阶段2：PodGroup创建"></a>阶段2：PodGroup创建</h3><h4 id="2-1-PodGroup的作用"><a href="#2-1-PodGroup的作用" class="headerlink" title="2.1 PodGroup的作用"></a>2.1 PodGroup的作用</h4><p>PodGroup是Volcano的核心概念，用于实现Gang调度：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(jc *jobcontroller)</span></span> createPodGroup(job *vcbatch.Job) <span class="type">error</span> {</span><br><span class="line">    podGroup := &amp;vcscheduling.PodGroup{</span><br><span class="line">        ObjectMeta: metav1.ObjectMeta{</span><br><span class="line">            Name:      job.Name,</span><br><span class="line">            Namespace: job.Namespace,</span><br><span class="line">        },</span><br><span class="line">        Spec: vcscheduling.PodGroupSpec{</span><br><span class="line">            MinMember: job.Spec.MinAvailable,</span><br><span class="line">            Queue:     job.Spec.Queue,</span><br><span class="line">        },</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> jc.vcClient.SchedulingV1beta1().PodGroups(job.Namespace).Create(podGroup)</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h4 id="2-2-PodGroup状态管理"><a href="#2-2-PodGroup状态管理" class="headerlink" title="2.2 PodGroup状态管理"></a>2.2 PodGroup状态管理</h4><p>PodGroup的状态转换：</p><pre class="mermaid">stateDiagram-v2    [*] --&gt; Pending    Pending --&gt; Inqueue    Inqueue --&gt; Running    Running --&gt; Completed    Running --&gt; Failed    Completed --&gt; [*]    Failed --&gt; [*]</pre><h3 id="阶段3：Pod创建"><a href="#阶段3：Pod创建" class="headerlink" title="阶段3：Pod创建"></a>阶段3：Pod创建</h3><h4 id="3-1-批量Pod创建"><a href="#3-1-批量Pod创建" class="headerlink" title="3.1 批量Pod创建"></a>3.1 批量Pod创建</h4><p>Job Controller会根据Job配置创建多个Pod：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller.go</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="type">int</span>(ts.Replicas); i++ {</span><br><span class="line">    podName := fmt.Sprintf(jobhelpers.PodNameFmt, job.Name, name, i)</span><br><span class="line">    <span class="keyword">if</span> _, found := pods[podName]; !found {</span><br><span class="line">        newPod := createJobPod(job, tc, ts.TopologyPolicy, i, jobForwarding)</span><br><span class="line">        <span class="comment">// 收集待创建的 Pod，并登记到 WaitGroup</span></span><br><span class="line">        podToCreateEachTask = <span class="built_in">append</span>(podToCreateEachTask, newPod)</span><br><span class="line">        waitCreationGroup.Add(<span class="number">1</span>)</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p>随后使用 goroutine + WaitGroup 并发向 API Server 创建 Pod：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller.go</span></span><br><span class="line"><span class="keyword">for</span> _, pod := <span class="keyword">range</span> podToCreateEachTask {</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(pod *v1.Pod)</span></span> {</span><br><span class="line">        <span class="keyword">defer</span> waitCreationGroup.Done()</span><br><span class="line">        _, err := kubeClient.CoreV1().Pods(pod.Namespace).Create(ctx, pod, metav1.CreateOptions{})</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &amp;&amp; !apierrors.IsAlreadyExists(err) {</span><br><span class="line">            <span class="comment">// 错误处理略</span></span><br><span class="line">        }</span><br><span class="line">    }(pod)</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h4 id="3-2-Pod-模板展开"><a href="#3-2-Pod-模板展开" class="headerlink" title="3.2 Pod 模板展开"></a>3.2 Pod 模板展开</h4><p>单个 Pod 的构造细节在 <code>createJobPod</code>（<code>pkg/controllers/job/job_controller_util.go</code>）：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller_util.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">createJobPod</span><span class="params">(job *batch.Job, template *v1.PodTemplateSpec,</span></span></span><br><span class="line"><span class="params"><span class="function">    topologyPolicy batch.NumaPolicy, ix <span class="type">int</span>, jobForwarding <span class="type">bool</span>)</span></span> *v1.Pod {</span><br><span class="line"></span><br><span class="line">    pod := &amp;v1.Pod{</span><br><span class="line">        ObjectMeta: metav1.ObjectMeta{</span><br><span class="line">            Name:      jobhelpers.MakePodName(job.Name, template.Name, ix),</span><br><span class="line">            Namespace: job.Namespace,</span><br><span class="line">            OwnerReferences: []metav1.OwnerReference{</span><br><span class="line">                *metav1.NewControllerRef(job, helpers.JobKind),</span><br><span class="line">            },</span><br><span class="line">        },</span><br><span class="line">        Spec: template.Spec,</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 省略 SchedulerName、Volume 等附加字段填充</span></span><br><span class="line">    <span class="keyword">return</span> pod</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h3 id="阶段4：调度处理"><a href="#阶段4：调度处理" class="headerlink" title="阶段4：调度处理"></a>阶段4：调度处理</h3><h4 id="4-1-调度器触发"><a href="#4-1-调度器触发" class="headerlink" title="4.1 调度器触发"></a>4.1 调度器触发</h4><p>当Pod创建后，调度器开始工作：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/scheduler/framework/session.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ssn *Session)</span></span> Open() {</span><br><span class="line">    <span class="comment">// 1. 获取集群快照</span></span><br><span class="line">    <span class="comment">// 2. 执行调度Actions</span></span><br><span class="line">    <span class="comment">// 3. 更新调度结果</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h4 id="4-2-调度Actions执行"><a href="#4-2-调度Actions执行" class="headerlink" title="4.2 调度Actions执行"></a>4.2 调度Actions执行</h4><p>调度器按顺序执行Actions：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/scheduler/actions/allocate/allocate.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(alloc *Action)</span></span> Execute(ssn *framework.Session) {</span><br><span class="line">    <span class="comment">// 1. Enqueue: 将Job加入调度队列</span></span><br><span class="line">    <span class="comment">// 2. Allocate: 为Pod分配节点</span></span><br><span class="line">    <span class="comment">// 3. Preempt: 处理抢占</span></span><br><span class="line">    <span class="comment">// 4. Reclaim: 处理资源回收</span></span><br><span class="line">    <span class="comment">// 5. Backfill: 处理回填</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h4 id="4-3-节点选择算法"><a href="#4-3-节点选择算法" class="headerlink" title="4.3 节点选择算法"></a>4.3 节点选择算法</h4><p>调度器使用多种算法选择最优节点：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/scheduler/plugins/predicates/predicates.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *predicatePlugin)</span></span> OnNodeAdd(node *v1.Node) {</span><br><span class="line">    <span class="comment">// 节点预选：过滤不满足条件的节点</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *predicatePlugin)</span></span> OnNodeUpdate(oldNode, newNode *v1.Node) {</span><br><span class="line">    <span class="comment">// 节点优选：为节点打分</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h1 id="🔍关键组件深度解析"><a href="#🔍关键组件深度解析" class="headerlink" title="🔍关键组件深度解析"></a>🔍关键组件深度解析</h1><h2 id="Controller-Manager组件"><a href="#Controller-Manager组件" class="headerlink" title="Controller Manager组件"></a>Controller Manager组件</h2><h3 id="Job-Controller"><a href="#Job-Controller" class="headerlink" title="Job Controller"></a>Job Controller</h3><p>Job Controller是Volcano的核心控制器，负责管理Job的生命周期：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller.go</span></span><br><span class="line"><span class="keyword">type</span> jobcontroller <span class="keyword">struct</span> {</span><br><span class="line">    vcClient    vcclientset.Interface</span><br><span class="line">    kubeClient  kubernetes.Interface</span><br><span class="line">    jobInformer vcinformer.JobInformer</span><br><span class="line">    podInformer corev1informer.PodInformer</span><br><span class="line">    <span class="comment">// ... 其他字段</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(jc *jobcontroller)</span></span> syncJob(job *vcbatch.Job) <span class="type">error</span> {</span><br><span class="line">    <span class="comment">// 1. 检查Job状态</span></span><br><span class="line">    <span class="comment">// 2. 创建/更新PodGroup</span></span><br><span class="line">    <span class="comment">// 3. 创建/更新Pod</span></span><br><span class="line">    <span class="comment">// 4. 更新Job状态</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h3 id="PodGroup-Controller"><a href="#PodGroup-Controller" class="headerlink" title="PodGroup Controller"></a>PodGroup Controller</h3><p>PodGroup Controller管理PodGroup的状态转换：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/podgroup/podgroup_controller.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(pgc *podgroupcontroller)</span></span> syncPodGroup(pg *vcscheduling.PodGroup) <span class="type">error</span> {</span><br><span class="line">    <span class="comment">// 1. 检查PodGroup状态</span></span><br><span class="line">    <span class="comment">// 2. 计算满足条件的Pod数量</span></span><br><span class="line">    <span class="comment">// 3. 更新PodGroup状态</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h2 id="Scheduler组件"><a href="#Scheduler组件" class="headerlink" title="Scheduler组件"></a>Scheduler组件</h2><h3 id="Cache机制"><a href="#Cache机制" class="headerlink" title="Cache机制"></a>Cache机制</h3><p>调度器的Cache维护集群状态快照：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/scheduler/cache/cache.go</span></span><br><span class="line"><span class="keyword">type</span> Cache <span class="keyword">struct</span> {</span><br><span class="line">    nodes <span class="keyword">map</span>[<span class="type">string</span>]*api.NodeInfo</span><br><span class="line">    jobs  <span class="keyword">map</span>[api.JobID]*api.JobInfo</span><br><span class="line">    pods  <span class="keyword">map</span>[<span class="type">string</span>]*api.PodInfo</span><br><span class="line">    <span class="comment">// ... 其他字段</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cache)</span></span> Snapshot() *api.ClusterInfo {</span><br><span class="line">    <span class="comment">// 创建集群快照</span></span><br><span class="line">    <span class="keyword">return</span> &amp;api.ClusterInfo{</span><br><span class="line">        Nodes: c.nodes,</span><br><span class="line">        Jobs:  c.jobs,</span><br><span class="line">        <span class="comment">// ... 其他信息</span></span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h3 id="Actions机制"><a href="#Actions机制" class="headerlink" title="Actions机制"></a>Actions机制</h3><p>Actions定义了调度器的核心操作：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/scheduler/actions/allocate/allocate.go</span></span><br><span class="line"><span class="keyword">type</span> Action <span class="keyword">struct</span> {</span><br><span class="line">    <span class="comment">// Action实现</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(alloc *Action)</span></span> Execute(ssn *framework.Session) {</span><br><span class="line">    <span class="comment">// 1. Enqueue: 入队操作</span></span><br><span class="line">    <span class="comment">// 2. Allocate: 分配操作</span></span><br><span class="line">    <span class="comment">// 3. Preempt: 抢占操作</span></span><br><span class="line">    <span class="comment">// 4. Reclaim: 回收操作</span></span><br><span class="line">    <span class="comment">// 5. Backfill: 回填操作</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h2 id="Webhook-Manager组件"><a href="#Webhook-Manager组件" class="headerlink" title="Webhook Manager组件"></a>Webhook Manager组件</h2><h3 id="Admission-Webhooks"><a href="#Admission-Webhooks" class="headerlink" title="Admission Webhooks"></a>Admission Webhooks</h3><p>准入控制器处理资源创建和修改：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pkg/webhooks/admission/job/admit.go</span></span><br><span class="line"><span class="keyword">type</span> jobAdmit <span class="keyword">struct</span> {</span><br><span class="line">    <span class="comment">// Webhook实现</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(job *jobAdmit)</span></span> Admit(ar *admissionv1.AdmissionReview) *admissionv1.AdmissionResponse {</span><br><span class="line">    <span class="comment">// 1. 解析请求</span></span><br><span class="line">    <span class="comment">// 2. 验证资源</span></span><br><span class="line">    <span class="comment">// 3. 返回结果</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><hr><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://github.com/volcano-sh/volcano">[1] Volcano GitHub 仓库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://volcano.sh/zh/">[2] Volcano 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/kube-scheduler/">[3] Kubernetes 调度器设计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://volcano.sh/zh/docs/architecture/">[4] Volcano 架构设计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/">[5] Kubernetes Webhook 机制<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://volcano.sh/zh/docs/actions/">[6] Volcano 调度器 Actions<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/architecture/controller/">[7] Kubernetes 控制器<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://volcano.sh/zh/docs/schduler_introduction/">[8] Volcano 调度器<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">深入解析Volcano的核心架构和Job创建到Pod调度的完整流程，通过代码分析揭示Volcano如何实现高效的批处理调度。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="Kubernetes" scheme="https://freshwlnd.github.io/tags/Kubernetes/"/>
    
    <category term="调度器" scheme="https://freshwlnd.github.io/tags/%E8%B0%83%E5%BA%A6%E5%99%A8/"/>
    
    <category term="Volcano" scheme="https://freshwlnd.github.io/tags/Volcano/"/>
    
    <category term="批处理" scheme="https://freshwlnd.github.io/tags/%E6%89%B9%E5%A4%84%E7%90%86/"/>
    
    <category term="架构设计" scheme="https://freshwlnd.github.io/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>【集群】云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</title>
    <link href="https://freshwlnd.github.io/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/"/>
    <id>https://freshwlnd.github.io/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/</id>
    <published>2025-08-24T07:11:32.000Z</published>
    <updated>2025-09-18T07:27:36.965Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p><ol><li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li><li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li><li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li><li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li><li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li><li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li><li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li><li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li><li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li><li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li><li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li><li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li><li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li><li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a></li></ol></blockquote><h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地环境测试结果与视频对比分析">本地环境测试结果与视频对比分析</a>中，我们发现本地测试结果与KubeCon技术分享视频中的结果存在显著差异。虽然整体趋势基本一致，但在某些测试场景下，本地测试的CREATED事件曲线、SCHEDULED事件表现与视频预期不符。</p><p>为了深入分析这些差异的原因，我们提出了五种可能影响实验效果的猜想，并依次进行了系统性的实验验证。本文总结了这些猜想的验证过程、实验结果和最终结论，为Volcano调度器的性能优化提供了重要参考。</p><h1 id="🔍问题背景回顾"><a href="#🔍问题背景回顾" class="headerlink" title="🔍问题背景回顾"></a>🔍问题背景回顾</h1><h2 id="1-本地测试与视频结果差异"><a href="#1-本地测试与视频结果差异" class="headerlink" title="1. 本地测试与视频结果差异"></a>1. 本地测试与视频结果差异</h2><p>根据<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="前期分析">前期分析</a>，我们发现了以下主要差异：</p><table><thead><tr><th>测试场景</th><th>视频预期</th><th>本地实际</th><th>差异程度</th></tr></thead><tbody><tr><td><strong>10K Jobs × 1 Pod</strong></td><td>CREATED阶段瓶颈严重</td><td>✅ 符合预期</td><td>基本一致</td></tr><tr><td><strong>500 Jobs × 20 Pods</strong></td><td>CREATED阶段性突变</td><td>⚠️ 部分符合</td><td>中等差异</td></tr><tr><td><strong>20 Jobs × 500 Pods</strong></td><td>调度速度平稳</td><td>❌ 出现突变</td><td>显著差异</td></tr><tr><td><strong>1 Job × 10K Pods</strong></td><td>调度速度平稳</td><td>❌ 出现突变</td><td>显著差异</td></tr></tbody></table><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/2025-KubeCon-A-Comparative-Analysis-5.png" alt="图1：性能测试中的参数配置"><figcaption>图1：性能测试中的参数配置</figcaption></figure></p><h2 id="2-差异现象分析"><a href="#2-差异现象分析" class="headerlink" title="2. 差异现象分析"></a>2. 差异现象分析</h2><p>这些差异主要表现为：</p><ol><li><strong>CREATED事件异常</strong>：在benchmark3和benchmark4中，CREATED事件出现阶段性突变，与视频中的平稳增长不符</li><li><strong>Pod创建数量不足</strong>：在某些测试中，实际创建的Pod数量远少于预期的10,000个</li><li><strong>调度性能瓶颈</strong>：调度器性能表现与预期存在较大差距</li></ol><h1 id="🧪五种猜想及其验证实验"><a href="#🧪五种猜想及其验证实验" class="headerlink" title="🧪五种猜想及其验证实验"></a>🧪五种猜想及其验证实验</h1><h2 id="猜想1：enqueue功能可能是性能瓶颈"><a href="#猜想1：enqueue功能可能是性能瓶颈" class="headerlink" title="猜想1：enqueue功能可能是性能瓶颈"></a>猜想1：enqueue功能可能是性能瓶颈</h2><h3 id="1-1-猜想依据"><a href="#1-1-猜想依据" class="headerlink" title="1.1 猜想依据"></a>1.1 猜想依据</h3><p>基于<a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="视频分析">视频分析</a>，我们猜测enqueue阶段可能会：</p><ul><li><strong>提前判断资源</strong>：在Pod创建前就判断资源是否充足</li><li><strong>限制Pod创建</strong>：当资源不足时，限制新Pod的创建速度</li><li><strong>影响CREATED事件</strong>：导致CREATED事件出现阶段性突变</li></ul><h3 id="1-2-实验设计"><a href="#1-2-实验设计" class="headerlink" title="1.2 实验设计"></a>1.2 实验设计</h3><p>我们通过<a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="禁用enqueue功能">禁用enqueue功能</a>来验证这一猜想：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改调度器配置，移除enqueue阶段</span></span><br><span class="line">actions: <span class="string">"allocate, backfill, reclaim"</span>  <span class="comment"># 原始：actions: "enqueue, allocate, backfill"</span></span><br></pre></td></tr></table></figure></div><h3 id="1-3-实验结果"><a href="#1-3-实验结果" class="headerlink" title="1.3 实验结果"></a>1.3 实验结果</h3><h4 id="第一种-Benchmark：10K-Jobs-×-1-Pod"><a href="#第一种-Benchmark：10K-Jobs-×-1-Pod" class="headerlink" title="第一种 Benchmark：10K Jobs × 1 Pod"></a>第一种 Benchmark：10K Jobs × 1 Pod</h4><p><strong>测试参数</strong>：每个Job只有1个Pod，共10K个Job，共10kPod</p><p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果几乎一致。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/1-no-enqueue/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="图2：对于猜想1，第一种benchmark测试结果"><figcaption>图2：对于猜想1，第一种benchmark测试结果</figcaption></figure></p><h4 id="第二种-Benchmark：500-Jobs-×-20-Pods"><a href="#第二种-Benchmark：500-Jobs-×-20-Pods" class="headerlink" title="第二种 Benchmark：500 Jobs × 20 Pods"></a>第二种 Benchmark：500 Jobs × 20 Pods</h4><p><strong>测试参数</strong>：每个Job有20个Pod，共500个Job，共10kPod</p><p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果几乎一致。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/1-no-enqueue/b.NoGang-500Job-no/output/panel-5.png?raw=true" alt="图3：对于猜想1，第二种benchmark测试结果"><figcaption>图3：对于猜想1，第二种benchmark测试结果</figcaption></figure></p><h4 id="第三种-Benchmark：20-Jobs-×-500-Pods"><a href="#第三种-Benchmark：20-Jobs-×-500-Pods" class="headerlink" title="第三种 Benchmark：20 Jobs × 500 Pods"></a>第三种 Benchmark：20 Jobs × 500 Pods</h4><p><strong>测试参数</strong>：每个Job有500Pod，共20个Job，共10kPod</p><p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果几乎一致，仍然存在“仅创建1000Pod”的bug。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/1-no-enqueue/c.NoGang-20Job-no/output/panel-5.png?raw=true" alt="图4：对于猜想1，第三种benchmark测试结果"><figcaption>图4：对于猜想1，第三种benchmark测试结果</figcaption></figure></p><h4 id="第四种-Benchmark：1-Job-×-10K-Pods"><a href="#第四种-Benchmark：1-Job-×-10K-Pods" class="headerlink" title="第四种 Benchmark：1 Job × 10K Pods"></a>第四种 Benchmark：1 Job × 10K Pods</h4><p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果几乎一致。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/1-no-enqueue/c.NoGang-20Job-no/output/panel-5.png?raw=true" alt="图5：对于猜想1，第四种benchmark测试结果"><figcaption>图5：对于猜想1，第四种benchmark测试结果</figcaption></figure></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p><strong>实验结论</strong>：enqueue阶段不是性能瓶颈</p><p><strong>关键发现</strong>：</p><ul><li>禁用enqueue后，测试结果与前期本地测试结果基本一致</li><li>CREATED事件仍然出现阶段性突变</li><li>调度性能没有显著改善</li></ul><p><strong>分析说明</strong>：enqueue主要负责任务入队和优先级排序，对Pod创建和调度的直接影响有限。CREATED事件的异常现象可能源于其他因素。</p><h2 id="猜想2：webhook超时可能导致性能测试异常"><a href="#猜想2：webhook超时可能导致性能测试异常" class="headerlink" title="猜想2：webhook超时可能导致性能测试异常"></a>猜想2：webhook超时可能导致性能测试异常</h2><h3 id="2-1-猜想依据"><a href="#2-1-猜想依据" class="headerlink" title="2.1 猜想依据"></a>2.1 猜想依据</h3><p>在<a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="问题排查过程">问题排查过程</a>中，我们发现了严重的webhook超时问题：</p><ul><li><strong>Pod创建失败率</strong>：98.7%的Pod创建请求因超时而失败</li><li><strong>超时配置</strong>：webhook超时时间设置为10秒</li><li><strong>日志证据</strong>：4.9GB的审计日志记录了大量超时错误</li></ul><h3 id="2-2-实验设计"><a href="#2-2-实验设计" class="headerlink" title="2.2 实验设计"></a>2.2 实验设计</h3><p>我们通过修改webhook超时时间从10秒增加到30秒来验证这一猜想：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 批量修改所有webhook配置文件的超时时间</span></span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-*.yaml</span><br></pre></td></tr></table></figure></div><h3 id="2-3-实验结果"><a href="#2-3-实验结果" class="headerlink" title="2.3 实验结果"></a>2.3 实验结果</h3><h4 id="第一种-Benchmark：10K-Jobs-×-1-Pod-1"><a href="#第一种-Benchmark：10K-Jobs-×-1-Pod-1" class="headerlink" title="第一种 Benchmark：10K Jobs × 1 Pod"></a>第一种 Benchmark：10K Jobs × 1 Pod</h4><p><strong>测试参数</strong>：每个Job只有1个Pod，共10K个Job，共10kPod</p><p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果几乎一致。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/2-long-webhook-timeout/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="图6：对于猜想2，第一种benchmark测试结果"><figcaption>图6：对于猜想2，第一种benchmark测试结果</figcaption></figure></p><h4 id="第二种-Benchmark：500-Jobs-×-20-Pods-1"><a href="#第二种-Benchmark：500-Jobs-×-20-Pods-1" class="headerlink" title="第二种 Benchmark：500 Jobs × 20 Pods"></a>第二种 Benchmark：500 Jobs × 20 Pods</h4><p><strong>测试参数</strong>：每个Job有20个Pod，共500个Job，共10kPod</p><p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果几乎一致。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/2-long-webhook-timeout/b.NoGang-500Job-no/output/panel-5.png?raw=true" alt="图7：对于猜想2，第二种benchmark测试结果"><figcaption>图7：对于猜想2，第二种benchmark测试结果</figcaption></figure></p><h4 id="第三种-Benchmark：20-Jobs-×-500-Pods-1"><a href="#第三种-Benchmark：20-Jobs-×-500-Pods-1" class="headerlink" title="第三种 Benchmark：20 Jobs × 500 Pods"></a>第三种 Benchmark：20 Jobs × 500 Pods</h4><p><strong>测试参数</strong>：每个Job有500Pod，共20个Job，共10kPod</p><p><strong>实际结果</strong>：<strong>✅有显著变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果完全不同，结果恢复为符合预期的正常状态“创建Pod数量达10000”。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/2-long-webhook-timeout/c.NoGang-20Job-no/output/panel-5.png?raw=true" alt="图8：对于猜想2，第三种benchmark测试结果"><figcaption>图8：对于猜想2，第三种benchmark测试结果</figcaption></figure></p><h4 id="第四种-Benchmark：1-Job-×-10K-Pods-1"><a href="#第四种-Benchmark：1-Job-×-10K-Pods-1" class="headerlink" title="第四种 Benchmark：1 Job × 10K Pods"></a>第四种 Benchmark：1 Job × 10K Pods</h4><p><strong>实际结果</strong>：<strong>✅有显著变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果完全不同，结果恢复为符合预期的正常状态“创建Pod数量达10000”。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/2-long-webhook-timeout/d.NoGang-1Job-no/output/panel-5.png?raw=true" alt="图9：对于猜想2，第四种benchmark测试结果"><figcaption>图9：对于猜想2，第四种benchmark测试结果</figcaption></figure></p><h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p><strong>实验结论</strong>：webhook超时确实是导致性能测试异常的主要原因</p><p><strong>关键发现</strong>：</p><ul><li><strong>benchmark3和benchmark4</strong>：从”创建Pod数量不到1000”恢复为正常状态”创建Pod数量达10000”</li><li><strong>性能恢复</strong>：Pod创建成功率从1.3%提升到接近100%</li><li><strong>测试稳定性</strong>：大规模Pod创建测试能够正常完成</li></ul><p><strong>分析说明</strong>：webhook超时时间过短（10秒）无法处理大量并发Pod创建请求，导致请求堆积和失败。将超时时间延长到30秒后，系统能够正常处理高并发负载。这也为我们指出了在大规模下需要注意的配置问题。</p><h2 id="猜想3：Volcano版本较低可能导致性能测试结果异常"><a href="#猜想3：Volcano版本较低可能导致性能测试结果异常" class="headerlink" title="猜想3：Volcano版本较低可能导致性能测试结果异常"></a>猜想3：Volcano版本较低可能导致性能测试结果异常</h2><h3 id="3-1-猜想依据"><a href="#3-1-猜想依据" class="headerlink" title="3.1 猜想依据"></a>3.1 猜想依据</h3><p>基于版本差异可能带来的影响，我们猜测：</p><ul><li><strong>性能优化差异</strong>：新版本可能包含重要的性能优化</li><li><strong>算法改进差异</strong>：调度算法可能在新版本中有显著改进</li><li><strong>配置默认值差异</strong>：新版本的默认配置可能更适合大规模测试</li></ul><h3 id="3-2-实验设计"><a href="#3-2-实验设计" class="headerlink" title="3.2 实验设计"></a>3.2 实验设计</h3><p>我们通过将Volcano版本从v1.11.0升级到v1.12.0-alpha.0来验证这一猜想：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 批量替换版本号</span></span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/*/deployment.yaml</span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/*/job.yaml</span><br></pre></td></tr></table></figure></div><h3 id="3-3-实验结果"><a href="#3-3-实验结果" class="headerlink" title="3.3 实验结果"></a>3.3 实验结果</h3><h4 id="第一种-Benchmark：10K-Jobs-×-1-Pod-2"><a href="#第一种-Benchmark：10K-Jobs-×-1-Pod-2" class="headerlink" title="第一种 Benchmark：10K Jobs × 1 Pod"></a>第一种 Benchmark：10K Jobs × 1 Pod</h4><p><strong>测试参数</strong>：每个Job只有1个Pod，共10K个Job，共10kPod</p><p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与验证猜想2时的结果几乎一致。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="图10：对于猜想3，第一种benchmark测试结果"><figcaption>图10：对于猜想3，第一种benchmark测试结果</figcaption></figure></p><h4 id="第二种-Benchmark：500-Jobs-×-20-Pods-2"><a href="#第二种-Benchmark：500-Jobs-×-20-Pods-2" class="headerlink" title="第二种 Benchmark：500 Jobs × 20 Pods"></a>第二种 Benchmark：500 Jobs × 20 Pods</h4><p><strong>测试参数</strong>：每个Job有20个Pod，共500个Job，共10kPod</p><p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与验证猜想2时的结果几乎一致。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/b.NoGang-500Job-no/output/panel-5.png?raw=true" alt="图11：对于猜想3，第二种benchmark测试结果"><figcaption>图11：对于猜想3，第二种benchmark测试结果</figcaption></figure></p><h4 id="第三种-Benchmark：20-Jobs-×-500-Pods-2"><a href="#第三种-Benchmark：20-Jobs-×-500-Pods-2" class="headerlink" title="第三种 Benchmark：20 Jobs × 500 Pods"></a>第三种 Benchmark：20 Jobs × 500 Pods</h4><p><strong>测试参数</strong>：每个Job有500Pod，共20个Job，共10kPod</p><p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与验证猜想2时的结果几乎一致。但CREATE速度似乎更快了些（也有可能只是随机波动）。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/c.NoGang-20Job-no/output/panel-5.png?raw=true" alt="图12：对于猜想3，第三种benchmark测试结果"><figcaption>图12：对于猜想3，第三种benchmark测试结果</figcaption></figure></p><h4 id="第四种-Benchmark：1-Job-×-10K-Pods-2"><a href="#第四种-Benchmark：1-Job-×-10K-Pods-2" class="headerlink" title="第四种 Benchmark：1 Job × 10K Pods"></a>第四种 Benchmark：1 Job × 10K Pods</h4><p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与验证猜想2时的结果几乎一致。但CREATE速度似乎更快了些（也有可能只是随机波动）。</p><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/d.NoGang-1Job-no/output/panel-5.png?raw=true" alt="图13：对于猜想3，第四种benchmark测试结果"><figcaption>图13：对于猜想3，第四种benchmark测试结果</figcaption></figure></p><h4 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h4><p><strong>实验结论</strong>：Volcano版本不是导致性能测试结果差异的主要原因</p><p><strong>关键发现</strong>：</p><ul><li>升级到v1.12.0-alpha.0后，测试结果与前期本地测试结果基本一致</li><li>CREATED事件的异常现象仍然存在</li><li>调度性能没有显著改善</li></ul><p><strong>分析说明</strong>：虽然版本升级可能带来一些改进，但核心的性能瓶颈问题仍然存在。这表明性能差异主要源于配置和架构层面的问题，而非版本本身。</p><h2 id="猜想4：webhook处理可能是性能瓶颈"><a href="#猜想4：webhook处理可能是性能瓶颈" class="headerlink" title="猜想4：webhook处理可能是性能瓶颈"></a>猜想4：webhook处理可能是性能瓶颈</h2><h3 id="4-1-猜想依据"><a href="#4-1-猜想依据" class="headerlink" title="4.1 猜想依据"></a>4.1 猜想依据</h3><p>基于webhook系统的复杂性，我们猜测webhook处理本身可能成为性能瓶颈：</p><ul><li><strong>多次判断开销</strong>：每个Pod创建请求需要经过多个webhook验证</li><li><strong>TLS证书验证</strong>：每次webhook调用都需要进行TLS验证</li><li><strong>网络延迟</strong>：webhook服务调用可能引入额外的网络延迟</li></ul><h3 id="4-2-实验设计"><a href="#4-2-实验设计" class="headerlink" title="4.2 实验设计"></a>4.2 实验设计</h3><p>我们通过<a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="完全禁用webhook功能">完全禁用webhook功能</a>来验证这一猜想：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除所有webhook配置，保留admission服务</span></span><br><span class="line">make disable-volcano-webhooks</span><br></pre></td></tr></table></figure></div><h3 id="4-3-实验结果"><a href="#4-3-实验结果" class="headerlink" title="4.3 实验结果"></a>4.3 实验结果</h3><h4 id="第一种-Benchmark：10K-Jobs-×-1-Pod-3"><a href="#第一种-Benchmark：10K-Jobs-×-1-Pod-3" class="headerlink" title="第一种 Benchmark：10K Jobs × 1 Pod"></a>第一种 Benchmark：10K Jobs × 1 Pod</h4><p><strong>测试参数</strong>：每个Job只有1个Pod，共10K个Job，共10kPod</p><p><strong>实际结果</strong>：<strong>✅性能明显上升</strong>。如下两图对比所示，整体斜率比前期测试结果更大，说明CREATED和SCHEDULE的速度更快。</p><p>优化前：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="图10：对于猜想3，第一种benchmark测试结果"><figcaption>图10：对于猜想3，第一种benchmark测试结果</figcaption></figure></p><p>优化后：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="图14：对于猜想4，第一种benchmark测试结果"><figcaption>图14：对于猜想4，第一种benchmark测试结果</figcaption></figure></p><h4 id="第二种-Benchmark：500-Jobs-×-20-Pods-3"><a href="#第二种-Benchmark：500-Jobs-×-20-Pods-3" class="headerlink" title="第二种 Benchmark：500 Jobs × 20 Pods"></a>第二种 Benchmark：500 Jobs × 20 Pods</h4><p><strong>测试参数</strong>：每个Job有20个Pod，共500个Job，共10kPod</p><p><strong>实际结果</strong>：<strong>✅性能略有上升</strong>。如下两图对比所示，CREATE斜率比前期测试结果更大（甚至好几段近乎直线上升），说明CREATED的速度显著上升；但与此同时需要注意的是，<strong>CREATE仍然存在阶梯状</strong>突变，证明CREATE瓶颈仍然需要通过其他方式解决。</p><p>优化前：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/b.NoGang-500Job-no/output/panel-5.png?raw=true" alt="图11：对于猜想3，第二种benchmark测试结果"><figcaption>图11：对于猜想3，第二种benchmark测试结果</figcaption></figure></p><p>优化后：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/b.NoGang-500Job-no/output/panel-5.png?raw=true" alt="图15：对于猜想4，第二种benchmark测试结果"><figcaption>图15：对于猜想4，第二种benchmark测试结果</figcaption></figure></p><h4 id="第三种-Benchmark：20-Jobs-×-500-Pods-3"><a href="#第三种-Benchmark：20-Jobs-×-500-Pods-3" class="headerlink" title="第三种 Benchmark：20 Jobs × 500 Pods"></a>第三种 Benchmark：20 Jobs × 500 Pods</h4><p><strong>测试参数</strong>：每个Job有500Pod，共20个Job，共10kPod</p><p><strong>✅性能明显上升</strong>。如下两图对比所示，整体斜率比前期测试结果更大，说明CREATED和SCHEDULE的速度更快。同时也注意到，即便如此也还是比另外两种调度器更慢些，意味着SCHEDULE部分调度性能本身也还有优化空间。</p><p>优化前：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/c.NoGang-20Job-no/output/panel-5.png?raw=true" alt="图12：对于猜想3，第三种benchmark测试结果"><figcaption>图12：对于猜想3，第三种benchmark测试结果</figcaption></figure></p><p>优化后：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/c.NoGang-20Job-no/output/panel-5.png?raw=true" alt="图16：对于猜想4，第三种benchmark测试结果"><figcaption>图16：对于猜想4，第三种benchmark测试结果</figcaption></figure></p><h4 id="第四种-Benchmark：1-Job-×-10K-Pods-3"><a href="#第四种-Benchmark：1-Job-×-10K-Pods-3" class="headerlink" title="第四种 Benchmark：1 Job × 10K Pods"></a>第四种 Benchmark：1 Job × 10K Pods</h4><p><strong>✅性能明显上升</strong>。如下两图对比所示，整体斜率比前期测试结果更大，说明CREATED和SCHEDULE的速度更快。同时和benchmark3一样，也注意到，即便如此也还是比另外两种调度器更慢些，意味着SCHEDULE部分调度性能本身也还有优化空间。</p><p>优化前：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/d.NoGang-1Job-no/output/panel-5.png?raw=true" alt="图13：对于猜想3，第四种benchmark测试结果"><figcaption>图13：对于猜想3，第四种benchmark测试结果</figcaption></figure></p><p>优化后：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/d.NoGang-1Job-no/output/panel-5.png?raw=true" alt="图17：对于猜想4，第四种benchmark测试结果"><figcaption>图17：对于猜想4，第四种benchmark测试结果</figcaption></figure></p><h4 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h4><p><strong>实验结论</strong>：webhook处理确实是重要的性能瓶颈</p><p><strong>关键发现</strong>：禁用webhook后，性能获得较大提升，Pod创建/调度速度显著加快，调度器整体性能表现改善</p><p><strong>分析说明</strong>：webhook系统虽然提供了重要的验证和修改功能，但在大规模Pod创建场景下，其处理开销成为了性能瓶颈。禁用webhook后，系统能够更直接地处理Pod创建请求，从而提升整体性能。</p><h2 id="猜想5：Volcano批处理机制可能导致CREATED阶段瓶颈"><a href="#猜想5：Volcano批处理机制可能导致CREATED阶段瓶颈" class="headerlink" title="猜想5：Volcano批处理机制可能导致CREATED阶段瓶颈"></a>猜想5：Volcano批处理机制可能导致CREATED阶段瓶颈</h2><h3 id="5-1-猜想依据"><a href="#5-1-猜想依据" class="headerlink" title="5.1 猜想依据"></a>5.1 猜想依据</h3><p>基于<a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="视频分析">视频分析</a>，我们注意到在benchmark1和benchmark2下，CREATED阶段成为性能瓶颈。视频中提到Volcano会”create pod in Batch”，即分批处理Job，当一批Job处理完后才会继续处理下一批Job。</p><p>这种批处理机制可能导致：</p><ul><li><strong>CREATED事件阶段性突变</strong>：批处理完成后，下一批Job的Pod创建会出现集中爆发</li><li><strong>资源浪费</strong>：批处理期间资源可能被闲置，且批处理完成后资源竞争激烈</li></ul><h3 id="5-2-实验验证"><a href="#5-2-实验验证" class="headerlink" title="5.2 实验验证"></a>5.2 实验验证</h3><p>虽然我们没有针对这一猜想进行专门的测试，但从前面所有实验结果都能证明这一点（尤其是benchmark1和benchmark2）：</p><ol><li><strong>enqueue实验</strong>：禁用enqueue后，CREATED事件仍然出现阶段性突变，说明问题不在enqueue阶段</li><li><strong>webhook超时实验</strong>：修复超时问题后，Pod创建数量恢复正常，但CREATED的阶段性特征仍然存在</li><li><strong>版本升级实验</strong>：升级到v1.12.0-alpha.0后，CREATED事件的异常现象仍然存在</li><li><strong>webhook禁用实验</strong>：即使禁用webhook，在Job数量较多时仍然存在Pod创建瓶颈</li></ol><p>这些实验结果的一致性表明，CREATED阶段的瓶颈问题源于更深层的架构设计，即Volcano的批处理机制。</p><h3 id="5-3-实验结论"><a href="#5-3-实验结论" class="headerlink" title="5.3 实验结论"></a>5.3 实验结论</h3><p><strong>实验结论</strong>：Volcano的批处理机制确实是CREATED阶段性能瓶颈的根本原因</p><p><strong>关键发现</strong>：</p><ul><li>批处理机制导致Pod创建出现阶段性突变</li><li>这种瓶颈无法通过调整配置参数完全解决</li><li>需要从架构层面进行优化</li></ul><p><strong>分析说明</strong>：Volcano的批处理设计虽然在某些场景下有利于资源管理和调度优化，但在大规模、高并发的Pod创建场景下，这种同步批处理机制成为了性能瓶颈。系统需要等待当前批次完成才能开始下一批次的处理，无法实现真正的并行流水线。</p><h1 id="📊实验结果综合分析"><a href="#📊实验结果综合分析" class="headerlink" title="📊实验结果综合分析"></a>📊实验结果综合分析</h1><table><thead><tr><th>猜想</th><th>验证方法</th><th>实验结果</th><th>结论</th></tr></thead><tbody><tr><td><strong>enqueue功能瓶颈</strong></td><td>禁用enqueue阶段</td><td>性能无显著改善</td><td>❌ 不是主要瓶颈</td></tr><tr><td><strong>webhook超时问题</strong></td><td>延长超时时间</td><td>Pod创建恢复正常</td><td>✅ 是重要瓶颈</td></tr><tr><td><strong>版本差异影响</strong></td><td>升级到v1.12.0-alpha.0</td><td>性能无显著改善</td><td>❌ 不是主要瓶颈</td></tr><tr><td><strong>webhook处理瓶颈</strong></td><td>完全禁用webhook</td><td>性能大幅提升</td><td>✅ 是主要瓶颈</td></tr><tr><td><strong>批处理机制瓶颈</strong></td><td>综合分析所有实验结果</td><td>CREATED阶段性突变“卡顿”问题持续存在</td><td>✅ 是根本瓶颈</td></tr></tbody></table><h1 id="🚀未来方向"><a href="#🚀未来方向" class="headerlink" title="🚀未来方向"></a>🚀未来方向</h1><h2 id="1-短期优化方案"><a href="#1-短期优化方案" class="headerlink" title="1. 短期优化方案"></a>1. 短期优化方案</h2><h3 id="1-1-调整webhook超时时间"><a href="#1-1-调整webhook超时时间" class="headerlink" title="1.1 调整webhook超时时间"></a>1.1 调整webhook超时时间</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将webhook超时时间从10秒增加到30秒</span></span><br><span class="line"><span class="attr">timeoutSeconds:</span> <span class="number">30</span>  <span class="comment"># 原始：timeoutSeconds: 10</span></span><br></pre></td></tr></table></figure></div><p><strong>适用场景</strong>：需要保持webhook功能完整性的生产环境<br><strong>优化效果</strong>：解决超时导致的测试异常问题</p><h3 id="1-2-优化webhook资源配置"><a href="#1-2-优化webhook资源配置" class="headerlink" title="1.2 优化webhook资源配置"></a>1.2 优化webhook资源配置</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 增加webhook服务的资源限制</span></span><br><span class="line"><span class="attr">resources:</span></span><br><span class="line">  <span class="attr">requests:</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">"512Mi"</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">"500m"</span></span><br><span class="line">  <span class="attr">limits:</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">"1Gi"</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">"1000m"</span></span><br></pre></td></tr></table></figure></div><p><strong>适用场景</strong>：资源受限但需要webhook功能的环境<br><strong>优化效果</strong>：提升webhook处理能力</p><h2 id="2-长期优化方向"><a href="#2-长期优化方向" class="headerlink" title="2. 长期优化方向"></a>2. 长期优化方向</h2><h3 id="2-1-替代webhook的验证机制"><a href="#2-1-替代webhook的验证机制" class="headerlink" title="2.1 替代webhook的验证机制"></a>2.1 替代webhook的验证机制</h3><p>基于<a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="我们的实验发现">我们的实验发现</a>，未来可以考虑：</p><ol><li><strong>加强Controller校验</strong>：将必要的校验功能转移到 Volcano Controller Manager（例如空指针判断等），为简单场景下禁用 webhook 做支撑</li><li><strong>使用CRD规则校验</strong>：或使用通用表达式语言（CEL）来实现K8s准入校验规则，验证CRD的值（使用 K8s v1.29 [stabe] x-kubernetes-validations 扩展），实现利用 Kubernetes CRD 的验证功能替代部分 validating webhook</li></ol><h3 id="2-2-优化CREATED批处理阻塞瓶颈“卡顿”问题"><a href="#2-2-优化CREATED批处理阻塞瓶颈“卡顿”问题" class="headerlink" title="2.2 优化CREATED批处理阻塞瓶颈“卡顿”问题"></a>2.2 优化CREATED批处理阻塞瓶颈“卡顿”问题</h3><p>基于第五个猜想的验证结果，针对Volcano批处理机制的根本性瓶颈，未来可以考虑：</p><ol><li><strong>动态批次调整</strong>：根据系统负载动态调整批次大小，避免资源闲置和突发负载</li><li><strong>异步批处理</strong>：将同步批处理改为异步处理，不阻塞下一批Job的Pod创建</li><li><strong>流水线优化</strong>：设计真正的流水线机制，实现Pod创建、验证、调度的并行处理</li></ol><!-- ### 2.3 异步处理机制设计异步的Pod验证和修改机制：1. **异步验证**：Pod创建后异步进行验证，不阻塞创建流程2. **批量处理**：将多个验证请求批量处理，提高效率3. **缓存机制**：缓存验证结果，减少重复计算--><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a href="!--swig%EF%BF%BC37--">[2] <a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></a></p><p><a href="!--swig%EF%BF%BC39--">[3] <a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></a></p><p><a href="!--swig%EF%BF%BC41--">[4] <a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></a></p><p><a href="!--swig%EF%BF%BC43--">[5] <a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></a></p><p><a href="!--swig%EF%BF%BC45--">[6] <a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></a></p><p><a href="!--swig%EF%BF%BC47--">[7] <a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/">[8] Kubernetes 文档 - Admission Controllers 准入控制 <i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/blog/2022/09/23/crd-validation-rules-beta/">[9] Kubernetes 文档 - Kubernetes 1.25: CustomResourceDefinition Validation Rules Graduate to Beta<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions">[10] Kubernetes 文档 - 使用 CustomResourceDefinition 扩展 Kubernetes API<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#validation">[11] Kubernetes 文档 - CRD Validation 合法性检查<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#validation-rules">[12] Kubernetes 文档 - CRD Validation Rules 合法性检查规则<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#validation-rules">[13] Kubernetes 文档 - CRD Validation Rules 合法性检查规则（K8s v1.29 [stabe]）<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/validating-admission-policy/">[14] Kubernetes 文档 - 验证准入策略（ValidatingAdmissionPolicy）（K8s v1.30 [stable]）<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://liangyuanpeng.com/post/k8s-admissionregistration-with-cel/">[15] 用cel表达式来实现k8s准入校验<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">本文总结了针对Volcano调度器性能测试结果异常的四种猜想及其验证实验，包括enqueue功能、webhook超时、版本差异和webhook处理瓶颈。通过系统性的实验验证，我们成功识别了webhook超时和webhook处理是主要的性能瓶颈，为调度器优化提供了重要参考。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="调度器" scheme="https://freshwlnd.github.io/tags/%E8%B0%83%E5%BA%A6%E5%99%A8/"/>
    
    <category term="K8s" scheme="https://freshwlnd.github.io/tags/K8s/"/>
    
    <category term="性能测试" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
    <category term="Volcano" scheme="https://freshwlnd.github.io/tags/Volcano/"/>
    
    <category term="性能瓶颈" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88/"/>
    
    <category term="实验验证" scheme="https://freshwlnd.github.io/tags/%E5%AE%9E%E9%AA%8C%E9%AA%8C%E8%AF%81/"/>
    
    <category term="系统优化" scheme="https://freshwlnd.github.io/tags/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>【集群】云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</title>
    <link href="https://freshwlnd.github.io/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/"/>
    <id>https://freshwlnd.github.io/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/</id>
    <published>2025-08-22T14:55:54.000Z</published>
    <updated>2025-09-18T11:08:24.525Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p><ol><li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li><li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li><li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li><li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li><li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li><li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li><li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li><li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li><li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li><li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li><li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li><li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li><li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li><li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a></li></ol></blockquote><h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="上一篇博客">上一篇博客</a>中，我们通过修改webhook超时时间解决了Pod创建数量不足的问题。然而，在实际测试过程中，我们发现webhook本身可能成为性能瓶颈，特别是在大规模Job提交的场景下。</p><p>本文详细介绍了如何通过修改<code>kube-scheduling-perf</code>的Makefile来完全禁用Volcano的webhook功能，分析了webhook对调度性能的影响，并探讨了未来通过CRD替代webhook的可能性。通过实验发现，即使禁用webhook，在Job数量较多时仍然存在Pod创建瓶颈，这为后续的调度器优化提供了重要参考。</p><h1 id="🖼️背景需求分析"><a href="#🖼️背景需求分析" class="headerlink" title="🖼️背景需求分析"></a>🖼️背景需求分析</h1><h2 id="1-Webhook性能瓶颈问题"><a href="#1-Webhook性能瓶颈问题" class="headerlink" title="1. Webhook性能瓶颈问题"></a>1. Webhook性能瓶颈问题</h2><h3 id="1-1-多次判断的性能开销"><a href="#1-1-多次判断的性能开销" class="headerlink" title="1.1 多次判断的性能开销"></a>1.1 多次判断的性能开销</h3><p>Volcano的webhook系统包含多个组件，每个Pod创建请求都需要经过：</p><ol><li><strong>Mutating Webhook</strong>：修改Pod配置（如添加<code>maxRetry</code>、<code>minAvailable</code>等字段）</li><li><strong>Validating Webhook</strong>：验证Pod配置的合法性</li><li><strong>Admission Service</strong>：处理webhook请求的服务</li><li><strong>TLS证书验证</strong>：确保webhook调用的安全性</li></ol><p>在<a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="之前的测试">之前的测试</a>中，我们发现webhook超时成为了Pod创建失败的主要原因，98.7%的请求因超时而失败。</p><h3 id="1-2-替代方案的可能性"><a href="#1-2-替代方案的可能性" class="headerlink" title="1.2 替代方案的可能性"></a>1.2 替代方案的可能性</h3><p>考虑到现代Kubernetes版本的发展趋势，webhook的某些功能可以通过以下方式替代：</p><ol><li><strong>加强Controller校验</strong>：将必要的校验功能转移到 Volcano Controller Manager（例如空指针判断等），为简单场景下禁用 webhook 做支撑</li><li><strong>使用CRD规则校验</strong>：或使用通用表达式语言（CEL）来实现K8s准入校验规则，验证CRD的值（使用 K8s v1.29 [stabe] x-kubernetes-validations 扩展），实现利用 Kubernetes CRD 的验证功能替代部分 Validating Webhook</li><li><strong>预配置模板</strong>：通过提前配置Job模板，减少运行时的修改需求</li></ol><h3 id="1-3-性能测试需求"><a href="#1-3-性能测试需求" class="headerlink" title="1.3 性能测试需求"></a>1.3 性能测试需求</h3><p>为了准确评估webhook对调度性能的影响，我们需要：</p><ul><li><strong>基准测试</strong>：在有webhook的情况下进行性能测试</li><li><strong>对比测试</strong>：在禁用webhook的情况下进行相同的性能测试</li><li><strong>瓶颈分析</strong>：识别webhook是否是真正的性能瓶颈</li></ul><h1 id="🔧方案设计与实现"><a href="#🔧方案设计与实现" class="headerlink" title="🔧方案设计与实现"></a>🔧方案设计与实现</h1><h2 id="1-整体设计思路"><a href="#1-整体设计思路" class="headerlink" title="1. 整体设计思路"></a>1. 整体设计思路</h2><h3 id="1-1-保留核心组件"><a href="#1-1-保留核心组件" class="headerlink" title="1.1 保留核心组件"></a>1.1 保留核心组件</h3><p>我们采用<strong>选择性禁用</strong>的策略，只删除webhook配置，保留其他重要组件：</p><ul><li>✅ <strong>保留</strong>：<code>volcano-admission</code> deployment、<code>volcano-admission-service</code>、<code>volcano-admission-init</code> job</li><li>❌ <strong>删除</strong>：所有<code>MutatingWebhookConfiguration</code>和<code>ValidatingWebhookConfiguration</code></li></ul><h3 id="1-2-实现方式"><a href="#1-2-实现方式" class="headerlink" title="1.2 实现方式"></a>1.2 实现方式</h3><p>通过修改<code>./clusters/volcano/Makefile</code>，在Volcano部署完成后自动删除webhook配置：</p><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: disable-volcano-webhooks</span></span><br><span class="line"><span class="section">disable-volcano-webhooks:</span></span><br><span class="line"><span class="comment"># 只删除webhook配置，保留admission服务和初始化组件</span></span><br><span class="line"><span class="comment"># 删除所有MutatingWebhookConfiguration</span></span><br><span class="line">-KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl delete mutatingwebhookconfiguration volcano-admission-service-jobs-mutate</span><br><span class="line">-KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl delete mutatingwebhookconfiguration volcano-admission-service-podgroups-mutate</span><br><span class="line">-KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl delete mutatingwebhookconfiguration volcano-admission-service-pods-mutate</span><br><span class="line">-KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl delete mutatingwebhookconfiguration volcano-admission-service-queues-mutate</span><br><span class="line"><span class="comment"># 删除所有ValidatingWebhookConfiguration</span></span><br><span class="line">-KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl delete validatingwebhookconfiguration volcano-admission-service-jobs-validate</span><br><span class="line">-KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl delete validatingwebhookconfiguration volcano-admission-service-pods-validate</span><br><span class="line">-KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl delete validatingwebhookconfiguration volcano-admission-service-queues-validate</span><br><span class="line">@echo <span class="string">"Volcano webhook configurations have been disabled, but admission service and init components are preserved"</span></span><br></pre></td></tr></table></figure></div><h2 id="2-具体实现步骤"><a href="#2-具体实现步骤" class="headerlink" title="2. 具体实现步骤"></a>2. 具体实现步骤</h2><h3 id="2-1-修改Makefile"><a href="#2-1-修改Makefile" class="headerlink" title="2.1 修改Makefile"></a>2.1 修改Makefile</h3><p>在<code>clusters/volcano/Makefile</code>中，我们添加了多个webhook控制选项：</p><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 完全禁用webhook</span></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: disable-volcano-webhooks</span></span><br><span class="line"><span class="section">disable-volcano-webhooks:</span></span><br><span class="line"><span class="comment"># 删除所有webhook配置</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 只禁用mutating webhook</span></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: disable-volcano-mutating-webhooks</span></span><br><span class="line"><span class="section">disable-volcano-mutating-webhooks:</span></span><br><span class="line"><span class="comment"># 只删除MutatingWebhookConfiguration</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 只禁用validating webhook</span></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: disable-volcano-validating-webhooks</span></span><br><span class="line"><span class="section">disable-volcano-validating-webhooks:</span></span><br><span class="line"><span class="comment"># 只删除ValidatingWebhookConfiguration</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新启用webhook</span></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: enable-volcano-webhooks</span></span><br><span class="line"><span class="section">enable-volcano-webhooks:</span></span><br><span class="line"><span class="comment"># 重新创建所有webhook配置</span></span><br></pre></td></tr></table></figure></div><h3 id="2-2-集成到部署流程"><a href="#2-2-集成到部署流程" class="headerlink" title="2.2 集成到部署流程"></a>2.2 集成到部署流程</h3><p>在<code>up</code>目标中集成webhook禁用：</p><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: up</span></span><br><span class="line"><span class="section">up: \</span></span><br><span class="line">create-cluster</span><br><span class="line">make wait</span><br><span class="line">make -j 2 \</span><br><span class="line">create-kwok \</span><br><span class="line">create-volcano</span><br><span class="line">make disable-volcano-webhooks  <span class="comment"># 自动禁用webhook</span></span><br><span class="line">make limit-built-controller-manager</span><br><span class="line">make uncordon</span><br></pre></td></tr></table></figure></div><h2 id="3-技术细节说明"><a href="#3-技术细节说明" class="headerlink" title="3. 技术细节说明"></a>3. 技术细节说明</h2><h3 id="3-1-Webhook配置类型"><a href="#3-1-Webhook配置类型" class="headerlink" title="3.1 Webhook配置类型"></a>3.1 Webhook配置类型</h3><p>我们禁用的webhook配置包括：</p><table><thead><tr><th>类型</th><th>配置名称</th><th>功能描述</th></tr></thead><tbody><tr><td><strong>Mutating</strong></td><td><code>volcano-admission-service-jobs-mutate</code></td><td>修改Job配置，添加<code>maxRetry</code>等字段</td></tr><tr><td><strong>Mutating</strong></td><td><code>volcano-admission-service-podgroups-mutate</code></td><td>修改PodGroup配置</td></tr><tr><td><strong>Mutating</strong></td><td><code>volcano-admission-service-pods-mutate</code></td><td>修改Pod配置</td></tr><tr><td><strong>Mutating</strong></td><td><code>volcano-admission-service-queues-mutate</code></td><td>修改Queue配置</td></tr><tr><td><strong>Validating</strong></td><td><code>volcano-admission-service-jobs-validate</code></td><td>验证Job配置合法性</td></tr><tr><td><strong>Validating</strong></td><td><code>volcano-admission-service-pods-validate</code></td><td>验证Pod配置合法性</td></tr><tr><td><strong>Validating</strong></td><td><code>volcano-admission-service-queues-validate</code></td><td>验证Queue配置合法性</td></tr></tbody></table><h3 id="3-2-保留组件的原因"><a href="#3-2-保留组件的原因" class="headerlink" title="3.2 保留组件的原因"></a>3.2 保留组件的原因</h3><p>我们选择保留以下组件的原因：</p><ol><li><strong><code>volcano-admission</code> deployment</strong>：保持服务架构完整性，避免其他组件依赖问题</li><li>**<code>volcano-admission-service</code>**：维持网络服务，避免服务发现失败</li><li><strong><code>volcano-admission-init</code> job</strong>：继续生成TLS证书，确保系统安全性</li></ol><h1 id="🚀未来展望与优化方向"><a href="#🚀未来展望与优化方向" class="headerlink" title="🚀未来展望与优化方向"></a>🚀未来展望与优化方向</h1><h2 id="1-CRD替代Webhook的可能性"><a href="#1-CRD替代Webhook的可能性" class="headerlink" title="1. CRD替代Webhook的可能性"></a>1. CRD替代Webhook的可能性</h2><h3 id="1-1-Kubernetes版本演进"><a href="#1-1-Kubernetes版本演进" class="headerlink" title="1.1 Kubernetes版本演进"></a>1.1 Kubernetes版本演进</h3><p>从Kubernetes 1.16开始，CRD支持更强大的验证和默认值设置：</p><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">validation:</span></span><br><span class="line">    <span class="attr">openAPIV3Schema:</span></span><br><span class="line">      <span class="comment"># 可以定义复杂的验证规则</span></span><br><span class="line">  <span class="attr">defaulting:</span></span><br><span class="line">    <span class="comment"># 可以设置默认值</span></span><br></pre></td></tr></table></figure></div><h3 id="1-2-替代方案设计"><a href="#1-2-替代方案设计" class="headerlink" title="1.2 替代方案设计"></a>1.2 替代方案设计</h3><p>未来可以考虑通过以下方式替代webhook：</p><ol><li><strong>CRD验证规则</strong>：在Job CRD中定义验证规则，替代validating webhook</li><li><strong>默认值设置</strong>：通过CRD的defaulting功能，替代mutating webhook</li><li><strong>准入策略</strong>：使用Pod Security Standards等内置策略</li></ol><h3 id="1-3-实现路径"><a href="#1-3-实现路径" class="headerlink" title="1.3 实现路径"></a>1.3 实现路径</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示例：通过CRD实现Job验证</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">jobs.batch.volcano.sh</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">validation:</span></span><br><span class="line">    <span class="attr">openAPIV3Schema:</span></span><br><span class="line">      <span class="attr">properties:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">properties:</span></span><br><span class="line">            <span class="attr">maxRetry:</span></span><br><span class="line">              <span class="attr">type:</span> <span class="string">integer</span></span><br><span class="line">              <span class="attr">minimum:</span> <span class="number">1</span></span><br><span class="line">              <span class="attr">maximum:</span> <span class="number">10</span></span><br><span class="line">            <span class="attr">minAvailable:</span></span><br><span class="line">              <span class="attr">type:</span> <span class="string">integer</span></span><br><span class="line">              <span class="attr">minimum:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">defaulting:</span></span><br><span class="line">    <span class="attr">openAPIV3Schema:</span></span><br><span class="line">      <span class="attr">properties:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">properties:</span></span><br><span class="line">            <span class="attr">maxRetry:</span></span><br><span class="line">              <span class="attr">default:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure></div><h2 id="2-Controller调度逻辑优化"><a href="#2-Controller调度逻辑优化" class="headerlink" title="2. Controller调度逻辑优化"></a>2. Controller调度逻辑优化</h2><p>基于测试结果，我们发现前期确定的优化点仍然存在。具体而言：</p><ol><li><strong>实验结果发现</strong>：即使禁用了webhook，在Job数量很多时仍然存在<a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="前期测试">前期测试</a>中提到的Pod CREATE 瓶颈。</li><li><strong>可能原因</strong>：Volcano会分批处理Job并CREATE Pod，当Job数量多时CREATE速度比SCHEDULE速度慢而成为瓶颈。</li><li><strong>后续思路</strong>：可以通过检查和修改controller的调度逻辑来进行优化。</li></ol><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a href="!--swig%EF%BF%BC23--">[2] <a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></a></p><p><a href="!--swig%EF%BF%BC25--">[3] <a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></a></p><p><a class="link" href="https://volcano.sh/zh/docs/architecture/">[4] Volcano 文档 - 架构<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/blog/2022/09/23/crd-validation-rules-beta/">[5] Kubernetes 文档 - Kubernetes 1.25: CustomResourceDefinition Validation Rules Graduate to Beta<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions">[6] Kubernetes 文档 - 使用 CustomResourceDefinition 扩展 Kubernetes API<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#validation">[7] Kubernetes 文档 - CRD Validation 合法性检查<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#validation-rules">[8] Kubernetes 文档 - CRD Validation Rules 合法性检查规则<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#validation-rules">[9] Kubernetes 文档 - CRD Validation Rules 合法性检查规则（K8s v1.29 [stabe]）<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/validating-admission-policy/">[10] Kubernetes 文档 - 验证准入策略（ValidatingAdmissionPolicy）（K8s v1.30 [stable]）<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://liangyuanpeng.com/post/k8s-admissionregistration-with-cel/">[11] 用cel表达式来实现k8s准入校验<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a href="!--swig%EF%BF%BC27--">[12] <a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></a> </p>]]></content>
    
    
    <summary type="html">本文详细介绍了如何通过修改kube-scheduling-perf的Makefile来禁用Volcano的webhook功能，分析了webhook对调度性能的影响，并探讨了未来通过CRD替代webhook的可能性。通过实验发现，即使禁用webhook，在Job数量较多时仍然存在Pod创建瓶颈，这为后续的调度器优化提供了重要参考。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="Webhook" scheme="https://freshwlnd.github.io/tags/Webhook/"/>
    
    <category term="调度器" scheme="https://freshwlnd.github.io/tags/%E8%B0%83%E5%BA%A6%E5%99%A8/"/>
    
    <category term="性能优化" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    
    <category term="K8s" scheme="https://freshwlnd.github.io/tags/K8s/"/>
    
    <category term="性能测试" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
    <category term="Volcano" scheme="https://freshwlnd.github.io/tags/Volcano/"/>
    
    <category term="CRD" scheme="https://freshwlnd.github.io/tags/CRD/"/>
    
  </entry>
  
  <entry>
    <title>【集群】云原生批调度实战：Volcano版本修改与性能测试优化</title>
    <link href="https://freshwlnd.github.io/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/"/>
    <id>https://freshwlnd.github.io/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/</id>
    <published>2025-08-19T17:25:19.000Z</published>
    <updated>2025-09-18T07:27:36.925Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p><ol><li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li><li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li><li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li><li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li><li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li><li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li><li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li><li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li><li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li><li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li><li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li><li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li><li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li><li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a></li></ol></blockquote><h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地环境测试结果与视频对比分析">本地环境测试结果与视频对比分析</a>中，我们发现本地测试结果与KubeCon技术分享视频中的结果存在显著差异。虽然整体趋势基本一致，但在某些测试场景下，本地测试的CREATED事件曲线、SCHEDULED事件表现与视频预期不符。</p><p>通过深入分析，我们猜测这些差异可能源于<strong>Volcano调度器版本不同</strong>。视频中使用的可能是较新的版本（如1.12.0-alpha.0），而本地环境使用的是较旧版本（v1.11.0）。本文详细介绍了如何查看当前测试所用的Volcano版本，如何自动化升级到目标版本，以及如何验证版本升级的效果。</p><h1 id="🔍问题回顾与分析"><a href="#🔍问题回顾与分析" class="headerlink" title="🔍问题回顾与分析"></a>🔍问题回顾与分析</h1><h2 id="1-本地测试与视频结果差异"><a href="#1-本地测试与视频结果差异" class="headerlink" title="1. 本地测试与视频结果差异"></a>1. 本地测试与视频结果差异</h2><h3 id="1-1-差异现象总结"><a href="#1-1-差异现象总结" class="headerlink" title="1.1 差异现象总结"></a>1.1 差异现象总结</h3><p>根据<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试结果">本地测试结果</a>，我们发现了以下主要差异：</p><table><thead><tr><th>测试场景</th><th>视频预期</th><th>本地实际</th><th>差异分析</th></tr></thead><tbody><tr><td><strong>10K Jobs × 1 Pod</strong></td><td>YuniKorn吞吐量最高</td><td>✅ 符合预期</td><td>基本一致</td></tr><tr><td><strong>500 Jobs × 20 Pods</strong></td><td>CREATED阶段性突变</td><td>⚠️ 部分符合</td><td>可能版本差异</td></tr><tr><td><strong>20 Jobs × 500 Pods</strong></td><td>CREATED成为瓶颈</td><td>❌ 出现突变</td><td>瓶颈效应不明显</td></tr><tr><td><strong>1 Job × 10K Pods</strong></td><td>调度速度平稳</td><td>❌ 出现突变</td><td>版本兼容性问题</td></tr></tbody></table><h3 id="1-2-差异原因猜测"><a href="#1-2-差异原因猜测" class="headerlink" title="1.2 差异原因猜测"></a>1.2 差异原因猜测</h3><p>基于测试结果分析，我们猜测差异可能源于：</p><ol><li><strong>调度器版本差异</strong>：本地使用v1.11.0，视频可能使用更新版本</li><li><strong>性能优化差异</strong>：新版本可能包含重要的性能优化</li><li><strong>算法改进差异</strong>：调度算法可能在新版本中有显著改进</li><li><strong>配置默认值差异</strong>：新版本的默认配置可能更适合大规模测试</li></ol><h1 id="🔍如何查看测试所用的Volcano版本"><a href="#🔍如何查看测试所用的Volcano版本" class="headerlink" title="🔍如何查看测试所用的Volcano版本"></a>🔍如何查看测试所用的Volcano版本</h1><h2 id="1-查看部署文件中的版本信息"><a href="#1-查看部署文件中的版本信息" class="headerlink" title="1. 查看部署文件中的版本信息"></a>1. 查看部署文件中的版本信息</h2><h3 id="1-1-直接查看配置文件"><a href="#1-1-直接查看配置文件" class="headerlink" title="1.1 直接查看配置文件"></a>1.1 直接查看配置文件</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看admission webhook manager版本</span></span><br><span class="line">grep <span class="string">"image:"</span> schedulers/volcano/volcano-admission/deployment.yaml | grep volcano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看scheduler版本</span></span><br><span class="line">grep <span class="string">"image:"</span> schedulers/volcano/volcano-scheduler/deployment.yaml | grep volcano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看controller manager版本</span></span><br><span class="line">grep <span class="string">"image:"</span> schedulers/volcano/volcano-controller/deployment.yaml | grep volcano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看初始化job版本</span></span><br><span class="line">grep <span class="string">"image:"</span> schedulers/volcano/volcano-admission-init/job.yaml | grep volcano</span><br></pre></td></tr></table></figure></div><h3 id="1-2-批量查看所有版本"><a href="#1-2-批量查看所有版本" class="headerlink" title="1.2 批量查看所有版本"></a>1.2 批量查看所有版本</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一次性查看所有Volcano组件版本</span></span><br><span class="line">grep -r <span class="string">"image:"</span> schedulers/volcano/ | grep volcano | grep -E <span class="string">"v[0-9]+\.[0-9]+\.[0-9]+"</span></span><br></pre></td></tr></table></figure></div><p><strong>输出示例</strong>：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">schedulers/volcano/volcano-admission/deployment.yaml:        image: kind-registry:5000/docker.io/volcanosh/vc-webhook-manager:v1.11.0</span><br><span class="line">schedulers/volcano/volcano-admission-init/job.yaml:        image: kind-registry:5000/docker.io/volcanosh/vc-webhook-manager:v1.11.0</span><br><span class="line">schedulers/volcano/volcano-scheduler/deployment.yaml:        image: kind-registry:5000/docker.io/volcanosh/vc-scheduler:v1.11.0</span><br><span class="line">schedulers/volcano/volcano-controller/deployment.yaml:        image: kind-registry:5000/docker.io/volcanosh/vc-controller-manager:v1.11.0</span><br></pre></td></tr></table></figure></div><h2 id="2-查看运行中的集群版本"><a href="#2-查看运行中的集群版本" class="headerlink" title="2. 查看运行中的集群版本"></a>2. 查看运行中的集群版本</h2><h3 id="2-1-检查已部署的Pod版本"><a href="#2-1-检查已部署的Pod版本" class="headerlink" title="2.1 检查已部署的Pod版本"></a>2.1 检查已部署的Pod版本</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置kubeconfig</span></span><br><span class="line"><span class="built_in">export</span> KUBECONFIG=./clusters/volcano/kubeconfig.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看运行中的Pod镜像版本</span></span><br><span class="line">kubectl get pods -n volcano-system -o jsonpath=<span class="string">'{range .items[*]}{.metadata.name}{"\t"}{.spec.containers[*].image}{"\n"}{end}'</span></span><br></pre></td></tr></table></figure></div><h3 id="2-2-查看ConfigMap中的配置"><a href="#2-2-查看ConfigMap中的配置" class="headerlink" title="2.2 查看ConfigMap中的配置"></a>2.2 查看ConfigMap中的配置</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看调度器配置</span></span><br><span class="line">kubectl get configmap -n volcano-system volcano-scheduler-configmap -o yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看admission webhook配置</span></span><br><span class="line">kubectl get validatingwebhookconfigurations -o yaml | grep -A 5 -B 5 volcano</span><br></pre></td></tr></table></figure></div><h2 id="3-版本信息汇总"><a href="#3-版本信息汇总" class="headerlink" title="3. 版本信息汇总"></a>3. 版本信息汇总</h2><p>通过上述方法，我们确认了当前环境使用的Volcano版本：</p><table><thead><tr><th>组件</th><th>当前版本</th><th>镜像名称</th></tr></thead><tbody><tr><td><strong>Webhook Manager</strong></td><td>v1.11.0</td><td><code>volcanosh/vc-webhook-manager:v1.11.0</code></td></tr><tr><td><strong>Scheduler</strong></td><td>v1.11.0</td><td><code>volcanosh/vc-scheduler:v1.11.0</code></td></tr><tr><td><strong>Controller Manager</strong></td><td>v1.11.0</td><td><code>volcanosh/vc-controller-manager:v1.11.0</code></td></tr></tbody></table><h1 id="🚀如何自动化升级Volcano版本"><a href="#🚀如何自动化升级Volcano版本" class="headerlink" title="🚀如何自动化升级Volcano版本"></a>🚀如何自动化升级Volcano版本</h1><h2 id="1-目标版本选择"><a href="#1-目标版本选择" class="headerlink" title="1. 目标版本选择"></a>1. 目标版本选择</h2><p>我们选择升级到<code>v1.12.0-alpha.0</code>，原因主要是KubeCon视频中说明使用了该版本。推测新版本中可能包含性能改进、旧版本中可能存在部分bug被修复，甚至调度算法可能也有所更新。</p><h2 id="2-版本升级脚本"><a href="#2-版本升级脚本" class="headerlink" title="2. 版本升级脚本"></a>2. 版本升级脚本</h2><h3 id="2-1-批量替换版本"><a href="#2-1-批量替换版本" class="headerlink" title="2.1 批量替换版本"></a>2.1 批量替换版本</h3><p>如果不想使用脚本，也可以手动执行：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 备份原文件</span></span><br><span class="line"><span class="built_in">cp</span> -r schedulers/volcano schedulers/volcano.backup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量替换版本</span></span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/*/deployment.yaml</span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/*/job.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证修改结果</span></span><br><span class="line">grep -r <span class="string">"image:"</span> schedulers/volcano/ | grep volcano | grep -E <span class="string">"v[0-9]+\.[0-9]+\.[0-9]+"</span></span><br></pre></td></tr></table></figure></div><h3 id="3-2-逐个文件修改"><a href="#3-2-逐个文件修改" class="headerlink" title="3.2 逐个文件修改"></a>3.2 逐个文件修改</h3><p>也可以逐个文件进行修改：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改admission webhook</span></span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/volcano-admission/deployment.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改scheduler</span></span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/volcano-scheduler/deployment.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改controller</span></span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/volcano-controller/deployment.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改初始化job</span></span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/volcano-admission-init/job.yaml</span><br></pre></td></tr></table></figure></div><h1 id="✅验证版本升级效果"><a href="#✅验证版本升级效果" class="headerlink" title="✅验证版本升级效果"></a>✅验证版本升级效果</h1><h2 id="1-配置文件验证"><a href="#1-配置文件验证" class="headerlink" title="1. 配置文件验证"></a>1. 配置文件验证</h2><h3 id="1-1-检查版本是否已更新"><a href="#1-1-检查版本是否已更新" class="headerlink" title="1.1 检查版本是否已更新"></a>1.1 检查版本是否已更新</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证所有文件是否已更新</span></span><br><span class="line">grep -r <span class="string">"image:"</span> schedulers/volcano/ | grep volcano | grep -E <span class="string">"v[0-9]+\.[0-9]+\.[0-9]+"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 期望输出：所有文件都显示 v1.12.0-alpha.0</span></span><br></pre></td></tr></table></figure></div><h3 id="1-2-检查文件完整性"><a href="#1-2-检查文件完整性" class="headerlink" title="1.2 检查文件完整性"></a>1.2 检查文件完整性</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查是否有遗漏的文件</span></span><br><span class="line">find schedulers/volcano/ -name <span class="string">"*.yaml"</span> -<span class="built_in">exec</span> grep -l <span class="string">"v1\.11\.0"</span> {} \;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果没有输出，说明所有文件都已更新</span></span><br></pre></td></tr></table></figure></div><h2 id="2-部署验证"><a href="#2-部署验证" class="headerlink" title="2. 部署验证"></a>2. 部署验证</h2><h3 id="2-1-重新部署Volcano"><a href="#2-1-重新部署Volcano" class="headerlink" title="2.1 重新部署Volcano"></a>2.1 重新部署Volcano</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 清理旧环境</span></span><br><span class="line">make down-volcano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新部署</span></span><br><span class="line">make up-volcano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等待服务就绪</span></span><br><span class="line">make wait-volcano</span><br></pre></td></tr></table></figure></div><h3 id="2-2-验证Pod镜像版本"><a href="#2-2-验证Pod镜像版本" class="headerlink" title="2.2 验证Pod镜像版本"></a>2.2 验证Pod镜像版本</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置kubeconfig</span></span><br><span class="line"><span class="built_in">export</span> KUBECONFIG=./clusters/volcano/kubeconfig.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查Pod是否使用新版本镜像</span></span><br><span class="line">kubectl get pods -n volcano-system -o jsonpath=<span class="string">'{range .items[*]}{.metadata.name}{"\t"}{.spec.containers[*].image}{"\n"}{end}'</span> | grep volcano</span><br></pre></td></tr></table></figure></div><p><strong>期望输出</strong>：所有Pod都应该显示<code>v1.12.0-alpha.0</code>版本</p><h3 id="2-3-检查服务状态"><a href="#2-3-检查服务状态" class="headerlink" title="2.3 检查服务状态"></a>2.3 检查服务状态</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查所有Pod状态</span></span><br><span class="line">kubectl get pods -n volcano-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查服务日志</span></span><br><span class="line">kubectl logs -n volcano-system deployment/volcano-scheduler --since=1m</span><br><span class="line">kubectl logs -n volcano-system deployment/volcano-controller-manager --since=1m</span><br></pre></td></tr></table></figure></div><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://github.com/volcano-sh/volcano/releases">[2] Volcano GitHub - Releases<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a href="!--swig%EF%BF%BC29--">[3] <a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></a></p><p><a href="!--swig%EF%BF%BC31--">[4] <a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></a></p><p><a href="!--swig%EF%BF%BC33--">[5] <a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></a> </p>]]></content>
    
    
    <summary type="html">本文回顾了本地测试与视频测试结果差异的问题，发现可能的原因在于Volcano调度器版本不同。文章详细介绍了如何查看测试所用的Volcano版本，如何将测试版本更换到1.12.0-alpha.0版本，以及如何验证版本升级效果。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="调度器" scheme="https://freshwlnd.github.io/tags/%E8%B0%83%E5%BA%A6%E5%99%A8/"/>
    
    <category term="性能优化" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    
    <category term="K8s" scheme="https://freshwlnd.github.io/tags/K8s/"/>
    
    <category term="性能测试" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
    <category term="Volcano" scheme="https://freshwlnd.github.io/tags/Volcano/"/>
    
    <category term="版本升级" scheme="https://freshwlnd.github.io/tags/%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7/"/>
    
    <category term="自动化脚本" scheme="https://freshwlnd.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%84%9A%E6%9C%AC/"/>
    
  </entry>
  
  <entry>
    <title>【集群】云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</title>
    <link href="https://freshwlnd.github.io/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/"/>
    <id>https://freshwlnd.github.io/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/</id>
    <published>2025-08-18T15:19:30.000Z</published>
    <updated>2025-09-18T07:27:36.925Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p><ol><li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li><li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li><li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li><li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li><li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li><li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li><li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li><li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li><li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li><li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li><li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li><li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li><li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li><li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a></li></ol></blockquote><h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="上一篇博客">上一篇博客</a>中，我们介绍了如何禁用Volcano调度器的enqueue功能。然而，在实际测试过程中，我们发现了一个更严重的问题：<strong>Pod创建数量始终少于10000，仅达到1000左右</strong>，这严重影响了测试结果的准确性。</p><p>本文详细记录了问题排查的完整过程，从发现异常现象到分析4.9GB的审计日志，最终定位到Webhook超时是导致Pod创建失败的根本原因。通过修改Webhook超时时间，我们成功解决了这个问题。</p><h1 id="🚨问题现象描述"><a href="#🚨问题现象描述" class="headerlink" title="🚨问题现象描述"></a>🚨问题现象描述</h1><h2 id="测试环境配置"><a href="#测试环境配置" class="headerlink" title="测试环境配置"></a>测试环境配置</h2><p>我们使用以下参数进行测试：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">make serial-test \</span><br><span class="line">    RESULT_RECENT_DURATION_SECONDS=60 TEST_TIMEOUT_SECONDS=160 \</span><br><span class="line">    NODES_SIZE=1000 \</span><br><span class="line">    QUEUES_SIZE=1  JOBS_SIZE_PER_QUEUE=20     PODS_SIZE_PER_JOB=500</span><br><span class="line"></span><br><span class="line">make serial-test \</span><br><span class="line">    RESULT_RECENT_DURATION_SECONDS=90 TEST_TIMEOUT_SECONDS=190 \</span><br><span class="line">    NODES_SIZE=1000 \</span><br><span class="line">    QUEUES_SIZE=1 JOBS_SIZE_PER_QUEUE=1 PODS_SIZE_PER_JOB=10000</span><br></pre></td></tr></table></figure></div><p><strong>预期结果</strong>：应该创建10,000个Pod<br><strong>实际结果</strong>：仅创建了不到1,000个Pod，成功率不到10%</p><h1 id="🔍问题排查过程"><a href="#🔍问题排查过程" class="headerlink" title="🔍问题排查过程"></a>🔍问题排查过程</h1><h2 id="1-初步分析"><a href="#1-初步分析" class="headerlink" title="1. 初步分析"></a>1. 初步分析</h2><p>首先，我们检查了测试环境的基本状态：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查Pod数量</span></span><br><span class="line">kubectl get pods -A | grep volcano-job | <span class="built_in">wc</span> -l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查Job状态</span></span><br><span class="line">kubectl get vcjob -A</span><br></pre></td></tr></table></figure></div><p>发现确实只有少量Pod被创建，大部分Pod创建请求似乎失败了。</p><h2 id="2-日志文件分析"><a href="#2-日志文件分析" class="headerlink" title="2. 日志文件分析"></a>2. 日志文件分析</h2><h3 id="2-1-日志文件大小"><a href="#2-1-日志文件大小" class="headerlink" title="2.1 日志文件大小"></a>2.1 日志文件大小</h3><p>测试完成后，我们发现审计日志文件异常巨大：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ls</span> -lh results/1755448387/logs/kube-apiserver-audit.volcano.log</span><br><span class="line"><span class="comment"># 输出：-rw-rw-rw- 1 root root 4.9G  8月 18 00:22 kube-apiserver-audit.volcano.log</span></span><br></pre></td></tr></table></figure></div><p><strong>4.9GB的日志文件</strong>表明系统产生了大量的审计记录，远大于其它测试的审计记录，猜测这意味着存在大量失败的操作。</p><h3 id="2-2-高效日志分析方法"><a href="#2-2-高效日志分析方法" class="headerlink" title="2.2 高效日志分析方法"></a>2.2 高效日志分析方法</h3><p>由于日志文件过大，我们采用了高效的分析方法：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计错误数量</span></span><br><span class="line">grep -c <span class="string">"context deadline exceeded"</span> kube-apiserver-audit.volcano.log</span><br><span class="line"><span class="comment"># 输出：520120</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计Webhook调用数量</span></span><br><span class="line">grep -c <span class="string">"validatepod.volcano.sh"</span> kube-apiserver-audit.volcano.log</span><br><span class="line"><span class="comment"># 输出：515531</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计Pod创建成功/失败数量</span></span><br><span class="line">grep -c <span class="string">"ResponseComplete.*pods.*create.*Success"</span> kube-apiserver-audit.volcano.log</span><br><span class="line"><span class="comment"># 输出：712</span></span><br><span class="line">grep -c <span class="string">"ResponseComplete.*pods.*create.*Failure"</span> kube-apiserver-audit.volcano.log</span><br><span class="line"><span class="comment"># 输出：520518</span></span><br></pre></td></tr></table></figure></div><h2 id="3-根本原因定位"><a href="#3-根本原因定位" class="headerlink" title="3. 根本原因定位"></a>3. 根本原因定位</h2><h3 id="3-1-错误模式分析"><a href="#3-1-错误模式分析" class="headerlink" title="3.1 错误模式分析"></a>3.1 错误模式分析</h3><p>通过分析日志中的错误信息，我们发现了统一的错误模式：</p><div class="code-container" data-rel="Json"><figure class="iseeu highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">  <span class="attr">"status"</span><span class="punctuation">:</span> <span class="string">"Failure"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"message"</span><span class="punctuation">:</span> <span class="string">"Internal error occurred: failed calling webhook \"validatepod.volcano.sh\": failed to call webhook: Post \"https://volcano-admission-service.volcano-system.svc:443/pods/validate?timeout=10s\": context deadline exceeded"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"reason"</span><span class="punctuation">:</span> <span class="string">"InternalError"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"code"</span><span class="punctuation">:</span> <span class="number">500</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></table></figure></div><p><strong>关键信息</strong>：</p><ul><li><strong>错误类型</strong>：Webhook调用超时</li><li><strong>超时时间</strong>：10秒</li><li><strong>影响范围</strong>：98.7%的Pod创建请求失败</li></ul><h3 id="3-2-统计数据汇总"><a href="#3-2-统计数据汇总" class="headerlink" title="3.2 统计数据汇总"></a>3.2 统计数据汇总</h3><table><thead><tr><th>指标</th><th>数量</th><th>占比</th></tr></thead><tbody><tr><td><strong>总Pod创建请求</strong></td><td>526,767</td><td>100%</td></tr><tr><td><strong>成功创建</strong></td><td>712</td><td>0.13%</td></tr><tr><td><strong>失败创建</strong></td><td>520,518</td><td>98.7%</td></tr><tr><td><strong>Webhook超时错误</strong></td><td>520,120</td><td>98.7%</td></tr></tbody></table><h2 id="4-问题根因分析"><a href="#4-问题根因分析" class="headerlink" title="4. 问题根因分析"></a>4. 问题根因分析</h2><h3 id="4-1-Webhook超时机制"><a href="#4-1-Webhook超时机制" class="headerlink" title="4.1 Webhook超时机制"></a>4.1 Webhook超时机制</h3><p>Volcano使用admission webhook来验证和修改Pod创建请求：</p><ol><li><p><strong>Pod创建流程</strong>：</p><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create pod → API Server → Admission Webhook → Volcano Controller → Pod创建</span><br></pre></td></tr></table></figure></div></li><li><p><strong>超时配置</strong>：</p><ul><li>当前配置：<code>timeoutSeconds: 10</code></li><li>问题：10秒内无法处理大量并发Pod创建请求</li></ul></li></ol><h3 id="4-2-性能瓶颈分析"><a href="#4-2-性能瓶颈分析" class="headerlink" title="4.2 性能瓶颈分析"></a>4.2 性能瓶颈分析</h3><p>当设置<code>PODS_SIZE_PER_JOB=10000</code>时：</p><ol><li><strong>并发压力</strong>：系统需要同时处理10,000个Pod创建请求</li><li><strong>Webhook负载</strong>：每个请求都需要经过admission webhook验证</li><li><strong>超时触发</strong>：大量请求堆积导致处理时间超过10秒</li><li><strong>失败连锁</strong>：超时失败导致Pod创建失败，影响整体测试结果</li></ol><h1 id="🔧问题修复方案"><a href="#🔧问题修复方案" class="headerlink" title="🔧问题修复方案"></a>🔧问题修复方案</h1><h2 id="1-修改Webhook超时时间"><a href="#1-修改Webhook超时时间" class="headerlink" title="1. 修改Webhook超时时间"></a>1. 修改Webhook超时时间</h2><h3 id="1-1-手动修改方法"><a href="#1-1-手动修改方法" class="headerlink" title="1.1 手动修改方法"></a>1.1 手动修改方法</h3><p>我们需要将所有webhook配置文件的超时时间从10秒增加到30秒：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查找所有webhook配置文件</span></span><br><span class="line">find schedulers/volcano/ -name <span class="string">"*webhook*.yaml"</span> -<span class="built_in">exec</span> grep -l <span class="string">"timeoutSeconds: 10"</span> {} \;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量修改超时时间</span></span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-*.yaml</span><br></pre></td></tr></table></figure></div><p><strong>重要说明</strong>：Kubernetes对webhook超时时间有严格限制，必须在1到30秒之间。我们最初尝试设置为60秒，但在部署时遇到了验证错误。</p><h2 id="1-3-Kubernetes超时时间限制"><a href="#1-3-Kubernetes超时时间限制" class="headerlink" title="1.3 Kubernetes超时时间限制"></a>1.3 Kubernetes超时时间限制</h2><p>在修复过程中，我们发现了一个重要的Kubernetes限制：</p><p>当我们尝试将webhook超时时间设置为60秒时，在部署过程中遇到了以下错误：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Error from server (Invalid): error when creating <span class="string">"../../schedulers/volcano"</span>: </span><br><span class="line">MutatingWebhookConfiguration.admissionregistration.k8s.io <span class="string">"volcano-admission-service-jobs-mutate"</span> </span><br><span class="line">is invalid: webhooks[0].timeoutSeconds: Invalid value: 60: </span><br><span class="line">the <span class="built_in">timeout</span> value must be between 1 and 30 seconds</span><br></pre></td></tr></table></figure></div><p>这个错误表明：</p><ul><li><strong>Kubernetes限制</strong>：webhook超时时间必须在1到30秒之间</li><li><strong>我们之前的设置</strong>：60秒超出了允许范围</li><li><strong>影响范围</strong>：所有7个webhook配置文件都无法部署</li></ul><h3 id="1-2-修改的文件列表"><a href="#1-2-修改的文件列表" class="headerlink" title="1.2 修改的文件列表"></a>1.2 修改的文件列表</h3><p>需要修改的7个webhook配置文件：</p><ol><li><code>admission-service-jobs-validate_validatingwebhookconfiguration.yaml</code></li><li><code>admission-service-queues-mutate_mutatingwebhookconfiguration.yaml</code></li><li><code>admission-service-jobs-mutate_mutatingwebhookconfiguration.yaml</code></li><li><code>admission-service-podgroups-mutate_mutatingwebhookconfiguration.yaml</code></li><li><code>admission-service-pods-mutate_mutatingwebhookconfiguration.yaml</code></li><li><code>admission-service-queues-validate_validatingwebhookconfiguration.yaml</code></li><li><code>admission-service-pods-validate_validatingwebhookconfiguration.yaml</code></li></ol><h2 id="2-修复实现"><a href="#2-修复实现" class="headerlink" title="2. 修复实现"></a>2. 修复实现</h2><p>为了修改配置，可以按照以下步骤进行：</p><h3 id="步骤1：备份原配置文件"><a href="#步骤1：备份原配置文件" class="headerlink" title="步骤1：备份原配置文件"></a>步骤1：备份原配置文件</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建备份目录</span></span><br><span class="line"><span class="built_in">mkdir</span> -p schedulers/volcano/backup-$(<span class="built_in">date</span> +%Y%m%d-%H%M%S)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 备份所有webhook配置文件</span></span><br><span class="line"><span class="built_in">cp</span> schedulers/volcano/admission-service-*.yaml schedulers/volcano/backup-$(<span class="built_in">date</span> +%Y%m%d-%H%M%S)/</span><br></pre></td></tr></table></figure></div><h3 id="步骤2：查找需要修改的文件"><a href="#步骤2：查找需要修改的文件" class="headerlink" title="步骤2：查找需要修改的文件"></a>步骤2：查找需要修改的文件</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查找所有包含timeoutSeconds的文件</span></span><br><span class="line">find schedulers/volcano/ -name <span class="string">"*webhook*.yaml"</span> -<span class="built_in">exec</span> grep -l <span class="string">"timeoutSeconds:"</span> {} \;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看当前超时设置</span></span><br><span class="line">grep -r <span class="string">"timeoutSeconds:"</span> schedulers/volcano/ | grep -E <span class="string">"[0-9]+"</span></span><br></pre></td></tr></table></figure></div><h3 id="步骤3：逐个修改文件"><a href="#步骤3：逐个修改文件" class="headerlink" title="步骤3：逐个修改文件"></a>步骤3：逐个修改文件</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改validating webhook配置文件</span></span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-jobs-validate_validatingwebhookconfiguration.yaml</span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-pods-validate_validatingwebhookconfiguration.yaml</span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-queues-validate_validatingwebhookconfiguration.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改mutating webhook配置文件</span></span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-jobs-mutate_mutatingwebhookconfiguration.yaml</span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-podgroups-mutate_mutatingwebhookconfiguration.yaml</span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-pods-mutate_mutatingwebhookconfiguration.yaml</span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-queues-mutate_mutatingwebhookconfiguration.yaml</span><br></pre></td></tr></table></figure></div><h3 id="步骤4：批量修改（推荐）"><a href="#步骤4：批量修改（推荐）" class="headerlink" title="步骤4：批量修改（推荐）"></a>步骤4：批量修改（推荐）</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一次性修改所有文件</span></span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-*.yaml</span><br></pre></td></tr></table></figure></div><h2 id="3-验证修复效果"><a href="#3-验证修复效果" class="headerlink" title="3. 验证修复效果"></a>3. 验证修复效果</h2><h3 id="3-1-检查配置修改"><a href="#3-1-检查配置修改" class="headerlink" title="3.1 检查配置修改"></a>3.1 检查配置修改</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查是否所有文件都已修改</span></span><br><span class="line">grep -r <span class="string">"timeoutSeconds:"</span> schedulers/volcano/ | grep -E <span class="string">"[0-9]+"</span></span><br><span class="line"><span class="comment"># 期望输出：所有文件都显示 timeoutSeconds: 30</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 确认没有遗漏的文件</span></span><br><span class="line">find schedulers/volcano/ -name <span class="string">"*webhook*.yaml"</span> -<span class="built_in">exec</span> grep -l <span class="string">"timeoutSeconds: 10"</span> {} \;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果上述命令有输出，说明还有文件未修改</span></span><br></pre></td></tr></table></figure></div><h3 id="3-2-重新部署测试"><a href="#3-2-重新部署测试" class="headerlink" title="3.2 重新部署测试"></a>3.2 重新部署测试</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新部署Volcano</span></span><br><span class="line">make up-volcano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新运行测试</span></span><br><span class="line">make serial-test \</span><br><span class="line">    RESULT_RECENT_DURATION_SECONDS=90 TEST_TIMEOUT_SECONDS=190 \</span><br><span class="line">    NODES_SIZE=1000 \</span><br><span class="line">    QUEUES_SIZE=1 JOBS_SIZE_PER_QUEUE=1 PODS_SIZE_PER_JOB=10000</span><br></pre></td></tr></table></figure></div><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://volcano.sh/zh/docs/architecture/">[2] Volcano 文档 - 架构<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/">[3] Kubernetes 文档 - Admission Controllers 准入控制 <i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a href="!--swig%EF%BF%BC30--">[4] <a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></a></p><p><a href="!--swig%EF%BF%BC32--">[5] <a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></a> </p>]]></content>
    
    
    <summary type="html">本文详细记录了在测试Volcano调度器时发现Pod创建数量始终少于10000，仅达到1000的问题排查过程。通过分析4.9GB的审计日志，发现大量Pod创建请求因Webhook超时而失败。文章介绍了如何修改Webhook超时时间。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="Webhook" scheme="https://freshwlnd.github.io/tags/Webhook/"/>
    
    <category term="调度器" scheme="https://freshwlnd.github.io/tags/%E8%B0%83%E5%BA%A6%E5%99%A8/"/>
    
    <category term="K8s" scheme="https://freshwlnd.github.io/tags/K8s/"/>
    
    <category term="性能测试" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
    <category term="Volcano" scheme="https://freshwlnd.github.io/tags/Volcano/"/>
    
    <category term="问题排查" scheme="https://freshwlnd.github.io/tags/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    
    <category term="超时修复" scheme="https://freshwlnd.github.io/tags/%E8%B6%85%E6%97%B6%E4%BF%AE%E5%A4%8D/"/>
    
  </entry>
  
  <entry>
    <title>【集群】云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</title>
    <link href="https://freshwlnd.github.io/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/"/>
    <id>https://freshwlnd.github.io/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/</id>
    <published>2025-08-17T15:06:07.000Z</published>
    <updated>2025-09-18T07:27:36.926Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p><ol><li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li><li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li><li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li><li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li><li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li><li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li><li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li><li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li><li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li><li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li><li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li><li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li><li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li><li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a></li></ol></blockquote><h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="上一篇博客">上一篇博客</a>中，我们分析了本地环境下的调度器性能测试结果，发现了一些有趣的现象：在某些测试场景下，CREATED事件会出现阶段性突变，而SCHEDULED事件则相对平稳。这种现象可能与调度器的enqueue机制有关。</p><p>本文详细介绍了如何禁用Volcano调度器的enqueue功能，通过对比分析来验证我们的猜测：<strong>enqueue可能会提前判断资源是否充足，从而在资源不足时限制Pod的创建，进而影响调度性能</strong>。</p><p>通过禁用enqueue功能，我们可以观察调度器在资源分配阶段的纯粹性能表现，为调度器性能优化提供重要参考。</p><h1 id="🧠Volcano调度器enqueue功能简介"><a href="#🧠Volcano调度器enqueue功能简介" class="headerlink" title="🧠Volcano调度器enqueue功能简介"></a>🧠Volcano调度器enqueue功能简介</h1><h2 id="什么是enqueue？"><a href="#什么是enqueue？" class="headerlink" title="什么是enqueue？"></a>什么是enqueue？</h2><p><strong>enqueue</strong>是Volcano调度器调度流程中的一个重要阶段，主要负责：</p><ol><li><strong>作业入队管理</strong>：将提交的Job添加到调度队列中</li><li><strong>优先级排序</strong>：根据Job的优先级、提交时间等因素进行排序</li><li><strong>资源预检查</strong>：提前判断集群资源是否满足Job需求</li><li><strong>队列容量控制</strong>：管理队列的容量限制和准入控制</li></ol><h2 id="enqueue对调度性能的影响"><a href="#enqueue对调度性能的影响" class="headerlink" title="enqueue对调度性能的影响"></a>enqueue对调度性能的影响</h2><p>基于<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="前期测试结果">前期测试结果</a>的分析，我们猜测enqueue可能会：</p><ul><li><strong>提前资源判断</strong>：在Pod创建前就判断资源是否充足</li><li><strong>限制Pod创建</strong>：当资源不足时，限制新Pod的创建速度</li><li><strong>影响CREATED事件</strong>：导致CREATED事件出现阶段性突变</li><li><strong>调度性能瓶颈</strong>：在某些场景下成为整体性能的瓶颈</li></ul><h2 id="Volcano调度器的完整调度流程"><a href="#Volcano调度器的完整调度流程" class="headerlink" title="Volcano调度器的完整调度流程"></a>Volcano调度器的完整调度流程</h2><pre class="mermaid">graph LR    A[Job提交] --&gt; B[enqueue]    B --&gt; C[allocate]    C --&gt; D[backfill]    D --&gt; E[reclaim]    E --&gt; F[preempt]        B1[enqueue阶段] --&gt; B2[队列管理]    B1 --&gt; B3[优先级排序]    B1 --&gt; B4[资源预检查]        C1[allocate阶段] --&gt; C2[资源分配]    C1 --&gt; C3[节点选择]    C1 --&gt; C4[Pod绑定]</pre><h1 id="🔧如何禁用Volcano的enqueue功能"><a href="#🔧如何禁用Volcano的enqueue功能" class="headerlink" title="🔧如何禁用Volcano的enqueue功能"></a>🔧如何禁用Volcano的enqueue功能</h1><h2 id="1-修改调度器配置文件"><a href="#1-修改调度器配置文件" class="headerlink" title="1. 修改调度器配置文件"></a>1. 修改调度器配置文件</h2><h3 id="1-1-修改主配置文件"><a href="#1-1-修改主配置文件" class="headerlink" title="1.1 修改主配置文件"></a>1.1 修改主配置文件</h3><p>编辑 <code>schedulers/volcano/scheduler.conf</code> 文件：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原始配置</span></span><br><span class="line">actions: <span class="string">"enqueue, allocate, backfill"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改为（移除enqueue）</span></span><br><span class="line">actions: <span class="string">"allocate, backfill"</span></span><br></pre></td></tr></table></figure></div><h3 id="1-2-修改测试配置文件"><a href="#1-2-修改测试配置文件" class="headerlink" title="1.2 修改测试配置文件"></a>1.2 修改测试配置文件</h3><p>编辑 <code>test/volcano/init.yaml</code> 文件：</p><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原始配置</span></span><br><span class="line"><span class="attr">actions:</span> <span class="string">"enqueue, allocate,#<span class="template-variable">{{ if .preemption }}</span> preempt,#<span class="template-variable">{{ end }}</span> backfill, reclaim"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改为（移除enqueue）</span></span><br><span class="line"><span class="attr">actions:</span> <span class="string">"allocate,#<span class="template-variable">{{ if .preemption }}</span> preempt,#<span class="template-variable">{{ end }}</span> backfill, reclaim"</span></span><br></pre></td></tr></table></figure></div><h2 id="2-重新部署Volcano调度器"><a href="#2-重新部署Volcano调度器" class="headerlink" title="2. 重新部署Volcano调度器"></a>2. 重新部署Volcano调度器</h2><p>修改配置后，需要重新部署调度器：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新构建和部署</span></span><br><span class="line">make up-volcano</span><br></pre></td></tr></table></figure></div><h1 id="🚀如何手动配置测试环境"><a href="#🚀如何手动配置测试环境" class="headerlink" title="🚀如何手动配置测试环境"></a>🚀如何手动配置测试环境</h1><h2 id="1-启动Volcano测试环境"><a href="#1-启动Volcano测试环境" class="headerlink" title="1. 启动Volcano测试环境"></a>1. 启动Volcano测试环境</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动完整的Volcano测试环境</span></span><br><span class="line">make prepare-volcano</span><br></pre></td></tr></table></figure></div><p>这个命令会依次执行：</p><ul><li><code>make up-volcano</code>：创建Kind集群并部署Volcano</li><li><code>make wait-volcano</code>：等待所有服务就绪</li><li><code>make test-init-volcano</code>：初始化测试环境，创建虚拟节点</li></ul><h2 id="2-验证环境状态"><a href="#2-验证环境状态" class="headerlink" title="2. 验证环境状态"></a>2. 验证环境状态</h2><h3 id="2-1-检查集群状态"><a href="#2-1-检查集群状态" class="headerlink" title="2.1 检查集群状态"></a>2.1 检查集群状态</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get nodes -o wide</span><br></pre></td></tr></table></figure></div><p>应该看到：</p><ul><li><code>volcano-control-plane</code>：控制平面节点</li><li><code>node-0</code>、<code>node-1</code>等：虚拟KWOK节点</li></ul><h3 id="2-2-检查Volcano服务状态"><a href="#2-2-检查Volcano服务状态" class="headerlink" title="2.2 检查Volcano服务状态"></a>2.2 检查Volcano服务状态</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get pods -n volcano-system</span><br></pre></td></tr></table></figure></div><p>确保所有Pod都处于Running状态。</p><h3 id="2-3-检查虚拟节点标签"><a href="#2-3-检查虚拟节点标签" class="headerlink" title="2.3 检查虚拟节点标签"></a>2.3 检查虚拟节点标签</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get nodes --show-labels | grep node-</span><br></pre></td></tr></table></figure></div><p>确保虚拟节点有正确的标签：<code>type=kwok</code></p><h1 id="🔍如何验证enqueue是否被成功禁用"><a href="#🔍如何验证enqueue是否被成功禁用" class="headerlink" title="🔍如何验证enqueue是否被成功禁用"></a>🔍如何验证enqueue是否被成功禁用</h1><h2 id="1-检查ConfigMap配置"><a href="#1-检查ConfigMap配置" class="headerlink" title="1. 检查ConfigMap配置"></a>1. 检查ConfigMap配置</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get configmap -n volcano-system volcano-scheduler-configmap -o yaml</span><br></pre></td></tr></table></figure></div><p><strong>期望结果</strong>：</p><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">volcano-scheduler.conf:</span> <span class="string">"actions: \"allocate, backfill, reclaim\"\n..."</span></span><br></pre></td></tr></table></figure></div><p><strong>关键点</strong>：配置中应该没有<code>enqueue</code>，只有<code>allocate, backfill, reclaim</code>。</p><h2 id="2-检查调度器启动日志"><a href="#2-检查调度器启动日志" class="headerlink" title="2. 检查调度器启动日志"></a>2. 检查调度器启动日志</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl logs -n volcano-system deployment/volcano-scheduler --since=1h | grep <span class="string">"Successfully loaded"</span></span><br></pre></td></tr></table></figure></div><p><strong>期望结果</strong>：</p><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Successfully loaded Scheduler conf, actions: [allocate backfill reclaim]</span><br></pre></td></tr></table></figure></div><p><strong>关键点</strong>：日志中应该显示<code>actions: [allocate backfill reclaim]</code>，没有enqueue。</p><h2 id="3-检查实时调度日志"><a href="#3-检查实时调度日志" class="headerlink" title="3. 检查实时调度日志"></a>3. 检查实时调度日志</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl logs -n volcano-system deployment/volcano-scheduler -f | grep -E <span class="string">"(enqueue|allocate|backfill)"</span></span><br></pre></td></tr></table></figure></div><p><strong>期望结果</strong>：应该只看到<code>allocate</code>和<code>backfill</code>相关的日志，没有<code>enqueue</code>相关的日志。</p><h1 id="🧪如何执行性能测试"><a href="#🧪如何执行性能测试" class="headerlink" title="🧪如何执行性能测试"></a>🧪如何执行性能测试</h1><h2 id="1-运行批处理作业测试"><a href="#1-运行批处理作业测试" class="headerlink" title="1. 运行批处理作业测试"></a>1. 运行批处理作业测试</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用小规模参数进行测试</span></span><br><span class="line">make start-volcano QUEUES_SIZE=1 JOBS_SIZE_PER_QUEUE=20 PODS_SIZE_PER_JOB=500</span><br></pre></td></tr></table></figure></div><p><strong>参数说明</strong>：</p><ul><li><code>QUEUES_SIZE=1</code>：创建1个队列</li><li><code>JOBS_SIZE_PER_QUEUE=20</code>：每个队列20个Job</li><li><code>PODS_SIZE_PER_JOB=500</code>：每个Job包含500个Pod</li><li><strong>总计</strong>：20个Job × 500个Pod = 10,000个Pod</li></ul><h2 id="2-测试执行过程"><a href="#2-测试执行过程" class="headerlink" title="2. 测试执行过程"></a>2. 测试执行过程</h2><p>测试程序会：</p><ol><li><strong>创建队列</strong>：<code>test-queue-long-term-research-0</code></li><li><strong>创建Job</strong>：20个Volcano Job</li><li><strong>创建Pod</strong>：每个Job创建500个Pod</li><li><strong>执行调度</strong>：Volcano调度器分配资源</li><li><strong>收集结果</strong>：记录CREATED和SCHEDULED事件</li></ol><h2 id="3-监控测试进度"><a href="#3-监控测试进度" class="headerlink" title="3. 监控测试进度"></a>3. 监控测试进度</h2><h3 id="3-1-查看Job状态"><a href="#3-1-查看Job状态" class="headerlink" title="3.1 查看Job状态"></a>3.1 查看Job状态</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看Volcano Job（注意：不是标准Kubernetes Job）</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get vcjob -A</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者使用完整API</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get jobs.batch.volcano.sh -A</span><br></pre></td></tr></table></figure></div><h3 id="3-2-查看Pod状态"><a href="#3-2-查看Pod状态" class="headerlink" title="3.2 查看Pod状态"></a>3.2 查看Pod状态</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看所有Pod</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get pods -A | grep volcano-job</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看特定Job的Pod</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get pods -l job-name=volcano-job-long-term-research-0-1</span><br></pre></td></tr></table></figure></div><h3 id="3-3-查看调度器日志"><a href="#3-3-查看调度器日志" class="headerlink" title="3.3 查看调度器日志"></a>3.3 查看调度器日志</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实时监控调度过程</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl logs -n volcano-system deployment/volcano-scheduler -f | grep -E <span class="string">"(Binding|allocate|task)"</span></span><br></pre></td></tr></table></figure></div><h1 id="📊如何验证测试是否正常执行"><a href="#📊如何验证测试是否正常执行" class="headerlink" title="📊如何验证测试是否正常执行"></a>📊如何验证测试是否正常执行</h1><h2 id="1-检查测试结果"><a href="#1-检查测试结果" class="headerlink" title="1. 检查测试结果"></a>1. 检查测试结果</h2><h3 id="1-1-查看测试程序输出"><a href="#1-1-查看测试程序输出" class="headerlink" title="1.1 查看测试程序输出"></a>1.1 查看测试程序输出</h3><p>测试完成后，应该看到类似输出：</p><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">=== RUN   TestBatchJob</span><br><span class="line">--- PASS: TestBatchJob (40.05s)</span><br><span class="line">PASS</span><br></pre></td></tr></table></figure></div><h3 id="1-2-检查Job和Pod状态"><a href="#1-2-检查Job和Pod状态" class="headerlink" title="1.2 检查Job和Pod状态"></a>1.2 检查Job和Pod状态</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查Job状态</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get vcjob -o wide</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查Pod状态分布</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get pods -A | grep volcano-job | awk <span class="string">'{print $3}'</span> | <span class="built_in">sort</span> | <span class="built_in">uniq</span> -c</span><br></pre></td></tr></table></figure></div><p><strong>期望结果</strong>：</p><ul><li>大部分Pod应该处于<code>Completed</code>状态</li><li>少量Pod可能处于<code>Running</code>或<code>Pending</code>状态</li><li>没有Pod处于<code>Failed</code>状态</li></ul><h2 id="2-验证调度行为"><a href="#2-验证调度行为" class="headerlink" title="2. 验证调度行为"></a>2. 验证调度行为</h2><h3 id="2-1-检查Pod调度位置"><a href="#2-1-检查Pod调度位置" class="headerlink" title="2.1 检查Pod调度位置"></a>2.1 检查Pod调度位置</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看Pod被调度到哪些节点</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get pods -A -o wide | grep volcano-job | awk <span class="string">'{print $1, $2, $8}'</span></span><br></pre></td></tr></table></figure></div><p><strong>期望结果</strong>：Pod应该被调度到虚拟节点（如<code>node-0</code>），而不是控制平面节点。</p><h3 id="2-2-检查资源分配"><a href="#2-2-检查资源分配" class="headerlink" title="2.2 检查资源分配"></a>2.2 检查资源分配</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看节点资源使用情况</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl describe node node-0</span><br></pre></td></tr></table></figure></div><h2 id="3-分析调度性能"><a href="#3-分析调度性能" class="headerlink" title="3. 分析调度性能"></a>3. 分析调度性能</h2><h3 id="3-1-对比enqueue启用-禁用的差异"><a href="#3-1-对比enqueue启用-禁用的差异" class="headerlink" title="3.1 对比enqueue启用/禁用的差异"></a>3.1 对比enqueue启用/禁用的差异</h3><p><strong>启用enqueue时</strong>：</p><ul><li>CREATED事件可能出现阶段性突变</li><li>SCHEDULED事件相对平稳</li><li>整体调度时间较长</li></ul><p><strong>禁用enqueue后</strong>：</p><ul><li>CREATED事件应该更加平稳</li><li>SCHEDULED事件可能成为瓶颈</li><li>整体调度时间可能缩短</li></ul><h3 id="3-2-关键指标对比"><a href="#3-2-关键指标对比" class="headerlink" title="3.2 关键指标对比"></a>3.2 关键指标对比</h3><table><thead><tr><th>指标</th><th>启用enqueue</th><th>禁用enqueue</th><th>差异分析</th></tr></thead><tbody><tr><td>CREATED事件曲线</td><td>阶段性突变</td><td>相对平稳</td><td>enqueue的资源预检查影响</td></tr><tr><td>SCHEDULED事件曲线</td><td>相对平稳</td><td>可能成为瓶颈</td><td>直接进入资源分配阶段</td></tr><tr><td>整体调度时间</td><td>较长</td><td>可能较短</td><td>跳过队列管理阶段</td></tr><tr><td>资源利用率</td><td>较高</td><td>可能较低</td><td>缺乏资源预优化</td></tr></tbody></table><h1 id="🧹如何清理测试环境"><a href="#🧹如何清理测试环境" class="headerlink" title="🧹如何清理测试环境"></a>🧹如何清理测试环境</h1><h2 id="1-停止测试"><a href="#1-停止测试" class="headerlink" title="1. 停止测试"></a>1. 停止测试</h2><p>如果测试还在运行，可以按<code>Ctrl+C</code>停止。</p><h2 id="2-清理测试环境"><a href="#2-清理测试环境" class="headerlink" title="2. 清理测试环境"></a>2. 清理测试环境</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 清理Volcano测试环境</span></span><br><span class="line">make down-volcano</span><br></pre></td></tr></table></figure></div><p>这个命令会：</p><ul><li>删除所有测试Pod和Job</li><li>销毁Kind集群</li><li>清理相关资源</li></ul><h2 id="3-验证清理结果"><a href="#3-验证清理结果" class="headerlink" title="3. 验证清理结果"></a>3. 验证清理结果</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查集群是否已销毁</span></span><br><span class="line">docker ps | grep volcano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查相关目录是否清理</span></span><br><span class="line"><span class="built_in">ls</span> -la clusters/volcano/</span><br></pre></td></tr></table></figure></div><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://volcano.sh/zh/docs/actions/">[2] Volcano Documentation - Scheduler Actions Enqueue<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://github.com/volcano-sh/volcano/blob/master/docs/user-guide/how_to_configure_scheduler.md">[3] Volcano GitHub - How to Configure Scheduler<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a href="!--swig%EF%BF%BC39--">[4] <a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></a></p><p><a href="!--swig%EF%BF%BC41--">[5] <a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></a> </p>]]></content>
    
    
    <summary type="html">本文详细介绍了如何禁用Volcano调度器的enqueue功能，包括配置修改、环境搭建、功能验证、性能测试和结果分析。通过禁用enqueue，可以观察调度器在资源分配阶段的性能表现，为调度器性能优化提供参考。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="调度器" scheme="https://freshwlnd.github.io/tags/%E8%B0%83%E5%BA%A6%E5%99%A8/"/>
    
    <category term="K8s" scheme="https://freshwlnd.github.io/tags/K8s/"/>
    
    <category term="性能测试" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
    <category term="Volcano" scheme="https://freshwlnd.github.io/tags/Volcano/"/>
    
    <category term="enqueue" scheme="https://freshwlnd.github.io/tags/enqueue/"/>
    
    <category term="调度优化" scheme="https://freshwlnd.github.io/tags/%E8%B0%83%E5%BA%A6%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>【论文】略读笔记86-前沿-DLRM的CPU-GPU分解调度</title>
    <link href="https://freshwlnd.github.io/2025/08/13/literature/literatureNotes86/"/>
    <id>https://freshwlnd.github.io/2025/08/13/literature/literatureNotes86/</id>
    <published>2025-08-13T04:10:32.000Z</published>
    <updated>2025-08-13T04:10:35.308Z</updated>
    
    <content type="html"><![CDATA[<h1 id="x1f4d6-《GPU-Disaggregated-Serving-for-Deep-Learning-Recommendation-Models-at-Scale》"><a href="#x1f4d6-《GPU-Disaggregated-Serving-for-Deep-Learning-Recommendation-Models-at-Scale》" class="headerlink" title="📖《GPU-Disaggregated Serving for Deep Learning Recommendation Models at Scale》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《GPU-Disaggregated Serving for Deep Learning Recommendation Models at Scale》</h1><p>2025 年 香港科技大学+阿里巴巴团队 发表于 CCF-A 类会议 NSDI。</p><p>作者之一<a class="link" href="https://www.zhihu.com/people/llllkkkk">刘侃<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>提到：实际工作在 n 年前就完成了，论文写作在 n-m 年前就完成了~<a href="#refer-anchor-1"><sup>[2,3]</sup></a>连这样的论文都花了这么久[/惊恐]</p><p>RTP（Real Time Prediction）<a href="#refer-anchor-1"><sup>[4]</sup></a>平台是阿里内部一个通用的在线预测平台，广泛支持淘天、本地生活、AIDC、菜鸟、大文娱等搜索和推荐业务场景的 DLRM（Deep Learning Recommendation Model）部署。自2022年起，RTP开始探索大规模GPU-Disaggregation技术的落地，运用RDMA高性能网络通信构建GPU-CPU全分离的分布式推理系统。</p><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul><li>在线推荐系统使用深度学习推荐模型（DLRMs）提供准确、个性化的推荐以提升用户体验。<ul><li>个性化推荐系统是许多面向用户、创造收入的网络服务的关键基础设施，如内容流媒体、电子商务、社交网络和网页搜索。这些系统使用深度学习推荐模型（DLRM）提供准确、个性化的推荐，以改善客户体验并增加用户参与度。</li><li>根据Meta的数据，DLRM服务消耗了当今AI云中大部分的推理资源，顶级推荐模型占用了<strong>超过79%的AI周期</strong>。</li></ul></li></ul><h3 id="DLRM特点"><a href="#DLRM特点" class="headerlink" title="DLRM特点"></a>DLRM特点</h3><p>鉴于现在 LLM 很火，作者之一刘侃用下面的表格对比了两者在线部署角度的差异，以便更好地理解问题。</p><blockquote><p>如果想了解更多 DLRM 的信息，可以参考原文或相关博客<a href="#refer-anchor-1"><sup>[2,3]</sup></a>，或原博客推荐的“典中典 W&amp;D<a href="#refer-anchor-1"><sup>[5]</sup></a>以及系统介绍<a href="#refer-anchor-1"><sup>[6]</sup></a>”。</p></blockquote><p>模型特点对比：<br>|-| DLRM | LLM |<br>|—|—|—|<br>|Feature Engineering|    ID 化、统计、笛卡尔积、查外表…太多了|    Tokenize，字符到 int 的 ID 转换|<br>|Feature Store|    100G-10T 量级，有行为序列、商品属性等|    额，如果是说 tokenizer 表的话，那就是 M 级别。|<br>|Embedding|    10G-1T 量级，大规模稀疏|    &lt;10G|<br>|Model|    DNN + Attention 等变种结合|    Transformer/Mamba，没了|</p><p>对应算力特点对比：</p><table><thead><tr><th>-</th><th>DLRM</th><th>LLM</th></tr></thead><tbody><tr><td>CPU</td><td>负载重，大量特征查表（如 KV）和计算。不同模型之间负载差距大，有 32c:1GPU 也有 128c:1GPU。</td><td>Tokenize 开销很小，剩下还有少量 Framework 和 KernelLaunch 开销。8c 算多的。</td></tr><tr><td>GPU</td><td>模型杂，方法多，实验也多；模型输入偏小，Kernel Launch 开销较大，算力利用有限。</td><td>社区很卷，都是标准算子，接近硬件算力极限。</td></tr></tbody></table><h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul><li>然而，大规模高效提供DLRM服务具有挑战性。</li><li>DLRMs表现出独特的资源使用模式：它们需要<strong>大量的CPU核心和巨大的内存</strong>，但只有<strong>少量GPU</strong>。<ul><li>DLRM提供具有严格的延迟服务级别目标（SLO），通常每个请求在数十毫秒的规模。同时，DLRM提供需要处理需求的频繁波动。满足延迟SLO通常意味着为<strong>峰值</strong>负载提供资源，这可以显著高于平均水平。</li></ul></li><li>在多GPU服务器上运行它们会迅速耗尽服务器的CPU和内存资源，导致大量未分配的GPU闲置，无法被其他任务利用。<ul><li>图1说明了阿里巴巴DLRM服务在生产集群中的资源需求。我们观察到明显的日间模式，峰值与谷值之比超过6倍；在季节性促销活动中，峰值负载可以比常规峰值高1.3倍，这与之前的报告一致。在如此规模上为峰值负载提供资源会导致显著的低利用率，使其在经济上不可行。</li></ul></li><li>为了减少过度配置，更好的策略是为平均负载进行配置，并在负载高峰期间启用容量借贷。<ul><li>像阿里巴巴这样的大型公司拥有多个特定用途的基础设施：一些用于训练，其他用于推理。当DLRM服务处于高峰时段时，它可以暂时从训练集群借用GPU服务器，因为训练作业对延迟不敏感，可以容忍中断。</li><li>然而，服务器池操作之间存在不匹配。<ul><li>与需要大量GPU周期的训练任务不同，推荐模型表现出较低的计算强度，并且不依赖于GPU。相反，它们执行稀疏计算，如嵌入，这需要大量内存来存储嵌入表，以及许多CPU核心用于查找和池化操作。因此，在训练服务器上运行推荐模型会迅速耗尽服务器的CPU和内存资源，留下大量未分配的GPU闲置。</li></ul></li><li>在我们的集群中，典型的DLRM服务请求48个CPU和1个GPU，而训练服务器通常有〈96个CPU，8个GPU〉。部署两个DLRM推理实例将占用主机上的所有CPU，留下6个未分配的GPU无法被其他任务利用。</li></ul></li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/2025-NSDI-Yang-GPU-Disaggregated.png?raw=true" alt="原文图1：DLRM服务的CPU需求表现出每日和季节性变化；GPU需求遵循相同趋势。从生产集群收集的跟踪数据，包括三个（带星号）电子商务促销活动。"><figcaption>原文图1：DLRM服务的CPU需求表现出每日和季节性变化；GPU需求遵循相同趋势。从生产集群收集的跟踪数据，包括三个（带星号）电子商务促销活动。</figcaption></figure></p><h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul><li>本文描述了Prism，一个生产级DLRM服务系统，通过<strong>资源解耦</strong>的方式消除GPU碎片化。<ul><li>Prism运行在共享基础设施上，其中一组CPU节点（CNs）通过高速RDMA网络与一组异构GPU节点（HNs）互连，形成两个可以独立扩展的资源池。<ul><li>每个CN拥有大量CPU核心和高内存，但没有GPU，而每个HN是一个典型的具有多个GPU但CPU和内存资源有限的训练服务器。</li><li>这种基础设施将具有固定配置的单体服务器集群分解为两个解耦的资源池，其中CNs提供丰富的CPU和内存资源，而HNs提供大量的GPU。这两个资源池可以独立扩展以匹配动态工作负载的变化需求。</li></ul></li><li>Prism自动将DLRMs划分为CPU密集型和GPU密集型子图，并在CNs和HNs上调度它们以实现解耦服务。<ul><li>给定一个DLRM，Prism自动将其计算图分为两个子图，一个包含CPU和内存密集型操作符，另一个GPU密集型。然后，系统将这两个子图调度到选定的CN和HN上进行解耦服务，并将结果返回给用户。</li></ul></li></ul></li><li>本文还描述了在生产规模下构建解耦的DLRM系统所面临的挑战、技术和经验教训。Prism采用各种技术来最小化由解耦引起的延迟开销，包括最优图划分、拓扑感知资源管理和SLO感知通信调度。<ul><li>首先，解耦需要对模型所有者透明。<ul><li>手动重构模型到解耦版本会增加精度下降的风险，并需要模型所有者额外的努力，因此是不理想的。</li></ul></li><li>其次，系统应扩展到数千台服务器以处理过度的负载峰值。<ul><li>鉴于流量激增，它应迅速将工作负载调度到大量服务器上，以在短时间内实现显著的总吞吐量。</li></ul></li><li>第三，系统应满足DLRM服务的严格延迟SLO，由于GPU解耦导致CN和HN之间存在非平凡的通信开销。</li></ul></li><li>Prism通过三个主要组件应对这些挑战：<ul><li>一个解耦优化的实时预测（RTP）框架，该框架在CN和HN之间最优地划分计算图（第4.1节），</li><li>一个拓扑感知的资源管理器，该管理器最小化服务器间和服务器内的通信开销（第4.2节），</li><li>以及SLO感知的通信调度，确保在目标延迟SLO内进行解耦服务（第4.3节）。</li></ul></li><li>总结而言，我们的主要贡献如下：<ul><li>• 我们在部署生产规模的弹性DLRM服务时，识别了资源配置的挑战，并激励了GPU解耦服务的需求。</li><li>• 我们设计和实现了Prism，通过解耦服务从CPU节点和异构GPU节点中收集资源，缓解了服务器配置与DLRM资源需求之间的不匹配，同时仍满足延迟SLOs。</li><li>• 我们在生产环境中评估了Prism，并证明它可以有效地减少资源碎片化，而不会损害服务性能，在促销活动期间实现高效的容量借贷。</li><li>我们将生产DLRM服务跟踪作为阿里巴巴集群跟踪计划的一部分发布<a href="#refer-anchor-1"><sup>[7]</sup></a>。</li></ul></li></ul><h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul><li>评估表明，Prism在拥挤的GPU集群中有效地将CPU和GPU碎片化降低了53%和27%。在季节性促销活动中，它有效地实现了从训练集群的容量借贷，节省了超过90%的GPU（§5）。Prism已在生产集群中部署超过两年，现在运行在超过10k个GPU上。</li></ul><h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul><li>操作经验。生产集群经常采用在线和离线任务的混合部署以提高效率。但在我们的情况下，分类的DLRM服务引入了频繁的RDMA网络通信。<ul><li>我们观察到，即使获得RNIC，RDMA转移潜伏期也可以在强烈的资源争夺中增加十倍。根本原因是在容器覆盖网络下，RDMA和TCP都依赖于覆盖网络方案进行通信。混合工作负载的TCP流量会影响网卡底层的流表逻辑，从而影响RDMA流量。</li><li>我们当前的解决方法涉及监视节点资源利用率和在线服务延迟，并在指标变得异常时触发离线任务的驱逐。我们认为这是未来研究的一个开放问题。</li></ul></li></ul><!-- ## <span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">&#x1f9e0;</span>疑问 --><hr><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://www.usenix.org/conference/nsdi25/presentation/yang">[1] Yang L, Wang Y, Yu Y, et al. {GPU-Disaggregated} Serving for Deep Learning Recommendation Models at Scale[C]//22nd USENIX Symposium on Networked Systems Design and Implementation (NSDI 25). 2025: 847-863.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://mp.weixin.qq.com/s/fk_x6pdu2BNdyIvnkfQRfA">[2] GPU，CPU，谁是谁的“伴侣”？—— 阿里 RTP 平台的异构资源解耦大冒险 - InfoQ<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://zhuanlan.zhihu.com/p/1892365414530516703">[3] 解读 NSDI25 GPU-Disaggregated Serving for Deep Learning Recommendation Models at Scal - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://developer.aliyun.com/article/674182">[4] 深度预测平台RTP介绍<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://arxiv.org/abs/1606.07792">[5] Wide &amp; Deep Learning for Recommender Systems<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://blog.csdn.net/tianshuai1111/article/details/136275123">[6] 【AI.OS】深入解读阿里开源系统全图化引擎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://github.com/alibaba/clusterdata/tree/master/cluster-trace-gpuv2025">[7] Github - alibaba/clusterdata/cluster-trace-gpuv2025<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">《GPU-Disaggregated Serving for Deep Learning Recommendation Models at Scale》，大规模深度学习推荐模型的 GPU 分解服务</summary>
    
    
    
    <category term="论文" scheme="https://freshwlnd.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    <category term="略读" scheme="https://freshwlnd.github.io/categories/%E8%AE%BA%E6%96%87/%E7%95%A5%E8%AF%BB/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E8%AE%BA%E6%96%87/%E7%95%A5%E8%AF%BB/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="AI-Infra" scheme="https://freshwlnd.github.io/tags/AI-Infra/"/>
    
    <category term="DLRM" scheme="https://freshwlnd.github.io/tags/DLRM/"/>
    
  </entry>
  
  <entry>
    <title>【集群】云原生批调度实战：Volcano 数据收集方法深度解析与Prometheus Histogram误差问题</title>
    <link href="https://freshwlnd.github.io/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/"/>
    <id>https://freshwlnd.github.io/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/</id>
    <published>2025-08-09T16:04:35.000Z</published>
    <updated>2025-09-18T07:27:36.958Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p><ol><li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li><li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li><li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li><li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li><li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li><li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li><li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li><li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li><li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li><li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li><li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li><li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li><li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li><li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a></li></ol></blockquote><p>在前期的文章中，我提到了<a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="调度器性能对比分析">调度器性能对比分析</a>中一个重要论断：传统方法使用Prometheus会造成很大误差，而audit-exporter方法能够准确记录性能。当时我误以为这种差异源于数据处理阶段的Prometheus histogram统计方法，但深入分析<a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="指标采集链路">指标采集链路</a>后发现，<strong>两种方法的核心差异实际上在数据收集阶段，而非数据处理阶段</strong>。</p><p>本文旨在澄清这一技术细节，并深入探讨Prometheus histogram的误差机制与替代方案。</p><hr><h1 id="🎯-问题澄清：数据收集-vs-数据处理"><a href="#🎯-问题澄清：数据收集-vs-数据处理" class="headerlink" title="🎯 问题澄清：数据收集 vs 数据处理"></a>🎯 问题澄清：数据收集 vs 数据处理</h1><h2 id="1-传统Prometheus方法-vs-Audit-Exporter方法"><a href="#1-传统Prometheus方法-vs-Audit-Exporter方法" class="headerlink" title="1. 传统Prometheus方法 vs Audit-Exporter方法"></a>1. 传统Prometheus方法 vs Audit-Exporter方法</h2><h3 id="传统Prometheus方法的数据收集路径"><a href="#传统Prometheus方法的数据收集路径" class="headerlink" title="传统Prometheus方法的数据收集路径"></a>传统Prometheus方法的数据收集路径</h3><p>传统的Kubernetes调度器性能监控依赖调度器自身暴露的Prometheus指标：</p><pre class="mermaid">graph LR    A[调度器内部逻辑] --&gt; B[调度器暴露metrics端点]    B --&gt; C[Prometheus定期抓取]    C --&gt; D[存储到TSDB]    D --&gt; E[Grafana查询展示]</pre><p><strong>核心特点</strong>：</p><ul><li><strong>数据源</strong>：调度器进程内部的instrumentation代码</li><li><strong>时间精度</strong>：受限于调度器代码的埋点位置和精度</li><li><strong>数据完整性</strong>：可能遗漏调度过程中的某些阶段</li><li><strong>系统开销</strong>：对调度器性能有直接影响</li></ul><h3 id="Audit-Exporter方法的数据收集路径"><a href="#Audit-Exporter方法的数据收集路径" class="headerlink" title="Audit-Exporter方法的数据收集路径"></a>Audit-Exporter方法的数据收集路径</h3><p>而audit-exporter方法从kube-apiserver的审计日志中提取性能数据：</p><pre class="mermaid">graph LR    A[调度器向APIServer发起请求] --&gt; B[APIServer记录审计日志]    B --&gt; C[audit-exporter解析日志]    C --&gt; D[转换为Prometheus指标]    D --&gt; E[Prometheus抓取存储]    E --&gt; F[Grafana查询展示]</pre><p><strong>核心特点</strong>：</p><ul><li><strong>数据源</strong>：kube-apiserver的完整请求审计记录</li><li><strong>时间精度</strong>：基于APIServer的高精度时间戳</li><li><strong>数据完整性</strong>：涵盖从请求到响应的完整生命周期</li><li><strong>系统开销</strong>：不影响调度器性能，仅增加APIServer审计开销</li></ul><h2 id="2-本质差异分析"><a href="#2-本质差异分析" class="headerlink" title="2. 本质差异分析"></a>2. 本质差异分析</h2><h3 id="✅-数据收集阶段的差异（核心）"><a href="#✅-数据收集阶段的差异（核心）" class="headerlink" title="✅ 数据收集阶段的差异（核心）"></a>✅ 数据收集阶段的差异（核心）</h3><p><strong>传统方法的局限性</strong>：</p><ol><li><strong>可控能力差</strong>：调度器内部的metric埋点可能无法覆盖所有关键路径，受制于代码中指标记录调用的位置和频率  </li><li><strong>潜在性能影响</strong>：在高负载下，调度器本身指标统计可能会影响调度性能</li></ol><p><strong>Audit-exporter方法的优势</strong>：</p><ol><li><strong>可控能力强</strong>：可以自定义捕获数据，例如本项目能监控每个API请求的完整生命周期（RequestReceived → ResponseComplete），且因为基于外部 APIServer，所以所有组件（调度器、控制器等）的请求都被统一记录</li><li><strong>无性能影响</strong>：基于外部 APIServer，低侵入性，不影响被监控组件的性能</li></ol><p>具体来说，通过audit日志能够精确记录关键事件：</p><div class="code-container" data-rel="Json"><figure class="iseeu highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">  <span class="attr">"verb"</span><span class="punctuation">:</span> <span class="string">"create"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"objectRef"</span><span class="punctuation">:</span> <span class="punctuation">{</span><span class="attr">"resource"</span><span class="punctuation">:</span> <span class="string">"pods"</span><span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"stage"</span><span class="punctuation">:</span> <span class="string">"ResponseComplete"</span><span class="punctuation">,</span> </span><br><span class="line">  <span class="attr">"stageTimestamp"</span><span class="punctuation">:</span> <span class="string">"2025-01-27T10:30:45.123456Z"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"requestReceivedTimestamp"</span><span class="punctuation">:</span> <span class="string">"2025-01-27T10:30:45.098123Z"</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></table></figure></div><p>通过解析这些事件，可以计算出精确的 <strong>Pod创建延迟</strong>、 <strong>调度延迟</strong> 等数据。</p><h3 id="❌-数据处理阶段的相似性"><a href="#❌-数据处理阶段的相似性" class="headerlink" title="❌ 数据处理阶段的相似性"></a>❌ 数据处理阶段的相似性</h3><p><strong>重要澄清</strong>：两种方法在数据处理阶段实际上是相同的！（之前我的博客中，知道数据处理方法中 histogram 会存在误差，但现在才发现这种误差两种方法都会有）</p><p>无论是传统方法还是audit-exporter方法，最终都会：</p><ol><li>将原始数据转换为Prometheus histogram指标</li><li>使用相同的bucket配置和histogram_quantile()函数</li><li>面临相同的线性插值误差问题</li></ol><p>因此，<strong>Prometheus histogram的误差问题在两种方法中都存在</strong>，差异并非来自数据处理阶段。</p><hr><h1 id="📊-Prometheus-Histogram误差深度解析"><a href="#📊-Prometheus-Histogram误差深度解析" class="headerlink" title="📊 Prometheus Histogram误差深度解析"></a>📊 Prometheus Histogram误差深度解析</h1><h2 id="1-Histogram工作原理"><a href="#1-Histogram工作原理" class="headerlink" title="1. Histogram工作原理"></a>1. Histogram工作原理</h2><p>Prometheus histogram通过预定义的bucket边界来统计数据分布：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 示例：调度延迟histogram配置</span></span><br><span class="line">latencyHistogram := prometheus.NewHistogram(prometheus.HistogramOpts{</span><br><span class="line">    Name: <span class="string">"scheduler_latency_seconds"</span>,</span><br><span class="line">    Buckets: []<span class="type">float64</span>{<span class="number">0.01</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">10</span>}, <span class="comment">// bucket边界</span></span><br><span class="line">})</span><br></pre></td></tr></table></figure></div><p>当收集到延迟数据时，每个观测值会被分配到相应的bucket中：</p><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">观测值: 0.3秒</span><br><span class="line">↓</span><br><span class="line">累计到bucket: le="0.5", le="1", le="5", le="10", le="+Inf"</span><br></pre></td></tr></table></figure></div><p>其中 le 指 less，即 bucket 记录“小于 x 的数字有多少个”。</p><h2 id="2-线性插值误差机制"><a href="#2-线性插值误差机制" class="headerlink" title="2. 线性插值误差机制"></a>2. 线性插值误差机制</h2><h3 id="均匀分布假设的问题"><a href="#均匀分布假设的问题" class="headerlink" title="均匀分布假设的问题"></a>均匀分布假设的问题</h3><p>Prometheus使用<code>histogram_quantile()</code>函数计算百分位数时，<strong>假设每个bucket内的数据均匀分布</strong>：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Prometheus源码中的线性插值逻辑（简化）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">linearInterpolation</span><span class="params">(bucketStart, bucketEnd <span class="type">float64</span>, rank, count <span class="type">float64</span>)</span></span> <span class="type">float64</span> {</span><br><span class="line">    <span class="keyword">return</span> bucketStart + (bucketEnd-bucketStart)*rank/count</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p><strong>例子</strong>：假设我们有bucket配置<code>[0.1, 0.5, 1.0]</code>，观测到以下数据：</p><table><thead><tr><th>Bucket范围</th><th>累计计数</th><th>实际分布</th></tr></thead><tbody><tr><td>(0, 0.1]</td><td>10</td><td>均匀分布</td></tr><tr><td>(0.1, 0.5]</td><td>90</td><td><strong>集中在0.12秒附近</strong></td></tr><tr><td>(0.5, 1.0]</td><td>100</td><td>均匀分布</td></tr></tbody></table><p>计算P90（第90个样本）：</p><ul><li><strong>Prometheus假设</strong>：P90在(0.1, 0.5]区间内均匀分布，计算得P90 ≈ 0.5秒</li><li><strong>实际情况</strong>：如果80个样本都集中在0.12秒附近，真实P90 ≈ 0.12秒</li><li><strong>结论</strong>：存在非常大的误差（尤其当桶边界非线性时，目前看大多数情况下桶边界都是指数级增长，具体原因可能是大部分数据都非均匀分布，数据范围太大时线性分布粒度过粗）</li></ul><h2 id="3-Bucket配置的关键影响"><a href="#3-Bucket配置的关键影响" class="headerlink" title="3. Bucket配置的关键影响"></a>3. Bucket配置的关键影响</h2><h3 id="默认Bucket的问题"><a href="#默认Bucket的问题" class="headerlink" title="默认Bucket的问题"></a>默认Bucket的问题</h3><p>不同Prometheus客户端库的默认bucket配置：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Go客户端默认bucket</span></span><br><span class="line">prometheus.DefBuckets = []<span class="type">float64</span>{</span><br><span class="line">    <span class="number">.005</span>, <span class="number">.01</span>, <span class="number">.025</span>, <span class="number">.05</span>, <span class="number">.1</span>, <span class="number">.25</span>, <span class="number">.5</span>, <span class="number">1</span>, <span class="number">2.5</span>, <span class="number">5</span>, <span class="number">10</span>,</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// Python客户端默认bucket  </span></span><br><span class="line">DEFAULT_BUCKETS = (</span><br><span class="line">    <span class="number">.005</span>, <span class="number">.01</span>, <span class="number">.025</span>, <span class="number">.05</span>, <span class="number">.075</span>, <span class="number">.1</span>, <span class="number">.25</span>, <span class="number">.5</span>, <span class="number">.75</span>, </span><br><span class="line">    <span class="number">1.0</span>, <span class="number">2.5</span>, <span class="number">5.0</span>, <span class="number">7.5</span>, <span class="number">10.0</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div><p>这些默认配置的问题：</p><ol><li><strong>覆盖范围过广</strong>：从5ms到10s，对特定应用场景分辨率不足</li><li><strong>分布不均</strong>：低延迟区间密集，高延迟区间稀疏</li></ol><h3 id="可能的备选Bucket策略"><a href="#可能的备选Bucket策略" class="headerlink" title="可能的备选Bucket策略"></a>可能的备选Bucket策略</h3><p><strong>1. 基于SLO设计</strong>：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 假设SLO为P95 &lt; 500ms, P99 &lt; 1s</span></span><br><span class="line">sloBuckets := []<span class="type">float64</span>{</span><br><span class="line">    <span class="number">0.050</span>, <span class="number">0.100</span>, <span class="number">0.200</span>, <span class="number">0.350</span>, <span class="comment">// P95周围密集采样</span></span><br><span class="line">    <span class="number">0.500</span>, <span class="number">0.650</span>, <span class="number">0.800</span>, <span class="number">0.950</span>, <span class="comment">// P99周围密集采样  </span></span><br><span class="line">    <span class="number">1.000</span>, <span class="number">2.000</span>, <span class="number">5.000</span>,        <span class="comment">// 异常情况覆盖</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p><strong>2. 对数分布</strong>：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指数增长，适合跨多个数量级的指标</span></span><br><span class="line">logBuckets := []<span class="type">float64</span>{</span><br><span class="line">    <span class="number">0.001</span>, <span class="number">0.002</span>, <span class="number">0.005</span>, <span class="number">0.01</span>, <span class="number">0.02</span>, <span class="number">0.05</span>, </span><br><span class="line">    <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>,</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p><strong>3. 动态调整</strong>：某些高级方案支持根据实际数据分布动态调整bucket（VictoriaMetrics似乎有这个功能）</p><hr><h1 id="🔧-Histogram替代方案与优化"><a href="#🔧-Histogram替代方案与优化" class="headerlink" title="🔧 Histogram替代方案与优化"></a>🔧 Histogram替代方案与优化</h1><h2 id="1-Summary指标"><a href="#1-Summary指标" class="headerlink" title="1. Summary指标"></a>1. Summary指标</h2><p>Prometheus提供了Summary类型作为histogram的替代：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">summary := prometheus.NewSummary(prometheus.SummaryOpts{</span><br><span class="line">    Name: <span class="string">"latency_seconds"</span>,</span><br><span class="line">    Objectives: <span class="keyword">map</span>[<span class="type">float64</span>]<span class="type">float64</span>{</span><br><span class="line">        <span class="number">0.5</span>: <span class="number">0.05</span>,  <span class="comment">// P50误差±5%</span></span><br><span class="line">        <span class="number">0.9</span>: <span class="number">0.01</span>,  <span class="comment">// P90误差±1% </span></span><br><span class="line">        <span class="number">0.99</span>: <span class="number">0.001</span>, <span class="comment">// P99误差±0.1%</span></span><br><span class="line">    },</span><br><span class="line">})</span><br></pre></td></tr></table></figure></div><p><strong>优势</strong>：</p><ul><li>客户端精确计算百分位数，无插值误差</li><li>内存占用相对固定</li><li>查询性能好</li></ul><p><strong>劣势</strong>：</p><ul><li><strong>无法聚合</strong>：不能跨实例计算全局百分位数</li><li><strong>预定义百分位</strong>：无法在查询时动态计算其他百分位数</li><li><strong>客户端开销</strong>：需要维护滑动窗口和排序</li></ul><hr><h1 id="🔚-总结"><a href="#🔚-总结" class="headerlink" title="🔚 总结"></a>🔚 总结</h1><p>通过本文的深入分析，我们可以得出以下关键结论：</p><h2 id="核心澄清"><a href="#核心澄清" class="headerlink" title="核心澄清"></a>核心澄清</h2><ol><li><p><strong>数据收集vs数据处理</strong>：audit-exporter方法与传统Prometheus方法的主要差异在于<strong>数据收集阶段</strong>（数据源和精度），而非数据处理阶段（histogram计算）。</p></li><li><p><strong>Histogram误差本质</strong>：Prometheus histogram的误差源于bucket内均匀分布假设与实际数据分布的差异，这在两种方法中都存在。默认bucket配置可能不匹配实际应用的延迟分布，需要根据SLO定制。</p></li></ol><hr><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="📝参考文献"><a href="#📝参考文献" class="headerlink" title="📝参考文献"></a>📝参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://cloud.tencent.com/developer/article/2210383">[1] 大规模集群仿真模拟与调度器压测方法<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://hulining.gitbook.io/prometheus/practices/histograms#errors-of-quantile-estimation">[2] Prometheus中文文档 - Histogram and Summary<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>%E3%80%82)</p><p><a class="link" href="https://mp.weixin.qq.com/s/5Y_pCPIJcRpIlqhdtb3XBw">[3] 蓝胖子编程梦 - prometheus描点原理<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://www.cnblogs.com/hobbybear/p/17531488.html">[4] 蓝胖子编程梦 - prometheus Histogram 统计原理<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[5] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://github.com/wzshiming/kube-apiserver-audit-exporter">[6] Github - kube-apiserver-audit-exporter<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> </p>]]></content>
    
    
    <summary type="html">深入分析audit-exporter与传统Prometheus监控方法的本质差异，澄清数据收集vs数据处理阶段的误区，并探讨Prometheus histogram的bucket分布假设与误差来源。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="K8s" scheme="https://freshwlnd.github.io/tags/K8s/"/>
    
    <category term="性能测试" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
    <category term="监控" scheme="https://freshwlnd.github.io/tags/%E7%9B%91%E6%8E%A7/"/>
    
    <category term="Volcano" scheme="https://freshwlnd.github.io/tags/Volcano/"/>
    
    <category term="Histogram" scheme="https://freshwlnd.github.io/tags/Histogram/"/>
    
  </entry>
  
  <entry>
    <title>【集群】云原生批调度实战：Volcano 自定义镜像与二次压测</title>
    <link href="https://freshwlnd.github.io/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/"/>
    <id>https://freshwlnd.github.io/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/</id>
    <published>2025-08-08T10:13:02.000Z</published>
    <updated>2025-09-18T07:27:36.926Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p><ol><li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li><li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li><li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li><li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li><li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li><li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li><li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li><li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li><li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li><li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li><li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li><li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li><li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li><li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a></li></ol></blockquote><p>（在未来）优化时，在调度器源码中加入 <strong>新算法</strong> 后，我们最关心的就是：</p><blockquote><p><em>「我改的逻辑到底是否提升了吞吐量？」</em></p></blockquote><p>本篇将手把手演示 <strong>本地构建自定义 Volcano Scheduler 镜像 → 替换到 Kind 集群 → 重跑 Benchmark</strong> 的全流程，帮助大家 <strong>快速验证改动效果</strong>。</p><hr><h1 id="1️⃣-Fork-amp-修改源码"><a href="#1️⃣-Fork-amp-修改源码" class="headerlink" title="1️⃣ Fork & 修改源码"></a>1️⃣ Fork &amp; 修改源码</h1><ol><li>Fork <a class="link" href="https://github.com/volcano-sh/volcano">Volcano<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 仓库；</li><li>切分支 <code>feat/my-algorithm</code>；</li><li>在 <code>pkg/scheduler/plugins/</code> 新增/修改调度逻辑；</li><li>本地单元测试通过后，进入构建阶段。</li></ol><blockquote><p><strong>示例改动</strong>：在 <code>allocate.go</code> 打印每次 <code>selectBestNode</code> 结果。</p></blockquote><hr><h1 id="2️⃣-本地构建镜像-amp-推送-Registry"><a href="#2️⃣-本地构建镜像-amp-推送-Registry" class="headerlink" title="2️⃣ 本地构建镜像 & 推送 Registry"></a>2️⃣ 本地构建镜像 &amp; 推送 Registry</h1><p>项目脚本已自带 <strong>本地 5000 端口 Registry</strong>，无需额外安装。关键脚本：</p><div class="code-container" data-rel="Sh"><figure class="iseeu highlight sh"><figcaption><span>hack/local-registry-with-load-images.sh:17:33</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create local registry container if not running</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="string">"<span class="subst">$(docker inspect -f '{{.State.Running}}' <span class="string">"<span class="variable">${reg_name}</span>"</span> 2&gt;/dev/null || true)</span>"</span> != <span class="string">'true'</span> ]]; <span class="keyword">then</span></span><br><span class="line">  target_image=<span class="string">"docker.io/library/registry:2.8.3"</span></span><br><span class="line">  <span class="keyword">if</span> [[ <span class="variable">${IMAGE_PREFIX}</span> != <span class="string">""</span> ]] &amp;&amp; ! docker image inspect <span class="string">"<span class="variable">${target_image}</span>"</span> &amp;&gt;/dev/null; <span class="keyword">then</span></span><br><span class="line">    docker pull <span class="string">"<span class="variable">${IMAGE_PREFIX}</span><span class="variable">${target_image}</span>"</span></span><br><span class="line">    docker tag <span class="string">"<span class="variable">${IMAGE_PREFIX}</span><span class="variable">${target_image}</span>"</span> <span class="string">"<span class="variable">${target_image}</span>"</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line">  docker run \</span><br><span class="line">    -d \</span><br><span class="line">    --restart=always \</span><br><span class="line">    -p <span class="string">"127.0.0.1:<span class="variable">${reg_port}</span>:5000"</span> \</span><br><span class="line">    --network bridge \</span><br><span class="line">    --name <span class="string">"<span class="variable">${reg_name}</span>"</span> \</span><br><span class="line">    -v <span class="string">"<span class="variable">${ROOT_DIR}</span>/registry-data:/var/lib/registry"</span> \</span><br><span class="line">    <span class="string">"<span class="variable">${target_image}</span>"</span> || :</span><br><span class="line">  <span class="built_in">sleep</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></div><p>构建 &amp; 推送命令：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设当前位于 volcano 仓库根目录</span></span><br><span class="line"><span class="built_in">export</span> TAG=dev</span><br><span class="line">make -C build scheduler-image \</span><br><span class="line">  IMAGE_REPO=kind-registry:5000/volcano-scheduler \</span><br><span class="line">  IMAGE_TAG=<span class="variable">${TAG}</span></span><br><span class="line"></span><br><span class="line">docker push kind-registry:5000/volcano-scheduler:<span class="variable">${TAG}</span></span><br></pre></td></tr></table></figure></div><blockquote><p>若在国内环境，可通过 <code>IMAGE_PREFIX</code> 拉取基础镜像，详见上文 Metrics 篇。</p></blockquote><p>Mermaid 流程一览：</p><pre class="mermaid">graph TD;  A[源码改动] --&gt; B("Docker build")  B --&gt; C("本地镜像 kind-registry:5000")  C --&gt; D("kustomize build → kubectl apply")  D --&gt; E("Kind 集群调度性能测试")</pre><hr><h1 id="3️⃣-替换-Deployment-中的镜像"><a href="#3️⃣-替换-Deployment-中的镜像" class="headerlink" title="3️⃣ 替换 Deployment 中的镜像"></a>3️⃣ 替换 Deployment 中的镜像</h1><p>调度器 Deployment 位于：</p><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><figcaption><span>schedulers/volcano/volcano-scheduler/deployment.yaml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">kind-registry:5000/docker.io/volcanosh/vc-scheduler:v1.11.0</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">volcano-scheduler</span></span><br></pre></td></tr></table></figure></div><p>只需把 <code>image:</code> 行替换为新镜像：</p><div class="code-container" data-rel="Diff"><figure class="iseeu highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="deletion">- image: kind-registry:5000/docker.io/volcanosh/vc-scheduler:v1.11.0</span></span><br><span class="line"><span class="addition">+ image: kind-registry:5000/volcano-scheduler:dev</span></span><br></pre></td></tr></table></figure></div><hr><h1 id="4️⃣-重新压测-amp-对比指标"><a href="#4️⃣-重新压测-amp-对比指标" class="headerlink" title="4️⃣ 重新压测 & 对比指标"></a>4️⃣ 重新压测 &amp; 对比指标</h1><ol><li><strong>启动集群 &amp; 压测</strong></li></ol><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">make prepare-volcano start-volcano \</span><br><span class="line">  IMAGE_PREFIX= \</span><br><span class="line">  NODES_SIZE=1000 QUEUES_SIZE=1 JOBS_SIZE_PER_QUEUE=500 PODS_SIZE_PER_JOB=20</span><br></pre></td></tr></table></figure></div><ol start="2"><li><strong>结束测试 &amp; 保存面板</strong></li></ol><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make end-volcano</span><br></pre></td></tr></table></figure></div><ol start="3"><li><strong>查看结果目录</strong>（假设时间戳 <code>1690300000</code>）：</li></ol><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">results/</span><br><span class="line">  └── 1690300000/</span><br><span class="line">      ├── audit.log</span><br><span class="line">      ├── metrics.json</span><br><span class="line">      └── panels/</span><br><span class="line">          ├── panel-1.png   # CREATED 曲线</span><br><span class="line">          ├── panel-2.png   # SCHEDULED 曲线</span><br><span class="line">          └── panel-3.png   # RUNNING 曲线</span><br></pre></td></tr></table></figure></div><hr><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://www.youtube.com/watch?v=njT5r3JjIaA&list=PLj6h78yzYM2MP0QhYFK8HOb8UqgbIkLMc&index=226">[2] A Comparative Analysis of Kueue, Volcano, and YuniKorn - Wei Huang, Apple &amp; Shiming Zhang, DaoCloud<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/audit/">[3] Kubernetes官方文档 - 审计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Policy">[4] Kubernetes官方文档 - 审计Policy配置参考<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">演示如何验证修改算法后调度器性能变化情况，包括 Fork Volcano 源码、构建本地镜像、替换 Deployment 并再次执行性能测试，实现算法改动的快速回归。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="K8s" scheme="https://freshwlnd.github.io/tags/K8s/"/>
    
    <category term="性能测试" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
    <category term="Volcano" scheme="https://freshwlnd.github.io/tags/Volcano/"/>
    
    <category term="镜像定制" scheme="https://freshwlnd.github.io/tags/%E9%95%9C%E5%83%8F%E5%AE%9A%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>【集群】云原生批调度实战：Volcano 指标采集与可视化</title>
    <link href="https://freshwlnd.github.io/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/"/>
    <id>https://freshwlnd.github.io/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/</id>
    <published>2025-08-07T14:59:25.000Z</published>
    <updated>2025-09-18T07:27:36.966Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p><ol><li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li><li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li><li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li><li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li><li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li><li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li><li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li><li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li><li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li><li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li><li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li><li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li><li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li><li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a></li></ol></blockquote><p>上一篇我们从 <strong>Makefile → Kind → 测试代码</strong> 串起了一次最小性能测试的全链路。本篇将回答另一个常见问题：</p><blockquote><p><em>「<code>TestBatchJob</code> 跑完后，Grafana 面板上的 CREATED / SCHEDULED / RUNNING 曲线是怎么来的？」</em></p></blockquote><p>下图给出了核心组件与数据流，阅读完本文，希望能够帮你快速实现：</p><ol><li>理解 审计日志 → Exporter → Prometheus+Grafana → 截图归档 的端到端链路；</li><li>自定义审计策略 &amp; 面板查询 &amp; 截图归档。</li></ol><pre class="mermaid">graph LR;  subgraph Control-Plane 审计日志    APIServer["Kube-APIServer(开启审计)"] --&gt;|/var/log/kubernetes/kube-apiserver-audit.log| NodeDisk[(control-plane 节点磁盘)]  end  NodeDisk --&gt; Exporter["Audit-Exporter(Deployment)"]  Exporter --&gt;|/metrics| Prometheus((Prometheus))  Prometheus --&gt; Grafana[(Grafana Dashboard)]  Grafana --&gt; Script[save-result-images.sh]</pre><hr><h1 id="1️⃣-审计日志：audit-policy-yaml-决定记录什么"><a href="#1️⃣-审计日志：audit-policy-yaml-决定记录什么" class="headerlink" title="1️⃣ 审计日志：audit-policy.yaml 决定记录什么"></a>1️⃣ 审计日志：audit-policy.yaml 决定<strong>记录什么</strong></h1><p>对应前文流程图中的 <code>Control-Plane 审计日志</code> 部分，在 Kubernetes 中，每个请求在不同执行阶段都会生成审计事件；这些审计事件会根据特定策略被预处理并写入后端。<a href="#refer-anchor-1"><sup>[3]</sup></a></p><p>在此过程中，Kubernetes 审计子系统需要一份 <em>Policy</em> 文件来声明规则（指明需记录的事件范围）。而本项目根目录的 <code>audit-policy.yaml</code> 中就声明了一套规则，重点拦截了衡量调度器吞吐量的关键对象 <strong>Pod / Job 的 CRUD</strong>：</p><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><figcaption><span>audit-policy.yaml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Policy</span></span><br><span class="line"><span class="attr">omitManagedFields:</span> <span class="literal">True</span></span><br><span class="line"><span class="attr">omitStages:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">RequestReceived</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">ResponseStarted</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">level:</span> <span class="string">RequestResponse</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">""</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">pods/binding</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">pods/status</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">batch</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">jobs</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">jobs/status</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">batch.volcano.sh</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">jobs</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">jobs/status</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">create</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">patch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">update</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">delete</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span></span><br></pre></td></tr></table></figure></div><ul><li><code>omitStages</code> 指明每个请求可无须记录相关的阶段（stage）。Kubernetes 中已定义的阶段有：<ul><li><code>RequestReceived</code> - 此阶段对应审计处理器接收到请求后， 并且在委托给其余处理器之前生成的事件。</li><li><code>ResponseStarted</code> - 在响应消息的头部发送后，响应消息体发送前生成的事件。 只有长时间运行的请求（例如 watch）才会生成这个阶段。</li><li><code>ResponseComplete</code> - 当响应消息体完成并且没有更多数据需要传输的时候。</li><li><code>Panic</code> - 当 panic 发生时生成。</li></ul></li><li><code>level: RequestResponse</code> 既保留请求头，也包含响应体，方便后续解析出 <strong>Result 及耗时</strong>。<ul><li><code>verbs</code> 指明此规则所适用的操作（verb）列表。将 CREATE / PATCH / UPDATE / DELETE 四类操作一次性覆盖；</li><li><code>resources</code> 指明此规则所适用的资源类别列表，包含 <code>batch</code>、<code>batch.volcano.sh/jobs</code> 等 CRD，兼顾不同调度器对象。字段 <code>group</code> 给出包含资源的 API 组的名称，空字符串代表 core API 组。</li></ul></li><li><code>level: Metadata</code> 则仅记录请求的元数据（请求的用户、时间戳、资源、动词等等）， 但是不记录请求或者响应的消息体。<ul><li><code>resources</code> 为空列表意味着适用于 API 组中的所有资源类别。</li></ul></li></ul><p>通常情况下，可以使用 <code>--audit-policy-file</code> 标志将包含策略的文件传递给 <code>kube-apiserver</code>。</p><!-- 在本项目中，...。 --><h2 id="▶️-FAQ：策略细节常见疑问"><a href="#▶️-FAQ：策略细节常见疑问" class="headerlink" title="▶️ FAQ：策略细节常见疑问"></a>▶️ FAQ：策略细节常见疑问</h2><blockquote><p>💡 以下内容专门回应在阅读源码时最常见的 3 个疑惑。</p></blockquote><p><strong>① <code>level: Metadata</code> 与 <code>level: RequestResponse</code> 有何区别？为何都要保留？</strong></p><ul><li>作用域不同：<ul><li><code>RequestResponse</code> 规则<strong>只</strong>匹配我们关心的调度相关资源（<code>pods</code> / <code>jobs</code> / <code>jobs.batch.volcano.sh</code> 等），并且显式列举了 <code>verbs</code>=<code>create|patch|update|delete</code>。它会把 <strong>请求头 + 响应体</strong> 全量落盘，方便后续 Exporter 解析出 <strong>Result (Success/Failure) 与延迟直方图</strong>。</li><li><code>Metadata</code> 规则的 <code>resources: []</code> 表示「兜底规则」——凡是不在前一条命中列表内的 <strong>任何</strong> 资源，统一只记录元数据（谁、何时、做了什么），<strong>不包含请求/响应体</strong>。这样既能保留审计合规性，又避免为海量无关对象写大文件。</li></ul></li><li>优先级：Kubernetes 会按照 YAML 中的 <strong>先后顺序</strong> 匹配规则，一旦命中即停止继续匹配。因此本项目先写精确匹配、再写兜底规则，二者不会冲突。</li><li>同时编写两条规则的目的：<strong>平衡指标精度与日志体积</strong>。<code>RequestResponse</code> 为核心对象提供高粒度延迟直方图与成功率计算；<code>Metadata</code> 兜底满足审计留痕合规，又避免为成百上千个与调度无关的对象写入冗余响应体，从而显著降低磁盘占用与解析成本。</li></ul><p><strong>② 为什么 <code>omitStages</code> 要排除 <code>RequestReceived</code> 和 <code>ResponseStarted</code>？最终会记录哪些 Stage？</strong></p><ul><li>背景：一次 API 请求最多可生成四个 Stage 事件（<code>RequestReceived</code> ➡ <code>ResponseStarted</code> ➡ <code>ResponseComplete</code> ➡ <code>Panic</code>）。其中 <code>RequestReceived</code> 与 <code>ResponseStarted</code> <em>体量大且价值有限</em>：<ul><li><code>RequestReceived</code> 只表明「请求到达了 APIServer」，但拿不到任何时长信息；</li><li><code>ResponseStarted</code> 仅对 <strong>长连接 watch</strong> 场景才会生成，对我们的批量 CRUD 测试用例几乎恒为空；</li></ul></li><li>因此在策略里把这两阶段排除，既减少日志体积，也避免 Exporter 做无意义解析。</li><li>与规则无冲突：<code>omitStages</code> 作用于 <strong>全局</strong>，告诉 APIServer 在生成审计事件时忽略指定阶段；后面的 <code>rules</code> 只决定「对哪些请求生成事件以及生成到什么 level」。二者工作维度不同，不会互相覆盖。</li><li>在本项目的批量 Job / Pod 测试中，最终实际落盘的 Stage 主要是：<ul><li><code>ResponseComplete</code> — 绝大多数正常请求；</li><li><code>Panic</code> — 只有当 APIServer panic 才会出现（理论上极少）。</li></ul></li><li>如何拿到「创建 / 调度 / 运行」等关键时间点？Exporter 仅需关注 <code>stage="ResponseComplete"</code> 的事件：<ul><li><strong>创建时间</strong>：匹配 <code>verb=create</code> 且 <code>resource=pods|jobs</code> 的完成时间戳；</li><li><strong>调度时间</strong>：匹配 <code>resource=pods/binding</code> 的完成时间戳（kube-scheduler 向 APIServer 发起 bind 请求）；</li><li><strong>运行时间</strong>：匹配 <code>resource=pods/status</code>、<code>verb=update</code> 且 <code>status.phase=Running</code> 的完成时间戳；<br>Exporter 在内存中以同名 Pod UID 关联多条事件，计算时间差即可，无需 <code>RequestReceived/Started</code> 阶段即可还原完整链路。</li><li><strong><code>Panic</code> 含义</strong>：当 APIServer 在处理请求过程中发生运行时崩溃并捕获到 panic 时才会生成，用于事后问题排查，正常测试流程极罕见。</li></ul></li></ul><p><strong>③ <code>audit-policy.yaml</code> 是如何交给 Kind 中的 kube-apiserver 的？</strong></p><ul><li>每个调度器对应的 Kind 集群（位于 <code>clusters/&lt;scheduler&gt;/kind.yaml</code>）都做了如下三种操作：<ol><li><code>extraMounts</code> 把根目录下的 <code>audit-policy.yaml</code> <strong>挂载</strong>到控制平面节点的 <code>/etc/kubernetes/policies/audit-policy.yaml</code>；</li><li><code>apiServer.extraVolumes</code> 定义名为 <code>audit-policies</code> 的 HostPath 卷，并将其挂载到同一路径，确保文件在 Pod 内可读；</li><li><code>apiServer.extraArgs</code> 增加<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">audit-policy-file:</span> <span class="string">/etc/kubernetes/policies/audit-policy.yaml</span></span><br><span class="line"><span class="attr">audit-log-path:</span> <span class="string">/var/log/kubernetes/kube-apiserver-audit.&lt;scheduler&gt;.log</span></span><br><span class="line"><span class="attr">audit-log-maxsize:</span> <span class="string">"10240"</span></span><br></pre></td></tr></table></figure></div>这样 APIServer 一启动就按照我们自定义的策略把审计事件写入宿主机 <code>/var/log/kubernetes/</code>，后续再被 Exporter Tail。</li></ol></li></ul><hr><h1 id="2️⃣-Exporter：kube-apiserver-audit-exporter-把日志变成指标"><a href="#2️⃣-Exporter：kube-apiserver-audit-exporter-把日志变成指标" class="headerlink" title="2️⃣ Exporter：kube-apiserver-audit-exporter 把日志变成指标"></a>2️⃣ Exporter：kube-apiserver-audit-exporter 把日志变成指标</h1><p>前文 Policy 决定了「记录什么」，Exporter 则决定了「怎么提炼指标」。<br>部署清单位于：<code>base/kube-apiserver-audit-exporter/kube-apiserver-audit-exporter/deployment.yaml</code></p><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><figcaption><span>base/kube-apiserver-audit-exporter/kube-apiserver-audit-exporter/deployment.yaml:24:41</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--audit-log-path</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/var/log/kubernetes/kube-apiserver-audit.log</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">kind-registry:5000/ghcr.io/wzshiming/kube-apiserver-audit-exporter/kube-apiserver-audit-exporter:v0.0.25</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">exporter</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">100Mi</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/var/log/kubernetes</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">audit-logs</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure></div><p>关键参数说明：</p><table><thead><tr><th>字段</th><th>含义</th><th>示例值</th></tr></thead><tbody><tr><td><code>--audit-log-path</code></td><td>审计日志所在宿主机路径</td><td><code>/var/log/kubernetes/kube-apiserver-audit.log</code></td></tr><tr><td><code>image</code></td><td>可独立升级的 Exporter 镜像</td><td><code>…/kube-apiserver-audit-exporter:v0.0.25</code></td></tr><tr><td>VolumeMount</td><td>将宿主机日志目录挂载进 Pod</td><td><code>mountPath: /var/log/kubernetes</code></td></tr></tbody></table><h2 id="📌-组件何时被部署？——-Makefile-触发点"><a href="#📌-组件何时被部署？——-Makefile-触发点" class="headerlink" title="📌 组件何时被部署？—— Makefile 触发点"></a>📌 组件何时被部署？—— Makefile 触发点</h2><p>在本仓库最常用的入口 <code>make default</code> 会连续执行多轮 <strong>serial-test</strong>。理解一次 <em>serial-test</em> 的执行序列即可明白监控组件的真实部署时机：</p><table><thead><tr><th>步骤</th><th>触发目标</th><th>关键动作</th></tr></thead><tbody><tr><td>1</td><td><code>prepare-&lt;scheduler&gt;</code></td><td><code>make up-&lt;scheduler&gt;</code> 创建 <strong>单个调度器集群</strong>，但此时 <em>没有</em> 监控栈</td></tr><tr><td>2</td><td><code>start-&lt;scheduler&gt;</code></td><td>运行性能测试 (<code>TestBatchJob</code> 等) 并 <strong>写入 audit-log</strong></td></tr><tr><td>3</td><td><code>end-&lt;scheduler&gt;</code></td><td><code>make down-&lt;scheduler&gt;</code> 销毁该集群，<strong>日志仍留在宿主机</strong> <code>/var/log/kubernetes/</code></td></tr><tr><td>⬇(循环)</td><td>(依次换下一个调度器)</td><td>…</td></tr><tr><td>4</td><td><code>prepare-overview</code></td><td><code>make up-overview</code> 创建 <strong>独立的 overview 集群</strong></td></tr><tr><td>5</td><td><code>start-overview</code></td><td><code>clusters/overview/Makefile:start-export</code> 部署 Exporter + PromStack，并把 <em>所有</em> <code>kube-apiserver-audit.*.log</code> HostPath 挂载到 Pod</td></tr><tr><td>6</td><td><code>save-result</code></td><td>睡 <code>$(RESULT_RECENT_DURATION_SECONDS)</code> 秒等待指标就绪→执行 <code>hack/save-result-images.sh</code> 截图</td></tr><tr><td>7</td><td><code>end-overview</code></td><td>销毁 overview 集群，聚合循环结束</td></tr></tbody></table><blockquote><p>也就是说：<strong>Export­er 和 Prometheus 直到 <em>所有</em> 调度器测试跑完后才被一次性拉起</strong>，随后一次性重放/解析先前留下的多份 audit-log。</p></blockquote><p>Exporter 会 tail 文件并实时解析，输出如下两类 Prometheus 指标（简化）：</p><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># HELP kube_audit_event_total Total number of audit events</span><br><span class="line"># TYPE kube_audit_event_total counter</span><br><span class="line">kube_audit_event_total{verb="create",resource="pods",status="Success"}  1280</span><br><span class="line"></span><br><span class="line"># HELP kube_audit_event_latency_seconds Histogram of audit event latency</span><br><span class="line"># TYPE kube_audit_event_latency_seconds histogram</span><br><span class="line">kube_audit_event_latency_seconds_bucket{resource="pods",le="0.1"} 240</span><br></pre></td></tr></table></figure></div><p>其中 <code>status="Success"</code> 字段让我们能够在 Grafana 中分别绘制 <strong>CREATED / SCHEDULED / RUNNING</strong> 三条曲线。</p><h2 id="🔍-内部实现：Exporter-如何-tail-解析？"><a href="#🔍-内部实现：Exporter-如何-tail-解析？" class="headerlink" title="🔍 内部实现：Exporter 如何 tail + 解析？"></a>🔍 内部实现：Exporter 如何 tail + 解析？</h2><p>该部分比较复杂，涉及另一个项目。简单理解后，将该部分分为以下三步：</p><ul><li><strong>跟踪文件</strong>：Exporter 使用 Go 语言实现，入口位于 &lt;base/kube-apiserver-audit-exporter&gt;，源仓库位于<a class="link" href="https://github.com/wzshiming/kube-apiserver-audit-exporter">https://github.com/wzshiming/kube-apiserver-audit-exporter<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>。其核心依赖 <code>tail</code>（或 OS <code>inotify</code>）持续读取宿主机 <code>/var/log/kubernetes/…audit.log</code>；</li><li><strong>JSON 解析</strong>：每行审计日志都是合法 JSON，Exporter 利用 <code>encoding/json</code> 反序列化为 <code>auditinternal.Event</code> 结构体，随后按 <code>verb / resource / stage / status</code> 维度进行 <code>map</code> 聚合；</li><li><strong>指标暴露</strong>：聚合结果通过 <code>prometheus/client_golang</code> 转为 <code>counter</code> 与 <code>histogram</code> 两类 <code>kube_audit_*</code> 指标；</li></ul><p>若要<strong>增加更多指标</strong>（如自定义 label、增加 <code>summary</code> 等）：</p><ul><li><strong>定位代码</strong>：仓库中路径 <code>exporter/metrics.go</code> 下可见：以apiRequests(api_requests_total)、podSchedulingLatency(pod_scheduling_latency_seconds)为例<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Metric definitions</span></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">  registry = prometheus.NewRegistry()</span><br><span class="line"></span><br><span class="line">  apiRequests = prometheus.NewCounterVec(prometheus.CounterOpts{</span><br><span class="line">    Name: <span class="string">"api_requests_total"</span>,</span><br><span class="line">    Help: <span class="string">"Total number of API requests to the scheduler"</span>,</span><br><span class="line">  }, []<span class="type">string</span>{<span class="string">"cluster"</span>, <span class="string">"namespace"</span>, <span class="string">"user"</span>, <span class="string">"verb"</span>, <span class="string">"resource"</span>, <span class="string">"code"</span>})</span><br><span class="line">  <span class="comment">// 核心为：apiRequests = prometheus.NewCounterVec(...)</span></span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  podSchedulingLatency = prometheus.NewHistogramVec(prometheus.HistogramOpts{</span><br><span class="line">    Name:    <span class="string">"pod_scheduling_latency_seconds"</span>,</span><br><span class="line">    Help:    <span class="string">"Duration from pod creation to scheduled on node in seconds"</span>,</span><br><span class="line">    Buckets: prometheus.ExponentialBuckets(<span class="number">0.001</span>, <span class="number">2</span>, <span class="number">20</span>),</span><br><span class="line">  }, []<span class="type">string</span>{<span class="string">"cluster"</span>, <span class="string">"namespace"</span>, <span class="string">"user"</span>})</span><br><span class="line">  <span class="comment">// 核心为：batchJobCompleteLatency = prometheus.NewCounterVec(...)</span></span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> {</span><br><span class="line">  registry.MustRegister(</span><br><span class="line">    apiRequests,</span><br><span class="line">    podSchedulingLatency,</span><br><span class="line">    ...</span><br><span class="line">  )</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// updateMetrics processes audit event and updates metrics</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Exporter)</span></span> updateMetrics(clusterLabel <span class="type">string</span>, event auditv1.Event) {</span><br><span class="line">  <span class="comment">// ... 根据需求，自定义规则将  verb/resource 填充指标 ...</span></span><br><span class="line">  <span class="keyword">if</span> event.Stage == auditv1.StageResponseComplete {</span><br><span class="line">    labels := []<span class="type">string</span>{</span><br><span class="line">      clusterLabel,</span><br><span class="line">      ns,</span><br><span class="line">      extractUserAgent(event.UserAgent),</span><br><span class="line">      event.Verb,</span><br><span class="line">      extractResourceName(event),</span><br><span class="line">      strconv.Itoa(<span class="type">int</span>(event.ResponseStatus.Code)),</span><br><span class="line">  }</span><br><span class="line">  apiRequests.WithLabelValues(labels...).Inc()</span><br><span class="line">  <span class="comment">// 核心为：apiRequests.WithLabelValues(labels...).Inc()</span></span><br><span class="line"> }</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> event.ObjectRef != <span class="literal">nil</span> {</span><br><span class="line">    <span class="keyword">switch</span> event.ObjectRef.Resource {</span><br><span class="line">    <span class="keyword">case</span> <span class="string">"pods"</span>:</span><br><span class="line">      <span class="keyword">if</span> event.ObjectRef.Subresource == <span class="string">"binding"</span> &amp;&amp; event.Verb == <span class="string">"create"</span> {</span><br><span class="line">        target := buildTarget(event.ObjectRef)</span><br><span class="line">        createTime, exists := p.podCreationTimes[target]</span><br><span class="line">        <span class="keyword">if</span> !exists {</span><br><span class="line">          <span class="comment">// Kueue's audit events may create pod/binding events before pod creation events</span></span><br><span class="line">          user := extractUserAgent(event.UserAgent)</span><br><span class="line">          podSchedulingLatency.WithLabelValues(</span><br><span class="line">            clusterLabel,</span><br><span class="line">            ns,</span><br><span class="line">            user,</span><br><span class="line">          ).Observe(<span class="number">0</span>)</span><br><span class="line">        <span class="comment">// 核心为：podSchedulingLatency.WithLabelValues(...).Observe()</span></span><br><span class="line">          p.podCreationTimes[target] = <span class="literal">nil</span></span><br><span class="line">          <span class="keyword">return</span></span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> createTime == <span class="literal">nil</span> {</span><br><span class="line">          <span class="keyword">return</span></span><br><span class="line">        }</span><br><span class="line">        latency := event.StageTimestamp.Sub(*createTime).Seconds()</span><br><span class="line"></span><br><span class="line">        user := extractUserAgent(event.UserAgent)</span><br><span class="line">        podSchedulingLatency.WithLabelValues(</span><br><span class="line">          clusterLabel,</span><br><span class="line">          ns,</span><br><span class="line">          user,</span><br><span class="line">        ).Observe(latency)</span><br><span class="line">      <span class="comment">// 核心为：podSchedulingLatency.WithLabelValues(...).Observe()</span></span><br><span class="line">        p.podCreationTimes[target] = <span class="literal">nil</span></span><br><span class="line"></span><br><span class="line">      }</span><br><span class="line">      ...</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div></li><li><strong>扩展步骤</strong>：<ol><li>复制：复制上述变量块，替换 <code>Name</code> 为 <code>kube_audit_pod_latency_seconds</code>（示例），同时调整 <code>Buckets</code>、<code>Help</code> 等参数；</li><li>修改：在 <code>updateMetrics</code> 中增加条件：<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> evt.ObjectRef.Resource == <span class="string">"pods"</span> {</span><br><span class="line">    podLatency.WithLabelValues(evt.Verb, evt.Stage).Observe(cost)</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div></li><li>注册：确保在 <code>init()</code> 或 <code>NewCollector()</code> 中 <code>registry.MustRegister(podLatency)</code>；</li><li>换镜像：<code>docker build -t &lt;registry&gt;/audit-exporter:dev . &amp;&amp; docker push …</code>，然后在 <code>base/kube-apiserver-audit-exporter/.../deployment.yaml</code> 更新 <code>image</code> 并 <code>kubectl apply -k</code>。</li></ol></li></ul><blockquote><p>完整示例可参考项目 <code>exporter/metrics.go</code> <a class="link" href="https://github.com/wzshiming/kube-apiserver-audit-exporter/blob/master/exporter/metrics.go">源码<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>。</p></blockquote><hr><h1 id="3️⃣-Prometheus-抓取：Kustomize-一条龙"><a href="#3️⃣-Prometheus-抓取：Kustomize-一条龙" class="headerlink" title="3️⃣ Prometheus 抓取：Kustomize 一条龙"></a>3️⃣ Prometheus 抓取：Kustomize 一条龙</h1><p><code>base/kube-prometheus-stack</code> 目录通过 Kustomize 把 Exporter、Prometheus Operator 与多个 ServiceMonitor 组合在一起，无需额外手动配置抓取目标。</p><ul><li>Prometheus 会自动发现 Exporter 的 <code>metrics</code> 端口；</li><li>Grafana 面板 JSON <code>audit-exporter.json</code> 已预置在同目录，标签切片（Scheduler 类型、Namespace、Verb）均可动态选择。</li></ul><blockquote><p>若要自定义阈值或颜色，只需 <code>kubectl edit cm grafana-dashboards</code> 后刷新浏览器即可即时生效。</p></blockquote><p>其中用到了 Kustomize 工具，较为复杂，在此仅简单介绍。</p><h2 id="✨-Kustomize-简介"><a href="#✨-Kustomize-简介" class="headerlink" title="✨ Kustomize 简介"></a>✨ Kustomize 简介</h2><p>Kustomize 是 Kubernetes 官方提供的 <strong>原生资源定制工具</strong>，核心理念是“声明式 Patch 与组合”。相比 <code>helm</code>，它无需模板语言，也不引入额外 CRD：</p><ul><li><strong>基础资源</strong>（Base）：每个目录下的 <code>kustomization.yaml</code> 列出若干 <code>resources</code>，可按文件或目录引用；</li><li><strong>叠加层</strong>（Overlay）：上层可以通过 <code>patches</code>, <code>images</code>, <code>replicas</code> 等声明式字段覆写或追加配置；</li><li><strong>生成器</strong>：<code>configMapGenerator</code>, <code>secretGenerator</code> 快速为应用生成引用。</li></ul><p>在本项目中：</p><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">base/kube-prometheus-stack/           # 监控基础组件 Base</span><br><span class="line">  ├── crd/                            # CRD 资源</span><br><span class="line">  ├── grafana/                        # Dashboard JSON 及账号</span><br><span class="line">  ├── ...</span><br><span class="line">  └── kustomization.yaml              # 声明所有组件</span><br></pre></td></tr></table></figure></div><p><code>clusters/overview/Makefile</code> 里的 <code>kubectl kustomize &lt;dir&gt; | hack/local-registry-with-load-images.sh</code> 两步做了：</p><ol><li><code>kubectl kustomize</code> → <strong>渲染</strong>：把以上 Base + Patch 解析成纯 YAML 清单；</li><li><code>local-registry-with-load-images.sh</code> → <strong>镜像处理</strong>：重写鏡像地址到本地 Kind Registry 并预先 <code>docker pull</code>；</li><li><code>kubectl create -k</code> → <strong>应用</strong>：批量创建 Exporter、Prometheus Operator、Alertmanager、ServiceMonitor 等所有资源，一次到位。</li></ol><p>因此我们才能“一键 make”拿到完整的监控栈。</p><hr><h1 id="4️⃣-截图归档：save-result-images-sh-归档面板截图"><a href="#4️⃣-截图归档：save-result-images-sh-归档面板截图" class="headerlink" title="4️⃣ 截图归档：save-result-images.sh 归档面板截图"></a>4️⃣ 截图归档：save-result-images.sh 归档面板截图</h1><p>运行 <code>make save-result</code> 后，<code>hack/save-result-images.sh</code> 会在本地循环调用 Grafana <code>render</code> API，按面板 ID 生成 <code>output/panel-*.png</code>：</p><div class="code-container" data-rel="Sh"><figure class="iseeu highlight sh"><figcaption><span>hack/save-result-images.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">RECENT_DURATION=<span class="variable">${RECENT_DURATION:-5min}</span></span><br><span class="line"></span><br><span class="line">FROM=$(<span class="built_in">date</span> -u -Iseconds -d <span class="string">"- <span class="variable">${RECENT_DURATION}</span>"</span> | sed <span class="string">'s/+00:00/.000Z/'</span>)</span><br><span class="line">TO=$(<span class="built_in">date</span> -u -Iseconds | sed <span class="string">'s/+00:00/.000Z/'</span>)</span><br><span class="line"></span><br><span class="line">OUTPUT=<span class="string">"<span class="variable">${ROOT_DIR}</span>/output"</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="string">"<span class="variable">${OUTPUT}</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> {1..8}; <span class="keyword">do</span></span><br><span class="line">  wget -O <span class="string">"<span class="variable">${OUTPUT}</span>/panel-<span class="variable">${i}</span>.png"</span> <span class="string">"http://127.0.0.1:8080/grafana/render/d-solo/perf?var-rate_interval=5s&amp;orgId=1&amp;from=<span class="variable">${FROM}</span>&amp;to=<span class="variable">${TO}</span>&amp;timezone=browser&amp;var-datasource=prometheus&amp;var-resource=\$__all&amp;var-user=\$__all&amp;var-verb=create&amp;var-verb=delete&amp;var-verb=patch&amp;var-verb=update&amp;var-namespace=default&amp;var-cluster=\$__all&amp;refresh=5s&amp;theme=dark&amp;panelId=panel-<span class="variable">${i}</span>&amp;__feature.dashboardSceneSolo&amp;width=900&amp;height=500&amp;scale=10"</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></div><ul><li><code>RECENT_DURATION</code> 环境变量控制 <em>截图时间窗口</em>（默认 5 分钟）；</li><li><code>FROM/TO</code> 时间戳使用 ISO-8601 UTC 毫秒格式，避免时区混淆；</li><li><code>panelId</code> 与面板 JSON 中的 <code>id</code> 一一对应，可根据需要扩展。</li></ul><p>示例输出目录结构：</p><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">output/</span><br><span class="line">  ├── panel-1.png   # CREATED 速率</span><br><span class="line">  ├── panel-2.png   # SCHEDULED 速率</span><br><span class="line">  ├── panel-3.png   # RUNNING 速率</span><br><span class="line">  └── …</span><br></pre></td></tr></table></figure></div><h2 id="⏱️-为什么三套调度器曲线对齐到同一起始时间？"><a href="#⏱️-为什么三套调度器曲线对齐到同一起始时间？" class="headerlink" title="⏱️ 为什么三套调度器曲线对齐到同一起始时间？"></a>⏱️ 为什么三套调度器曲线对齐到同一起始时间？</h2><p>在 <em>serial-test</em> 模式下，Exporter 直到第 4 步才启动，<strong>它会从头开始顺序扫描所有 audit-log</strong>。Prometheus 采集时将「第一次 scrape 该指标的时刻」视为样本时间戳，而不是事件发生时间。因此：</p><ul><li>当 Exporter 第一次读取 <em>三份</em> 日志文件时（约 <strong>T0</strong>），所有指标都会带上 <strong>T0</strong> 的统一时间戳；</li><li>读取完第一份文件后继续第二、第三份——对于 Prometheus 来说也仍是 “T0~T0+Δ” 的时间窗口；</li></ul><p>结果就是：Grafana 图上三条曲线似乎“同一时刻起跑”。它们并非并发，而是 <strong>日志回放造成的时间折叠</strong> —— 先跑的调度器其实更早完成，但其事件被延后才被采集。</p><p>如果希望曲线按真实事件时间展开，可以：</p><ol><li>修改 Exporter，让它把 <code>evt.StageTimestamp</code> 用作 Prometheus <code>histogram</code> 的 <code>ObserveWithTimestamp</code>；</li><li>或者在测试流程中提前启动 overview 集群，使 Exporter 按实时模式持续采集。</li></ol><p>如果想<strong>亲眼查看 audit-log</strong>，有两种方法：</p><ol><li><strong>直接读宿主机文件</strong>（Kind 节点实际上是 Docker 容器）：<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> kueue-control-plane \</span><br><span class="line">  <span class="built_in">cat</span> /var/log/kubernetes/kube-apiserver-audit.kueue.log | <span class="built_in">head</span></span><br></pre></td></tr></table></figure></div>三个文件名称分别为 <code>kube-apiserver-audit.{kueue|volcano|yunikorn}.log</code>。</li><li><strong>查看 Exporter 容器日志</strong>（overview 集群）：<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n monitoring logs deploy/kube-apiserver-audit-exporter | <span class="built_in">head</span></span><br></pre></td></tr></table></figure></div>启动时它会打印 <code>starting from offset=0 file=...</code>，表明正在从头重放。</li></ol><blockquote><p>日志文件很大，可用 <code>grep '"verb":"create"'</code> 等命令过滤感兴趣事件，字段含义详见 Kubernetes 官方审计文档。</p></blockquote><h2 id="📊-Panel-一览速查表"><a href="#📊-Panel-一览速查表" class="headerlink" title="📊 Panel 一览速查表"></a>📊 Panel 一览速查表</h2><table><thead><tr><th>面板 ID</th><th>Grafana 标题</th><th>输出文件</th><th>主要查询</th><th>典型用途</th></tr></thead><tbody><tr><td>panel-1</td><td>Pod Scheduling Latency Group By UserAgent</td><td>panel-1.png</td><td><code>histogram_quantile(0.99, pod_scheduling_latency_seconds_bucket)</code> 等分位线</td><td>调度延迟长尾监控</td></tr><tr><td>panel-2</td><td>Total API Calls Group By (UserAgent, Verb, Resource)</td><td>panel-2.png</td><td><code>api_requests_total</code> 累积</td><td>全维度 API 调用计数</td></tr><tr><td>panel-3</td><td>API Calls Rate Group By (UserAgent, Verb, Resource)</td><td>panel-3.png</td><td><code>rate(api_requests_total[$rate_interval])</code></td><td>API 吞吐趋势（含资源/动词维度）</td></tr><tr><td>panel-4</td><td>BatchJob Completion Latency Group By UserAgent</td><td>panel-4.png</td><td><code>histogram_quantile(... batchjob_completion_latency_seconds_bucket)</code></td><td>关注 Job 完成延迟</td></tr><tr><td>panel-5</td><td>Total Pod Scheduled Group By UserAgent</td><td>panel-5.png</td><td><code>sum(pod_scheduling_latency_seconds_count)</code> vs <code>sum(api_requests_total{verb="create",resource="pods"})</code></td><td>对比已调度与已创建 Pod 总量</td></tr><tr><td>panel-6</td><td>Total BatchJob Completed Group By UserAgent</td><td>panel-6.png</td><td><code>sum(batchjob_completion_latency_seconds_count)</code></td><td>Job 完成总量统计</td></tr><tr><td>panel-7</td><td>Total API Calls Group By UserAgent</td><td>panel-7.png</td><td><code>sum(api_requests_total) by (cluster,user)</code></td><td>按 UserAgent 维度累计 API 调用</td></tr><tr><td>panel-8</td><td>API Calls Rate Group By UserAgent</td><td>panel-8.png</td><td><code>rate(api_requests_total[$rate_interval])</code></td><td>按 UserAgent 维度 API 吞吐</td></tr></tbody></table><blockquote><p>以上所有查询皆可在 <code>base/kube-prometheus-stack/audit-exporter.json</code> 中找到对应 <code>panel.id</code> 的 <code>expr</code> 字段。</p></blockquote><h3 id="🏷️-CREATED-SCHEDULED-指标与-Panel-5-解读"><a href="#🏷️-CREATED-SCHEDULED-指标与-Panel-5-解读" class="headerlink" title="🏷️ CREATED / SCHEDULED 指标与 Panel-5 解读"></a>🏷️ CREATED / SCHEDULED 指标与 Panel-5 解读</h3><p>Grafana 的 <strong>panel-5.png</strong>（<code>Total Pod Scheduled Group By UserAgent</code>）同时叠加了 <em>累计已调度</em> 与 <em>累计已创建</em> 两条时间序列，用来快速判断“调度器吞吐量是否跟得上工作负载产生速度”。</p><p>两条序列的 PromQL 如下：</p><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 已调度总量（Series-A）</span><br><span class="line">sum(pod_scheduling_latency_seconds_count{cluster=~"$cluster",namespace=~"$namespace",user=~"$user"}) by (cluster,user)</span><br><span class="line"></span><br><span class="line"># 已创建总量（Series-B）</span><br><span class="line">sum(api_requests_total{cluster=~"$cluster",namespace=~"$namespace",user=~"$user",resource="pods",verb="create"}) by (cluster,user)</span><br></pre></td></tr></table></figure></div><blockquote><p>💡 <strong>资源类型</strong></p><ul><li>两条序列均针对 <strong>Pod</strong> 资源：<ul><li><strong>Series-B（CREATED）</strong> 捕获 <code>verb=create, resource=pods</code> 的审计事件；</li><li><strong>Series-A（SCHEDULED）</strong> 统计 <code>pod_scheduling_latency_seconds_count</code> 直方图计数，同样基于 Pod UID 聚合。</li></ul></li><li>Volcano 中的 <strong>PodGroup</strong> 仅在 <em>Gang</em> 场景下辅助调度，不会出现在上述指标中，因其创建频次远低于 Pod，且非调度器吞吐主瓶颈。</li></ul></blockquote><h3 id="ℹ️-为什么-Panel-5-采用-pod-scheduling-latency-seconds-count？可以改用-api-requests-total-吗？"><a href="#ℹ️-为什么-Panel-5-采用-pod-scheduling-latency-seconds-count？可以改用-api-requests-total-吗？" class="headerlink" title="ℹ️ 为什么 Panel-5 采用 pod_scheduling_latency_seconds_count？可以改用 api_requests_total 吗？"></a>ℹ️ 为什么 Panel-5 采用 <code>pod_scheduling_latency_seconds_count</code>？可以改用 <code>api_requests_total</code> 吗？</h3><ol><li><strong>数据源差异</strong><ul><li><code>api_requests_total{verb="create",resource="pods/binding"}</code> 也能反映调度动作，但 <strong>Exporter 默认并未将 <code>pods/binding</code> 事件打入此 Counter</strong>，而是交由 <code>pod_scheduling_latency_seconds</code> Histogram 统一处理（具体实现可见本文“<a href="#-%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0exporter-%E5%A6%82%E4%BD%95-tail--%E8%A7%A3%E6%9E%90">🔍 内部实现：Exporter 如何 tail + 解析？</a>”章节代码示例），以便同时统计累积延迟。</li><li>Histogram 自带 <code>_count</code> 系列，天然表示 <strong>成功调度次数</strong>；其 Bucket 仍能计算 P99 等延迟 —— 一举两得。</li></ul></li><li><strong>统计精度</strong><ul><li>Exporter 对同一 Pod 仅在 <strong>首次绑定成功</strong> 时 <code>Observe</code> 一次，所以 <code>_count</code> 与实际调度 Pod 数量一一对应，不会多计。</li><li>若直接使用 <code>api_requests_total</code> 方案，需要确保：<ol><li>Exporter 也把 <code>pods/binding</code> 计入 Counter；</li><li>Retry 或失败重试场景会导致多计，需要额外 <code>status="Success"</code> 过滤。</li></ol></li></ul></li><li><strong>替代方案</strong><ul><li>若你更习惯 Counter，可在 <code>metrics.go</code> 中追加：<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">podBindRequests := prometheus.NewCounterVec(... name=<span class="string">"pod_bind_requests_total"</span> ...)</span><br><span class="line"><span class="comment">// 在 event.ObjectRef.Subresource=="binding" 时 Inc()</span></span><br></pre></td></tr></table></figure></div></li><li>然后在 Dashboard 将 Panel-5 的 Series-A 改为 <code>sum(pod_bind_requests_total)</code>。</li></ul></li></ol><p>⚖️ <strong>结论</strong>：默认 <code>_count</code> 与 Counter 效果一致且无需新指标，<strong>不会导致调度数量误差</strong>；若需要可根据上述方法自定义。</p><hr><h1 id="5️⃣-本地验证：三步走"><a href="#5️⃣-本地验证：三步走" class="headerlink" title="5️⃣ 本地验证：三步走"></a>5️⃣ 本地验证：三步走</h1><ol><li><strong>最小规模跑一次</strong></li></ol><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">make prepare-volcano start-volcano end-volcano \</span><br><span class="line">    NODES_SIZE=1 JOBS_SIZE_PER_QUEUE=1 PODS_SIZE_PER_JOB=1</span><br></pre></td></tr></table></figure></div><ol start="2"><li><strong>打开 Grafana</strong></li></ol><p>浏览器访问 <a class="link" href="http://127.0.0.1:8080/grafana">http://127.0.0.1:8080/grafana<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>，Dashboards → <code>perf</code>，即可看到实时曲线。</p><ol start="3"><li><strong>查看截图</strong></li></ol><p>测试结束后，<code>output/</code> 将出现自动截好的图片，确认时间轴与曲线一致。</p><hr><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://www.youtube.com/watch?v=njT5r3JjIaA&list=PLj6h78yzYM2MP0QhYFK8HOb8UqgbIkLMc&index=226">[2] A Comparative Analysis of Kueue, Volcano, and YuniKorn - Wei Huang, Apple &amp; Shiming Zhang, DaoCloud<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/audit/">[3] Kubernetes官方文档 - 审计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Policy">[4] Kubernetes官方文档 - 审计Policy配置参考<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">延续上一篇测试流程拆解，本文聚焦 kube-apiserver 审计日志如何被导出、转化为 Prometheus 指标并在 Grafana 面板上呈现。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="K8s" scheme="https://freshwlnd.github.io/tags/K8s/"/>
    
    <category term="性能测试" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
    <category term="监控" scheme="https://freshwlnd.github.io/tags/%E7%9B%91%E6%8E%A7/"/>
    
    <category term="Volcano" scheme="https://freshwlnd.github.io/tags/Volcano/"/>
    
  </entry>
  
  <entry>
    <title>【集群】云原生批调度实战：Volcano 测试流程拆解</title>
    <link href="https://freshwlnd.github.io/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/"/>
    <id>https://freshwlnd.github.io/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/</id>
    <published>2025-07-27T08:21:35.000Z</published>
    <updated>2025-09-18T07:27:36.963Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p><ol><li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li><li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li><li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li><li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li><li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li><li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li><li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li><li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li><li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li><li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li><li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li><li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li><li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li><li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a></li></ol></blockquote><p>本文将以 Volcano 为代表，解析<a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">kube-scheduler-performance<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>工具一次 <strong>调度器性能测试</strong> 从集群启动到结果归档的完整链路，搞清楚 <strong>每个步骤调用了哪些文件、各自作用是什么</strong>，为后续指标剖析与实验扩展打下基础。</p><p>阅读完本文，希望能够帮你快速实现：</p><ol><li>复现最小规模的 Volcano 性能测试；</li><li>在源码中快速定位某一步骤的入口脚本 / YAML。</li></ol><hr><h1 id="1️⃣-执行链路总览"><a href="#1️⃣-执行链路总览" class="headerlink" title="1️⃣ 执行链路总览"></a>1️⃣ 执行链路总览</h1><p>执行一次最小测试的命令非常简单：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">make prepare-volcano start-volcano end-volcano \</span><br><span class="line">    NODES_SIZE=1 JOBS_SIZE_PER_QUEUE=1 PODS_SIZE_PER_JOB=1</span><br></pre></td></tr></table></figure></div><p>这背后却触发了 <strong>≥ 10</strong> 个 Makefile 目标与 <strong>30+</strong> 个 YAML / Shell / Go 文件。整体时序如图所示（流程简化，仅保留关键节点）：</p><pre class="mermaid">graph TD;    A[prepare-volcano] --&gt; B[up-volcano];    B --&gt; C[kind 创建测试集群];    C --&gt; D[wait-volcano];    D --&gt; E[test-init-volcano];    A -.-&gt;|完成后调用| F[start-volcano];    F --&gt; G[reset-auditlog-volcano];    G --&gt; H[test-batch-job-volcano];    F -.-&gt; |完成后调用| I[end-volcano];    I --&gt; J[down-volcano];</pre><blockquote><p>Tips: <code>prepare-volcano → start-volcano → end-volcano</code> 由根 Makefile 的 <code>define test-scheduler</code> 宏在编译期自动展开。</p></blockquote><h2 id="宏展开示例：Volcano"><a href="#宏展开示例：Volcano" class="headerlink" title="宏展开示例：Volcano"></a>宏展开示例：Volcano</h2><p><code>define test-scheduler</code> 是一个带占位符 <code>$(1)</code> 的宏，最后通过 <code>$(foreach sched,$(SCHEDULERS),$(eval $(call test-scheduler,$(sched))))</code> 对 <em>kueue / volcano / yunikorn</em> 进行循环替换。下面以 <strong>Volcano</strong> 为例简要对比“模板”与“实例”——</p><p><strong>模板片段（截自 Makefile:110:140）</strong></p><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">define</span> test-scheduler</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: prepare-$(1)</span></span><br><span class="line"><span class="section">prepare-$(1):</span></span><br><span class="line">make up-$(1)</span><br><span class="line">make wait-$(1)</span><br><span class="line">make test-init-$(1)</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: start-$(1)</span></span><br><span class="line"><span class="section">start-$(1):</span></span><br><span class="line">make reset-auditlog-$(1)</span><br><span class="line">make test-batch-job-$(1)</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: end-$(1)</span></span><br><span class="line"><span class="section">end-$(1):</span></span><br><span class="line">make down-$(1)</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: up-$(1)</span></span><br><span class="line"><span class="section">up-$(1):</span></span><br><span class="line">make -C ./clusters/$(1) up</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: down-$(1)</span></span><br><span class="line"><span class="section">down-$(1):</span></span><br><span class="line">-make -C ./clusters/$(1) down</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: wait-$(1)</span></span><br><span class="line"><span class="section">wait-$(1):</span></span><br><span class="line">make -C ./clusters/$(1) wait</span><br><span class="line"></span><br><span class="line"><span class="section">bin/test-$(1): $(shell find ./test/utils ./test/$(1) -type f)</span></span><br><span class="line"><span class="variable">$(GO_IN_DOCKER)</span> go test -c -o ./bin/test-$(1) ./test/$(1)</span><br></pre></td></tr></table></figure></div><p><strong>展开后（自动生成）的部分规则</strong></p><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: prepare-volcano</span></span><br><span class="line"><span class="section">prepare-volcano:</span></span><br><span class="line">make up-volcano</span><br><span class="line">make wait-volcano</span><br><span class="line">make test-init-volcano</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: start-volcano</span></span><br><span class="line"><span class="section">start-volcano:</span></span><br><span class="line">make reset-auditlog-volcano</span><br><span class="line">make test-batch-job-volcano</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: end-volcano</span></span><br><span class="line"><span class="section">end-volcano:</span></span><br><span class="line">make down-volcano</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure></div><p>借助这种“写一次、生成三份”的做法，大幅减少了针对不同调度器写重复 Make 目标的工作量。</p><hr><h1 id="2️⃣-关键-Makefile-目标拆解"><a href="#2️⃣-关键-Makefile-目标拆解" class="headerlink" title="2️⃣ 关键 Makefile 目标拆解"></a>2️⃣ 关键 Makefile 目标拆解</h1><table><thead><tr><th>目标</th><th>所在文件</th><th>主要命令</th><th>职责说明</th></tr></thead><tbody><tr><td><code>prepare-volcano</code></td><td>根 <code>Makefile</code></td><td><code>make up-volcano</code> <code>make wait-volcano</code> <code>make test-init-volcano</code></td><td>集群启动 + 基础就绪检查 + 预热测试二进制</td></tr><tr><td><code>up-volcano</code></td><td><code>clusters/volcano/Makefile</code></td><td><code>kind create cluster</code> &amp; 部署 Volcano</td><td>创建 Kind 集群并应用 Volcano 相关 Kustomize 资源</td></tr><tr><td><code>wait-volcano</code></td><td>同上</td><td><code>kubectl wait --for=condition=Ready</code></td><td>等待所有 Pod Ready，含 controller / scheduler</td></tr><tr><td><code>test-init-volcano</code></td><td>根 <code>Makefile</code></td><td>运行 <code>bin/test-volcano -run ^TestInit</code></td><td>生成初始队列、扩容节点</td></tr><tr><td><code>start-volcano</code></td><td>根 <code>Makefile</code></td><td><code>make reset-auditlog-volcano</code> <code>make test-batch-job-volcano</code></td><td>清空上一轮 audit 日志 &amp; 正式发压</td></tr><tr><td><code>reset-auditlog-volcano</code></td><td><code>clusters/volcano/Makefile</code></td><td><code>kubectl delete</code> audit-log ConfigMap</td><td>置空历史日志，保证数据窗口准确</td></tr><tr><td><code>test-batch-job-volcano</code></td><td>根 <code>Makefile</code></td><td><code>bin/test-volcano -run ^TestBatchJob</code></td><td>按参数批量提交 Job / Pod 并记录时间线</td></tr><tr><td><code>end-volcano</code></td><td>根 <code>Makefile</code></td><td><code>make down-volcano</code></td><td>销毁 Kind 集群，释放资源</td></tr></tbody></table><hr><h1 id="3️⃣-clusters-volcano-目录速览"><a href="#3️⃣-clusters-volcano-目录速览" class="headerlink" title="3️⃣ clusters/volcano 目录速览"></a>3️⃣ clusters/volcano 目录速览</h1><ul><li><code>kind.yaml</code>：集群版本、节点数量、containerd 本地镜像仓库挂载；</li><li><code>deployment.yaml</code>：Volcano Controller 与 Scheduler 部署模板；</li><li><code>kustomization.yaml</code>：声明所有资源并支持 <code>image</code> 覆盖；</li><li><code>service.yaml</code>：暴露 Volcano webhook / metrics（如需）。</li></ul><p>这些文件通过 <code>kustomize build</code> 管道被 <code>up-volcano</code> 目标应用到 Kind 集群中。</p><hr><h1 id="4️⃣-test-volcano-测试代码剖析"><a href="#4️⃣-test-volcano-测试代码剖析" class="headerlink" title="4️⃣ test/volcano 测试代码剖析"></a>4️⃣ test/volcano 测试代码剖析</h1><p>核心 Go 测试位于 <code>test/volcano/</code> 目录，包含两个主要测试函数和一套完整的 Provider 实现。<strong>整体思路</strong>：通过 Go 语言编写测试用例，调用 Kubernetes API 在真实集群中创建资源，模拟大规模批量调度场景。</p><h2 id="TestInit-和-TestBatchJob-流程"><a href="#TestInit-和-TestBatchJob-流程" class="headerlink" title="TestInit 和 TestBatchJob 流程"></a>TestInit 和 TestBatchJob 流程</h2><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><figcaption><span>test/volcano/batch_job_test.go</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestInit</span><span class="params">(t *testing.T)</span></span> {</span><br><span class="line">err := provider.AddNodes(t.Context())</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">t.Fatal(err)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">err = provider.InitCase(t.Context())</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">t.Fatal(err)</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestBatchJob</span><span class="params">(t *testing.T)</span></span> {</span><br><span class="line">err := provider.AddJobs(t.Context())</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">t.Fatal(err)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">err = utils.WaitDeployment(t.Context(), utils.Resources)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">t.Fatal(err)</span><br><span class="line">}</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p><strong>核心逻辑</strong>：</p><ul><li><code>TestInit</code>：<strong>集群预热阶段</strong>，创建假节点（通过 KWOK）和配置 Volcano 队列层级</li><li><code>TestBatchJob</code>：<strong>正式压测阶段</strong>，批量提交 Job 并等待调度完成</li></ul><p>两个测试函数通过 **全局变量 <code>provider</code>**（VolcanoProvider 实例）共享状态，测试参数从环境变量或 Makefile 传入。</p><h2 id="参数传递机制解析"><a href="#参数传递机制解析" class="headerlink" title="参数传递机制解析"></a>参数传递机制解析</h2><p>测试参数的传递遵循 <strong>Makefile → 环境变量 → Go Flag → Provider 实例</strong> 的四级链路：</p><h3 id="1-Makefile-参数定义"><a href="#1-Makefile-参数定义" class="headerlink" title="1. Makefile 参数定义"></a>1. Makefile 参数定义</h3><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><figcaption><span>Makefile</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">CPU_PER_NODE ?= 128</span><br><span class="line">MEMORY_PER_NODE ?= 1024Gi</span><br><span class="line">NODES_SIZE ?= 1</span><br><span class="line"></span><br><span class="line">QUEUES_SIZE ?= 1</span><br><span class="line">JOBS_SIZE_PER_QUEUE ?= 1</span><br><span class="line">PODS_SIZE_PER_JOB ?= 1</span><br><span class="line"></span><br><span class="line">CPU_REQUEST_PER_POD ?= 1</span><br><span class="line">MEMORY_REQUEST_PER_POD ?= 1Gi</span><br><span class="line"></span><br><span class="line">GANG ?= false</span><br><span class="line">PREEMPTION ?= false</span><br></pre></td></tr></table></figure></div><h3 id="2-环境变量注入"><a href="#2-环境变量注入" class="headerlink" title="2. 环境变量注入"></a>2. 环境变量注入</h3><p>当执行 <code>make test-batch-job-volcano</code> 时，Makefile 会将上述变量作为环境变量传递给测试进程：</p><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><figcaption><span>Makefile</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">TEST_ENVS = \</span><br><span class="line">    NODES_SIZE=<span class="variable">$(NODES_SIZE)</span> \</span><br><span class="line">    CPU_PER_NODE=<span class="variable">$(CPU_PER_NODE)</span> \</span><br><span class="line">    MEMORY_PER_NODE=<span class="variable">$(MEMORY_PER_NODE)</span> \</span><br><span class="line">    QUEUES_SIZE=<span class="variable">$(QUEUES_SIZE)</span> \</span><br><span class="line">    JOBS_SIZE_PER_QUEUE=<span class="variable">$(JOBS_SIZE_PER_QUEUE)</span> \</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></div><h3 id="3-Go-Flag-解析"><a href="#3-Go-Flag-解析" class="headerlink" title="3. Go Flag 解析"></a>3. Go Flag 解析</h3><p><code>test/volcano/main_test.go</code> 中，<code>provider.AddFlags()</code> 调用 <code>test/utils/option.go</code> 的标准 flag 库：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><figcaption><span>test/utils/option.go</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(o *Options)</span></span> AddFlags() {</span><br><span class="line">    flag.StringVar(&amp;o.CpuPerNode, <span class="string">"cpu-per-node"</span>, getEnv(<span class="string">"CPU_PER_NODE"</span>, <span class="string">"32"</span>), <span class="string">"CPU resources per node"</span>)</span><br><span class="line">    flag.StringVar(&amp;o.MemoryPerNode, <span class="string">"memory-per-node"</span>, getEnv(<span class="string">"MEMORY_PER_NODE"</span>, <span class="string">"256Gi"</span>), <span class="string">"Memory resources per node"</span>)</span><br><span class="line">    flag.IntVar(&amp;o.NodeSize, <span class="string">"nodes-size"</span>, getEnvInt(<span class="string">"NODES_SIZE"</span>, <span class="number">1</span>), <span class="string">"Number of nodes to create"</span>)</span><br><span class="line">    </span><br><span class="line">    flag.IntVar(&amp;o.QueueSize, <span class="string">"queues-size"</span>, getEnvInt(<span class="string">"QUEUES_SIZE"</span>, <span class="number">1</span>), <span class="string">"Number of queues to create"</span>)</span><br><span class="line">    flag.IntVar(&amp;o.JobsSizePerQueue, <span class="string">"jobs-size-per-queue"</span>, getEnvInt(<span class="string">"JOBS_SIZE_PER_QUEUE"</span>, <span class="number">1</span>), <span class="string">"Number of jobs per queue"</span>)</span><br><span class="line">    flag.IntVar(&amp;o.PodsSizePerJob, <span class="string">"pods-size-per-job"</span>, getEnvInt(<span class="string">"PODS_SIZE_PER_JOB"</span>, <span class="number">1</span>), <span class="string">"Number of pods per job"</span>)</span><br><span class="line">    </span><br><span class="line">    flag.BoolVar(&amp;o.Gang, <span class="string">"gang"</span>, getEnvBool(<span class="string">"GANG"</span>, <span class="literal">false</span>), <span class="string">"Enable gang scheduling"</span>)</span><br><span class="line">    flag.BoolVar(&amp;o.Preemption, <span class="string">"preemption"</span>, getEnvBool(<span class="string">"PREEMPTION"</span>, <span class="literal">false</span>), <span class="string">"Enable preemption"</span>)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getEnv</span><span class="params">(key, fallback <span class="type">string</span>)</span></span> <span class="type">string</span> {</span><br><span class="line">    <span class="keyword">if</span> value, exists := os.LookupEnv(key); exists {</span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> fallback</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><h3 id="4-优先级覆盖机制"><a href="#4-优先级覆盖机制" class="headerlink" title="4. 优先级覆盖机制"></a>4. 优先级覆盖机制</h3><p>参数读取有明确的优先级：<strong>命令行参数 &gt; 环境变量 &gt; 默认值</strong></p><p>例如：</p><ul><li><code>make test-batch-job-volcano NODES_SIZE=100</code>：通过 Makefile 变量传递</li><li><code>NODES_SIZE=200 ./bin/test-volcano</code>：直接设置环境变量</li><li><code>./bin/test-volcano -nodes-size=300</code>：命令行参数（最高优先级）</li></ul><p>因此，当我们在前面代码中看到 <code>p.CpuPerNode</code>、<code>p.NodeSize</code> 等字段时，它们的值最终来源于这套参数传递链路，确保了测试规模可以通过 Makefile 灵活调控。</p><h2 id="VolcanoProvider-核心实现"><a href="#VolcanoProvider-核心实现" class="headerlink" title="VolcanoProvider 核心实现"></a>VolcanoProvider 核心实现</h2><h3 id="1-AddNodes：批量创建假节点"><a href="#1-AddNodes：批量创建假节点" class="headerlink" title="1. AddNodes：批量创建假节点"></a>1. AddNodes：批量创建假节点</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><figcaption><span>test/volcano/provider_test.go</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *VolcanoProvider)</span></span> AddNodes(ctx context.Context) <span class="type">error</span> {</span><br><span class="line">builder := utils.NewNodeBuilder().</span><br><span class="line">WithFastReady().</span><br><span class="line">WithCPU(p.CpuPerNode).</span><br><span class="line">WithMemory(p.MemoryPerNode)</span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> p.NodeSize {</span><br><span class="line">err := utils.Resources.Create(ctx,</span><br><span class="line">builder.</span><br><span class="line">WithName(fmt.Sprintf(<span class="string">"node-%d"</span>, i)).</span><br><span class="line">Build(),</span><br><span class="line">)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p><strong>解析</strong>：通过 <code>utils.NewNodeBuilder()</code> 构造器模式批量生成 Node 对象。关键点：</p><ul><li><code>WithFastReady()</code>：设置节点状态为 Ready，跳过真实硬件检测</li><li><code>WithCPU(p.CpuPerNode)</code>：每个节点的 CPU 容量（如 “128”）</li><li><code>WithMemory(p.MemoryPerNode)</code>：每个节点的内存容量（如 “1024Gi”）</li></ul><h3 id="2-InitCase：配置-Volcano-调度器"><a href="#2-InitCase：配置-Volcano-调度器" class="headerlink" title="2. InitCase：配置 Volcano 调度器"></a>2. InitCase：配置 Volcano 调度器</h3><p><strong>关键代码片段</strong>：</p><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><figcaption><span>test/volcano/provider_test.go</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *VolcanoProvider)</span></span> InitCase(ctx context.Context) <span class="type">error</span> {</span><br><span class="line"><span class="comment">// 1. 解析资源配额</span></span><br><span class="line">cpuPerQueue, err := resource.ParseQuantity(p.CpuPerQueue)</span><br><span class="line">memoryPerQueue, err := resource.ParseQuantity(p.MemoryPerQueue)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 计算层级资源限制</span></span><br><span class="line"><span class="keyword">if</span> p.CpuLendingLimit != <span class="string">""</span> {</span><br><span class="line">cpuLendingLimit, err := resource.ParseQuantity(p.CpuLendingLimit)</span><br><span class="line">hierarchy = <span class="literal">true</span></span><br><span class="line">cpuCapabilityTotal = utils.TimesQuantity(cpuPerQueue, p.QueueSize+p.ImpactingQueuesSize+p.CriticalQueuesSize).String()</span><br><span class="line">cpuCapability = cpuPerQueue.String()</span><br><span class="line">cpuPerQueue.Sub(cpuLendingLimit)  <span class="comment">// deserved = capability - lending</span></span><br><span class="line">cpuDeserved = cpuPerQueue.String()</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3. 更新 root Queue 配置</span></span><br><span class="line">obj := &amp;unstructured.Unstructured{}</span><br><span class="line">obj.SetName(<span class="string">"root"</span>)</span><br><span class="line">obj.SetAPIVersion(<span class="string">"scheduling.volcano.sh/v1beta1"</span>)</span><br><span class="line">obj.SetKind(<span class="string">"Queue"</span>)</span><br><span class="line">err = utils.Resources.Patch(ctx, obj, k8s.Patch{</span><br><span class="line">PatchType: types.MergePatchType,</span><br><span class="line">Data: []<span class="type">byte</span>(fmt.Sprintf(<span class="string">`{"spec":{"capability":{"cpu": %q, "memory": %q}}}`</span>, cpuCapabilityTotal, memoryCapabilityTotal)),</span><br><span class="line">})</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4. 重启 Volcano Scheduler 使配置生效</span></span><br><span class="line">err = utils.RestartDeployment(ctx, utils.Resources, <span class="string">"volcano-scheduler"</span>, <span class="string">"volcano-system"</span>)</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p><strong>核心逻辑解析</strong>：</p><ol><li><strong>资源计算</strong>：根据队列数量计算总容量（<code>cpuCapabilityTotal</code>）和单队列配额（<code>cpuCapability</code>）</li><li><strong>层级调度</strong>：如果设置了 <code>CpuLendingLimit</code>，启用 <code>hierarchy=true</code>，计算 <code>deserved</code>（保证资源）和 <code>capability</code>（借用上限）</li><li><strong>动态配置</strong>：通过 <code>unstructured.Unstructured</code> 直接操作 CRD，避免导入 Volcano 依赖</li><li><strong>热重启</strong>：更新 ConfigMap 后重启 Scheduler Pod，确保新配置生效</li></ol><h3 id="3-AddJobs：分批提交作业"><a href="#3-AddJobs：分批提交作业" class="headerlink" title="3. AddJobs：分批提交作业"></a>3. AddJobs：分批提交作业</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><figcaption><span>test/volcano/provider_test.go</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *VolcanoProvider)</span></span> AddJobs(ctx context.Context) <span class="type">error</span> {</span><br><span class="line">steps := []<span class="keyword">struct</span> {</span><br><span class="line">queueSize    <span class="type">int</span></span><br><span class="line">jobsPerQueue <span class="type">int</span></span><br><span class="line">podsPerJob   <span class="type">int</span></span><br><span class="line">priority     <span class="type">string</span></span><br><span class="line">duration     <span class="type">string</span></span><br><span class="line">delay        time.Duration</span><br><span class="line">}{</span><br><span class="line">{p.QueueSize, p.JobsSizePerQueue, p.PodsSizePerJob, <span class="string">"long-term-research"</span>, p.PodDuration, <span class="number">0</span>},</span><br><span class="line">{p.ImpactingQueuesSize, p.ImpactingJobsSizePerQueue, p.ImpactingPodsSizePerJob, <span class="string">"business-impacting"</span>, p.ImpactingPodDuration, <span class="number">5</span> * time.Second},</span><br><span class="line">{p.CriticalQueuesSize, p.CriticalJobsSizePerQueue, p.CriticalPodsSizePerJob, <span class="string">"human-critical"</span>, p.CriticalPodDuration, <span class="number">5</span> * time.Second},</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _, step := <span class="keyword">range</span> steps {</span><br><span class="line"><span class="keyword">if</span> step.delay &gt; <span class="number">0</span> {</span><br><span class="line">time.Sleep(step.delay)  <span class="comment">// 模拟业务场景：优先级作业延迟到达</span></span><br><span class="line">}</span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> step.queueSize {</span><br><span class="line"><span class="keyword">for</span> <span class="keyword">range</span> step.jobsPerQueue {</span><br><span class="line">err := p.addSingleJobs(ctx, step.podsPerJob, i, step.priority, step.duration)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div><p><strong>策略解析</strong>：通过 <strong>三阶段提交</strong> 模拟真实多租户场景：</p><ol><li><strong>第一波</strong>：<code>long-term-research</code> 队列，立即提交（delay=0）</li><li><strong>第二波</strong>：<code>business-impacting</code> 队列，5秒后提交（模拟业务高峰）</li><li><strong>第三波</strong>：<code>human-critical</code> 队列，再5秒后提交（模拟紧急任务）</li></ol><p>每个阶段都有独立的 <strong>queueSize × jobsPerQueue × podsPerJob</strong> 三维参数，可灵活调整压测规模。</p><h2 id="Volcano-Job-模板解析"><a href="#Volcano-Job-模板解析" class="headerlink" title="Volcano Job 模板解析"></a>Volcano Job 模板解析</h2><p>使用的是 Volcano CRD <code>batch.volcano.sh/v1alpha1/Job</code>，关键字段：</p><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><figcaption><span>test/volcano/batch_job.yaml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch.volcano.sh/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">volcano-job-#{{</span> <span class="string">.name</span> <span class="string">}}-#{{</span> <span class="string">.index</span> <span class="string">}}</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment">#{{ if .gang }}</span></span><br><span class="line">  <span class="attr">minAvailable:</span> <span class="comment">#{{ .size }}</span></span><br><span class="line">  <span class="comment">#{{ else }}</span></span><br><span class="line">  <span class="attr">minAvailable:</span> <span class="number">1</span></span><br><span class="line">  <span class="comment">#{{ end }}</span></span><br><span class="line">  <span class="attr">schedulerName:</span> <span class="string">volcano</span></span><br><span class="line">  <span class="attr">queue:</span> <span class="comment">#{{ .queue }}</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">replicas:</span> <span class="comment">#{{ .size }}</span></span><br><span class="line">    <span class="attr">template:</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sleep</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">hello-world</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="comment">#{{ .cpuRequestPerPod }}</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="comment">#{{ .memoryRequestPerPod }}</span></span><br><span class="line">        <span class="attr">nodeSelector:</span></span><br><span class="line">          <span class="attr">"type":</span> <span class="string">kwok</span></span><br></pre></td></tr></table></figure></div><p><strong>模板机制解析</strong>：</p><ul><li><strong>模板语法</strong>：<code>#{{ .variable }}</code> 由 <code>utils.YamlWithArgs()</code> 在运行时替换</li><li><strong>Gang 调度</strong>：<code>minAvailable: #{{ .size }}</code> 要求所有 Pod 同时就绪，模拟 MPI/AI 训练场景</li><li><strong>资源隔离</strong>：<code>queue: #{{ .queue }}</code> 指定队列，<code>schedulerName: volcano</code> 确保由 Volcano 调度</li><li><strong>假负载</strong>：<code>nodeSelector: "type": kwok</code> 强制调度到假节点，<code>image: hello-world</code> 秒级启动</li></ul><p><strong>实际执行过程</strong>：<code>addSingleJobs()</code> 调用 <code>utils.YamlWithArgs()</code> 将参数注入模板，再通过 <code>decoder.DecodeEach()</code> 解析 YAML 并调用 Kubernetes API 创建 Job。</p><hr><p><strong>技术要点总结</strong>：整个测试框架通过 <code>sigs.k8s.io/e2e-framework</code> 与真实 API Server 通信，产生的所有 API 调用都会被 audit-policy.yaml 记录，为后续指标分析提供数据源。</p><hr><h1 id="5️⃣-hack-脚本的幕后协同"><a href="#5️⃣-hack-脚本的幕后协同" class="headerlink" title="5️⃣ hack 脚本的幕后协同"></a>5️⃣ hack 脚本的幕后协同</h1><table><thead><tr><th>脚本</th><th>触发时机</th><th>作用</th></tr></thead><tbody><tr><td><code>hack/kind-with-local-registry.sh</code></td><td><code>up-volcano</code> 前</td><td>启动本地 5001 registry + 注入 containerd 配置（**在每个 Kind 节点的 <code>/etc/containerd/certs.d/</code> 写入 <code>hosts.toml</code>**，指向本地仓库），实现“边拉边推、本地秒级拉取”</td></tr><tr><td><code>hack/local-registry-with-load-images.sh</code></td><td><code>up-volcano</code> 期间</td><td>将远端镜像拉取后重新打 tag 推到本地 registry，Kind 节点下载极快</td></tr><tr><td><code>hack/replace-qps.sh</code></td><td><em>可选</em></td><td>修改 APIServer QPS，<strong>一键替换所有带 <code># &lt;--QPS</code> 注释的 YAML 中的数值</strong>，从而把 <code>--kube-api-qps</code> 或 webhook QPS 提到 1000+，缓解 API Server 限流</td></tr><tr><td><code>hack/save-result-images.sh</code></td><td>测试结束后</td><td>调用 Grafana API 截图面板，写入 <code>output/</code> 归档</td></tr></tbody></table><h2 id="containerd-配置注入示例"><a href="#containerd-配置注入示例" class="headerlink" title="containerd 配置注入示例"></a>containerd 配置注入示例</h2><p><code>hack/kind-with-local-registry.sh</code> 的核心逻辑：</p><div class="code-container" data-rel="Sh"><figure class="iseeu highlight sh"><figcaption><span>hack/kind-with-local-registry.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create kind cluster with containerd registry configuration</span></span><br><span class="line">kind create cluster --config <span class="string">"<span class="variable">${KIND_CONFIG:-}</span>"</span> --name <span class="string">"<span class="variable">${KIND_CLUSTER_NAME:-kind}</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure containerd registry hosts on all nodes</span></span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> $(kind get nodes); <span class="keyword">do</span></span><br><span class="line">  docker <span class="built_in">exec</span> <span class="string">"<span class="variable">${node}</span>"</span> <span class="built_in">mkdir</span> -p <span class="string">"<span class="variable">${registry_dir}</span>"</span></span><br><span class="line">  docker <span class="built_in">exec</span> -i <span class="string">"<span class="variable">${node}</span>"</span> <span class="built_in">tee</span> <span class="string">"<span class="variable">${registry_dir}</span>/hosts.toml"</span> &gt;/dev/null &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">[host."http://${in_cluster_registry}"]</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></div><p><strong>核心原理</strong>：脚本为每个 Kind 节点在 <code>/etc/containerd/certs.d/kind-registry:5000/hosts.toml</code> 写入配置，告诉 containerd 优先从本地 registry 拉取镜像，实现离线加速。</p><h4 id="修改-APIServer-QPS-示例"><a href="#修改-APIServer-QPS-示例" class="headerlink" title="修改 APIServer QPS 示例"></a>修改 APIServer QPS 示例</h4><p>当测试遇到 API Server QPS 瓶颈时，可以手动调用脚本，批量调整：</p><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把所有标记为 "# &lt;--QPS" 的数值统一改为 2000</span></span><br><span class="line">hack/replace-qps.sh 2000</span><br></pre></td></tr></table></figure></div><p>脚本核心逻辑：</p><div class="code-container" data-rel="Sh"><figure class="iseeu highlight sh"><figcaption><span>hack/replace-qps.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">find . \</span><br><span class="line">    -iname <span class="string">"*.yaml"</span> \</span><br><span class="line">    -not \( -path ./vendor/\* -o -path ./tmp/\* \) \</span><br><span class="line">    -<span class="built_in">type</span> f \</span><br><span class="line">    -<span class="built_in">exec</span> sed -i <span class="string">'s|\([0-9]\+\)\(.\+\)# &lt;--QPS|'</span><span class="variable">${QPS}</span><span class="string">'\2# &lt;--QPS|g'</span> {} +</span><br></pre></td></tr></table></figure></div><p><strong>工作原理</strong>：遍历项目内所有 <code>.yaml</code> 文件，将包含 <code># &lt;--QPS</code> 标记行的数字替换为指定值。项目中共有 12 个文件、20+ 处配置受影响，包括调度器组件的 <code>--kube-api-qps</code>/<code>--kube-api-burst</code> 和 Kind 集群的 <code>kube-api-qps</code> 参数。</p><hr><h1 id="6️⃣-结语"><a href="#6️⃣-结语" class="headerlink" title="6️⃣ 结语"></a>6️⃣ 结语</h1><p>至此，我们已经串起了 <strong>Volcano 性能测试的最小可运行链路</strong>，并定位了关键 Makefile 目标与 YAML / Go 源码。下一篇将深入 <strong>指标采集与可视化</strong>，详解 audit-exporter 如何把 <code>CREATED / SCHEDULED / RUNNING</code> 三条曲线绘制到同一张 Grafana 面板。</p><blockquote><p>📌 <strong>实践练习</strong>：如果感兴趣，可以尝试把 <code>JOBS_SIZE_PER_QUEUE</code> 改为 2，再次运行测试，观察 <code>logs/</code> 与 <code>results/</code> 目录下是否出现新的时间戳文件夹，并查看面板截图差异。 </p></blockquote><hr><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://www.youtube.com/watch?v=njT5r3JjIaA&list=PLj6h78yzYM2MP0QhYFK8HOb8UqgbIkLMc&index=226">[2] A Comparative Analysis of Kueue, Volcano, and YuniKorn - Wei Huang, Apple &amp; Shiming Zhang, DaoCloud<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">本文是针对 kube-scheduling-perf 项目中 Volcano 调度器测试流程的第一篇解析，手把手带你读懂一次 make prepare-volcano → start-volcano → end-volcano 的全过程。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="调度器" scheme="https://freshwlnd.github.io/tags/%E8%B0%83%E5%BA%A6%E5%99%A8/"/>
    
    <category term="K8s" scheme="https://freshwlnd.github.io/tags/K8s/"/>
    
    <category term="性能测试" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
    <category term="Volcano" scheme="https://freshwlnd.github.io/tags/Volcano/"/>
    
  </entry>
  
  <entry>
    <title>【集群】云原生批调度实战：本地环境测试结果与视频对比分析</title>
    <link href="https://freshwlnd.github.io/2025/07/23/k8s/k8s-scheduler-performance-test-local/"/>
    <id>https://freshwlnd.github.io/2025/07/23/k8s/k8s-scheduler-performance-test-local/</id>
    <published>2025-07-23T06:28:27.000Z</published>
    <updated>2025-09-18T07:27:36.925Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p><ol><li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li><li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li><li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li><li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li></ol></blockquote><h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="上一篇博客">上一篇博客</a>中，我们详细介绍了 <code>kube-scheduling-perf</code> 项目的自动化测试框架。本文记录了笔者在本地环境中实际运行该测试工具的过程，并将测试结果与 <a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="KubeCon 技术分享">KubeCon 技术分享</a> 中的视频结果进行对比分析。</p><p>通过对比发现，虽然整体趋势基本一致，但在某些测试场景下存在显著差异，这些差异主要源于硬件配置、软件版本等因素的影响。本文分析了这些差异的原因，为读者在实际部署和测试时提供参考。</p><h1 id="🖼️测试环境配置"><a href="#🖼️测试环境配置" class="headerlink" title="🖼️测试环境配置"></a>🖼️测试环境配置</h1><h2 id="硬件配置"><a href="#硬件配置" class="headerlink" title="硬件配置"></a>硬件配置</h2><p>应 <a class="link" href="https://github.com/hwdef">@hwdef<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 建议，想办法更换了系统和实验环境，避免了前期<a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="实践篇博客">实践篇博客</a>遇到的大量因为内核版本导致的问题，也避免用低版本系统测出不准确数据导致对性能测试和优化的影响。<br>顺便一提，在实践中遇到的与内核版本无关的通用性问题也已提交<a class="link" href="https://github.com/wzshiming/kube-scheduling-perf/pull/17">PR<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>到kube-scheduling-perf仓库～</p><table><thead><tr><th>配置项</th><th>规格</th></tr></thead><tbody><tr><td><strong>操作系统</strong></td><td>Ubuntu Linux 5.15.0-143-generic</td></tr><tr><td><strong>CPU</strong></td><td>Intel Xeon Gold 6230 @ 2.10GHz, 8核</td></tr><tr><td><strong>内存</strong></td><td>15GB (可用13GB)</td></tr><tr><td><strong>存储</strong></td><td>79GB (可用21GB)</td></tr></tbody></table><h2 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本"></a>软件版本</h2><table><thead><tr><th>软件</th><th>版本</th></tr></thead><tbody><tr><td><strong>Docker</strong></td><td>27.5.1</td></tr><tr><td><strong>Kubernetes</strong></td><td>1.32.2 (Kind集群)</td></tr><tr><td><strong>kubectl</strong></td><td>v1.33.2</td></tr><tr><td><strong>Go</strong></td><td>1.24 (Docker容器)</td></tr></tbody></table><h2 id="存储需求"><a href="#存储需求" class="headerlink" title="存储需求"></a>存储需求</h2><table><thead><tr><th>项目</th><th>大小</th></tr></thead><tbody><tr><td><strong>当前结果目录</strong></td><td>15GB</td></tr><tr><td><strong>单个测试结果</strong></td><td>1.3GB - 2.7GB（主要占空间的是日志文件）</td></tr><tr><td><strong>建议预留空间</strong></td><td>50GB+</td></tr></tbody></table><h1 id="🧠测试结果对比分析"><a href="#🧠测试结果对比分析" class="headerlink" title="🧠测试结果对比分析"></a>🧠测试结果对比分析</h1><h2 id="第一种-Benchmark：10K-Jobs-×-1-Pod"><a href="#第一种-Benchmark：10K-Jobs-×-1-Pod" class="headerlink" title="第一种 Benchmark：10K Jobs × 1 Pod"></a>第一种 Benchmark：10K Jobs × 1 Pod</h2><p><strong>测试参数</strong>：每个Job只有1个Pod，共10K个Job，共10kPod</p><h3 id="预期结果（基于视频）"><a href="#预期结果（基于视频）" class="headerlink" title="预期结果（基于视频）"></a>预期结果（基于视频）</h3><ul><li>YuniKorn吞吐量比另外两种调度器更高，主要是因为 Kueue 和 Volcano 的 Job 受 K8s Webhook QPS限制</li><li>CREATED和SCHEDULED事件之间的差距很小，说明没有调度阶段不为瓶颈、没有排队，此时性能瓶颈为创建阶段</li></ul><h3 id="实际结果"><a href="#实际结果" class="headerlink" title="实际结果"></a>实际结果</h3><ul><li><strong>符合预期</strong>：如下图所示，YuniKorn的吞吐量确实高于其他两种调度器</li><li><strong>瓶颈分析</strong>：CREATED和SCHEDULED事件紧密跟随，说明调度阶段不是瓶颈，性能瓶颈确实在创建阶段</li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/0-raw/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="图1：本地测试，无GangScheduling要求下，第一种benchmark测试结果"><figcaption>图1：本地测试，无GangScheduling要求下，第一种benchmark测试结果</figcaption></figure></p><h2 id="第二种-Benchmark：500-Jobs-×-20-Pods"><a href="#第二种-Benchmark：500-Jobs-×-20-Pods" class="headerlink" title="第二种 Benchmark：500 Jobs × 20 Pods"></a>第二种 Benchmark：500 Jobs × 20 Pods</h2><p><strong>测试参数</strong>：每个Job有20个Pod，共500个Job，共10kPod</p><h3 id="预期结果（基于视频）-1"><a href="#预期结果（基于视频）-1" class="headerlink" title="预期结果（基于视频）"></a>预期结果（基于视频）</h3><ul><li>Volcano的调度速度慢于另外两种调度器</li><li>SCHEDULED明显滞后于CREATED，说明调度速度较慢，此时性能瓶颈为调度（且根据斜率，前期调度速度快、后期逐渐变慢）</li><li>CREATED阶段性突变现象（正常情况下CREATED应该匀速增加，这里的现象说明controller会间歇性卡住一会儿）</li></ul><h3 id="实际结果-1"><a href="#实际结果-1" class="headerlink" title="实际结果"></a>实际结果</h3><ul><li><strong>部分符合预期</strong>：Volcano的调度速度确实慢于其他调度器</li><li><strong>差异点</strong>：CREATED没有成为瓶颈，始终比SCHEDULED的速度更快，与视频中的预期不符</li><li><strong>可能原因</strong>：本地环境的硬件资源限制或软件版本差异影响了测试结果</li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/0-raw/b.NoGang-500Job/output/panel-5.png?raw=true" alt="图2：本地测试，无GangScheduling要求下，第二种benchmark测试结果"><figcaption>图2：本地测试，无GangScheduling要求下，第二种benchmark测试结果</figcaption></figure></p><h3 id="进一步测试结果"><a href="#进一步测试结果" class="headerlink" title="进一步测试结果"></a>进一步测试结果</h3><p>在 <a class="link" href="https://github.com/hwdef">@hwdef<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 支持下，在 <code>24核 CPU，96 GB 内存</code> 环境下开展测试，发现：是硬件资源限制影响了测试结果。</p><ul><li><strong>部分符合预期</strong>：Volcano的调度速度确实慢于其他调度器，且 CREATED 成为了瓶颈，确定是硬件资源限制影响了测试结果。</li><li><strong>差异点</strong>：资源丰富后，CREATED瓶颈效应存在，但反而由于资源过多，导致瓶颈效应不明显，与视频中的预期有所差异。</li><li><strong>其他问题</strong>：缺少 kueue 数据，需要重复测试（确保镜像被正确拉取）或延长 timeout 时间。</li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/0-raw/b.NoGang-500Job/output/panel-5-hwdef.png?raw=true" alt="图3：高资源量环境下测试，无GangScheduling要求下，第二种benchmark测试结果"><figcaption>图3：高资源量环境下测试，无GangScheduling要求下，第二种benchmark测试结果</figcaption></figure></p><h2 id="第三种-Benchmark：20-Jobs-×-500-Pods"><a href="#第三种-Benchmark：20-Jobs-×-500-Pods" class="headerlink" title="第三种 Benchmark：20 Jobs × 500 Pods"></a>第三种 Benchmark：20 Jobs × 500 Pods</h2><p><strong>测试参数</strong>：每个Job有500Pod，共20个Job，共10kPod</p><h3 id="预期结果（基于视频）-2"><a href="#预期结果（基于视频）-2" class="headerlink" title="预期结果（基于视频）"></a>预期结果（基于视频）</h3><ul><li>Volcano的调度速度仍然慢于另外两种调度器</li><li>SCHEDULED仍然明显滞后于CREATED，说明调度速度较慢，此时性能瓶颈为调度（且根据斜率，前期调度速度比第二种benchmark下更慢、后期逐渐加速）</li><li>不存在CREATED阶段性突变现象</li></ul><h3 id="实际结果-2"><a href="#实际结果-2" class="headerlink" title="实际结果"></a>实际结果</h3><ul><li><strong>与预期不符</strong>：反而更接近第二种benchmark的预期，前期CREATED和SCHEDULED线紧贴、后期CREATED出现阶段性突变。但至少验证了 CREATED 确实会成为瓶颈。</li><li><strong>可能原因</strong>：<ul><li>可能是CREATED成为瓶颈，导致SCHEDULED速度被严重限制</li><li>可能是SCHEDULED本来就很慢，反过来导致CREATED没必要提前创建（可能新版本下有其他机制做出该决策）</li></ul></li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/0-raw/c.NoGang-20Job/output/panel-5.png?raw=true" alt="图4：本地测试，无GangScheduling要求下，第三种benchmark测试结果"><figcaption>图4：本地测试，无GangScheduling要求下，第三种benchmark测试结果</figcaption></figure></p><h3 id="进一步测试结果-1"><a href="#进一步测试结果-1" class="headerlink" title="进一步测试结果"></a>进一步测试结果</h3><p>在 <a class="link" href="https://github.com/hwdef">@hwdef<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 支持下，在 <code>24核 CPU，96 GB 内存</code> 环境下开展测试，发现：不是硬件资源限制问题。</p><ul><li>与原环境下结果类似，证明即使提供更多硬件资源也仍然存在该问题。</li><li>验证了 CREATED 确实会成为瓶颈，同时可能有 SCHEDULED 对 CREATED 的反向限制。</li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/0-raw/c.NoGang-20Job/output/panel-5-hwdef.png?raw=true" alt="图5：高资源量环境下测试，无GangScheduling要求下，第三种benchmark测试结果"><figcaption>图5：高资源量环境下测试，无GangScheduling要求下，第三种benchmark测试结果</figcaption></figure></p><h2 id="第四种-Benchmark：1-Job-×-10K-Pods"><a href="#第四种-Benchmark：1-Job-×-10K-Pods" class="headerlink" title="第四种 Benchmark：1 Job × 10K Pods"></a>第四种 Benchmark：1 Job × 10K Pods</h2><p><strong>测试参数</strong>：每个Job有10kPod，共1个Job，共10kPod</p><h3 id="预期结果（基于视频）-3"><a href="#预期结果（基于视频）-3" class="headerlink" title="预期结果（基于视频）"></a>预期结果（基于视频）</h3><ul><li>现象与第三种benchmark类似</li><li>根据斜率，调度速度整体比较平稳</li></ul><h3 id="实际结果-3"><a href="#实际结果-3" class="headerlink" title="实际结果"></a>实际结果</h3><ul><li><strong>与预期不符</strong>：和第三种benchmark类似，CREATED出现阶段性突变。</li><li><strong>可能原因</strong>：本地环境的资源限制影响了大规模Pod的创建和调度。</li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/0-raw/d.NoGang-1Job/output/panel-5.png?raw=true" alt="图6：本地测试，无GangScheduling要求下，第四种benchmark测试结果"><figcaption>图6：本地测试，无GangScheduling要求下，第四种benchmark测试结果</figcaption></figure></p><h3 id="进一步测试结果-2"><a href="#进一步测试结果-2" class="headerlink" title="进一步测试结果"></a>进一步测试结果</h3><p>在 <a class="link" href="https://github.com/hwdef">@hwdef<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 支持下，在 <code>24核 CPU，96 GB 内存</code> 环境下开展测试，发现：不是硬件资源限制问题。</p><ul><li>与原环境下结果类似，证明即使提供更多硬件资源也仍然存在该问题。</li><li>验证了 CREATED 确实会成为瓶颈，同时可能有 SCHEDULED 对 CREATED 的反向限制。（与第三种测试几乎一致）</li></ul><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/0-raw/d.NoGang-1Job/output/panel-5-hwdef.png?raw=true" alt="图7：高资源量环境下测试，无GangScheduling要求下，第四种benchmark测试结果"><figcaption>图7：高资源量环境下测试，无GangScheduling要求下，第四种benchmark测试结果</figcaption></figure></p><h2 id="Gang调度测试"><a href="#Gang调度测试" class="headerlink" title="Gang调度测试"></a>Gang调度测试</h2><h3 id="预期结果（基于视频）-4"><a href="#预期结果（基于视频）-4" class="headerlink" title="预期结果（基于视频）"></a>预期结果（基于视频）</h3><ul><li>Volcano的性能都是最佳的</li></ul><h3 id="实际结果-4"><a href="#实际结果-4" class="headerlink" title="实际结果"></a>实际结果</h3><ul><li><strong>与预期不符</strong>：可能由于机器资源有限，大部分情况下集中调度甚至无法正常创建Pod</li><li><strong>额外发现</strong>：YuniKorn所创建的Pod数量大于10k，猜测可能是出现bug导致Pod重启（但按理说使用模拟环境不应该有该问题）</li></ul><h1 id="🔨差异原因分析"><a href="#🔨差异原因分析" class="headerlink" title="🔨差异原因分析"></a>🔨差异原因分析</h1><h2 id="1-硬件资源限制"><a href="#1-硬件资源限制" class="headerlink" title="1. 硬件资源限制"></a>1. 硬件资源限制</h2><p><strong>本地环境限制</strong>：</p><ul><li>CPU：8核 vs 视频中可能使用更高配置（kube-scheduling-perf仓库推荐 16核）</li><li>内存：15GB vs 视频中可能使用更大内存（kube-scheduling-perf仓库推荐 16GB）</li></ul><p><strong>影响</strong>：硬件资源不足可能导致：</p><ul><li>Pod创建速度受限</li><li>调度器处理能力下降</li><li>系统整体性能瓶颈</li></ul><h2 id="2-软件版本差异"><a href="#2-软件版本差异" class="headerlink" title="2. 软件版本差异"></a>2. 软件版本差异</h2><p><strong>版本对比</strong>：</p><ul><li>Kubernetes：1.32.2 vs 视频中可能使用不同版本</li><li>Docker：27.5.1 vs 视频中可能使用不同版本</li><li>调度器版本：可能存在差异</li></ul><p><strong>影响</strong>：不同版本可能存在：</p><ul><li>性能优化差异</li><li>Bug修复差异</li><li>默认配置差异</li></ul><h1 id="🏥总结与反思"><a href="#🏥总结与反思" class="headerlink" title="🏥总结与反思"></a>🏥总结与反思</h1><h2 id="主要发现"><a href="#主要发现" class="headerlink" title="主要发现"></a>主要发现</h2><ol><li><strong>整体趋势一致</strong>：虽然存在差异，但三种调度器的相对性能排名基本符合预期</li><li><strong>环境影响显著</strong>：硬件配置、软件版本、网络环境等因素对测试结果有重要影响</li><li><strong>资源瓶颈明显</strong>：在资源受限的本地环境中，CREATED事件更容易成为瓶颈</li></ol><h2 id="后续工作"><a href="#后续工作" class="headerlink" title="后续工作"></a>后续工作</h2><ol><li><strong>脚本分析</strong>：进一步浏览 kube-scheduling-perf 脚本所使用的环境、所监控的指标、所使用的监控方式，为后续增加其它指标监控做准备</li><li><strong>调度器分析</strong>：进一步分析CREATED阶段性突变的具体原因</li></ol><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://www.youtube.com/watch?v=njT5r3JjIaA&list=PLj6h78yzYM2MP0QhYFK8HOb8UqgbIkLMc&index=226">[2] A Comparative Analysis of Kueue, Volcano, and YuniKorn - Wei Huang, Apple &amp; Shiming Zhang, DaoCloud<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kueue.sigs.k8s.io/">[3] Kueue Documentation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://volcano.sh/">[4] Volcano Documentation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://yunikorn.apache.org/">[5] YuniKorn Documentation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">本文记录了在本地环境中使用 kube-scheduling-perf 工具对 Kueue、Volcano、YuniKorn 三大调度器进行性能测试的实际结果，并与 KubeCon 技术分享中的视频结果进行对比分析。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="调度器" scheme="https://freshwlnd.github.io/tags/%E8%B0%83%E5%BA%A6%E5%99%A8/"/>
    
    <category term="K8s" scheme="https://freshwlnd.github.io/tags/K8s/"/>
    
    <category term="性能测试" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
    <category term="Volcano" scheme="https://freshwlnd.github.io/tags/Volcano/"/>
    
    <category term="本地测试" scheme="https://freshwlnd.github.io/tags/%E6%9C%AC%E5%9C%B0%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>【集群】Kubernetes Webhook 实战：Kueue 调度器准入控制故障排除与性能优化</title>
    <link href="https://freshwlnd.github.io/2025/07/11/k8s/k8s-scheduler-performance-test-webhook/"/>
    <id>https://freshwlnd.github.io/2025/07/11/k8s/k8s-scheduler-performance-test-webhook/</id>
    <published>2025-07-11T03:49:11.000Z</published>
    <updated>2025-07-11T04:14:26.258Z</updated>
    
    <content type="html"><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><blockquote><p><strong>📖 文档定位</strong>：本文为 Kueue 调度器 Webhook 机制的<strong>实战故障排除篇</strong>，与 <a href="/2025/07/08/k8s/k8s-webhook/" title="理论介绍文档">理论介绍文档</a> 形成互补。理论文档重点解析 Webhook 的基本概念和工作原理，而本文则专注于解决实际部署和测试过程中遇到的 Webhook 相关问题。</p></blockquote><p><strong>适用场景</strong>：如果您在部署 Kueue 调度器或进行调度器性能测试时遇到 Webhook 相关的错误，那么本文档将为您提供详细的问题诊断和解决方案。</p><h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><h2 id="问题起源"><a href="#问题起源" class="headerlink" title="问题起源"></a>问题起源</h2><p>在 <a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="调度器性能测试调试">调度器性能测试调试</a> 过程中，我们遇到了一个典型的 Webhook 连接问题：</p><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Internal error occurred: failed calling webhook "mresourceflavor.kb.io": failed to call webhook: </span><br><span class="line">Post "https://kueue-webhook-service.kueue-system.svc:443/mutate-kueue-x-k8s-io-v1beta1-resourceflavor?timeout=10s": </span><br><span class="line">dial tcp 10.96.33.70:443: connect: connection refused</span><br></pre></td></tr></table></figure></div><p>这个错误不仅影响了测试的顺利进行，也让我们深入思考了 Webhook 在 Kubernetes 调度器中的重要作用。</p><h2 id="为什么需要-Webhook？"><a href="#为什么需要-Webhook？" class="headerlink" title="为什么需要 Webhook？"></a>为什么需要 Webhook？</h2><h3 id="1-准入控制需求"><a href="#1-准入控制需求" class="headerlink" title="1. 准入控制需求"></a>1. 准入控制需求</h3><ul><li><strong>资源验证</strong>：确保创建的资源符合集群策略</li><li><strong>自动标签</strong>：为工作负载添加必要的元数据</li><li><strong>队列管理</strong>：协调工作负载与调度队列的关系</li></ul><h3 id="2-扩展性要求"><a href="#2-扩展性要求" class="headerlink" title="2. 扩展性要求"></a>2. 扩展性要求</h3><ul><li><strong>动态配置</strong>：无需重启 API 服务器即可添加新的验证规则</li><li><strong>外部集成</strong>：允许外部系统参与资源管理决策</li><li><strong>安全增强</strong>：提供额外的安全验证层</li></ul><h1 id="🧠Webhook-在-Kueue-中的作用机制"><a href="#🧠Webhook-在-Kueue-中的作用机制" class="headerlink" title="🧠Webhook 在 Kueue 中的作用机制"></a>🧠Webhook 在 Kueue 中的作用机制</h1><h2 id="1-准入控制机制"><a href="#1-准入控制机制" class="headerlink" title="1. 准入控制机制"></a>1. 准入控制机制</h2><p>Kueue 使用 Webhook 实现以下核心功能：</p><h3 id="1-1-资源验证"><a href="#1-1-资源验证" class="headerlink" title="1.1 资源验证"></a>1.1 资源验证</h3><ul><li><strong>Job 验证</strong>：检查 Kubernetes Job 是否符合 Kueue 管理要求</li><li><strong>Pod 验证</strong>：验证 Pod 的资源请求和限制</li><li><strong>ResourceFlavor 验证</strong>：确保资源风味配置正确</li></ul><h3 id="1-2-自动标签管理"><a href="#1-2-自动标签管理" class="headerlink" title="1.2 自动标签管理"></a>1.2 自动标签管理</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自动添加的标签示例</span></span><br><span class="line"><span class="attr">kueue.x-k8s.io/managed:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">kueue.x-k8s.io/queue-name:</span> <span class="string">"default"</span></span><br></pre></td></tr></table></figure></div><h3 id="1-3-队列分配"><a href="#1-3-队列分配" class="headerlink" title="1.3 队列分配"></a>1.3 队列分配</h3><ul><li><strong>工作负载分类</strong>：根据标签将工作负载分配到相应队列</li><li><strong>资源配额检查</strong>：验证工作负载是否超出队列资源限制</li></ul><h2 id="2-Webhook-类型"><a href="#2-Webhook-类型" class="headerlink" title="2. Webhook 类型"></a>2. Webhook 类型</h2><h3 id="2-1-Mutating-Webhook（修改性）"><a href="#2-1-Mutating-Webhook（修改性）" class="headerlink" title="2.1 Mutating Webhook（修改性）"></a>2.1 Mutating Webhook（修改性）</h3><ul><li><strong>作用</strong>：修改资源内容</li><li><strong>时机</strong>：在验证性 Webhook 之前执行</li><li><strong>功能</strong>：添加默认标签、注解等</li></ul><h3 id="2-2-Validating-Webhook（验证性）"><a href="#2-2-Validating-Webhook（验证性）" class="headerlink" title="2.2 Validating Webhook（验证性）"></a>2.2 Validating Webhook（验证性）</h3><ul><li><strong>作用</strong>：验证资源是否符合规则</li><li><strong>时机</strong>：在资源持久化到 etcd 之前</li><li><strong>结果</strong>：允许或拒绝请求</li></ul><h2 id="3-工作流程详解"><a href="#3-工作流程详解" class="headerlink" title="3. 工作流程详解"></a>3. 工作流程详解</h2><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">用户创建 Job → API 服务器接收请求 → Mutating Webhook → Validating Webhook → 持久化到 etcd</span><br></pre></td></tr></table></figure></div><p><strong>具体步骤</strong>：</p><ol><li><strong>请求接收</strong>：用户提交 Job 创建请求</li><li><strong>Webhook 拦截</strong>：API 服务器根据配置拦截请求</li><li><strong>修改处理</strong>：Mutating Webhook 添加必要标签</li><li><strong>验证处理</strong>：Validating Webhook 检查资源合规性</li><li><strong>结果返回</strong>：处理结果返回给 API 服务器</li><li><strong>资源创建</strong>：验证通过后，Job 被创建</li></ol><h1 id="🔨Webhook-配置详解"><a href="#🔨Webhook-配置详解" class="headerlink" title="🔨Webhook 配置详解"></a>🔨Webhook 配置详解</h1><h2 id="1-服务配置"><a href="#1-服务配置" class="headerlink" title="1. 服务配置"></a>1. 服务配置</h2><h3 id="1-1-Webhook-服务定义"><a href="#1-1-Webhook-服务定义" class="headerlink" title="1.1 Webhook 服务定义"></a>1.1 Webhook 服务定义</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kueue-webhook-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kueue-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">9443</span>  <span class="comment"># 指向 webhook 服务器的端口</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">control-plane:</span> <span class="string">controller-manager</span></span><br></pre></td></tr></table></figure></div><h3 id="1-2-Webhook-服务器配置"><a href="#1-2-Webhook-服务器配置" class="headerlink" title="1.2 Webhook 服务器配置"></a>1.2 Webhook 服务器配置</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">webhook:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">9443</span>  <span class="comment"># webhook 服务器监听端口</span></span><br><span class="line">  <span class="attr">timeoutSeconds:</span> <span class="number">10</span>  <span class="comment"># 超时时间</span></span><br></pre></td></tr></table></figure></div><h2 id="2-Webhook-规则配置"><a href="#2-Webhook-规则配置" class="headerlink" title="2. Webhook 规则配置"></a>2. Webhook 规则配置</h2><h3 id="2-1-Mutating-Webhook-配置"><a href="#2-1-Mutating-Webhook-配置" class="headerlink" title="2.1 Mutating Webhook 配置"></a>2.1 Mutating Webhook 配置</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">admissionregistration.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">MutatingWebhookConfiguration</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kueue-mutating-webhook-configuration</span></span><br><span class="line"><span class="attr">webhooks:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mjob.kb.io</span></span><br><span class="line">  <span class="attr">clientConfig:</span></span><br><span class="line">    <span class="attr">service:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">kueue-webhook-service</span></span><br><span class="line">      <span class="attr">namespace:</span> <span class="string">kueue-system</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/mutate-batch-v1-job</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">"batch"</span>]</span><br><span class="line">    <span class="attr">apiVersions:</span> [<span class="string">"v1"</span>]</span><br><span class="line">    <span class="attr">operations:</span> [<span class="string">"CREATE"</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">"jobs"</span>]</span><br><span class="line">  <span class="attr">failurePolicy:</span> <span class="string">Fail</span></span><br><span class="line">  <span class="attr">timeoutSeconds:</span> <span class="number">10</span></span><br></pre></td></tr></table></figure></div><h3 id="2-2-Validating-Webhook-配置"><a href="#2-2-Validating-Webhook-配置" class="headerlink" title="2.2 Validating Webhook 配置"></a>2.2 Validating Webhook 配置</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">admissionregistration.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ValidatingWebhookConfiguration</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kueue-validating-webhook-configuration</span></span><br><span class="line"><span class="attr">webhooks:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">vresourceflavor.kb.io</span></span><br><span class="line">  <span class="attr">clientConfig:</span></span><br><span class="line">    <span class="attr">service:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">kueue-webhook-service</span></span><br><span class="line">      <span class="attr">namespace:</span> <span class="string">kueue-system</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/validate-kueue-x-k8s-io-v1beta1-resourceflavor</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">"kueue.x-k8s.io"</span>]</span><br><span class="line">    <span class="attr">apiVersions:</span> [<span class="string">"v1beta1"</span>]</span><br><span class="line">    <span class="attr">operations:</span> [<span class="string">"CREATE"</span>, <span class="string">"UPDATE"</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">"resourceflavors"</span>]</span><br></pre></td></tr></table></figure></div><h2 id="3-证书管理"><a href="#3-证书管理" class="headerlink" title="3. 证书管理"></a>3. 证书管理</h2><h3 id="3-1-TLS-证书配置"><a href="#3-1-TLS-证书配置" class="headerlink" title="3.1 TLS 证书配置"></a>3.1 TLS 证书配置</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 证书存储在 Secret 中</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kueue-webhook-server-cert</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kueue-system</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">kubernetes.io/tls</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">tls.crt:</span> <span class="string">&lt;base64-encoded-cert&gt;</span></span><br><span class="line">  <span class="attr">tls.key:</span> <span class="string">&lt;base64-encoded-key&gt;</span></span><br></pre></td></tr></table></figure></div><h3 id="3-2-证书挂载"><a href="#3-2-证书挂载" class="headerlink" title="3.2 证书挂载"></a>3.2 证书挂载</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在 Deployment 中挂载证书</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">webhook-server-cert</span></span><br><span class="line">  <span class="attr">secret:</span></span><br><span class="line">    <span class="attr">secretName:</span> <span class="string">kueue-webhook-server-cert</span></span><br><span class="line"><span class="attr">volumeMounts:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">webhook-server-cert</span></span><br><span class="line">  <span class="attr">mountPath:</span> <span class="string">/tmp/certs</span></span><br><span class="line">  <span class="attr">readOnly:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></div><h1 id="🚨常见问题及解决方案"><a href="#🚨常见问题及解决方案" class="headerlink" title="🚨常见问题及解决方案"></a>🚨常见问题及解决方案</h1><h2 id="问题1：Webhook-连接被拒绝"><a href="#问题1：Webhook-连接被拒绝" class="headerlink" title="问题1：Webhook 连接被拒绝"></a>问题1：Webhook 连接被拒绝</h2><h3 id="错误现象"><a href="#错误现象" class="headerlink" title="错误现象"></a>错误现象</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">failed calling webhook "mresourceflavor.kb.io": failed to call webhook: </span><br><span class="line">Post "https://kueue-webhook-service.kueue-system.svc:443/mutate-kueue-x-k8s-io-v1beta1-resourceflavor?timeout=10s": </span><br><span class="line">dial tcp 10.96.33.70:443: connect: connection refused</span><br></pre></td></tr></table></figure></div><h3 id="可能原因"><a href="#可能原因" class="headerlink" title="可能原因"></a>可能原因</h3><ol><li><strong>Webhook 服务未启动</strong></li><li><strong>Webhook Pod 未就绪</strong></li><li><strong>证书未正确生成</strong></li><li><strong>服务端点未配置</strong></li></ol><h3 id="诊断步骤"><a href="#诊断步骤" class="headerlink" title="诊断步骤"></a>诊断步骤</h3><h4 id="步骤1：检查-Webhook-Pod-状态"><a href="#步骤1：检查-Webhook-Pod-状态" class="headerlink" title="步骤1：检查 Webhook Pod 状态"></a>步骤1：检查 Webhook Pod 状态</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查 Pod 是否运行</span></span><br><span class="line">kubectl get pods -n kueue-system -l control-plane=controller-manager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Pod 详细信息</span></span><br><span class="line">kubectl describe pod -n kueue-system -l control-plane=controller-manager</span><br></pre></td></tr></table></figure></div><h4 id="步骤2：检查-Webhook-服务"><a href="#步骤2：检查-Webhook-服务" class="headerlink" title="步骤2：检查 Webhook 服务"></a>步骤2：检查 Webhook 服务</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查服务是否存在</span></span><br><span class="line">kubectl get service kueue-webhook-service -n kueue-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看服务详细信息</span></span><br><span class="line">kubectl describe service kueue-webhook-service -n kueue-system</span><br></pre></td></tr></table></figure></div><h4 id="步骤3：检查服务端点"><a href="#步骤3：检查服务端点" class="headerlink" title="步骤3：检查服务端点"></a>步骤3：检查服务端点</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查端点是否配置</span></span><br><span class="line">kubectl get endpoints kueue-webhook-service -n kueue-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看端点详细信息</span></span><br><span class="line">kubectl describe endpoints kueue-webhook-service -n kueue-system</span><br></pre></td></tr></table></figure></div><h4 id="步骤4：检查证书"><a href="#步骤4：检查证书" class="headerlink" title="步骤4：检查证书"></a>步骤4：检查证书</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查证书 Secret 是否存在</span></span><br><span class="line">kubectl get secret kueue-webhook-server-cert -n kueue-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看证书详细信息</span></span><br><span class="line">kubectl describe secret kueue-webhook-server-cert -n kueue-system</span><br></pre></td></tr></table></figure></div><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="方案1：等待服务就绪"><a href="#方案1：等待服务就绪" class="headerlink" title="方案1：等待服务就绪"></a>方案1：等待服务就绪</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 等待 Pod 就绪</span></span><br><span class="line">kubectl <span class="built_in">wait</span> --<span class="keyword">for</span>=condition=ready pod -l control-plane=controller-manager -n kueue-system --<span class="built_in">timeout</span>=120s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等待服务端点就绪</span></span><br><span class="line">kubectl <span class="built_in">wait</span> --<span class="keyword">for</span>=condition=ready endpoints kueue-webhook-service -n kueue-system --<span class="built_in">timeout</span>=60s</span><br></pre></td></tr></table></figure></div><h4 id="方案2：重新生成证书"><a href="#方案2：重新生成证书" class="headerlink" title="方案2：重新生成证书"></a>方案2：重新生成证书</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除现有证书</span></span><br><span class="line">kubectl delete secret kueue-webhook-server-cert -n kueue-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启 Kueue 控制器</span></span><br><span class="line">kubectl rollout restart deployment kueue-controller-manager -n kueue-system</span><br></pre></td></tr></table></figure></div><h4 id="方案3：检查网络连接"><a href="#方案3：检查网络连接" class="headerlink" title="方案3：检查网络连接"></a>方案3：检查网络连接</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试服务可访问性</span></span><br><span class="line">kubectl run test-webhook --image=busybox --<span class="built_in">rm</span> -it --restart=Never -- \</span><br><span class="line">  wget -qO- --no-check-certificate https://kueue-webhook-service.kueue-system.svc:443/healthz</span><br></pre></td></tr></table></figure></div><h2 id="问题2：Webhook-超时"><a href="#问题2：Webhook-超时" class="headerlink" title="问题2：Webhook 超时"></a>问题2：Webhook 超时</h2><h3 id="错误现象-1"><a href="#错误现象-1" class="headerlink" title="错误现象"></a>错误现象</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">failed calling webhook: timeout=10s</span><br></pre></td></tr></table></figure></div><h3 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="方案1：增加超时时间"><a href="#方案1：增加超时时间" class="headerlink" title="方案1：增加超时时间"></a>方案1：增加超时时间</h4><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改 webhook 配置</span></span><br><span class="line"><span class="attr">webhooks:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mjob.kb.io</span></span><br><span class="line">  <span class="attr">timeoutSeconds:</span> <span class="number">30</span>  <span class="comment"># 增加超时时间</span></span><br></pre></td></tr></table></figure></div><h4 id="方案2：优化-Webhook-性能"><a href="#方案2：优化-Webhook-性能" class="headerlink" title="方案2：优化 Webhook 性能"></a>方案2：优化 Webhook 性能</h4><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 增加资源限制</span></span><br><span class="line"><span class="attr">resources:</span></span><br><span class="line">  <span class="attr">requests:</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">500m</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">512Mi</span></span><br><span class="line">  <span class="attr">limits:</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">1000m</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">1Gi</span></span><br></pre></td></tr></table></figure></div><h4 id="方案3：调整并发处理"><a href="#方案3：调整并发处理" class="headerlink" title="方案3：调整并发处理"></a>方案3：调整并发处理</h4><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 增加并发处理能力</span></span><br><span class="line"><span class="attr">controller:</span></span><br><span class="line">  <span class="attr">groupKindConcurrency:</span></span><br><span class="line">    <span class="attr">Job.batch:</span> <span class="number">100</span></span><br><span class="line">    <span class="attr">Pod:</span> <span class="number">100</span></span><br><span class="line">    <span class="attr">Workload.kueue.x-k8s.io:</span> <span class="number">100</span></span><br></pre></td></tr></table></figure></div><h2 id="问题3：证书问题"><a href="#问题3：证书问题" class="headerlink" title="问题3：证书问题"></a>问题3：证书问题</h2><h3 id="错误现象-2"><a href="#错误现象-2" class="headerlink" title="错误现象"></a>错误现象</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x509: certificate signed by unknown authority</span><br></pre></td></tr></table></figure></div><h3 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="方案1：重新生成证书"><a href="#方案1：重新生成证书" class="headerlink" title="方案1：重新生成证书"></a>方案1：重新生成证书</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除现有证书</span></span><br><span class="line">kubectl delete secret kueue-webhook-server-cert -n kueue-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启控制器</span></span><br><span class="line">kubectl rollout restart deployment kueue-controller-manager -n kueue-system</span><br></pre></td></tr></table></figure></div><h4 id="方案2：检查证书配置"><a href="#方案2：检查证书配置" class="headerlink" title="方案2：检查证书配置"></a>方案2：检查证书配置</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证证书配置</span></span><br><span class="line">kubectl get secret kueue-webhook-server-cert -n kueue-system -o yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查证书内容</span></span><br><span class="line">kubectl get secret kueue-webhook-server-cert -n kueue-system -o jsonpath=<span class="string">'{.data.tls\.crt}'</span> | <span class="built_in">base64</span> -d | openssl x509 -text -noout</span><br></pre></td></tr></table></figure></div><h1 id="🔍调试方法"><a href="#🔍调试方法" class="headerlink" title="🔍调试方法"></a>🔍调试方法</h1><h2 id="1-日志分析"><a href="#1-日志分析" class="headerlink" title="1. 日志分析"></a>1. 日志分析</h2><h3 id="查看-Webhook-服务器日志"><a href="#查看-Webhook-服务器日志" class="headerlink" title="查看 Webhook 服务器日志"></a>查看 Webhook 服务器日志</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 webhook 服务器日志</span></span><br><span class="line">kubectl logs -n kueue-system -l control-plane=controller-manager -c manager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实时跟踪日志</span></span><br><span class="line">kubectl logs -n kueue-system -l control-plane=controller-manager -c manager -f</span><br></pre></td></tr></table></figure></div><h3 id="查看-API-服务器日志"><a href="#查看-API-服务器日志" class="headerlink" title="查看 API 服务器日志"></a>查看 API 服务器日志</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 API 服务器日志</span></span><br><span class="line">kubectl logs -n kube-system kube-apiserver-kind-control-plane</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 API 服务器审计日志</span></span><br><span class="line">kubectl logs -n kube-system kube-apiserver-kind-control-plane | grep webhook</span><br></pre></td></tr></table></figure></div><h2 id="2-配置检查"><a href="#2-配置检查" class="headerlink" title="2. 配置检查"></a>2. 配置检查</h2><h3 id="检查-Webhook-配置"><a href="#检查-Webhook-配置" class="headerlink" title="检查 Webhook 配置"></a>检查 Webhook 配置</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 mutating webhook 配置</span></span><br><span class="line">kubectl get mutatingwebhookconfiguration kueue-mutating-webhook-configuration -o yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 validating webhook 配置</span></span><br><span class="line">kubectl get validatingwebhookconfiguration kueue-validating-webhook-configuration -o yaml</span><br></pre></td></tr></table></figure></div><h3 id="检查服务配置"><a href="#检查服务配置" class="headerlink" title="检查服务配置"></a>检查服务配置</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看服务配置</span></span><br><span class="line">kubectl get service kueue-webhook-service -n kueue-system -o yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看端点配置</span></span><br><span class="line">kubectl get endpoints kueue-webhook-service -n kueue-system -o yaml</span><br></pre></td></tr></table></figure></div><h2 id="3-网络测试"><a href="#3-网络测试" class="headerlink" title="3. 网络测试"></a>3. 网络测试</h2><h3 id="测试服务连通性"><a href="#测试服务连通性" class="headerlink" title="测试服务连通性"></a>测试服务连通性</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试服务可访问性</span></span><br><span class="line">kubectl run test-webhook --image=busybox --<span class="built_in">rm</span> -it --restart=Never -- \</span><br><span class="line">  wget -qO- --no-check-certificate https://kueue-webhook-service.kueue-system.svc:443/healthz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试端口连通性</span></span><br><span class="line">kubectl run test-port --image=busybox --<span class="built_in">rm</span> -it --restart=Never -- \</span><br><span class="line">  nc -zv kueue-webhook-service.kueue-system.svc 443</span><br></pre></td></tr></table></figure></div><h1 id="🏥实战总结"><a href="#🏥实战总结" class="headerlink" title="🏥实战总结"></a>🏥实战总结</h1><h2 id="关键要点"><a href="#关键要点" class="headerlink" title="关键要点"></a>关键要点</h2><ol><li><strong>Webhook 是 Kueue 的核心组件</strong>：负责准入控制、资源验证和自动标签管理</li><li><strong>证书管理至关重要</strong>：TLS 证书是 Webhook 安全通信的基础</li><li><strong>服务就绪检查</strong>：确保 Webhook 服务完全就绪是避免连接问题的关键</li></ol><h2 id="实践经验"><a href="#实践经验" class="headerlink" title="实践经验"></a>实践经验</h2><p>通常可考虑的故障排除流程如下：</p><ol><li><strong>检查 Pod 状态</strong>：确认 Webhook 服务正在运行</li><li><strong>验证服务配置</strong>：检查服务和端点配置</li><li><strong>检查证书</strong>：验证 TLS 证书是否正确</li><li><strong>测试连通性</strong>：确认网络连接正常</li><li><strong>查看日志</strong>：分析错误信息和性能指标</li></ol><p>希望本文档能够帮助您更好地理解和解决 Kubernetes 集群中的 Webhook 相关问题！</p><hr><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E9%92%A9%E5%AD%90">[1] Webhook - Wikipedia<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/">[2] Kubernetes 中的准入控制 - 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://github.com/volcano-sh/volcano/tree/master/pkg/webhooks">[3] Volcano Webhook Implementation - GitHub<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/cluster-administration/admission-webhooks-good-practices/">[4] Admission Webhook 良好实践 - Kubernetes官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/webhook/">[5] Webhook Mode - Kubernetes官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/">[6] Kubernetes API Server 参数 - 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://juejin.cn/post/7437727364082040871">[7] 什么是Webhook？工作原理？如何实现？缺点？ - 掘金<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://zhuanlan.zhihu.com/p/606844215">[8] 详细介绍一下webhook技术 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://blog.csdn.net/m0_71808387/article/details/140469408">[9] Webhook 是什么？详解其工作原理 - CSDN<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://www.redhat.com/zh-cn/topics/automation-and-management/shenmeshi-webhook">[10] 什么是 Webhook？ - RedHat<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://www.cnblogs.com/keep-live/articles/16544143.html">[11] kubernetes的webhook开发 - 博客园<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">本文基于调度器性能测试项目中的实际故障案例，深入解析 Kueue 调度器的 Webhook 机制。从理论到实践，从故障现象到解决方案，提供完整的 Webhook 准入控制实战指南，助您快速定位和解决 Kubernetes 集群中的 Webhook 相关问题。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    <category term="实战" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Kubernetes" scheme="https://freshwlnd.github.io/tags/Kubernetes/"/>
    
    <category term="Webhook" scheme="https://freshwlnd.github.io/tags/Webhook/"/>
    
    <category term="准入控制" scheme="https://freshwlnd.github.io/tags/%E5%87%86%E5%85%A5%E6%8E%A7%E5%88%B6/"/>
    
    <category term="调度器" scheme="https://freshwlnd.github.io/tags/%E8%B0%83%E5%BA%A6%E5%99%A8/"/>
    
    <category term="性能优化" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    
    <category term="Kueue" scheme="https://freshwlnd.github.io/tags/Kueue/"/>
    
    <category term="故障排除" scheme="https://freshwlnd.github.io/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4/"/>
    
  </entry>
  
  <entry>
    <title>【集群】Kubernetes Webhook入门：准入控制机制与性能瓶颈分析</title>
    <link href="https://freshwlnd.github.io/2025/07/08/k8s/k8s-webhook/"/>
    <id>https://freshwlnd.github.io/2025/07/08/k8s/k8s-webhook/</id>
    <published>2025-07-08T01:24:17.000Z</published>
    <updated>2025-09-18T07:27:36.971Z</updated>
    
    <content type="html"><![CDATA[<!-- > 本系列《Kubernetes深度解析》计划分为以下几篇，点击查看其它内容。 --><!-- > 1. <a href="/2025/07/08/k8s/k8s-webhook/" title="Kubernetes Webhook入门：准入控制机制与性能瓶颈分析">Kubernetes Webhook入门：准入控制机制与性能瓶颈分析</a> --><!-- > 2. （待续）Kubernetes调度器性能优化实践 --><!-- > 3. （待续）大规模集群资源管理策略 --><!-- > 4. （待续）云原生架构设计最佳实践 --><h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="调度器性能对比分析">调度器性能对比分析</a>中，我们发现Webhook可能在大规模情况下成为Volcano创建Job的限制因素。为了深入理解这一现象，本文将从Webhook的基本概念出发，系统梳理其在Kubernetes生态系统中的作用机制和性能影响。</p><h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>在调度器性能测试中，我们发现了一个有趣的现象：Volcano调度器在大量Job创建时会出现阶段性阻塞，其中一个可能的原因是Webhook QPS限制。这引发了我们对Webhook机制的深入思考：</p><h3 id="核心问题"><a href="#核心问题" class="headerlink" title="核心问题"></a>核心问题</h3><ol><li><strong>大背景</strong>：Webhook的起源是什么？为什么Kubernetes需要这种机制？</li><li><strong>小背景</strong>：Webhook在K8s/Volcano中是如何应用的？</li><li><strong>出发点</strong>：在K8s中应用Webhook时是否有什么参数存在限制，如跟<code>--kube-api-qps</code>有什么关系？为什么要设计这种限制？</li><li><strong>挑战</strong>：什么情况下会成为瓶颈限制性能？</li></ol><h1 id="🧠问题回答"><a href="#🧠问题回答" class="headerlink" title="🧠问题回答"></a>🧠问题回答</h1><h2 id="问题一：Webhook的起源是什么？"><a href="#问题一：Webhook的起源是什么？" class="headerlink" title="问题一：Webhook的起源是什么？"></a>问题一：Webhook的起源是什么？</h2><h3 id="Webhook概念的起源"><a href="#Webhook概念的起源" class="headerlink" title="Webhook概念的起源"></a>Webhook概念的起源</h3><p><strong>Webhook</strong>一词最早出现在2007年，由Jeff Lindsay提出<a href="#refer-anchor-1"><sup>[1]</sup></a>。它描述了一种”反向API调用”的机制，即服务器在特定事件发生时主动向客户端发送HTTP请求，而不是客户端主动轮询服务器。</p><h3 id="什么是Webhook？一个简单的比喻"><a href="#什么是Webhook？一个简单的比喻" class="headerlink" title="什么是Webhook？一个简单的比喻"></a>什么是Webhook？一个简单的比喻</h3><p>想象一下<strong>闹钟</strong>的工作原理<a href="#refer-anchor-7"><sup>[7]</sup></a>：</p><blockquote><p>你在手机上定了一个明天早上6点的闹钟（注册webhook），当时间来到第二天早上6点时，手机闹钟响起（触发webhook），你就会被叫醒（你的服务器收到通知并执行相应操作）。</p></blockquote><p><strong>Webhook</strong>就是这样一种”反向通知”机制：</p><ul><li><strong>传统方式</strong>：你每隔几分钟就问一次”有新消息吗？”（周期性拉取）</li><li><strong>Webhook方式</strong>：有新消息时，系统主动告诉你”有新消息了！”（触发式推送）</li></ul><h3 id="Webhook在不同场景下的应用"><a href="#Webhook在不同场景下的应用" class="headerlink" title="Webhook在不同场景下的应用"></a>Webhook在不同场景下的应用</h3><h4 id="1-传统应用场景（事件驱动）"><a href="#1-传统应用场景（事件驱动）" class="headerlink" title="1. 传统应用场景（事件驱动）"></a>1. 传统应用场景（事件驱动）</h4><ul><li><strong>钉钉机器人</strong>：当有重要事件发生时，钉钉主动向你的webhook地址发送消息</li><li><strong>支付系统</strong>：支付成功后，支付平台主动通知商家系统</li><li><strong>GitHub代码推送</strong>：代码推送后，GitHub主动通知CI/CD系统</li></ul><h4 id="2-Kubernetes应用场景（请求拦截）"><a href="#2-Kubernetes应用场景（请求拦截）" class="headerlink" title="2. Kubernetes应用场景（请求拦截）"></a>2. Kubernetes应用场景（请求拦截）</h4><ul><li><strong>准入控制</strong>：当用户创建Pod时，API服务器主动调用Webhook进行检查</li><li><strong>资源验证</strong>：验证Pod是否符合集群的安全策略</li><li><strong>资源修改</strong>：给Pod添加默认标签或注解</li></ul><h3 id="在Kubernetes中的应用"><a href="#在Kubernetes中的应用" class="headerlink" title="在Kubernetes中的应用"></a>在Kubernetes中的应用</h3><p>在Kubernetes中，Webhook被用作<strong>准入控制器（Admission Controller）</strong>的一种实现方式<a href="#refer-anchor-2"><sup>[2]</sup></a>。准入控制器是Kubernetes API服务器的一个插件机制，用于在资源创建、修改或删除之前进行拦截和处理。</p><h3 id="为什么需要Webhook？"><a href="#为什么需要Webhook？" class="headerlink" title="为什么需要Webhook？"></a>为什么需要Webhook？</h3><p>想象一下<strong>海关检查</strong>的工作<a href="#refer-anchor-8"><sup>[8]</sup></a>：</p><blockquote><p>当有货物要进入国家时，海关会检查：</p><ul><li>这个货物符合进口规定吗？（验证）</li><li>需要添加标签或修改包装吗？（修改）</li><li>有安全隐患吗？（安全验证）</li></ul></blockquote><p>Kubernetes的Webhook就像这个海关：</p><ol><li><strong>扩展性需求</strong>：Kubernetes需要支持各种自定义的验证和修改逻辑</li><li><strong>动态配置</strong>：Webhook可以在不重启API服务器的情况下动态添加新的验证规则</li><li><strong>外部集成</strong>：允许外部系统参与Kubernetes的资源管理决策</li><li><strong>安全增强</strong>：提供额外的安全验证层</li></ol><h3 id="为什么K8s下的Webhook和其他场景的Webhook看起来似乎不一样？"><a href="#为什么K8s下的Webhook和其他场景的Webhook看起来似乎不一样？" class="headerlink" title="为什么K8s下的Webhook和其他场景的Webhook看起来似乎不一样？"></a>为什么K8s下的Webhook和其他场景的Webhook看起来似乎不一样？</h3><p><strong>关键理解</strong>：Webhook的本质都是<strong>HTTP回调机制</strong>，区别在于<strong>触发时机</strong>和<strong>处理方式</strong>：</p><table><thead><tr><th>场景</th><th>触发时机</th><th>处理方式</th><th>目的</th></tr></thead><tbody><tr><td><strong>传统应用</strong></td><td>事件发生时</td><td>异步通知</td><td>推送信息</td></tr><tr><td><strong>Kubernetes</strong></td><td>请求到达时</td><td>同步拦截</td><td>验证/修改</td></tr></tbody></table><p><strong>相同点</strong>：</p><ul><li>都是基于HTTP的回调机制（触发式推送而非周期性拉取）</li><li>都是服务器主动调用外部服务</li><li>都支持自定义处理逻辑</li></ul><p><strong>不同点</strong>：</p><ul><li><strong>触发条件</strong>：事件驱动 vs 请求驱动</li><li><strong>处理方式</strong>：异步推送 vs 同步拦截</li><li><strong>响应要求</strong>：无响应要求 vs 必须返回结果</li></ul><h2 id="问题二：Webhook在K8s-Volcano中是如何应用的？"><a href="#问题二：Webhook在K8s-Volcano中是如何应用的？" class="headerlink" title="问题二：Webhook在K8s/Volcano中是如何应用的？"></a>问题二：Webhook在K8s/Volcano中是如何应用的？</h2><h3 id="Kubernetes中的Webhook类型"><a href="#Kubernetes中的Webhook类型" class="headerlink" title="Kubernetes中的Webhook类型"></a>Kubernetes中的Webhook类型</h3><h4 id="1-验证性Webhook（Validating-Webhook）"><a href="#1-验证性Webhook（Validating-Webhook）" class="headerlink" title="1. 验证性Webhook（Validating Webhook）"></a>1. 验证性Webhook（Validating Webhook）</h4><ul><li><strong>作用</strong>：验证资源是否符合特定规则</li><li><strong>时机</strong>：在资源被持久化到etcd之前</li><li><strong>结果</strong>：允许或拒绝请求</li></ul><h4 id="2-修改性Webhook（Mutating-Webhook）"><a href="#2-修改性Webhook（Mutating-Webhook）" class="headerlink" title="2. 修改性Webhook（Mutating Webhook）"></a>2. 修改性Webhook（Mutating Webhook）</h4><ul><li><strong>作用</strong>：修改资源内容</li><li><strong>时机</strong>：在验证性Webhook之前</li><li><strong>结果</strong>：返回修改后的资源</li></ul><h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">用户创建Pod → API服务器接收请求 → 修改性Webhook → 验证性Webhook → 持久化到etcd</span><br></pre></td></tr></table></figure></div><p><strong>具体例子</strong>：</p><ol><li>用户提交一个Pod创建请求</li><li>API服务器收到请求后，先调用修改性Webhook</li><li>修改性Webhook可能会给Pod添加默认标签</li><li>然后调用验证性Webhook检查Pod是否符合规则</li><li>如果验证通过，Pod被保存到etcd；如果失败，请求被拒绝</li></ol><h2 id="问题三：Webhook的QPS限制机制"><a href="#问题三：Webhook的QPS限制机制" class="headerlink" title="问题三：Webhook的QPS限制机制"></a>问题三：Webhook的QPS限制机制</h2><h3 id="QPS限制参数"><a href="#QPS限制参数" class="headerlink" title="QPS限制参数"></a>QPS限制参数</h3><h4 id="1-kube-api-qps"><a href="#1-kube-api-qps" class="headerlink" title="1. --kube-api-qps"></a>1. <code>--kube-api-qps</code></h4><ul><li><strong>含义</strong>：API服务器向Webhook服务发送请求的速率限制</li><li><strong>默认值</strong>：通常为50 QPS</li><li><strong>作用范围</strong>：所有Webhook请求的总和</li></ul><h4 id="2-kube-api-burst"><a href="#2-kube-api-burst" class="headerlink" title="2. --kube-api-burst"></a>2. <code>--kube-api-burst</code></h4><ul><li><strong>含义</strong>：突发请求的最大数量</li><li><strong>默认值</strong>：通常为100</li><li><strong>作用</strong>：允许短时间的突发流量</li></ul><h3 id="与-kube-api-qps的关系"><a href="#与-kube-api-qps的关系" class="headerlink" title="与--kube-api-qps的关系"></a>与<code>--kube-api-qps</code>的关系</h3><p><strong>关系说明</strong>：</p><ul><li><code>--kube-api-qps</code>控制API服务器向所有外部服务（包括Webhook）发送请求的速率</li><li>Webhook请求也受到这个限制的约束</li><li>当Webhook服务响应慢时，会占用更多的QPS配额</li></ul><h3 id="为什么设计这种限制？"><a href="#为什么设计这种限制？" class="headerlink" title="为什么设计这种限制？"></a>为什么设计这种限制？</h3><h4 id="1-保护API服务器"><a href="#1-保护API服务器" class="headerlink" title="1. 保护API服务器"></a>1. 保护API服务器</h4><ul><li>防止Webhook服务过载影响API服务器性能</li><li>避免资源耗尽导致系统崩溃</li></ul><h4 id="2-公平性保证"><a href="#2-公平性保证" class="headerlink" title="2. 公平性保证"></a>2. 公平性保证</h4><ul><li>确保不同Webhook服务获得公平的处理机会</li><li>防止单个Webhook占用过多资源</li></ul><h2 id="问题四：什么情况下会成为瓶颈？"><a href="#问题四：什么情况下会成为瓶颈？" class="headerlink" title="问题四：什么情况下会成为瓶颈？"></a>问题四：什么情况下会成为瓶颈？</h2><h3 id="瓶颈场景分析"><a href="#瓶颈场景分析" class="headerlink" title="瓶颈场景分析"></a>瓶颈场景分析</h3><h4 id="1-大规模Job创建"><a href="#1-大规模Job创建" class="headerlink" title="1. 大规模Job创建"></a>1. 大规模Job创建</h4><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">场景：同时创建1000个Job，每个Job包含100个Pod</span><br><span class="line">影响：需要调用100,000次Webhook</span><br><span class="line">瓶颈：Webhook QPS限制导致请求排队</span><br></pre></td></tr></table></figure></div><h4 id="2-Webhook服务响应慢"><a href="#2-Webhook服务响应慢" class="headerlink" title="2. Webhook服务响应慢"></a>2. Webhook服务响应慢</h4><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">场景：Webhook服务处理单个请求需要100ms</span><br><span class="line">影响：即使QPS限制为50，实际吞吐量可能只有10 QPS</span><br><span class="line">瓶颈：Webhook服务成为性能瓶颈</span><br></pre></td></tr></table></figure></div><h4 id="3-复杂的验证逻辑"><a href="#3-复杂的验证逻辑" class="headerlink" title="3. 复杂的验证逻辑"></a>3. 复杂的验证逻辑</h4><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">场景：Webhook需要查询外部数据库进行验证</span><br><span class="line">影响：每次验证都需要网络调用，增加延迟</span><br><span class="line">瓶颈：网络延迟和外部服务响应时间</span><br></pre></td></tr></table></figure></div><h3 id="生活中的类比"><a href="#生活中的类比" class="headerlink" title="生活中的类比"></a>生活中的类比</h3><p>想象一下<strong>银行柜台</strong>的场景<a href="#refer-anchor-9"><sup>[9]</sup></a>：</p><blockquote><p>银行有10个柜台，每个柜台每分钟最多处理2个客户（QPS限制）。</p><ul><li>正常情况下：客户排队，柜台按顺序处理</li><li>高峰期：大量客户同时到达，柜台处理不过来，排队时间变长</li><li>柜台效率低：即使有10个柜台，如果每个客户处理时间很长，整体处理能力也会下降</li></ul></blockquote><p>Webhook的瓶颈就像这个银行柜台：</p><ul><li><strong>QPS限制</strong>：就像柜台数量有限</li><li><strong>处理时间</strong>：就像每个客户的处理时间</li><li><strong>排队等待</strong>：就像客户在银行排队</li></ul><h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><p>目前仅有粗浅地了解，接下来会进一步开展后续研究，例如：</p><ol><li><p><strong>Webhook最佳实践</strong></p><ul><li>性能优化策略</li><li>错误处理机制</li><li>监控和告警</li></ul></li><li><p><strong>调度器集成</strong></p><ul><li>Volcano Webhook实现细节</li><li>其他调度器的Webhook使用</li><li>性能对比分析</li></ul></li><li><p><strong>大规模集群优化</strong></p><ul><li>Webhook在高并发场景下的表现</li><li>瓶颈识别和解决方案</li><li>最佳配置参数</li></ul></li></ol><hr><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E9%92%A9%E5%AD%90">[1] Webhook - Wikipedia<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/">[2] Kubernetes 中的准入控制 - 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://github.com/volcano-sh/volcano/tree/master/pkg/webhooks">[3] Volcano Webhook Implementation - GitHub<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/cluster-administration/admission-webhooks-good-practices/">[4] Admission Webhook 良好实践 - Kubernetes官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/webhook/">[5] Webhook Mode - Kubernetes官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/">[6] Kubernetes API Server 参数 - 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://juejin.cn/post/7437727364082040871">[7] 什么是Webhook？工作原理？如何实现？缺点？ - 掘金<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://zhuanlan.zhihu.com/p/606844215">[8] 详细介绍一下webhook技术 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://blog.csdn.net/m0_71808387/article/details/140469408">[9] Webhook 是什么？详解其工作原理 - CSDN<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://www.redhat.com/zh-cn/topics/automation-and-management/shenmeshi-webhook">[10] 什么是 Webhook？ - RedHat<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://www.cnblogs.com/keep-live/articles/16544143.html">[11] kubernetes的webhook开发 - 博客园<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">本文初步解析Kubernetes Webhook的基本概念、工作原理和在调度器中的应用。从Webhook的起源出发，分析其在K8s中的应用场景，探讨QPS限制机制，为理解大规模集群中的性能瓶颈提供理论基础。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云计算" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="Kubernetes" scheme="https://freshwlnd.github.io/tags/Kubernetes/"/>
    
    <category term="Webhook" scheme="https://freshwlnd.github.io/tags/Webhook/"/>
    
    <category term="准入控制" scheme="https://freshwlnd.github.io/tags/%E5%87%86%E5%85%A5%E6%8E%A7%E5%88%B6/"/>
    
    <category term="调度器" scheme="https://freshwlnd.github.io/tags/%E8%B0%83%E5%BA%A6%E5%99%A8/"/>
    
    <category term="性能优化" scheme="https://freshwlnd.github.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>【操作系统】计算机硬件架构基础：CPU执行原理与架构演进</title>
    <link href="https://freshwlnd.github.io/2025/07/07/os/os-architecture/"/>
    <id>https://freshwlnd.github.io/2025/07/07/os/os-architecture/</id>
    <published>2025-07-07T00:48:11.000Z</published>
    <updated>2025-07-08T01:22:33.804Z</updated>
    
    <content type="html"><![CDATA[<!-- > 本系列《操作系统基础知识》计划分为以下几篇，点击查看其它内容。 --><!-- > 1. <a href="/2025/07/07/os/os-architecture/" title="计算机硬件架构基础：CPU执行原理与架构演进">计算机硬件架构基础：CPU执行原理与架构演进</a> --><!-- > 2. （待续）操作系统内存管理原理 --><!-- > 3. （待续）操作系统进程调度机制 --><!-- > 4. （待续）操作系统文件系统设计 --><h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>计算机硬件是操作系统运行的基础，理解硬件架构对于深入学习操作系统至关重要。本文基于小林coding的优质内容<a href="#refer-anchor-1"><sup>[1]</sup></a>，系统梳理计算机硬件的工作原理，重点解析CPU执行程序的机制、32/64位架构的区别，以及x86/x64/ARM64等主流架构的演进历程。</p><h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><h2 id="为什么需要理解硬件架构？"><a href="#为什么需要理解硬件架构？" class="headerlink" title="为什么需要理解硬件架构？"></a>为什么需要理解硬件架构？</h2><p>在深入学习操作系统之前，理解计算机硬件架构是必不可少的基础。操作系统作为硬件和软件之间的桥梁，其设计理念和实现机制都深深植根于底层硬件特性。</p><h3 id="核心问题"><a href="#核心问题" class="headerlink" title="核心问题"></a>核心问题</h3><ol><li><strong>CPU如何执行程序？</strong> - 理解指令执行的基本流程</li><li><strong>32位与64位架构的区别？</strong> - 掌握位宽对性能的影响</li><li><strong>不同架构的演进历程？</strong> - 了解技术发展的历史脉络</li></ol><h1 id="🧠问题回答"><a href="#🧠问题回答" class="headerlink" title="🧠问题回答"></a>🧠问题回答</h1><h2 id="问题一：CPU是如何执行程序的？"><a href="#问题一：CPU是如何执行程序的？" class="headerlink" title="问题一：CPU是如何执行程序的？"></a>问题一：CPU是如何执行程序的？</h2><h3 id="基本执行流程"><a href="#基本执行流程" class="headerlink" title="基本执行流程"></a>基本执行流程</h3><p>CPU执行程序的基本流程可以概括为：</p><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">程序编译 → CPU读取指令 → 执行指令 → 跳转下一条指令</span><br></pre></td></tr></table></figure></div><ol><li><strong>程序编译</strong>：高级语言程序被编译成汇编代码，最终转换为机器指令</li><li><strong>指令读取</strong>：CPU从内存中读取指令到指令寄存器</li><li><strong>指令执行</strong>：CPU解析指令并执行相应的操作</li><li><strong>地址跳转</strong>：程序计数器更新，指向下一条指令</li></ol><h3 id="冯诺依曼架构"><a href="#冯诺依曼架构" class="headerlink" title="冯诺依曼架构"></a>冯诺依曼架构</h3><p>现代计算机都基于冯诺依曼架构，包含五个核心设备：</p><h4 id="CPU内部设备"><a href="#CPU内部设备" class="headerlink" title="CPU内部设备"></a>CPU内部设备</h4><ul><li><strong>运算器</strong>：执行算术和逻辑运算</li><li><strong>控制器</strong>：协调各组件工作，控制指令执行流程</li><li><strong>寄存器组</strong>：（为优化而生，不包含在五个核心组件之内）<ul><li><strong>通用寄存器</strong>：存储计算过程中的临时数据</li><li><strong>程序计数器（PC）</strong>：存储当前执行指令的内存地址</li><li><strong>指令寄存器（IR）</strong>：存储当前正在执行的指令</li></ul></li></ul><h4 id="外部设备"><a href="#外部设备" class="headerlink" title="外部设备"></a>外部设备</h4><ul><li><strong>存储器</strong>：存储程序和数据</li><li><strong>输入设备</strong>：接收外部数据</li><li><strong>输出设备</strong>：输出计算结果</li></ul><h4 id="总线连接（连接CPU内外部设备，不包含在五个核心设备之内）"><a href="#总线连接（连接CPU内外部设备，不包含在五个核心设备之内）" class="headerlink" title="总线连接（连接CPU内外部设备，不包含在五个核心设备之内）"></a>总线连接（连接CPU内外部设备，不包含在五个核心设备之内）</h4><ul><li><strong>地址总线</strong>：指定要访问的内存地址</li><li><strong>控制总线</strong>：传输控制信号</li><li><strong>数据总线</strong>：传输实际数据</li></ul><h3 id="关键技术细节"><a href="#关键技术细节" class="headerlink" title="关键技术细节"></a>关键技术细节</h3><h4 id="电压表示"><a href="#电压表示" class="headerlink" title="电压表示"></a>电压表示</h4><ul><li><strong>0和1的表示</strong>：通过低电压和高电压来表示二进制数据</li><li><strong>信号传输</strong>：总线上的电信号传输数字信息</li></ul><h4 id="总线带宽"><a href="#总线带宽" class="headerlink" title="总线带宽"></a>总线带宽</h4><ul><li><strong>地址总线带宽</strong>：决定可访问的内存地址范围</li><li><strong>数据总线带宽</strong>：决定一次传输的数据量</li><li><strong>带宽匹配</strong>：CPU位宽应与总线带宽匹配以获得最佳性能</li></ul><h4 id="位宽影响"><a href="#位宽影响" class="headerlink" title="位宽影响"></a>位宽影响</h4><ul><li><strong>32位CPU</strong>：理论上可访问4GB内存空间</li><li><strong>64位CPU</strong>：可访问巨大的内存空间（理论上限为2^64字节）</li></ul><h2 id="问题二：32位与64位架构的区别和优劣？"><a href="#问题二：32位与64位架构的区别和优劣？" class="headerlink" title="问题二：32位与64位架构的区别和优劣？"></a>问题二：32位与64位架构的区别和优劣？</h2><h3 id="CPU层面"><a href="#CPU层面" class="headerlink" title="CPU层面"></a>CPU层面</h3><h4 id="计算能力"><a href="#计算能力" class="headerlink" title="计算能力"></a>计算能力</h4><ul><li><strong>32位CPU</strong>：一次最多处理32位数据</li><li><strong>64位CPU</strong>：一次最多处理64位数据</li><li><strong>性能影响</strong>：对于32位以内的计算，两者性能相近；64位计算时，64位CPU有明显优势</li></ul><h4 id="内存寻址"><a href="#内存寻址" class="headerlink" title="内存寻址"></a>内存寻址</h4><ul><li><strong>32位限制</strong>：理论上最多访问4GB内存</li><li><strong>64位优势</strong>：可访问巨大的内存空间</li></ul><h3 id="软件层面"><a href="#软件层面" class="headerlink" title="软件层面"></a>软件层面</h3><h4 id="指令集差异"><a href="#指令集差异" class="headerlink" title="指令集差异"></a>指令集差异</h4><ul><li><strong>32位软件</strong>：使用32位指令集</li><li><strong>64位软件</strong>：使用64位指令集</li><li><strong>兼容性</strong>：64位CPU通常向下兼容32位软件</li></ul><h4 id="性能影响"><a href="#性能影响" class="headerlink" title="性能影响"></a>性能影响</h4><ul><li><strong>寄存器数量</strong>：64位架构通常有更多寄存器</li><li><strong>指令效率</strong>：64位指令可以处理更大数据块</li><li><strong>内存带宽</strong>：64位架构可以更高效地利用内存带宽</li></ul><h3 id="操作系统层面"><a href="#操作系统层面" class="headerlink" title="操作系统层面"></a>操作系统层面</h3><p>操作系统也是一种特殊的软件，其位宽决定了：</p><ul><li><strong>内存管理能力</strong>：64位系统可以管理更大内存</li><li><strong>进程地址空间</strong>：64位系统为每个进程提供更大地址空间</li><li><strong>系统调用接口</strong>：64位系统提供64位系统调用</li></ul><h2 id="问题三：主流处理器架构的演进历程"><a href="#问题三：主流处理器架构的演进历程" class="headerlink" title="问题三：主流处理器架构的演进历程"></a>问题三：主流处理器架构的演进历程</h2><h3 id="x86架构（Intel-AMD）"><a href="#x86架构（Intel-AMD）" class="headerlink" title="x86架构（Intel/AMD）"></a>x86架构（Intel/AMD）</h3><h4 id="历史发展"><a href="#历史发展" class="headerlink" title="历史发展"></a>历史发展</h4><ul><li><strong>起源</strong>：1978年Intel推出8086处理器，开创x86架构</li><li><strong>演进</strong>：从16位（8086）→32位（80386）→64位（x86-64）</li><li><strong>特点</strong>：复杂指令集（CISC），指令丰富但复杂</li></ul><h4 id="代表产品"><a href="#代表产品" class="headerlink" title="代表产品"></a>代表产品</h4><ul><li><strong>早期产品</strong>：Intel 8086、80286、80386、80486</li><li><strong>经典产品</strong>：Intel Pentium系列（奔腾）</li><li><strong>现代产品</strong>：<ul><li><strong>Intel</strong>：Core系列（i3/i5/i7/i9）、Xeon系列（服务器）</li><li><strong>AMD</strong>：Athlon系列、Phenom系列、Ryzen系列、EPYC系列</li></ul></li></ul><h3 id="x64架构（x86-64-AMD64）"><a href="#x64架构（x86-64-AMD64）" class="headerlink" title="x64架构（x86-64/AMD64）"></a>x64架构（x86-64/AMD64）</h3><h4 id="技术特点"><a href="#技术特点" class="headerlink" title="技术特点"></a>技术特点</h4><ul><li><strong>64位扩展</strong>：在x86基础上扩展64位能力</li><li><strong>向下兼容</strong>：完全兼容32位x86软件</li><li><strong>性能提升</strong>：更大的内存空间和更高的计算能力</li></ul><h4 id="代表产品-1"><a href="#代表产品-1" class="headerlink" title="代表产品"></a>代表产品</h4><ul><li><strong>Intel</strong>：Core系列（i3/i5/i7/i9）、Xeon系列</li><li><strong>AMD</strong>：Ryzen系列、EPYC系列</li></ul><h3 id="ARM64架构"><a href="#ARM64架构" class="headerlink" title="ARM64架构"></a>ARM64架构</h3><h4 id="技术特点-1"><a href="#技术特点-1" class="headerlink" title="技术特点"></a>技术特点</h4><ul><li><strong>精简指令集</strong>：RISC架构，指令简单高效</li><li><strong>低功耗设计</strong>：同等性能下功耗更低</li><li><strong>模块化设计</strong>：可根据需求定制处理器核心</li></ul><h4 id="代表产品-2"><a href="#代表产品-2" class="headerlink" title="代表产品"></a>代表产品</h4><ul><li><strong>移动设备</strong>：<ul><li><strong>Apple</strong>：A系列芯片（A14、A15、M1、M2等）</li><li><strong>Qualcomm</strong>：Snapdragon系列</li><li><strong>Huawei</strong>：Kirin系列</li><li><strong>Samsung</strong>：Exynos系列</li></ul></li><li><strong>服务器</strong>：Amazon Graviton、Ampere Altra等</li></ul><h3 id="架构对比总结"><a href="#架构对比总结" class="headerlink" title="架构对比总结"></a>架构对比总结</h3><table><thead><tr><th>特性</th><th>x86</th><th>x64</th><th>ARM64</th></tr></thead><tbody><tr><td>指令集</td><td>CISC</td><td>CISC</td><td>RISC</td></tr><tr><td>位宽</td><td>32位</td><td>64位</td><td>64位</td></tr><tr><td>功耗</td><td>较高</td><td>较高</td><td>较低</td></tr><tr><td>性能</td><td>中等</td><td>高</td><td>中等-高</td></tr><tr><td>应用场景</td><td>传统PC</td><td>主流计算</td><td>移动设备+新兴领域</td></tr></tbody></table><hr><hr><ul><li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li><li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li></ul><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div><p><a class="link" href="https://xiaolincoding.com/os/1_hardware/how_cpu_run.html">[1] 小林coding - 图解系统<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://blog.csdn.net/qq_41063141/article/details/131444672">[2] x86_64和ARM64的区别以及发展 - CSDN博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://blog.csdn.net/qq_24433609/article/details/125991550">[3] x86-64、amd64、arm、aarch64 都是些什么？ - CSDN博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://www.cnblogs.com/zhaoqingqing/p/13145115.html">[4] x86 x64 arm64的区别  - 博客园<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://www.intel.cn/content/www/cn/zh/processors/processor-numbers.html">[5] Intel处理器产品线 - Intel官网<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://www.amd.com/zh-cn/products/specifications.html">[6] AMD处理器产品线 - AMD官网<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p><p><a class="link" href="https://www.arm.com/zh-TW/products/silicon-ip-cpu">[7] ARM架构发展历程 - ARM官网<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>]]></content>
    
    
    <summary type="html">本文深入解析计算机硬件架构的基础知识，包括CPU执行程序的原理、32/64位架构的区别、x86/x64/ARM64架构的演进历程。基于小林coding的优质内容，系统梳理计算机硬件的工作原理和架构发展脉络。</summary>
    
    
    
    <category term="技术" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="计算机基础" scheme="https://freshwlnd.github.io/categories/%E6%8A%80%E6%9C%AF/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="操作系统" scheme="https://freshwlnd.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="计算机架构" scheme="https://freshwlnd.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%9E%B6%E6%9E%84/"/>
    
    <category term="CPU" scheme="https://freshwlnd.github.io/tags/CPU/"/>
    
    <category term="硬件原理" scheme="https://freshwlnd.github.io/tags/%E7%A1%AC%E4%BB%B6%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
</feed>
