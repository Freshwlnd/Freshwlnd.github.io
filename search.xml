<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>【网络】前向纠错FEC技术</title>
    <url>/2025/05/15/Forward-Error-Correction/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>前向纠错（Forward Error Correction, FEC）是一种通过在数据中增加冗余信息来提升通信可靠性的技术。本文将介绍FEC的基本原理、常见类型（D-FEC与A-FEC）、典型应用场景，并结合实际网络环境分析其优势与局限性，帮助读者全面理解FEC在现代网络中的作用。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><p>在调研RoCE（RDMA over Converged Ethernet）环境下的丢包恢复机制时，发现传统网络领域已经广泛应用前向纠错（FEC）技术来提升数据传输的可靠性。为此，本文对FEC相关技术进行了系统梳理和总结，旨在为高可靠性网络设计提供参考。</p>
<h1 id="🧠整理"><a href="#🧠整理" class="headerlink" title="🧠整理"></a>🧠整理</h1><h2 id="FEC-前向纠错-1"><a href="#FEC-前向纠错-1" class="headerlink" title="FEC 前向纠错[1]"></a>FEC 前向纠错<a href="#refer-anchor-1"><sup>[1]</sup></a></h2><h3 id="简介："><a href="#简介：" class="headerlink" title="简介："></a>简介：</h3><ul>
<li>前向纠错（Forward Error Correction，简称FEC）是一种增加数据通讯可信度的数据编码技术，通过流分类识别指定数据流，为其增加携带校验信息的冗余包，如果网络中出现了报文丢失或者报文损伤，则通过冗余包还原报文。<br>简单地说，FEC通过传输冗余包，包损坏丢失时支持直接恢复，避免重传</li>
<li>适合带宽高、重传代价高场景，如实时通讯和高误码率的通讯环境。</li>
</ul>
<h3 id="实现："><a href="#实现：" class="headerlink" title="实现："></a>实现：</h3><p>如下图所示，FEC优化技术按照以下流程：</p>
<ol>
<li>发起端接收流量报文，识别出需要进行抗丢包优化的指定数据流；  </li>
<li>发起端基于数据流的原始包，按照算法编码（如XOR编码、RS编码）生成冗余包；  </li>
</ol>
<ul>
<li>发起端的CPE（Customer Premise Equipment，指移动信号接入设备）对原始包封装FEC私有头。  </li>
<li>发起端的CPE对一批原始包进行FEC编码，生成FEC冗余包。  <ul>
<li>发起端可以根据编码矩阵（即生成矩阵）算法对多个原始包生成多个冗余包。  </li>
</ul>
</li>
</ul>
<ol start="3">
<li>将原始包与冗余包一起发出。网络情况较差时，报文和冗余包都可能出现丢失。  </li>
<li>接收端的CPE对接收到的原始包和冗余包进行FEC解码。  </li>
</ol>
<ul>
<li>接收端CPE从网络收包，检测丢包信息，进行FEC解码。  <ul>
<li>根据编码矩阵和实际收到的包计算出解码矩阵（即还原矩阵），根据解码矩阵和收到的包解码出丢失的原包。  </li>
<li>只要一个编码块中的丢包数不超过冗余包数量，就可以恢复该编码块中的丢包。  </li>
</ul>
</li>
<li>接收端CPE解码完成后，恢复丢包，剥掉私有头。  </li>
</ul>
<ol start="5">
<li>接收端的CPE把恢复后的包按顺序发给接收端的其他设备。<br>对于每次编解码，会以包为单位进行丢包检测与恢复。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://info.support.huawei.com/hedex/api/pages/EDOC1100413637/FZN1022J/01/resources/zh-cn_image_0000001391152334.png" alt="图1"><figcaption>图1</figcaption></figure><br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://info.support.huawei.com/hedex/api/pages/EDOC1100413637/FZN1022J/01/resources/zh-cn_image_0000001458071557.png" alt="图2"><figcaption>图2</figcaption></figure></li>
</ol>
<h3 id="分类："><a href="#分类：" class="headerlink" title="分类："></a>分类：</h3><p>FEC有两种，分别为Determined FEC（D-FEC）和Adaptive FEC（A-FEC）</p>
<ul>
<li>D-FEC（Determined FEC，固定冗余率 FEC）：按固定的丢包率生成冗余报文。</li>
<li>A-FEC（Adaptive FEC，自适应 FEC）：根据解码侧返回的丢包信息动态生成冗余报文。</li>
</ul>
<h2 id="D-FEC-固定-静态-前向纠错-1"><a href="#D-FEC-固定-静态-前向纠错-1" class="headerlink" title="D-FEC 固定/静态 前向纠错[1]"></a>D-FEC 固定/静态 前向纠错<a href="#refer-anchor-1"><sup>[1]</sup></a></h2><h3 id="简介：-1"><a href="#简介：-1" class="headerlink" title="简介："></a>简介：</h3><ul>
<li>在FEC技术的基础上，D-FEC按固定的丢包率生成冗余报文，冗余包数量不变。</li>
</ul>
<h3 id="分析："><a href="#分析：" class="headerlink" title="分析："></a>分析：</h3><ul>
<li>优点：机制简明，实现简单</li>
<li>缺点：<ol>
<li>浪费带宽 </li>
</ol>
<ul>
<li>固定的丢包率无法动态调整，在实际网络丢包率低的时候，冗余校验包往往造成带宽的浪费。尤其在网络出现拥塞的时候，增加过多的冗余校验包会进一步加剧网络负担，对其他业务带来影响。  </li>
</ul>
<ol start="2">
<li>不足以恢复丢包 </li>
</ol>
<ul>
<li>当实际网络丢包率异常增高，并大于手动配置的固定丢包率，会使得短时间内产生的FEC冗余校验包数量不足，无法恢复丢包。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://info.support.huawei.com/hedex/api/pages/EDOC1100413637/FZN1022J/01/resources/zh-cn_image_0000001391311918.png" alt="图3"><figcaption>图3</figcaption></figure></li>
</ul>
</li>
</ul>
<h3 id="应用场景："><a href="#应用场景：" class="headerlink" title="应用场景："></a>应用场景：</h3><ul>
<li>当网络带宽充足、不怕浪费，但是网络质量差、丢包率变化波动大时，优先选择D-FEC。</li>
</ul>
<h2 id="A-FEC-自适应-动态-前向纠错-1-5"><a href="#A-FEC-自适应-动态-前向纠错-1-5" class="headerlink" title="A-FEC 自适应/动态 前向纠错[1,5]"></a>A-FEC 自适应/动态 前向纠错<a href="#refer-anchor-1"><sup>[1,5]</sup></a></h2><h3 id="简介：-2"><a href="#简介：-2" class="headerlink" title="简介："></a>简介：</h3><ul>
<li>A-FEC是对D-FEC的改进，改进了D-FEC浪费带宽和实际网络丢包率过高时不能恢复丢包的问题。</li>
<li>如下图，A-FEC可以检测网络中的报文丢失情况，自动调整FEC冗余率，从而实现：<ul>
<li>在丢包率低的时候节约带宽。</li>
<li>在丢包率高的时候保证恢复能力。通过适应性地提高冗余率，以抵消网络报文丢失造成的影响。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://info.support.huawei.com/hedex/api/pages/EDOC1100413637/FZN1022J/01/resources/zh-cn_image_0000001441311989.png" alt="图4"><figcaption>图4</figcaption></figure></li>
</ul>
</li>
</ul>
<h3 id="实现：-1"><a href="#实现：-1" class="headerlink" title="实现："></a>实现：</h3><p>如下图所示，A-FEC优化技术按照以下流程，在简单FEC的基础上额外增加第6、7步骤以自适应动态调整冗余率：</p>
<ol>
<li>发起端接收流量报文，识别出需要进行抗丢包优化的指定数据流；</li>
<li>发起端基于数据流的原始包，按照算法编码（如XOR编码、RS编码）生成冗余包；</li>
</ol>
<ul>
<li>发起端的CPE（Customer Premise Equipment，指移动信号接入设备）对原始包封装FEC私有头。</li>
<li>发起端的CPE对一批原始包进行FEC编码，生成FEC冗余包。<ul>
<li>发起端可以根据编码矩阵（即生成矩阵）算法对多个原始包生成多个冗余包。</li>
</ul>
</li>
</ul>
<ol start="3">
<li>将原始包与冗余包一起发出。网络情况较差时，报文和冗余包都可能出现丢失。</li>
<li>接收端的CPE对接收到的原始包和冗余包进行FEC解码。</li>
</ol>
<ul>
<li>接收端CPE从网络收包，检测丢包信息，进行FEC解码。<ul>
<li>根据编码矩阵和实际收到的包计算出解码矩阵（即还原矩阵），根据解码矩阵和收到的包解码出丢失的原包。</li>
<li>只要一个编码块中的丢包数不超过冗余包数量，就可以恢复该编码块中的丢包。</li>
</ul>
</li>
<li>接收端CPE解码完成后，恢复丢包，剥掉私有头。</li>
</ul>
<ol start="5">
<li>接收端的CPE把恢复后的包按顺序发给接收端的其他设备。</li>
<li>接收端的CPE实时统计丢包信息反馈给发起端的CPE。</li>
<li>发起端的CPE对接收的丢包信息进行处理。 </li>
</ol>
<ul>
<li>根据丢包信息计算出所需冗余率。<ul>
<li>计算冗余率时，可采用三种方式：（参考开源工具WebRTC (Web Real-Time Communications)<a href="#refer-anchor-1"><sup>[6]</sup></a>）<ul>
<li> a.使用当前丢包率。</li>
<li> b.使用一阶指数平滑算法，拟合一阶线性函数，预测丢包率。</li>
<li> c.使用一段窗口期内的最大丢包率。</li>
</ul>
</li>
</ul>
</li>
<li>根据所需冗余率，计算出下次数据传输所需冗余包数量。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://download.huawei.com/mdl/image/download?uuid=6eb2e9dc6d434d57bec03240f02e844f" alt="图5"><figcaption>图5</figcaption></figure></li>
</ul>
<h3 id="分析：-1"><a href="#分析：-1" class="headerlink" title="分析："></a>分析：</h3><ul>
<li>优点：自适应调控，节约带宽的同时保障恢复能力。</li>
<li>缺点：实现复杂，响应偏慢。</li>
</ul>
<h3 id="应用场景：-1"><a href="#应用场景：-1" class="headerlink" title="应用场景："></a>应用场景：</h3><ul>
<li>当网络带宽不足，网络质量差，但是丢包率不剧烈波动的网络，优先选择A-FEC。</li>
</ul>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><ul>
<li><p>RoCE通常在DC内使用，当扩展到DC间或其它不稳定网络（例如无线网络）时，传统重传方案可能不太适用（每次重传都要付出巨大代价），此时使用修复/恢复技术会是一个好的选择（已有论文考虑相关内容<a href="#refer-anchor-1"><sup>[12]</sup></a>）。当然，暂时还没看到业界到底如何实践，也不确定应用于真实场景是否会出现额外问题。</p>
</li>
<li><p>对于FEC的具体分类，D-FEC和A-FEC各有优劣，实际应用中需结合网络带宽、丢包率波动等因素灵活选用。</p>
</li>
<li><p>此外，FEC的引入虽然提升了可靠性，但也带来了实现复杂度和带宽开销的权衡，后续可进一步关注其在新型网络架构中的优化与演进。</p>
</li>
<li><p>此外，华为的文档总结得非常清晰，感恩！</p>
</li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>


<h2 id="【FEC基础介绍】"><a href="#【FEC基础介绍】" class="headerlink" title="【FEC基础介绍】"></a>【FEC基础介绍】</h2><p><a class="link" href="https://info.support.huawei.com/hedex/api/pages/EDOC1100413637/FZN1022J/01/resources/zh-cn_topic_0000001441471753.html">[1] 华为，《FEC技术》，https://info.support.huawei.com/hedex/api/pages/EDOC1100413637/FZN1022J/01/resources/zh-cn_topic_0000001441471753.html<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link" href="https://zhuanlan.zhihu.com/p/695187928">[2] 深圳领存技术有限公司，《什么是向前纠错码（FEC）》，https://zhuanlan.zhihu.com/p/695187928<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link" href="https://zh.wikipedia.org/zh-hans/%E5%89%8D%E5%90%91%E9%8C%AF%E8%AA%A4%E6%9B%B4%E6%AD%A3">[3] 维基百科，《前向纠错》，https://zh.wikipedia.org/zh-hans/前向錯誤更正<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h2 id="【FEC数学分析】"><a href="#【FEC数学分析】" class="headerlink" title="【FEC数学分析】"></a>【FEC数学分析】</h2><p><a class="link" href="https://blog.csdn.net/u010178611/article/details/82656838">[4] CSDN，《FEC算法数学推导》，https://blog.csdn.net/u010178611/article/details/82656838<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h2 id="【动态FEC介绍】"><a href="#【动态FEC介绍】" class="headerlink" title="【动态FEC介绍】"></a>【动态FEC介绍】</h2><p><a class="link" href="https://info.support.huawei.com/info-finder/encyclopedia/zh/%E8%87%AA%E9%80%82%E5%BA%94%E5%89%8D%E5%90%91%E7%BA%A0%E9%94%99.html">[5] 华为，《什么是A-FEC？》，https://info.support.huawei.com/info-finder/encyclopedia/zh/自适应前向纠错.html<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link" href="https://blog.csdn.net/CrystalShaw/article/details/103183607">[6] CSDN，《webrtc QOS方法二.3（FEC冗余度配置）》，https://blog.csdn.net/CrystalShaw/article/details/103183607<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h2 id="【FEC实现】"><a href="#【FEC实现】" class="headerlink" title="【FEC实现】"></a>【FEC实现】</h2><p><a class="link" href="https://blog.csdn.net/CrystalShaw/article/details/103183607">[6] CSDN，《webrtc QOS方法二.3（FEC冗余度配置）》，https://blog.csdn.net/CrystalShaw/article/details/103183607<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link" href="https://github.com/xtaci/kcptun/issues/376">[7] Github-kcptun，《动态fec 支持》，https://github.com/xtaci/kcptun/issues/376<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link" href="https://zhuanlan.zhihu.com/p/445235472">[8] 知乎，《前向纠错技术（FEC）的测试和验证》，https://zhuanlan.zhihu.com/p/445235472<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link" href="https://blog.csdn.net/qw225967/article/details/123405797">[9] CSDN，《流媒体弱网优化之路(FEC)——FEC的应用奥秘（附demo）》，https://blog.csdn.net/qw225967/article/details/123405797<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link" href="https://blog.csdn.net/m0_46213128/article/details/133885883">[10] CSDN，《FEC(forward error correction) 前向纠错算法库函数解析》，https://blog.csdn.net/m0_46213128/article/details/133885883<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link" href="https://patents.google.com/patent/CN106656422A/zh">[11] 专利CN106656422A，《一种动态调整fec冗余度的流媒体传输方法》，https://patents.google.com/patent/CN106656422A/zh<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h2 id="【其它】"><a href="#【其它】" class="headerlink" title="【其它】"></a>【其它】</h2><p><a class="link" href="https://ieeexplore.ieee.org/abstract/document/10682853">[12] T. Zuo et al., “LoWAR: Enhancing RDMA over Lossy WANs with Transparent Error Correction,” 2024 IEEE/ACM 32nd International Symposium on Quality of Service (IWQoS), Guangzhou, China, 2024, pp. 1-10, doi: 10.1109/IWQoS61813.2024.10682853.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>业界现状</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>纠错</tag>
        <tag>RoCE</tag>
      </tags>
  </entry>
  <entry>
    <title>【学术】文献管理与文献阅读经验总结</title>
    <url>/2023/12/05/academic-literature/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><ul>
<li>本文总结了所搜集到的文献管理与文献阅读经验。先分析了目标，再列举了相关工具。</li>
</ul>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><ul>
<li>近期阅读论文时总觉得读完后内容不过脑子，左眼进右眼出。于是决定通过调研学习一下前辈们对文献管理、文献阅读的经验。</li>
<li>对于文献管理与文献阅读，有以下几个问题：<ul>
<li>1）文献管理的目的是什么？</li>
<li>2）文献阅读的目的是什么？阅读过程中应该关注的是什么？</li>
<li>3）有哪些工具能实现以上两方面需求？有什么优劣势？</li>
</ul>
</li>
</ul>
<h1 id="🧠目标"><a href="#🧠目标" class="headerlink" title="🧠目标"></a>🧠目标</h1><h2 id="📚文献管理"><a href="#📚文献管理" class="headerlink" title="📚文献管理"></a>📚文献管理</h2><p>根据毕导的说法<a href="#refer-anchor-1"><sup>[1]</sup></a>：</p>
<ol>
<li>高效组织你下载的文献，让软件帮你过目不忘</li>
<li>大幅提升读文献的篇数和速度</li>
<li>写论文时引用文献极其方便</li>
<li>让导师觉得你很努力很内行</li>
</ol>
<h2 id="🏫文献阅读"><a href="#🏫文献阅读" class="headerlink" title="🏫文献阅读"></a>🏫文献阅读</h2><ol>
<li>理解文章内容</li>
<li>归纳领域问题</li>
<li>归纳领域现状边界</li>
</ol>
<h1 id="🔨工具"><a href="#🔨工具" class="headerlink" title="🔨工具"></a>🔨工具</h1><h2 id="📚文献管理-1"><a href="#📚文献管理-1" class="headerlink" title="📚文献管理"></a>📚文献管理</h2><ul>
<li>文献管理工具：Zotero<a href="#refer-anchor-1"><sup>[1]</sup></a>。Zotero具有高自由度和良好的生态环境，让Zotero社区开发了许多实用的插件。</li>
</ul>
<p>对于前文分析的目标，除了使用 Zotero 等工具快速将论文导入数据库外，更重要的应当是<strong>分类</strong>的方法。<br>说是<strong>分类</strong>，但其实是为了对文献进行恰当地存储，从而便于深刻地记忆并快速查找。根据 flomo 的思想<a href="#refer-anchor-2"><sup>[2]</sup></a>，“如何分类文献”的本质是“如何组织信息”。<br>目前使用的分类方法有两个维度：</p>
<ol>
<li>按阅读进度：待略读（题目摘要相关）；待精读（题目摘要引言相关）；已精读（全文相关）。</li>
<li>按内容领域。</li>
</ol>
<h2 id="🏫文献阅读-1"><a href="#🏫文献阅读-1" class="headerlink" title="🏫文献阅读"></a>🏫文献阅读</h2><ul>
<li>三人格分裂（费曼学习法）<a href="#refer-anchor-3"><sup>[3]</sup></a>：<ul>
<li>将自己分裂为三个角色：作者、自己、师兄弟姐妹/导师</li>
<li>1）作者-自己：<ul>
<li>阅读的过程是一场“teach yourself”。想象作者正在通过一场讲座向你传达他所发现的问题及方法，时不时切换到作者的角度思考他为什么这么写。</li>
</ul>
</li>
<li>2）自己-师兄弟姐妹/导师：<ul>
<li>在不看论文的前提下复盘，想象正在向师兄弟姐妹/导师们介绍这篇论文。找到作者角度逻辑之外的“唐突的”“缺失的”步骤。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="🏥其他待阅读"><a href="#🏥其他待阅读" class="headerlink" title="🏥其他待阅读"></a>🏥其他待阅读</h1><ol>
<li>知乎答主<a href="#refer-anchor-4"><sup>[4]</sup></a>推荐：b站up主 X_LAB <a href="#refer-anchor-5"><sup>[5]</sup></a>（国家杰青，教授钟澄）论文引用量17000+ 杰青手把手教你阅读与整理文献。</li>
<li>借助 GPT 提高文献整理效率<a href="#refer-anchor-6"><sup>[6]</sup></a>。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://www.zhihu.com/question/26857521/answer/2662236762" >[1] 如何高效管理文献？ - 毕导的回答 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link"   href="https://help.flomoapp.com/thinking/iarp.html" >[2] 如何规划标签？ - flomo101<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link"   href="https://www.zhihu.com/question/549016289/answer/2854114663" >[3] 怎么样保持每天看文献？ - 年华似水的回答 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link"   href="https://www.zhihu.com/question/50973300/answer/3202305715" >[4] 博士生如何进行文献阅读和文献整理？ - 没眼睛的Lip的回答 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-5"></div>

<p><a class="link"   href="https://space.bilibili.com/16532816/" >[5] 钟澄老师XLab的个人空间 - bilibili视频<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-6"></div>

<p><a class="link"   href="https://zhuanlan.zhihu.com/p/625188310" >[6] Zotero GPT 辅助文献阅读方法论 - Sheeper-Xu的文章 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>学术</category>
      </categories>
      <tags>
        <tag>文献管理</tag>
        <tag>工具整理</tag>
      </tags>
  </entry>
  <entry>
    <title>【AI】强化学习入门路径及优质资料</title>
    <url>/2023/12/08/ai-RL-introduction/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>简单总结了学习强化学习的路径以及相关优质资料。</p>
<h1 id="🖼️前置知识——机器学习-深度学习-1"><a href="#🖼️前置知识——机器学习-深度学习-1" class="headerlink" title="🖼️前置知识——机器学习/深度学习[1]"></a>🖼️前置知识——机器学习/深度学习<a href="#refer-anchor-1"><sup>[1]</sup></a></h1><ol>
<li><p>入门推荐台大李宏毅的机器学习课程<a href="#refer-anchor-2"><sup>[2]</sup></a>。<br> <strong>优点</strong>：李宏毅老师讲课风格比较诙谐，内容清晰又不失深度。<br> <strong>缺点</strong>：课时多、涵盖内容种类太多。</p>
</li>
<li><p>吴恩达的机器学习课程<a href="#refer-anchor-3"><sup>[3]</sup></a>。<br> <strong>优点</strong>：讲课清晰，内容紧凑。<br> <strong>缺点</strong>：英文授课，中文字幕有些跳戏。</p>
</li>
</ol>
<ul>
<li>对于深度学习和机器学习有一定理解后，就有了强化学习的基础。</li>
</ul>
<h1 id="🧠基础知识——强化学习-1-4-5"><a href="#🧠基础知识——强化学习-1-4-5" class="headerlink" title="🧠基础知识——强化学习[1][4][5]"></a>🧠基础知识——强化学习<a href="#refer-anchor-1"><sup>[1]</sup></a><a href="#refer-anchor-4"><sup>[4]</sup></a><a href="#refer-anchor-5"><sup>[5]</sup></a></h1><ol>
<li><p>先推荐莫凡的强化学习入门视频<a href="#refer-anchor-6"><sup>[6]</sup></a><br> <strong>优点</strong>：课时时间都超短，且附有实现代码，配合代码复现效果更佳。<br> <strong>缺点</strong>：课时过短，很多内容消化不了，容易一知半解。</p>
</li>
<li><p>再推荐一个openai整理的的RL核心论文网站<a href="#refer-anchor-7"><sup>[7]</sup></a></p>
</li>
<li><p>论文看不懂？正常！再结合李宏毅老师的视频理解一波<a href="#refer-anchor-8"><sup>[8]</sup></a></p>
</li>
<li><p>David Silver的课程<a href="#refer-anchor-9"><sup>[9]</sup></a>也非常棒！PPT和授课内容都非常棒。视频可以找到中文版字幕。</p>
</li>
<li><p>内容还是太过零碎化？实体强化学习”圣经“来一本。（《强化学习（第2版）》<a href="#refer-anchor-10"><sup>[10]</sup></a>）</p>
</li>
<li><p>推荐先看看OpenAI Spinning Up<a href="#refer-anchor-11"><sup>[11]</sup></a>，内容较少读得快、且条理比较清晰，后面提到的两个案例库都根据Spinningup的数学符号来写的，方便大家对照代码。</p>
</li>
<li><p>另外几个系统的进阶课程<a href="#refer-anchor-12"><sup>[12]</sup></a><a href="#refer-anchor-13"><sup>[13]</sup></a></p>
</li>
<li><p>王树森老师的课程，讲得很不错<a href="#refer-anchor-14"><sup>[14]</sup></a>。</p>
</li>
<li><p>周博磊老师，也是这个领域非常厉害的老师，课程详细全面<a href="#refer-anchor-15"><sup>[15]</sup></a>。</p>
</li>
</ol>
<h1 id="🔨实践资料——代码库-1-4"><a href="#🔨实践资料——代码库-1-4" class="headerlink" title="🔨实践资料——代码库[1][4]"></a>🔨实践资料——代码库<a href="#refer-anchor-1"><sup>[1]</sup></a><a href="#refer-anchor-4"><sup>[4]</sup></a></h1><p>尝试运行与实现基础算法，可以帮助你更好地理解对应的基础知识，这里有两个相关的RL案例库：</p>
<ol>
<li>一个是面向产品化而提供高层抽象：RLzoo-面向产品化的RL库<a href="#refer-anchor-16"><sup>[16]</sup></a>（会有一些大型RL案例会放到这里）；</li>
<li>另一个是面向科研而提供浅层抽象：TL-面向科研的RL库<a href="#refer-anchor-17"><sup>[17]</sup></a>（有常用RL方法的论文列表）。</li>
</ol>
<p>最后放个大的：Paper with Code<a href="#refer-anchor-18"><sup>[18]</sup></a>。</p>
<ul>
<li>Papers with Code 是一个包含机器学习论文及其代码实现的网站。 大多数论文都是有GitHub代码的，这个网站对机器学习方向做了任务分类，检索对应的论文、数据、代码和精度榜单一目了然。</li>
<li>目前，网站已包含114,474 篇带代码的论文、 11,915 个基准测试、 4,574 个任务、 15,541 个数据集。<blockquote>
<p>Papers with Code 的使命是创建一个免费和开放的资源 机器学习论文、代码、数据集、方法和评估表。<br>The mission of Papers with Code is to create a free and open resource with Machine Learning papers, code, datasets, methods and evaluation tables.</p>
</blockquote>
</li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1">

<p><a class="link"   href="https://www.zhihu.com/question/353476712/answer/883189174" >[1] 求问强化学习的学习路线？ - 盛夏的果核的回答 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-2">

<p><a class="link"   href="https://www.bilibili.com/video/av35932863/?from=search&seid=3183765777770933150" >[2] 机器学习-李宏毅(2019) Machine Learning-bilibili<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-3">

<p><a class="link"   href="https://www.bilibili.com/video/av9912938?from=search&seid=4863540311864515527" >[3] 机器学习（Machine Learning）- 吴恩达（Andrew Ng）-bilibili<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-4">

<p><a class="link"   href="https://www.zhihu.com/question/277325426/answer/767807599" >[4] 强化学习怎么入门好？ - 董豪的回答 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-5">


<p><a class="link"   href="https://www.zhihu.com/question/275906449/answer/2843223015" >[5] 强化学习怎么入门？ - 阿路阿路的回答 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-6">

<p><a class="link"   href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/" >[6] morvanzhou-强化学习视频<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-7">

<p><a class="link"   href="https://spinningup.openai.com/en/latest/spinningup/keypapers.html" >[7] 强化学习-关键性论文<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-8">

<p><a class="link"   href="https://www.bilibili.com/video/av24724071/?p=1" >[8] 李宏毅深度强化学习(国语)课程(2018)-bilibili=<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-9">

<p><a class="link"   href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" >[9] Teaching<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-10">

<p><a class="link"   href="http://product.dangdang.com/27926613.html" >[10] 《强化学习（第2版）》（加）Richard S. Sutton（理查德·桑顿）【简介_书评_在线阅读】 - 当当图书<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-11">

<p><a class="link"   href="https://link.zhihu.com/?target=https://spinningup.openai.com/en/latest/" >[11] OpenAI - Spinning Up<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-12">

<p><a class="link"   href="https://link.zhihu.com/?target=https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs" >[12] UCL course: Advanced DL and RL<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-13">

<p><a class="link"   href="https://link.zhihu.com/?target=https://katefvision.github.io/" >[13] Deep RL and Control<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-14">

<p><a class="link"   href="https://search.bilibili.com/all?vt=76593277&keyword=%E7%8E%8B%E6%A0%91%E6%A3%AE%20%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0&from_source=webtop_search&spm_id_from=333.1007&search_source=5" >[14] 强化学习课程-王树森-bilibili<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-15">

<p><a class="link"   href="https://www.bilibili.com/video/BV1LE411G7Xj/?spm_id_from=333.337.search-card.all.click" >[15] 强化学习课程-周博磊-bilibili<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-16">

<p><a class="link"   href="https://link.zhihu.com/?target=https://github.com/tensorlayer/RLzoo" >[16] RLzoo：面向产品化的RL库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-17">

<p><a class="link"   href="https://link.zhihu.com/?target=https://github.com/tensorlayer/tensorlayer/tree/master/examples/reinforcement_learning" >[17] TL：面向科研的RL库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-18">

<p><a class="link"   href="https://paperswithcode.com/" >[18] Paper with Code<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>
]]></content>
      <categories>
        <category>技术</category>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【容灾】容灾、高可用以及单元化简介</title>
    <url>/2025/03/27/fault-tolerance/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>最近在调研业界对于跨地域数据中心利用的需求，正好发现容错是一大需求，于是基于几份材料（主要来自于字节跳动）<a href="#refer-anchor-1"><sup>[1-4]</sup></a>总结业界容灾、高可用以及单元化方案的情况。<br>此外，本篇也已发布于我们团队整理的<a class="link"   href="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/tree/main" >Awesome Cloud<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>。这是一个关于云计算领域中最优质的论文、工具和信息的精选列表，适合开发者和研究人员参考。欢迎大家前来点赞、star和交流。</p>
<h1 id="🧠总结"><a href="#🧠总结" class="headerlink" title="🧠总结"></a>🧠总结</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol start="0">
<li><a href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E5%A3%B0%E6%98%8E">参考文献声明</a></li>
<li><a href="#%E8%83%8C%E6%99%AF%E9%9C%80%E6%B1%82">背景需求</a>  </li>
<li><a href="#%E5%AE%B9%E7%81%BE%E6%BC%94%E8%BF%9B%E8%B7%AF%E7%BA%BF">容灾演进路线</a>  </li>
<li><a href="#%E5%AE%B9%E7%81%BE%E5%AE%9E%E8%B7%B5%E6%A1%88%E4%BE%8B">容灾实践案例</a>  </li>
<li><a href="#%E5%8D%95%E5%85%83%E5%8C%96%E6%96%B9%E6%A1%88">单元化方案</a>  </li>
<li><a href="#%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91">未来方向</a>  </li>
</ol>
<h2 id="1-背景需求"><a href="#1-背景需求" class="headerlink" title="1. 背景需求 "></a>1. 背景需求 <a id="背景需求"></a></h2><ul>
<li><strong>容灾定义</strong>：  <ul>
<li>广义的容灾，可以认为是业务连续性计划当中的灾难恢复的能力，即能够容忍灾难的能力。</li>
<li>如何在灾难发生时，保证生产业务系统的不间断运行，需要我们健全快速容错 / 故障切换能力，即容灾能力，包含了常态化容灾建设以及针对能力进行的周期性演练验收。</li>
</ul>
</li>
<li>系统可用性定义及示意图<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-1.jpg?raw=true"
                      alt="系统可用性定义"
                ><figcaption>系统可用性定义</figcaption></figure><br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-2.jpg?raw=true"
                      alt="系统可用性示意图"
                ><figcaption>系统可用性示意图</figcaption></figure><br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-3.jpg?raw=true"
                      alt="系统可用性表"
                ><figcaption>系统可用性表</figcaption></figure></li>
</ul>
<hr>
<h2 id="2-容灾演进路线"><a href="#2-容灾演进路线" class="headerlink" title="2. 容灾演进路线 "></a>2. 容灾演进路线 <a id="容灾演进路线"></a></h2><h3 id="趋势"><a href="#趋势" class="headerlink" title="趋势"></a>趋势</h3><ul>
<li>单机房→多机房</li>
<li>单地域→多地域</li>
<li>单机→灾备(副本不干活)→多活(副本也干活)<br>目前，业界内一些领先的大公司已经实现了相当成熟的异地多活部署模式。<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-4.jpg?raw=true"
                      alt="系统演进趋势"
                ><figcaption>系统演进趋势</figcaption></figure></li>
</ul>
<h3 id="关键要素"><a href="#关键要素" class="headerlink" title="关键要素"></a>关键要素</h3><p>容灾建设需关注 <strong>资源</strong>、<strong>流量</strong>、<strong>数据</strong> 三要素：  </p>
<ol>
<li><p>容灾建设强依赖于<strong>资源</strong>评估。</p>
<ul>
<li>首要任务是评估资源容量是否充足，进一步需要判断是同城资源不足，还是异地资源不足。</li>
</ul>
</li>
<li><p>基于资源评估，再考虑<strong>流量</strong>。</p>
<ul>
<li>是否可切换，能切换多少；</li>
<li>如果资源不足，则需要决定哪些业务或服务需要降级。</li>
</ul>
</li>
<li><p><strong>数据</strong>的恢复也是一个不可忽视的问题。</p>
<ul>
<li>灾难场景下的逃逸通常会导致一定的数据损失，如何修复数据是必须重点关注的问题。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="3-容灾实践案例"><a href="#3-容灾实践案例" class="headerlink" title="3. 容灾实践案例 "></a>3. 容灾实践案例 <a id="容灾实践案例"></a></h2><h3 id="3-1-传统单机房"><a href="#3-1-传统单机房" class="headerlink" title="3.1 传统单机房"></a>3.1 传统单机房</h3><h4 id="a-单机架构"><a href="#a-单机架构" class="headerlink" title="a. 单机架构"></a>a. 单机架构</h4><ul>
<li><strong>单机</strong>：<ul>
<li>缺点：只要出现单点故障（磁盘损坏、OS异常、误删数据等）就很容易导致数据全丢失。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-5.jpg?raw=true"
                     
                ></li>
</ul>
</li>
</ul>
<h4 id="b-机房内主从副本"><a href="#b-机房内主从副本" class="headerlink" title="b. 机房内主从副本"></a>b. 机房内主从副本</h4><ul>
<li><strong>冷备（仅数据）</strong>：定期备份<ul>
<li>缺点：恢复时间长、数据完整性低。<ul>
<li>恢复需要较多时间造成恢复期间不可用。</li>
<li>备份的数据完整性较低（不是最新的）。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-6.jpg?raw=true"
                     
                ></li>
</ul>
</li>
</ul>
</li>
<li><strong>机房内主从副本（热备）</strong>：数据库主备<ul>
<li>缺点：同机房冗余，无法应对机房级故障。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-7.jpg?raw=true"
                     
                ></li>
</ul>
</li>
</ul>
<h4 id="不足：字节案例（2018年）："><a href="#不足：字节案例（2018年）：" class="headerlink" title="不足：字节案例（2018年）："></a>不足：<strong>字节案例（2018年）</strong>：</h4><ul>
<li>业务快速发展导致资源瓶颈，物理机房容量不足。<ul>
<li>到了 2018 年，随着商业化加速，业务的快速发展带来了一个重大问题：资源瓶颈。</li>
<li>因为物理机房的容量是有限的，无法满足业务的快速增长。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-8.jpg?raw=true"
                     
                ></li>
</ul>
</li>
</ul>
<h3 id="3-2-同城双机房"><a href="#3-2-同城双机房" class="headerlink" title="3.2 同城双机房"></a>3.2 同城双机房</h3><h4 id="a-同城灾备"><a href="#a-同城灾备" class="headerlink" title="a. 同城灾备"></a>a. 同城灾备</h4><ul>
<li><strong>冷备（仅数据）</strong>：定期备份<ul>
<li>缺点：同传统单机房。  <ul>
<li>恢复需要较多时间造成恢复期间不可用。</li>
<li>备份的数据完整性较低（不是最新的）。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-9.jpg?raw=true"
                     
                ></li>
</ul>
</li>
</ul>
</li>
<li><strong>热备（全部备份）</strong>：机房镜像<ul>
<li>从机房是主机房的镜像，只有在主机房发生故障不可用后才会接管流量对外提供服务。</li>
<li>缺点：资源浪费、故障恢复时间长、灾备机房可靠性低（日常无法校验）。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-10.jpg?raw=true"
                     
                ><h4 id="b-同城双活"><a href="#b-同城双活" class="headerlink" title="b. 同城双活"></a>b. 同城双活</h4></li>
</ul>
</li>
<li><strong>同城双活（DNS 流量转发）</strong>：  <ul>
<li>两机房同时服务。<ul>
<li>DNS转发流量，业务层各自工作，数据层使用主备模式。</li>
</ul>
</li>
<li>缺点：无法应对城市级灾害（如地震）。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-11.jpg?raw=true"
                     
                ></li>
</ul>
</li>
</ul>
<h4 id="不足：字节案例："><a href="#不足：字节案例：" class="headerlink" title="不足：字节案例："></a>不足：<strong>字节案例</strong>：</h4><ul>
<li>双机房解决资源与单点故障，但无法应对城市级灾害（控制面未独立部署、资源不足）。  <ul>
<li>这种模式在一定程度上解决了资源问题和单点故障问题，但无法应对城市级灾害（机房故障or专线故障）：<ul>
<li>一方面是控制面没有独立部署，导致在单个机房出现问题或专线中断时，容灾指令无法正常下发；</li>
<li>另一方面双机房最初只为解决业务发展需求，并没有进行相应的容灾冗余部署，需要做机房切流时没有足够的资源支撑。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-12.jpg?raw=true"
                     
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-13.jpg?raw=true"
                     
                ></li>
</ul>
</li>
</ul>
</li>
<li>启发：业界实际场景需预留资源，所设计算法需兼顾日常性能和突发情况性能。</li>
</ul>
<h3 id="3-3-同城多机房"><a href="#3-3-同城多机房" class="headerlink" title="3.3 同城多机房"></a>3.3 同城多机房</h3><ul>
<li><strong>优化方案</strong>：业务分散部署，IDC 全互联降低专线中断影响。控制面与数据面分离，支持指令正常下发。<ul>
<li>资源/业务：增加机房数量，将不同业务的Master分散部署。</li>
<li>网络：采用了 IDC 全互联的方式，大大降低单专线中断情况下对业务的影响。</li>
<li>管理：控制面和数据面分离，即使IDC出现问题，指令仍然可以正常下发。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-14.jpg?raw=true"
                     
                ></li>
</ul>
</li>
</ul>
<p>能够很好应对两个主要的容灾场景：专线中断和 AZ 不可用。</p>
<ul>
<li><strong>分层降级策略</strong>：优先降低离线业务，再按预设优先级降低在线业务，会考虑到组件、集群、业务功能等复杂维度。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-15.jpg?raw=true"
                     
                ></li>
</ul>
<h3 id="3-4-异地多活"><a href="#3-4-异地多活" class="headerlink" title="3.4 异地多活"></a>3.4 异地多活</h3><h4 id="两地三中心（异地灾备）："><a href="#两地三中心（异地灾备）：" class="headerlink" title="两地三中心（异地灾备）："></a><strong>两地三中心（异地灾备）</strong>：</h4><ul>
<li>同城双活 + 异城一灾备。通常应用在银行、金融、政企项目中。 </li>
<li>缺点：灾备机房利用率低、启用时间长。<ul>
<li>与同城灾备类似，灾备机房利用率低、启用灾备机房需要时间、启用后不确定是否能按预期工作。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-16.jpg?raw=true"
                     
                ><h4 id="异地双活"><a href="#异地双活" class="headerlink" title="异地双活"></a><strong>异地双活</strong></h4></li>
</ul>
</li>
<li>两机房同时服务，机房内应用只访问本机房数据库。</li>
<li>缺点：双主架构需互相实时同步，实施复杂。</li>
<li>解决：业界主要使用 <strong>【单元化】</strong> ，不同机房几乎完全独立，彼此少耦合，只有存储层依赖同步组件互相进行数据同步。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-17.jpg?raw=true"
                     
                ><h4 id="异地多活"><a href="#异地多活" class="headerlink" title="异地多活"></a><strong>异地多活</strong></h4></li>
<li>多机房同时服务。异地双活基础上部署多个机房。可任意扩展新机房，只需在最上层定义清楚请求的分片规则。</li>
<li>缺点：实施复杂、维护成本大。</li>
<li>优点：机房独立，存储层通过同步组件实现数据同步。<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-18.jpg?raw=true"
                      alt="网状"
                ><figcaption>网状</figcaption></figure><br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-19.jpg?raw=true"
                      alt="星状"
                ><figcaption>星状</figcaption></figure></li>
</ul>
<h4 id="不足：字节案例"><a href="#不足：字节案例" class="headerlink" title="不足：字节案例"></a>不足：<strong>字节案例</strong></h4><ul>
<li>华东-华北 RTT &gt;30ms，对强一致性/低延迟业务不可用，但部分业务可适配。  <ul>
<li>在字节跳动的异地建设模式中，经过测算发现，华东到华北之间的网络往返时间（RTT）大于 30 毫秒。</li>
<li>对于那些对数据强一致性要求高或请求响应时间要求高的业务来说不可接受。</li>
<li>但也存在部分特殊业务能够使用特殊方式发挥异地多活优势。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-20.jpg?raw=true"
                     
                ></li>
</ul>
</li>
<li>启发：异构业务混合部署，根据不同特点充分利用资源。</li>
</ul>
<hr>
<h2 id="4-单元化方案"><a href="#4-单元化方案" class="headerlink" title="4. 单元化方案 "></a>4. 单元化方案 <a id="单元化方案"></a></h2><h3 id="4-1-背景需求"><a href="#4-1-背景需求" class="headerlink" title="4.1 背景需求"></a>4.1 背景需求</h3><p>分布式部署业务后，必须关注数据同步问题，因此需要单元化！</p>
<h4 id="推力"><a href="#推力" class="headerlink" title="推力"></a><strong>推力</strong></h4><p>资源限制、合规要求、容灾需求。  </p>
<ul>
<li>由于部分原因<strong>不得不</strong>分布式部署业务：<ul>
<li><strong>资源限制</strong>：单机房受物理资源上限限制，同城多机房受地区的能评和供电等限制，无法做到机房的无限扩展，随着业务规模的扩大，长期一定会面临多地数据中心的布局；</li>
<li><strong>合规要求</strong>：全球化产品通常会面临不同地区的合规要求（例如欧盟的 GDPR），会有当地用户数据只能存储在当地的要求，业务天然需要考虑围绕不同的合规区域构建单元；</li>
<li><strong>容灾考虑</strong>：核心业务有城市级异地容灾需求，通过单元化方式可以构建异地单元，每个单元都有常态真实流量，流量可以灵活地在单元间进行调度。</li>
</ul>
</li>
</ul>
<h4 id="拉力"><a href="#拉力" class="headerlink" title="拉力"></a><strong>拉力</strong></h4><p>用户体验提升（就近调度）、成本优化、风险隔离。</p>
<ul>
<li>由于部分收益<strong>主动</strong>分布式部署业务：<ul>
<li><strong>业务体验提升</strong>：通过结合就近调度，能够将用户流量调度到最近的单元，从而降低请求耗时，提升用户体验；</li>
<li><strong>成本优化</strong>：相比于异地冷备，两地三中心等传统容灾架构，分布式业务各个单元都能直接承载流量，减少资源冗余；</li>
<li><strong>隔离控制</strong>：在最小的单元范围内去做各种技术演进，能够有效控制风险半径。</li>
</ul>
</li>
</ul>
<h3 id="4-2-方法"><a href="#4-2-方法" class="headerlink" title="4.2 方法"></a>4.2 方法</h3><ul>
<li><strong>核心理念</strong>：按维度划分业务单元，单元内自包含。  <ul>
<li>将业务按照某种维度划分成一个个单元，理想情况下每个单元内部都是完成所有业务操作的自包含集合，能独立处理业务流程。</li>
</ul>
</li>
<li><strong>数据同步</strong>：各单元存储部分数据，整体组合为完整数据集。  <ul>
<li>各个单元均有其中一部分数据，所有单元的数据组合起来是完整的数据（各企业实际落地过程中会结合实际业务和基建情况做一些折中）。</li>
</ul>
</li>
<li><strong>流量管理</strong>：按分区（如用户 ID）Sharding 到对应单元。  <ul>
<li>流量按照某种分区维度（例如流量所属用户）Sharding 到不同的单元，调度上按照流量携带的分区信息进行调度，保证同一时刻该分区的数据写入都在同一个单元。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-10-21.jpg?raw=true"
                     
                ></li>
</ul>
</li>
</ul>
<h3 id="4-3-挑战"><a href="#4-3-挑战" class="headerlink" title="4.3 挑战"></a>4.3 挑战</h3><ul>
<li><strong>流量路由</strong>：需解决请求链路环节的单元识别与纠偏。  <ul>
<li>如何将流量调度到正确的单元问题。需要考虑在请求链路哪个环节（客户端、流量入口、内网 RPC、存储层等）、根据请求什么信息（用户 ID、地理位置等）进行用户归属单元的识别，以及如何进行走错单元流量的纠偏。</li>
</ul>
</li>
<li><strong>数据正确性</strong>：同步延迟导致的问题（如用户跨单元操作后的数据不一致）。  <ul>
<li>业务上需要感知同步延迟带来的正确性问题。<ul>
<li>例如归属单元1的用户A评论了归属单元2的用户B的抖音短视频，系统在单元1给B发了一个通知。</li>
<li>但B查看评论的流量被按B的单元归属调度到了单元2，由于数据同步延迟问题，B打开抖音后看不到评论。</li>
</ul>
</li>
</ul>
</li>
<li>启发：调度部署相关研究中较少看到对具有“单元化”特点应用的管理，可以进一步探讨。</li>
</ul>
<hr>
<h2 id="5-未来方向"><a href="#5-未来方向" class="headerlink" title="5. 未来方向 "></a>5. 未来方向 <a id="未来方向"></a></h2><ul>
<li>多Region成本优化：异构业务混合部署，优化资源利用。  <ul>
<li>全局视角：字节跳动从原本的单 Region 内同城容灾架构演进到多 Region 异地单元化架构周期比较短（截至2024-11-12，一年半左右），基础设施对多 Region 视角的支持还比较不足，对业务的整体研发和业务管理成本偏高，需要将多 Region 的研发和业务管理成本打平到单 Region。</li>
<li>从计算资源成本视角：在原来三机房同城容灾模式下，每个机房需要预留 50% 的 Buffer 用于机房故障容灾，演进到异地单元化架构后，基于两个容灾单元间的六个机房，部分业务机房故障可以将流量分摊到其他五个机房，此时各机房仅需 20% 的 Buffer。</li>
<li>从存储资源成本视角：在同城容灾+异地多活容灾模式下，各单元都支持同城容灾，部分业务可以直接进行数据的单元化拆分，单元内各自只有一部分数据（加起来是全量数据），理想情况下存储成本减少一半。</li>
</ul>
</li>
<li>数据多活管理优化：单元化应用的调度与管理研究。  <ul>
<li>字节跳动目前的存储对 AP 场景更友好（侧重抖音这种社交类场景，系统优先保证高可用性和容错性，对一致性要求可以适当降低），主要围绕单 Region 构建。</li>
<li>在多单元场景下对于电商、支付类（对数据一致要求非常高）的业务支持较弱。异地单元化架构下，多单元数据多活强依赖于数据同步能力，导致业务上的限制偏大（例如写只能统一在一个单元），公司对于跨 Region 强一致数据库具有很高的需求。</li>
</ul>
</li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://www.infoq.cn/article/r6NV8uZ6M79rAAuVXVrg?utm_source=related_read&utm_medium=article" >[1]《字节跳动容灾实践：同城容灾 + 异地多活是最好的模式吗？》<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link"   href="https://www.cnblogs.com/z-sm/p/18021567" >[2]《城市级别系统容灾建设方案演进（同城灾备、同城双活、两地三中心、异地双活、异地多活）》<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link"   href="https://www.infoq.cn/article/itqowhjhw23s5yhyyg5v" >[3]《单元化架构在字节跳动的落地实践》<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link"   href="https://blog.csdn.net/Nick_Liux/article/details/129627121" >[4]《16.系统高可用说明》<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>业界现状</category>
      </categories>
      <tags>
        <tag>容灾</tag>
        <tag>高可用</tag>
        <tag>单元化</tag>
      </tags>
  </entry>
  <entry>
    <title>【SSH】ssh通过跳板机免密登录</title>
    <url>/2025/04/27/ssh-no-password/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在日常运维中，ssh免密登录可以极大地提高效率，避免频繁输入密码的麻烦。本文将分享如何在两台服务器之间实现免密登录，尤其是通过跳板机实现两层转发的免密操作。</p>
<hr>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><p>场景：  </p>
<ul>
<li>有两台服务器，A作为跳板机，B作为主力机（其上有两个用户：<code>root</code> 和 <code>user</code>）。  </li>
<li>本机到A跳板机已实现免密，但每次从A连接到B仍需输入密码，尤其是<code>user</code>用户的免密配置遇到了较多问题。</li>
</ul>
<p>目标：  </p>
<ul>
<li>实现从本机通过A跳板机到B服务器的<code>root</code>和<code>user</code>用户的免密登录。</li>
</ul>
<hr>
<h1 id="🧠思路"><a href="#🧠思路" class="headerlink" title="🧠思路"></a>🧠思路</h1><ol>
<li><strong>基础免密操作</strong>：通过<code>ssh-keygen</code>生成密钥对，并使用<code>ssh-copy-id</code>上传到目标服务器。  </li>
<li><strong>两层转发免密</strong>：将密钥对拷贝到跳板机，在跳板机与目标服务器之间实现免密。  </li>
<li><strong>排查问题</strong>：针对<code>user</code>用户免密失败的问题，逐步排查权限和配置问题。</li>
</ol>
<hr>
<h1 id="🔨解决"><a href="#🔨解决" class="headerlink" title="🔨解决"></a>🔨解决</h1><h2 id="1-基础免密操作"><a href="#1-基础免密操作" class="headerlink" title="1. 基础免密操作"></a>1. 基础免密操作</h2><p>参考：<a class="link" href="https://blog.csdn.net/jeikerxiao/article/details/84105529">CSDN教程<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>步骤：  </p>
<ol>
<li>在本地生成密钥对：  <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure></div></li>
<li>将公钥上传到目标服务器：  <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-copy-id user@A</span><br></pre></td></tr></table></figure></div>

</li>
</ol>
<h2 id="2-两层转发root免密操作"><a href="#2-两层转发root免密操作" class="headerlink" title="2. 两层转发root免密操作"></a>2. 两层转发<code>root</code>免密操作</h2><p>参考：<a class="link" href="https://blog.csdn.net/omaidb/article/details/128400630">CSDN教程<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>步骤：  </p>
<ol>
<li>将本地生成的密钥对拷贝到跳板机A：  <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">scp ~/.ssh/id_rsa* user@A:~/.ssh/</span><br></pre></td></tr></table></figure></div></li>
<li>在跳板机A上，将公钥上传到目标服务器B的<code>root</code>用户：  <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-copy-id root@B</span><br></pre></td></tr></table></figure></div>

</li>
</ol>
<h2 id="3-两层转发user免密操作"><a href="#3-两层转发user免密操作" class="headerlink" title="3. 两层转发user免密操作"></a>3. 两层转发<code>user</code>免密操作</h2><p>参考：<a class="link" href="https://zhuanlan.zhihu.com/p/667251729">知乎教程<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>、<a class="link" href="https://blog.csdn.net/lisongjia123/article/details/78513244">CSDN教程<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>问题：  </p>
<ul>
<li><code>user</code>用户免密失败，最终发现是因为用户目录权限不正确。  </li>
</ul>
<p>解决：  </p>
<ol>
<li>确保<code>user</code>用户的<code>home</code>目录及<code>.ssh</code>文件夹权限正确：  <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chmod</span> 700 /home/user</span><br><span class="line"><span class="built_in">chmod</span> 700 /home/user/.ssh</span><br><span class="line"><span class="built_in">chmod</span> 600 /home/user/.ssh/authorized_keys</span><br><span class="line"><span class="built_in">chown</span> -R user:user /home/user</span><br></pre></td></tr></table></figure></div></li>
<li>再次上传公钥并测试免密登录。</li>
</ol>
<hr>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><ol>
<li><p><strong>分而治之</strong>：<br>将复杂的三级关系（本机 -&gt; A -&gt; B）拆分为两个两级关系（本机 -&gt; A，A -&gt; B），逐步排查问题。  </p>
</li>
<li><p><strong>查看报错技巧</strong>：  </p>
<ul>
<li>客户端：使用<code>ssh -vvv</code>查看连接过程中的详细日志。  </li>
<li>服务端：修改<code>/etc/ssh/sshd_config</code>文件，开启<code>LogLevel DEBUG</code>模式，监控<code>/var/log/messages</code>或<code>/var/log/secure</code>日志。  </li>
</ul>
</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://blog.csdn.net/jeikerxiao/article/details/84105529">[1] CSDN教程 - 基础免密操作<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>  </p>
<div id="refer-anchor-2"></div>

<p><a class="link" href="https://blog.csdn.net/omaidb/article/details/128400630">[2] CSDN教程 - 两层转发root免密<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>  </p>
<div id="refer-anchor-3"></div>

<p><a class="link" href="https://zhuanlan.zhihu.com/p/667251729">[3] 知乎教程 - 两层转发user免密<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>  </p>
<div id="refer-anchor-4"></div>

<p><a class="link" href="https://blog.csdn.net/lisongjia123/article/details/78513244">[4] CSDN教程 - ssh排查技巧<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>  </p>
<div id="refer-anchor-5"></div>

<p><a class="link" href="https://www.cnblogs.com/yjmyzz/p/4481720.html">[5] 博客园 - ssh排查技巧<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>ssh</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>【TestBed】人工智能新技术实验床（泰）简介</title>
    <url>/2023/09/06/testbed/</url>
    <content><![CDATA[<h1 id="实验床（泰）"><a href="#实验床（泰）" class="headerlink" title="实验床（泰）"></a>实验床（泰）</h1><h2 id="💡简介-1"><a href="#💡简介-1" class="headerlink" title="💡简介[1]"></a>💡简介<a href="#refer-anchor-1"><sup>[1]</sup></a></h2><ul>
<li>实验床简介<ul>
<li>能提供芯片和系统等基础环境，是面向研究、开发与应用验证的试验装置。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Freshwlnd/image/blob/blog/testbed_structure.png?raw=true"
                      alt="泰架构"
                ><figcaption>泰架构</figcaption></figure></p>
<ul>
<li><p>实验床具体介绍</p>
<ul>
<li>人工智能新技术实验床（泰）是全球首个大规模开放性AI实验床。该实验床为制定以人工智能为代表的新技术标准提供依据，为验证和展示新技术提供平台，具备大规模复杂场景构建能力，提供新技术实训教育平台和欣秀科教交流工具。</li>
<li>实验床服务<strong>提供多种主流测试环境</strong>，测试环境秒级生成，可提供定制化测试环境，可根据需求提供测试节点或节点集群。在<strong>性能监控</strong>方面提供用户权限隔离、用户行为监控、性能监控和资源调度等。实验床集合了多种State-of-practice的硬件环境，包括不同型号的GPU、CPU、AI智能芯片（寒武纪）、RISC-V云平台等。</li>
</ul>
</li>
<li><p>实验床资源和贡献单位</p>
<ul>
<li>实验床由国际测试委员会（BenchCouncil）联合中科院计算所、国家超算中心深圳中心、俄亥俄州立大学、中科云达、寒武纪、工信部中国软件评测中心、之江实验室、中国开放指令生态(RISC-V)联盟和西安交通大学等国内外单位建设，将由北京尖峰新锐信息科技研究院和国家超算中心深圳中心进行管理维护。 其中，实验床节点分布中国北京、天津、深圳、南京、浙江、新加坡、美国等地，节点内硬件涵盖典型数据中心服务节点、GPU测试群、RISC-V云，以及寒武纪测试节点等。</li>
</ul>
</li>
</ul>
<h2 id="🔨功能"><a href="#🔨功能" class="headerlink" title="🔨功能"></a>🔨功能</h2><ol>
<li>为制定以人工智能为代表的新技术标准提供<strong>依据</strong>，其将客观<strong>评价新技术</strong>，并发布<strong>技术性能榜</strong>，具体包括IoT(端)、Edge(边缘)、数据中心和高性能计算机人工智能评测基准和性能排行榜。（性能排行榜主要面向硬件芯片、系统、软件架构、具体算法，分为硬件赛道、系统赛道、自由赛道）</li>
<li>具备大规模复杂<strong>场景构建</strong>能力，将为验证和展示新技术提供平台。</li>
<li>提供新技术实训教育平台和欣秀科教交流工具，发挥推广和培训新技术、培养人才的作用。</li>
</ol>
<ul>
<li>测试基准与标准市场：对不同领域孵化了一系列基准和工具，也选择、汇总并推荐了一系列有影响力的基准项目。</li>
</ul>
<h2 id="🏞️案例"><a href="#🏞️案例" class="headerlink" title="🏞️案例"></a>🏞️案例</h2><h3 id="1️⃣-大数据基准测试仪：BigDataBench"><a href="#1️⃣-大数据基准测试仪：BigDataBench" class="headerlink" title="1️⃣ 大数据基准测试仪：BigDataBench"></a>1️⃣ 大数据基准测试仪：BigDataBench</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><ul>
<li>提供：<ul>
<li>多种层次（微基准、组件级基准、应用级基准）的<strong>基准测试工具</strong>。</li>
<li>多种基于大数据软件栈实现的<strong>大数据软件系统</strong>。</li>
<li>覆盖多种应用场景，提供多种类型的大数据负载<strong>真实数据集 &amp; 数据生成工具</strong>。</li>
</ul>
</li>
<li>实现：<ul>
<li>硬件、软件、业务系统/算法的定量评测。<ul>
<li>体现系统/算法问题，指导系统/算法设计；对比系统/算法性能，指导系统/算法选型。</li>
</ul>
</li>
<li>简化并标准化大数据基准测试框架开发。</li>
<li>简化并标准化输入数据设计。<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Freshwlnd/image/blob/blog/BigDataBench.png?raw=true"
                      alt="大数据基准测试仪：BigDataBench内容组成"
                ><figcaption>大数据基准测试仪：BigDataBench内容组成</figcaption></figure></li>
</ul>
</li>
</ul>
<h4 id="具体介绍"><a href="#具体介绍" class="headerlink" title="具体介绍"></a>具体介绍</h4><ul>
<li>以大数据的测量、分析、优化为理论基础，实现对于硬件系统、软件系统和业务系统的定量评测。为大数据系统的设计、选型、验收、 扩容、优化提供全生命周期的测试服务。</li>
<li>BigDataBench 负载涵盖搜索引擎、电子商务和社交网络等互联网服务类型，多媒体处理等大数据负载。负载包含 20 多种，且提供主流大数据系统实现。</li>
<li>数据集提供六种真实数据集，覆盖多种数据来源（文本、表、图、图像）和多种数据类型（结构化、非结构化、半结构化）。</li>
<li>同时提供基于真实数据生成的数据生成工具，能够在多种数据源之任意缩放所生成的数据集，并保持重要的种子数据特征。</li>
</ul>
<h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><ol>
<li>通用大数据软件系统的设计和选型</li>
<li>通用大数据硬件系统的设计和选型</li>
<li>特定领域大数据系统和硬件设计和选型</li>
<li>指导大数据算法和系统的优化</li>
<li>大数据算法与系统的科研</li>
<li>大数据评测服务与排名</li>
</ol>
<h3 id="2️⃣-人工智能基准测试仪：AIBench"><a href="#2️⃣-人工智能基准测试仪：AIBench" class="headerlink" title="2️⃣ 人工智能基准测试仪：AIBench"></a>2️⃣ 人工智能基准测试仪：AIBench</h3><h4 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h4><ul>
<li>提供：<ul>
<li>用于细粒度分析和代码优化的<strong>算子级微基准</strong>，用于复杂组件性能和质量评价的<strong>任务组件级基准</strong>。</li>
<li>层次化模块化定制<strong>开发框架</strong>（负载类型、领域定制）。</li>
<li><strong>自动部署 &amp; 分析工具</strong></li>
</ul>
</li>
<li>实现：<ul>
<li>AI 软、硬件系统、算法（训练、推理）的定量测评。<ul>
<li>AI 系统/算法 设计、选型。</li>
</ul>
</li>
<li>简化并标准化 AI 基准测试框架开发。</li>
<li>简化并标准化数据输入。<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Freshwlnd/image/blob/blog/AIBench.png?raw=true"
                      alt="内容组成"
                ><figcaption>内容组成</figcaption></figure></li>
</ul>
</li>
</ul>
<h4 id="具体介绍-1"><a href="#具体介绍-1" class="headerlink" title="具体介绍"></a>具体介绍</h4><ul>
<li>提供一套可定制和扩展的人工智能基准测试框架，采用层次化和模块化的设计，支持定制领域及定制负载的扩展。根据不同的评测需求，该框架支持构建便于细粒度分析和代码优化的人工智能算子级微测试基准，以及便于复杂组件性能和质量评价（如 AI 模型准确度）的任务组件级测试基准。 AIBench 覆盖典型的 AI 处理任务，提供图像/语音/音视频处理等人工智能处理模式和类型。</li>
</ul>
<h4 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h4><ol>
<li>通用 AI 软、硬件系统的设计、选型</li>
<li>AI 加速器的设计、选型</li>
<li>指导 AI 系统的优化</li>
<li>AI 算法与系统的科研研究</li>
<li>AI 训练的评测服务与排名</li>
<li>AI 推理的评测服务与排名</li>
</ol>
<h3 id="3️⃣-场景模拟器：ScenarioSimulator"><a href="#3️⃣-场景模拟器：ScenarioSimulator" class="headerlink" title="3️⃣ 场景模拟器：ScenarioSimulator"></a>3️⃣ 场景模拟器：ScenarioSimulator</h3><h4 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h4><ul>
<li>提供：<ul>
<li>支持复杂场景的快速构建、模拟的组件和框架：<ul>
<li>场景核心抽象，已搭建部分领域模拟和评测系统，定制化场景设置、扩展；</li>
<li>复杂场景支持组件：云边端协同组件、多用户多任务并发模拟组件；</li>
<li>面向异构框架和系统的一键式部署安装组件。</li>
</ul>
</li>
<li>自动化性能分析组件。</li>
</ul>
</li>
<li>实现：<ul>
<li>复杂系统的定量测评。</li>
<li>简化并标准化复杂系统基准测试框架开发。</li>
<li>简化并标准化数据输入。<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Freshwlnd/image/blob/blog/ScenarioSimulator.png?raw=true"
                      alt="内容组成"
                ><figcaption>内容组成</figcaption></figure></li>
</ul>
</li>
</ul>
<h4 id="具体介绍-2"><a href="#具体介绍-2" class="headerlink" title="具体介绍"></a>具体介绍</h4><ul>
<li>基于场景的仿真、测试和验证工具平台，支持大规模复杂场景快速构建和模拟；可以提供工业互联网、军事、医疗等不同领域下的测试验证系统，以及未来应用领域和新兴技术的测试和验证。 其特点如下：<ol>
<li>适应复杂应用场景和未来应用场景的快速模拟和仿真，支持场景的核心抽象，能降低真实应用的复杂性 2-3 个数量级；</li>
<li>支持领域定制的场景扩展，结合用户需求定制化场景服务；</li>
<li>提供工业互联网、医疗等领域的核心场景模拟和评测；</li>
<li>提供云端、边缘端、设备端协同交互的复杂应用场景模拟，如自动驾驶、智能家居等；</li>
<li>一键式部署安装，省去不同框架和系统的熟悉成本，提供安装模版进行一键自动安装；</li>
<li>支持多用户多任务并发模拟，支持真实用户环境的仿真测试和验证；</li>
<li>全生命周期管理，覆盖领域场景的设计、选型、验收、上线的全生命周期；</li>
<li>自动化性能分析，实时分析场景的整体执行性能以及各个子系统和模块的性能，提供复杂场景部署和优化的建议。</li>
</ol>
</li>
<li>完整的真实场景往往涉及到多个子系统、模块以及组件的相互协同，通过执行流和数据流的方式提供在线服务或者离线分析。相比传统的仅基于单一组件级别的测试工具而言，ScenarioSimulator 能够模拟真实的云端、边缘端、设备端以及三者协同处理的多种应用场景，其评测的结果更能反映整体的性能、从而避免传统评测工具下易导致评测误导性的问题，提出更符合真实场景的有效的部署建议和优化结论。</li>
</ul>
<h4 id="应用场景-2"><a href="#应用场景-2" class="headerlink" title="应用场景"></a>应用场景</h4><ol>
<li>科研和探索类项目成果的场景式展现和演示</li>
<li>成果集成式展现和演示</li>
<li>前沿技术实验床，可用于开展科研探索和试验</li>
<li>复杂系统的早中期系统的验证和测试</li>
<li>未来探索类项目的提前验证</li>
<li>超复杂系统的仿真和验证测试</li>
</ol>
<h3 id="4️⃣-全景式负载分析工具"><a href="#4️⃣-全景式负载分析工具" class="headerlink" title="4️⃣ 全景式负载分析工具"></a>4️⃣ 全景式负载分析工具</h3><h4 id="简介-3"><a href="#简介-3" class="headerlink" title="简介"></a>简介</h4><ul>
<li>提供：<ul>
<li>自顶向下的运行环境分析组件：<ul>
<li>运行环境层（中间表示 IR 层负载特征）；</li>
<li>操作系统层（指令集架构 ISA 层负载特征）；</li>
<li>硬件平台层（微架构层负载特征）。</li>
</ul>
</li>
</ul>
</li>
<li>实现：<ul>
<li>自顶向下全面的负载特征刻画测评。<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Freshwlnd/image/blob/blog/BenchCouncil.png?raw=true"
                      alt="内容组成"
                ><figcaption>内容组成</figcaption></figure></li>
</ul>
</li>
</ul>
<h4 id="具体介绍-3"><a href="#具体介绍-3" class="headerlink" title="具体介绍"></a>具体介绍</h4><ul>
<li>传统的负载分析方法，专注于在某一层进行分析，如利用特定架构上的硬件性能计数 器进行特定微架构分析、利用二进制流的插桩分析进行微架构独立的特定 ISA 分析、 利用编译器的 IR 分析进行 ISA 独立的分析。这些方法缺少自顶向下的全景式分析， 从而无法准确捕捉负载的本质特征。BenchCouncil 全景式的负载特征分析工具提供自顶向下的关联分析：提供从 IR 层到 ISA 层和微架构层的负载特征关联分析，全面 刻画负载特征，指导软硬件协同设计。</li>
</ul>
<h4 id="应用场景-3"><a href="#应用场景-3" class="headerlink" title="应用场景"></a>应用场景</h4><ol>
<li>处理器设计的负载特征分析</li>
<li>指令集设计的负载特征分析</li>
<li>处理器评测服务与排名</li>
<li>系统结构方向的科研研究</li>
<li>热点函数和性能瓶颈分析与定位</li>
<li>软硬件协同设计</li>
</ol>
<h3 id="5️⃣-网络仿真分析仪"><a href="#5️⃣-网络仿真分析仪" class="headerlink" title="5️⃣ 网络仿真分析仪"></a>5️⃣ 网络仿真分析仪</h3><h4 id="简介-4"><a href="#简介-4" class="headerlink" title="简介"></a>简介</h4><ul>
<li>提供：<ul>
<li>大规模数据中心的网络仿真模拟组件；</li>
<li>大规模数据中心的流量特征分析组件。</li>
</ul>
</li>
<li>实现：<ul>
<li>自顶向下全面的负载特征刻画测评。</li>
<li>简化并标准化分布式集群网络环境仿真。</li>
<li>简化并标准化数据输入。<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Freshwlnd/image/blob/blog/NetworkBench.png?raw=true"
                      alt="内容组成"
                ><figcaption>内容组成</figcaption></figure></li>
</ul>
</li>
</ul>
<h4 id="具体介绍-4"><a href="#具体介绍-4" class="headerlink" title="具体介绍"></a>具体介绍</h4><ul>
<li>大规模网络仿真和流量分析对于上层应用级别的网络特征分析和优化、以及底层硬件 级别的交换机芯片评测和架构改进均具有至关重要的作用。</li>
<li>BenchCouncil 网络模拟与分析仪支持大规模数据中心的网络仿真模拟与流量特征分析，其特点如下：<ol>
<li>支持任意网络拓扑和集群规模的模拟，并能有效仿真分布式集群环境；</li>
<li>提供真实现代负载的网络流量特征分析模型，包括大数据、人工智能、互联网服务等；</li>
<li>提供基于真实网络流量模型的流量重放工具，能够保持真实流量特性并支持微妙 / 纳秒级的仿真模拟；</li>
<li>提供网络特征与交换机芯片特征的映射模型，从交换性能、拥塞控制、时延抖动、突发吸纳、缓存容量等维度全面评测交换机芯片性能。</li>
</ol>
</li>
</ul>
<h4 id="应用场景-4"><a href="#应用场景-4" class="headerlink" title="应用场景"></a>应用场景</h4><ol>
<li>大规模网络系统的测试与验证</li>
<li>网络与系统的科研研究</li>
<li>网络与系统的工业级研发</li>
<li>网络与系统的选型，评估和优化</li>
<li>网络与系统成果的集成展现与显示</li>
<li>未来网络系统的仿真与验证</li>
</ol>
<h2 id="🧠问题"><a href="#🧠问题" class="headerlink" title="🧠问题"></a>🧠问题</h2><ol>
<li>怎么用？是底层资源管理平台？是输入确定的评价平台？（根据例子解释）<ul>
<li>可定制的测试环境提供及基准测试平台。</li>
</ul>
</li>
<li>是仅提供测试环境？由用户自行输入数据集？<ul>
<li>提供简化输入的组件。</li>
</ul>
</li>
<li>按照“仅测试环境”的假设来说，排行榜的作用是展示各种“测试环境性能”也就说得过去了。那该平台是否提供了“模型性能”排行榜？如果没有，是否还有必要增加排行榜？<ul>
<li>能提供算法的测试。</li>
</ul>
</li>
</ol>
<h1 id="📚相关知识"><a href="#📚相关知识" class="headerlink" title="📚相关知识"></a>📚相关知识</h1><h2 id="benchmark-与-baseline"><a href="#benchmark-与-baseline" class="headerlink" title="benchmark 与 baseline"></a>benchmark 与 baseline</h2><ul>
<li><p>benchmark 是一个过程，baseline 是 benckmark 这个过程中的一次实例。</p>
</li>
<li><p>benchmark 过程包括三个步骤：</p>
<ol>
<li>设置(setup): 根据实验目的做得设置，通常也是在论文实验结果之前要交代的实验设置，根据所要研究的问题选择合适的数据集、算法、对比算法、比较参数等等。</li>
<li>执行(execution): 这个部分就是按照上一步的设置进行实验。</li>
<li>分析(analysis): 通过各种分析方法分析上一步得到的实验结果，用来佐证提出的算法或者假设。</li>
</ol>
</li>
</ul>
<h2 id="微基准测试"><a href="#微基准测试" class="headerlink" title="微基准测试"></a>微基准测试</h2><ul>
<li>微基准测试(Micro-benchmarks)是基准测试中的一种方法，用来测试<strong>微小代码单元</strong>的性能，通常这个微小代码单元可以是一段算法，一个方法，一个数据结构。</li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://www.benchcouncil.org/cn/testbed.html" >[1] BenchCouncil新技术实验床（泰）<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>业界现状</category>
      </categories>
      <tags>
        <tag>实验床</tag>
      </tags>
  </entry>
  <entry>
    <title>【视频流】mkv与mp4区别，以及利用ffmpeg转换</title>
    <url>/2025/03/23/mkv-mp4-ffmpeg/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在日常工作中，我们经常需要录制会议并将其转化为文字。然而，录制的视频文件通常是mkv格式，而飞书妙记仅支持mp4格式。这篇文章将探讨mkv与mp4的区别，并介绍如何使用ffmpeg在mac上进行格式转换。此外，我们还会简要探讨ffmpeg的工作原理。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><p>最近经常有会议录屏及转文字需求，但发现录屏生成的文字总是mkv格式，而好用的飞书妙记却仅支持mp4格式。所以首先第一个好奇的问题是：mkv与mp4有什么区别？<br>其次，折腾了很久之后发现 mac 上可以直接用 ffmpeg 转换格式，所以这篇文章也会记录一下如何使用 ffmpeg 转换视频格式。此外第二个好奇的问题是：ffmpeg 的原理是什么？</p>
<h1 id="🧠思路"><a href="#🧠思路" class="headerlink" title="🧠思路"></a>🧠思路</h1><p>为了满足将mkv格式转换为mp4格式的需求，我们需要了解以下几点：</p>
<ol>
<li>mkv与mp4的区别。</li>
<li>如何在mac上安装并使用ffmpeg进行格式转换。</li>
<li>ffmpeg的基本工作原理。</li>
</ol>
<h1 id="🔨解决"><a href="#🔨解决" class="headerlink" title="🔨解决"></a>🔨解决</h1><h2 id="mkv与mp4的区别"><a href="#mkv与mp4的区别" class="headerlink" title="mkv与mp4的区别"></a>mkv与mp4的区别</h2><p>总结而言：MP4有更好的兼容性，但视频质量比MKV略差；MKV有着更好的质量，但是文件大小更大，且兼容性略差。<a href="#refer-anchor-1"><sup>[1]</sup></a><br>mkv（Matroska Video File）和mp4（MPEG-4 Part 14）都是常见的视频文件格式。它们的主要区别在于：</p>
<ul>
<li><strong>容器格式</strong>：mkv是一个开放标准的多媒体容器格式，可以包含无限数量的视频、音频、图片或字幕轨道。mp4是由国际标准化组织（ISO）定义的多媒体容器格式，广泛用于视频播放和流媒体。</li>
<li><strong>兼容性</strong>：mp4格式在各种设备和平台上具有更好的兼容性，而mkv格式则更灵活，支持更多的编码格式和功能。</li>
</ul>
<h3 id="mkv"><a href="#mkv" class="headerlink" title="mkv"></a>mkv</h3><ul>
<li><strong>简介</strong>：MKV（Matroska Video File）是一种新的多媒体封装格式，这个封装格式可<strong>把多种不同编码的视频</strong>及<strong>16条或以上不同格式的音频</strong>和<strong>语言不同的字幕</strong>封装到一个Matroska Media档内。Matroska同时还可以提供非常好的交互功能，而且比MPEG的方便、强大。<a href="#refer-anchor-1"><sup>[1]</sup></a></li>
<li><strong>特点</strong>：Matroska最大的特点就是能容纳多种不同类型编码的视频、音频及字幕流，甚至囊括了RealMedia及QuickTime这类流媒体，可以说是对传统媒体封装格式的一次大颠覆！它现在几乎变成了一个万能的媒体容器。另外，MKV格式也更适合需要压缩大型视频文件的情况，因为它可以保持高质量并同时减小文件大小。</li>
<li><strong>原理</strong>：Matroska所谓的封装AVI、RM、MOV等媒体，并不是简单将它们不加改变的合并到Matroska中，而是将它们的音视频流进行了重新组织。</li>
<li><strong>播放</strong>：播放Matroska这类格式并不需要专用的播放器，任何DirectShow的播放器都可以播放MKV、OGM、MP4文件，仅需安装相应 Matroska 解码分离器插件即可。现有的播放器要播放MKV格式仅需安装相应的分离器插件即可。</li>
<li>其它补充材料：mkv文件细节解析<a href="#refer-anchor-5">5</a></li>
</ul>
<h3 id="mp4"><a href="#mp4" class="headerlink" title="mp4"></a>mp4</h3><ul>
<li><strong>简介</strong>：MPEG（Moving Picture Experts Group），是一个国际标准组织（IS0）认可的媒体封装形式，受到大部份机器的支持。其储存方式多样，可以适应不同的应用环境。MPEG的控制功能丰富，可以有多个视频（即角度）、音轨、字幕（位图字幕）等等。</li>
<li><strong>特点</strong>：MP4是一种数字多媒体容器格式，用于存储音频、视频、字幕和图像。它是MPEG-4标准的一部分，广泛用于存储数字音频和视频流，以及其他数据，如静态图像和文本。</li>
<li><strong>原理</strong>：MP4格式是由国际标准化组织（ISO）定义的多媒体容器格式，它采用了一种层次化的结构，可以存储多种编码格式的视频和音频数据。</li>
<li><strong>播放</strong>：MP4格式的视频几乎可以在所有设备和平台的播放器上播放，包括计算机、手机、平板电脑、电视等。尤其是支持所有的移动设备，而 MKV 则几乎不被所有的移动设备支持。</li>
</ul>
<h2 id="使用ffmpeg转换格式"><a href="#使用ffmpeg转换格式" class="headerlink" title="使用ffmpeg转换格式"></a>使用ffmpeg转换格式</h2><p>在mac上使用ffmpeg转换视频格式巨巨巨简单。以下是具体步骤：</p>
<ol>
<li><strong>安装ffmpeg</strong>：可以通过Homebrew安装ffmpeg<a href="#refer-anchor-2"><sup>[2]</sup></a>。打开终端并输入以下命令： <div class="code-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">brew install ffmpeg</span><br></pre></td></tr></table></figure></div></li>
<li><strong>转换视频格式</strong>：安装完成后，可以使用以下命令将mkv文件转换为mp4文件： <div class="code-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">ffmpeg -i <span class="variable">$&#123;input&#125;</span>.mkv -codec copy <span class="variable">$&#123;output&#125;</span>.mp4</span><br></pre></td></tr></table></figure></div>
 这里，<code>-i</code>参数指定输入文件，<code>-codec copy</code>参数表示直接复制视频和音频流而不进行重新编码。<code>input</code>和<code>output</code>分别为输入和输出文件的名称。</li>
</ol>
<h2 id="ffmpeg的原理"><a href="#ffmpeg的原理" class="headerlink" title="ffmpeg的原理"></a>ffmpeg的原理</h2><p>ffmpeg是一个开源的多媒体框架，可以用来录制、转换和流式传输音视频。<a href="#refer-anchor-3"><sup>[3]</sup></a></p>
<ul>
<li><strong>简介</strong>：FFmpeg是一个开源免费跨平台的视频和音频流方案，属于自由软件，采用LGPL或GPL许可证（依据你选择的组件）。它提供了<strong>录制、转换以及流化音视频</strong>的完整解决方案。</li>
<li><strong>特点</strong>：它包含了非常先进的音频/视频编解码库libavcodec，为了保证高可移植性和编解码质量，libavcodec里很多codec都是从头开发的。FFmpeg在Linux平台下开发，但它同样也可以在其它操作系统环境中编译运行，包括Windows、Mac OS X等。</li>
<li><strong>组成</strong>：FFmpeg项目由以下几部分组成：<a href="#refer-anchor-3"><sup>[3,4]</sup></a><ul>
<li>FFMpeg：视频文件<strong>转换</strong>命令行工具,也支持经过实时电视卡抓取和编码成视频文件。</li>
<li>FFServer：基于HTTP(RTSP正在开发中)用于实时广播的<strong>多媒体服务器</strong>，也支持时间平移.</li>
<li>FFplay：用SDL和FFmpeg库开发的一个简单的<strong>媒体播放器</strong>.</li>
<li>libavcodec：一个包含了所有FFmpeg音视频<strong>编解码器的库</strong>.为了保证最优性能和高可复用性,大多数编解码器从头开发的.</li>
<li>libavformat：一个包含了所有的普通音视格式的<strong>解析器和产生器的库</strong>，用于是如何输出的封装和解封装.</li>
<li>libavfilter：提供音视频效果<strong>过滤功能</strong>，可以对音视频流进行各种操作。例如，裁剪、旋转、改变亮度和添加水印等。</li>
<li>libavdevice：允许FFmpeg<strong>与各种输入输出设备交互</strong>，例如摄像头、录音设备等。</li>
<li>libswscale：用于<strong>图像缩放、颜色空间转换</strong>等操作，支持不同分辨率和像素格式之间的转换。</li>
<li>libswresample：用于音频<strong>重采样</strong>，支持音频流的转换和处理。</li>
</ul>
</li>
<li><strong>工作原理</strong>：FFmpeg的工作原理非常复杂，但简单来说，<a href="#refer-anchor-4"><sup>[4]</sup></a><ul>
<li><strong>输入</strong>：使用libavformat读取输入文件的容器格式，解析出音视频流的信息（包括编码格式、时长、分辨率等）。</li>
<li><strong>解码</strong>：通过libavcodec解码音视频流，将输入的多媒体文件解码为原始音频和视频帧数据流。</li>
<li><strong>处理</strong>：对数据流进行各种处理，如剪辑、滤镜、转码等。例如可选地，使用libavfilter进行各种处理，例如裁剪、缩放、添加特效等。如果进行转码操作，FFmpeg会根据目标格式设置相应的编码参数和选项。</li>
<li><strong>编码</strong>：通过libavcodec，将经过处理后的数据重新编码成目标格式。</li>
<li><strong>输出</strong>：使用libavformat将编码后的视频和音频流封装到目标媒体格式中。</li>
</ul>
</li>
</ul>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><p>通过这次学习和实践，我们不仅了解了mkv与mp4的区别，还掌握了使用ffmpeg进行视频格式转换的方法。这为我们在日常工作中处理视频文件提供了极大的便利。同时，我们也对ffmpeg的工作原理有了初步的认识，为进一步深入学习打下了基础。<br>值得未来深入阅读的材料：</p>
<ul>
<li><a href="#refer-anchor-5">mkv文件细节解析<sup>[5]</sup></a></li>
<li><a href="#refer-anchor-6">FFmpeg 工作原理和常用命令<sup>[6]</sup></a></li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://zhuanlan.zhihu.com/p/147722579" >[1] 什么是MKV格式？和MP4什么区别？ - 麦琪的礼物的文章 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link"   href="https://developer.aliyun.com/article/1260303" >[2] MacOS安装FFmpeg<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link"   href="https://developer.aliyun.com/article/244880" >[3] FFmpeg介绍及参数详细说明<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link"   href="https://zhuanlan.zhihu.com/p/1379282496" >[4] FFMPEG原理与使用 - 中国电信天翼云的文章 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-5"></div>

<p><a class="link"   href="https://blog.csdn.net/H2008066215019910120/article/details/130753817" >[5] ffmpeg mkv 文件解析<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-6"></div>

<p><a class="link"   href="https://tech-service-wiki.readthedocs.io/en/latest/tech/ffmpeg.html" >[6] FFmpeg 工作原理和常用命令<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>视频处理</category>
      </categories>
      <tags>
        <tag>工具整理</tag>
        <tag>视频</tag>
      </tags>
  </entry>
  <entry>
    <title>【ACM】2021 ICPC 银川站 - dp题</title>
    <url>/2023/05/16/algorithm/2021%E9%93%B6%E5%B7%9D-dp/</url>
    <content><![CDATA[<p>回想ACM生涯，印象最深刻的似乎就是这两道在正式比赛中的绝杀题，两道题都是在最后一小时内憋出并成功拿下金银牌的关键题。一道是2019徐州的树上题，另一道就是这道2021银川dp题。这次来回顾一下后者的解法，前者就等以后再说吧（前面的区域，以后再来探索吧[doge]）。</p>
<h1 id="题目介绍（大意）"><a href="#题目介绍（大意）" class="headerlink" title="题目介绍（大意）"></a>题目介绍（大意）</h1><h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>有一个长度为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></svg></mjx-container>数组，第<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewBox="0 -661 345 672"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container>个数字为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="1.937ex" height="1.355ex" role="img" focusable="false" viewBox="0 -441 856 598.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(562,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>。需要将列表分成<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g></svg></mjx-container>段，每一段的价值为：该段数字中最大值与最小值之差，即<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="17.282ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 7638.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(878,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1407,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1979,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2368,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(2897,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3508.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(4508.4,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5386.4,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5731.4,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(6331.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6720.4,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(7249.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>。<br>求如何分段能获得最高的总价值（<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g></svg></mjx-container>个段价值之和）。</p>
<h2 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h2><p>第一行为两个空格分割的整数<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></svg></mjx-container>(1≤<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></svg></mjx-container>≤10000)和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g></svg></mjx-container>(1≤<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g></svg></mjx-container>≤<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></svg></mjx-container>)，分别表示数组长度和目标段数。<br>第二行为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></svg></mjx-container>个空格分割的正整数，第i个数字<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="1.937ex" height="1.355ex" role="img" focusable="false" viewBox="0 -441 856 598.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(562,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>(1≤<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="1.937ex" height="1.355ex" role="img" focusable="false" viewBox="0 -441 856 598.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(562,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>≤500000)为第<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewBox="0 -661 345 672"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container>个数字的值。</p>
<h2 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h2><p>所有分段方案中最高总价值。</p>
<h2 id="样例输入1"><a href="#样例输入1" class="headerlink" title="样例输入1"></a>样例输入1</h2><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">5 1</span><br><span class="line">2 4 5 6 3</span><br></pre></td></tr></table></figure></div>

<h2 id="样例输出1"><a href="#样例输出1" class="headerlink" title="样例输出1"></a>样例输出1</h2><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">4</span><br></pre></td></tr></table></figure></div>

<h2 id="样例输入2"><a href="#样例输入2" class="headerlink" title="样例输入2"></a>样例输入2</h2><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">5 2</span><br><span class="line">2 4 5 6 3</span><br></pre></td></tr></table></figure></div>

<h2 id="样例输出2"><a href="#样例输出2" class="headerlink" title="样例输出2"></a>样例输出2</h2><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">6</span><br></pre></td></tr></table></figure></div>

<hr>
<h1 id="解法1"><a href="#解法1" class="headerlink" title="解法1"></a>解法1</h1><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><blockquote>
<p>核心思路：将题目的解空间放宽</p>
</blockquote>
<ul>
<li><p>原本题意可构建dp数组，dp[i][j]表示要分为i段时前j个数字的最优解。</p>
<ul>
<li>朴素算法即考虑第j个人可以和前面哪些人组成一组（最多j种情况，即[1,j]或[2,j]或…或[j,j]成一组）。设取[s,j]为一组，则分数为dp[i-1][s-1]+max(a[s],…,a[j])-min(a[s],…,a[j])。</li>
<li>故有O(n^3)的解法，转移方程为：dp[i][j] = max(dp[i-1][s-1]+max(a[s],…,a[i])-min(a[s],…,a[j]))【注意s的边界需要考虑】</li>
</ul>
</li>
<li><p>将解空间放宽：将转移方程放大为：dp[i][j] = max(dp[i-1][s-1]+a[f1]-a[f2])，其中s与上述公式含义相同，f1和f2为[s,j]中的任意数字。很容易发现该公式与上述公式答案相同。</p>
<ul>
<li><p>再考虑dp[i][j]和dp[i][j-1]的解空间间的差异即可简单递推。</p>
</li>
<li><p>设 {dp[x][y]}表示dp[x][y]的解空间（即dp[x][y]应当在该集合内搜索）</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">{dp[i][j-1]} = {</span><br><span class="line">                dp[i-1][i-1]+a[i~j-1]-a[i~j-1],</span><br><span class="line">                dp[i-1][i]+a[i+1~j-1]-a[i+1~j-1],</span><br><span class="line">                ...</span><br><span class="line">                dp[i-1][j-2]+a[j-1~j-1]-a[j-1~j-1]</span><br><span class="line">                }</span><br><span class="line">{dp[i][j]} = {</span><br><span class="line">                dp[i-1][i-1]+a[i~j]-a[i~j],</span><br><span class="line">                dp[i-1][i]+a[i+1~j]-a[i+1~j],</span><br><span class="line">                ...</span><br><span class="line">                dp[i-1][j-1]+a[j~j]-a[j~j]</span><br><span class="line">                }</span><br></pre></td></tr></table></figure></div></li>
<li><p>则有 </p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">{dp[i][j]}-{dp[i][j-1]} = {</span><br><span class="line">                dp[i-1][i-1]+a[j]-a[i~j-1], dp[i-1][i-1]+a[i~j-1]-a[j], dp[i-1][i-1]+a[j]-a[j]</span><br><span class="line">                dp[i-1][i]+a[j]-a[i+1~j-1], dp[i-1][i]+a[i+1~j-1]-a[j], dp[i-1][i]+a[j]-a[j]</span><br><span class="line">                ...</span><br><span class="line">                dp[i-1][j-2]+a[j]-a[j-1~j-1], dp[i-1][j-2]+a[j-1~j-1]-a[j], dp[i-1][j-2]+a[j]-a[j]</span><br><span class="line">                dp[i-1][j-1]+a[j]-a[j]</span><br><span class="line">                }</span><br></pre></td></tr></table></figure></div></li>
<li><p>可以发现，dp[i-1][x]-a[x+1<del>j-1] 的最大值 以及 dp[i-1][x]+a[x+1</del>j-1] 的最大值 是可以O(1)维护的，设前者为maxDPaddA（即该数字为dp+a的最大值），后者为maxDPsubA（同理）</p>
</li>
<li><p>则转移方程为 dp[i][j] = max(dp[i][j-1],maxDPaddA-a[j],maxDPsubA+a[j])</p>
</li>
</ul>
</li>
</ul>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//#define ACM_LOCAL 1</span></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> 1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> ONLINE_JUDGE</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> endl <span class="string">'\n'</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">GlobalData</span> {</span><br><span class="line">    <span class="type">int</span> N, k;</span><br><span class="line">    vector&lt;ll&gt; dp[<span class="number">2</span>];</span><br><span class="line">    vector&lt;ll&gt; a;</span><br><span class="line">    ll ans;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">()</span> </span>{</span><br><span class="line">        ans = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">input</span><span class="params">()</span> </span>{</span><br><span class="line">        cin &gt;&gt; N &gt;&gt; k;</span><br><span class="line">        a = dp[<span class="number">0</span>] = dp[<span class="number">1</span>] = <span class="built_in">vector</span>&lt;ll&gt;(N<span class="number">+1</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>; i&lt;=N; i++) cin &gt;&gt; a[i];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">outputAns</span><span class="params">()</span> </span>{</span><br><span class="line">        cout &lt;&lt; ans &lt;&lt; endl;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">preSolve</span><span class="params">()</span> </span>{}</span><br><span class="line">} globalData;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">preSolve</span><span class="params">()</span> </span>{</span><br><span class="line">    globalData.<span class="built_in">preSolve</span>();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">input</span><span class="params">()</span> </span>{</span><br><span class="line">    globalData.<span class="built_in">init</span>();</span><br><span class="line">    globalData.<span class="built_in">input</span>();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">output</span><span class="params">()</span> </span>{</span><br><span class="line">    globalData.<span class="built_in">outputAns</span>();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">solve</span><span class="params">()</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> nowDPno=<span class="number">0</span>, lstDPno=<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    ll mx, mn;</span><br><span class="line">    mx = mn = globalData.a[<span class="number">1</span>];</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>; i&lt;=globalData.N; i++) {</span><br><span class="line">        mx = <span class="built_in">max</span>(mx, globalData.a[i]);</span><br><span class="line">        mn = <span class="built_in">min</span>(mn, globalData.a[i]);</span><br><span class="line">        globalData.dp[nowDPno][i] = mx-mn;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>; i&lt;=globalData.k; i++) {</span><br><span class="line">        <span class="built_in">swap</span>(nowDPno,lstDPno);</span><br><span class="line">        globalData.dp[nowDPno] = <span class="built_in">vector</span>&lt;ll&gt;(globalData.N<span class="number">+1</span>);</span><br><span class="line"></span><br><span class="line">        ll maxDP, maxDPaddA, maxDPsubA;</span><br><span class="line">        maxDP = globalData.dp[lstDPno][i<span class="number">-1</span>];</span><br><span class="line">        maxDPaddA = globalData.dp[lstDPno][i<span class="number">-1</span>]+globalData.a[i];</span><br><span class="line">        maxDPsubA = globalData.dp[lstDPno][i<span class="number">-1</span>]-globalData.a[i];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=i<span class="number">+1</span>; j&lt;=globalData.N; j++) {</span><br><span class="line">            maxDP = <span class="built_in">max</span>(maxDP, globalData.dp[lstDPno][j<span class="number">-1</span>]);</span><br><span class="line">            maxDPaddA = <span class="built_in">max</span>(maxDPaddA,maxDP+globalData.a[j]);</span><br><span class="line">            maxDPsubA = <span class="built_in">max</span>(maxDPsubA,maxDP-globalData.a[j]);</span><br><span class="line">            globalData.dp[nowDPno][j] = <span class="built_in">max</span>(globalData.dp[nowDPno][j<span class="number">-1</span>],<span class="built_in">max</span>(maxDPaddA-globalData.a[j],maxDPsubA+globalData.a[j]));</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    globalData.ans = globalData.dp[nowDPno][globalData.N];</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>{</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> ACM_LOCAL</span></span><br><span class="line">    <span class="built_in">freopen</span>(<span class="string">"./data/0.in"</span>, <span class="string">"r"</span>, stdin);</span><br><span class="line">    <span class="built_in">freopen</span>(<span class="string">"./data/0.out"</span>, <span class="string">"w"</span>, stdout);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    ios_base::<span class="built_in">sync_with_stdio</span>(<span class="literal">false</span>);</span><br><span class="line">    cin.<span class="built_in">tie</span>(<span class="literal">nullptr</span>);</span><br><span class="line">    cout.<span class="built_in">tie</span>(<span class="literal">nullptr</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">preSolve</span>();</span><br><span class="line">    <span class="type">int</span> T = <span class="number">1</span>;</span><br><span class="line">    <span class="comment">// cin &gt;&gt; T;</span></span><br><span class="line">    <span class="keyword">while</span> (T--) {</span><br><span class="line">        <span class="built_in">input</span>();</span><br><span class="line">        <span class="built_in">solve</span>();</span><br><span class="line">        <span class="built_in">output</span>();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure></div>


<hr>
<h1 id="解法2"><a href="#解法2" class="headerlink" title="解法2"></a>解法2</h1><h2 id="思路（来自网络）"><a href="#思路（来自网络）" class="headerlink" title="思路（来自网络）"></a>思路（来自网络）</h2><ul>
<li>可以将每段价值转换成选择两个数相减，使得最后总和最大，那么最优必是最大值减去最小值，其实也可以看成选一个数乘上1，再选一个数乘上-1</li>
<li>那么设   <div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">dp[i][j][0] 表示前 i 个数分成 j 段，且第 j 段还未选择两个数，</span><br><span class="line">dp[i][j][1] 表示第 j 段已经选了一个数乘上1，</span><br><span class="line">dp[i][j][2] 表示第 j 段已经选了一个数乘上-1，</span><br><span class="line">dp[i][j][3] 表示第 j 段已经完了两个数。</span><br></pre></td></tr></table></figure></div></li>
<li>那么转移就是 O(1) 转移，具体看代码。</li>
</ul>
<h2 id="代码（非常有简单美）"><a href="#代码（非常有简单美）" class="headerlink" title="代码（非常有简单美）"></a>代码（非常有简单美）</h2><div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> GCC diagnostic <span class="keyword">error</span> <span class="string">"-std=c++11"</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;ctime&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> iss ios::sync_with_stdio(false)</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">typedef</span> <span class="type">unsigned</span> <span class="type">long</span> <span class="type">long</span> ull;</span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">int</span>,<span class="type">int</span>&gt; pii;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> mod=<span class="number">1e9</span><span class="number">+7</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> MAXN=<span class="number">1e4</span><span class="number">+5</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> inf=<span class="number">0x3f3f3f3f</span>;</span><br><span class="line">ll dp[<span class="number">2</span>][MAXN][<span class="number">5</span>];</span><br><span class="line"><span class="type">int</span> a[MAXN];</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">int</span> n, x;</span><br><span class="line">    cin&gt;&gt;n&gt;&gt;x;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++){</span><br><span class="line">        cin&gt;&gt;a[i];</span><br><span class="line">    }</span><br><span class="line">    <span class="built_in">memset</span>(dp,-inf,<span class="keyword">sizeof</span> dp);</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">0</span>][<span class="number">3</span>]=<span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> f=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++){</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=n;j++){</span><br><span class="line"></span><br><span class="line">            dp[f][j][<span class="number">0</span>]=dp[f^<span class="number">1</span>][j<span class="number">-1</span>][<span class="number">3</span>];</span><br><span class="line">            dp[f][j][<span class="number">1</span>]=dp[f^<span class="number">1</span>][j<span class="number">-1</span>][<span class="number">3</span>]+a[i];</span><br><span class="line">            dp[f][j][<span class="number">2</span>]=dp[f^<span class="number">1</span>][j<span class="number">-1</span>][<span class="number">3</span>]-a[i];</span><br><span class="line">            dp[f][j][<span class="number">3</span>]=dp[f^<span class="number">1</span>][j<span class="number">-1</span>][<span class="number">3</span>];</span><br><span class="line">            dp[f][j][<span class="number">0</span>]=<span class="built_in">max</span>(dp[f][j][<span class="number">0</span>],dp[f^<span class="number">1</span>][j][<span class="number">0</span>]);</span><br><span class="line">            dp[f][j][<span class="number">1</span>]=<span class="built_in">max</span>(dp[f][j][<span class="number">1</span>],dp[f^<span class="number">1</span>][j][<span class="number">1</span>]);</span><br><span class="line">            dp[f][j][<span class="number">1</span>]=<span class="built_in">max</span>(dp[f][j][<span class="number">1</span>],dp[f^<span class="number">1</span>][j][<span class="number">0</span>]+a[i]);</span><br><span class="line">            dp[f][j][<span class="number">2</span>]=<span class="built_in">max</span>(dp[f][j][<span class="number">2</span>],dp[f^<span class="number">1</span>][j][<span class="number">2</span>]);</span><br><span class="line">            dp[f][j][<span class="number">2</span>]=<span class="built_in">max</span>(dp[f][j][<span class="number">2</span>],dp[f^<span class="number">1</span>][j][<span class="number">0</span>]-a[i]);</span><br><span class="line">            dp[f][j][<span class="number">3</span>]=<span class="built_in">max</span>(dp[f][j][<span class="number">3</span>],dp[f^<span class="number">1</span>][j][<span class="number">3</span>]);</span><br><span class="line">            dp[f][j][<span class="number">3</span>]=<span class="built_in">max</span>(dp[f][j][<span class="number">3</span>],dp[f^<span class="number">1</span>][j][<span class="number">2</span>]+a[i]);</span><br><span class="line">            dp[f][j][<span class="number">3</span>]=<span class="built_in">max</span>(dp[f][j][<span class="number">3</span>],dp[f^<span class="number">1</span>][j][<span class="number">1</span>]-a[i]);</span><br><span class="line">        }</span><br><span class="line">        f^=<span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line">    f^=<span class="number">1</span>;</span><br><span class="line">    cout&lt;&lt;dp[f][x][<span class="number">3</span>]&lt;&lt;endl;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
]]></content>
      <categories>
        <category>算法</category>
        <category>题目解析</category>
        <category>ICPC区域赛</category>
      </categories>
      <tags>
        <tag>DP</tag>
      </tags>
  </entry>
  <entry>
    <title>【ACM】 最短路径算法</title>
    <url>/2018/07/05/algorithm/ShortestPath/</url>
    <content><![CDATA[<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1531369451&di=f74d562d1d7462eb7fe3c5a776859ab6&imgtype=jpg&er=1&src=http://static.freepik.com/free-photo/shortest-path-problem_21018875.jpg"
                      alt="最短路径算法" title="最短路径"
                ><figcaption>最短路径算法</figcaption></figure></p>
<hr>
<p>·（ <del>整理的并不完善</del>）<br>·<em>（就是手痒想写点东西）</em><br>·<strong>（顺便熟悉一下MarkDown基础语法）</strong><br>· <a class="link"   href="https://github.com/Freshwlnd/template/blob/master/Graph/ShortestPath" >模版代码<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>· （<strong>需解决的问题</strong>：理清各算法的原理，以及因此导致的适用范围）<br>· （<strong>状态</strong>：像不懂数学公式的意义，只会套用，不会变通）<br>· （问题列举：</p>
<blockquote>
<p>判断环权值<br>字典序<br>求最长路径</p>
</blockquote>
<hr>
<h1 id="算法："><a href="#算法：" class="headerlink" title="算法："></a>算法：</h1><h2 id="Dijkstra-算法"><a href="#Dijkstra-算法" class="headerlink" title="Dijkstra 算法"></a>Dijkstra 算法</h2><p><strong>解决对象</strong> ：单源最短路径（边不能为负）<br><strong>原理</strong> ：每次松弛后，最近点的当前距离是其最短距离。<br><strong>方法</strong> ：  </p>
<blockquote>
<p><em>容器</em> ：  </p>
<blockquote>
<p><code>邻接矩阵图 graph[ ][ ]        //记录各点间距（无距离为INF，自己到自己为0）</code><br><code>数组 marked[ ]            //记录是否已得到最短路</code><br><code>数组 lenth[ ]            //记录已得到的距离</code></p>
</blockquote>
</blockquote>
<blockquote>
<p><em>过程</em>：  </p>
<blockquote>
<ol>
<li>设初始点为 v  </li>
<li>通过 v 点更新 lenth[] 数据  <blockquote>
<p>a. marked[v] = 1<br>b. 选取 v 使 marked[v] == 0 且 lenth[v] 最小  </p>
</blockquote>
</li>
<li>重复2直到 marked[] 中所有都为1   </li>
</ol>
</blockquote>
</blockquote>
<hr>
<h2 id="Floyd-算法"><a href="#Floyd-算法" class="headerlink" title="Floyd 算法"></a>Floyd 算法</h2><p><strong>解决对象</strong> ：图中每两个点的最短距离（边不为负）<br><strong>原理</strong> ：向路径中依次加入点，加入的点的距离已是当前最短。<br>  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>【子图dp思想】</strong><br><strong>问题</strong> ：[floyd一定是对的吗？]([floyd算法:我们真的明白floyd吗? - CSDN博客]<a class="link"   href="https://blog.csdn.net/ljhandlwt/article/details/52096932" >https://blog.csdn.net/ljhandlwt/article/details/52096932<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>)<br><strong>方法</strong> ：  </p>
 <div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(k=0;k&lt;n;k++) &#123;  </span><br><span class="line">　　for(i=0;i&lt;n;i++) &#123;  </span><br><span class="line">　　　　for(j=0;j&lt;n;j++) &#123;  </span><br><span class="line">　　　　　　if(graph[I][j] &gt; graph[I][k] + graph[k][j]) &#123;  </span><br><span class="line">　　　　　　　　graph[i][j] &gt; graph[i][k] + graph[k][j])   </span><br><span class="line">　　　　　　&#125;  </span><br><span class="line">　　　　&#125;  </span><br><span class="line">　　&#125;  </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></div>
<hr>
<h2 id="Bellman-Ford-算法"><a href="#Bellman-Ford-算法" class="headerlink" title="Bellman-Ford 算法"></a>Bellman-Ford 算法</h2><p><strong>解决对象</strong> ：单源最短路径/判断负权回路（复杂度较高）<br><strong>原理</strong> ：遍历每条边，每次遍历得到一个节点的最短距离（类似Dijkstra）。<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>【简单遍历】</strong><br><strong>方法</strong> ：  </p>
<blockquote>
<p><em>容器</em> ：  </p>
<blockquote>
<p><code>邻接矩阵图 graph[ ][ ]    //记录各点间距</code><br><code>数组 lenth[ ]            //储存最短距离</code>  </p>
</blockquote>
<p><em>过程</em>：  </p>
<blockquote>
<ol>
<li>设初始点为 v  </li>
<li>循环n-1次：  <blockquote>
<p>a. 对每条边 edge(v,u), 如果 lenth[v]+edge(v,u) &lt; lenth[u], 更新lenth[u]</p>
</blockquote>
</li>
<li>（若需判断负环）再循环n-1次，若有边能被更新则说明有负环。  </li>
</ol>
</blockquote>
</blockquote>
<hr>
<h2 id="SPFA-算法"><a href="#SPFA-算法" class="headerlink" title="SPFA 算法"></a>SPFA 算法</h2><p><strong>解决对象</strong> ：单源最短路径（边可为负）（会因特殊数据导致复杂度很高）<br><strong>原理</strong> ：类似堆调整，对每个被更新过的节点进行更新。【相当于剪枝的遍历】<br> &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>【bellman的优化】</strong><br><strong>方法</strong> ：  </p>
<blockquote>
<p><em>容器</em> ：  </p>
<blockquote>
<p><code>邻接矩阵图 graph[ ][ ]    //记录各点间距</code><br><code>队列    queue                //储存处理点v</code><br><code>数组 lenth[ ]                //储存最短距离</code>  </p>
</blockquote>
<p><em>过程</em>：  </p>
<blockquote>
<ol>
<li>将起点入队    </li>
<li>出队v<blockquote>
<p>a.更新v周围点<br>b.如果被更新，入队</p>
</blockquote>
</li>
<li>重复2直到队空 </li>
</ol>
</blockquote>
</blockquote>
<hr>
<h2 id="A-算法"><a href="#A-算法" class="headerlink" title="A* 算法"></a>A* 算法</h2><p><strong>解决对象</strong> ：在地图上找点对点最短路。<br><strong>原理</strong> ：类似Dijkstra算法，每次更新权值，并找当前点可达的权值最小点。<br><strong>方法</strong> ：  </p>
<blockquote>
<p><em>容器</em> ：  </p>
<blockquote>
<p><code>权值 F = G+H        //G为从起点到当前点移动的距离，H为到终点的估计移动距离</code><br><code>数组 open[ ]        //用于记录点是否可达</code><br><code>数组 close[ ]        //用于记录点是否不可达（已走过或是墙）</code></p>
</blockquote>
<p><em>过程</em>：  </p>
<blockquote>
<ol>
<li>设起点为v  </li>
<li>遍历v周围可达点u，并做：  <blockquote>
<p>a. u在close[ ]中，则跳过.<br>b. u不在open[ ]中， 则加入open[]并计算权值F.<br>c. u在open[ ]中，计算F并与原本权值比较，取较小.  </p>
</blockquote>
</li>
<li>重复2，直到到达终点. </li>
</ol>
</blockquote>
</blockquote>
<hr>
<h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><p>关于路径：   </p>
<blockquote>
<p><font size=1>一个巧妙的方法：<br><em>（在 HDU 1385 中实现过）</em><br><code>int path[ ][ ]        //path[i][j]记录从i到j的第二个节点</code>  </p>
</blockquote>
<hr>
<h1 id="回顾反思"><a href="#回顾反思" class="headerlink" title="回顾反思"></a>回顾反思</h1><p>学习过程回顾：   </p>
<blockquote>
<p>本次学习过程中经历了三个阶段：摸索算法-&gt;尝试运用-&gt;回顾剖析<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在第一个阶段中只是简单地罗列算法，像是本篇blog中每个算法的「方法」模块，知道过程，但只能死记硬背生搬硬套。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在第二个阶段中，运用算法解题的过程中遭到了很多打击：选错算法、一直WA之类的。与此同时也在不断吸收各个题解的精华，对算法有进一步的了解。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第三个过程则是在第二个过程中顿悟达到的。连续的挫败引发了总结的欲望，从题解中吸收的知识为成功总结打下基石。  </p>
</blockquote>
<p>反思：   </p>
<blockquote>
<p>  &emsp;&emsp;1.第一个阶段花费时间过多，状态较差，不清楚所作所为的目标。但时间花费还是必要的，「迷茫」也是入门阶段无法避免的挑战，下次还要更加打起精神来。<br>  &emsp;&emsp;2.达成主线任务(学习算法)的过程中还会遇到支线任务(markdown知识掌握)，做支线任务之余不能忘了把主要精力放在主线任务上。支线任务可以用于放松心情。（成就感十足）<br> &emsp;&emsp;3.游戏什么的应该当作阶段性奖励，能很好地达到放松的目的，也能更好地推进任务完成。<br> &emsp;&emsp;4.写博客实在是太爽了！（终于找到督促自己实时反思的途径了）  </p>
</blockquote>
<p>未解决问题（挖坑）：  </p>
<blockquote>
<p> 1.<strong>markdown语法在hexo框架下显示错误</strong>  </p>
<blockquote>
<p> <em>猜测</em>：  </p>
<blockquote>
<p>是从 bear 复制到 Macdown 时发生错误*  </p>
</blockquote>
<p> <em>解决</em>：  </p>
<blockquote>
<p>去掉html下划线代码后，格式显示成功。也许是不兼容的原因。  </p>
</blockquote>
</blockquote>
<blockquote>
<p> 2.<strong>blog图片的相对路径引用</strong><br> （存放在文件夹的什么位置问题）  </p>
</blockquote>
</blockquote>
<hr>
<p>题目目录：<br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=1217" >HDU 1217: Arbitrage<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=1224" >HDU 1224: Free DIY Tour<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=1385" >HDU 1385: Minimum Transport Cost<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=1869" >HDU 1869: 六度分离<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=1874" >HDU 1874: 畅通工程续<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=2066" >HDU 2066: 一个人的旅行<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=2112" >HDU  2112: HDU Today<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=2544" >HDU 2544: 最短路<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=2680" >HDU 2680: Choose the best route<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=2722" >HDU 2722: Here We Go(relians) Again<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=2923" >HDU 2923: Einbahnstrasse<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=3339" >HDU 3339: In Action<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=3790" >HDU 3790: 最短路径问题<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>算法介绍</category>
      </categories>
      <tags>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title>【ACM】二分图匹配问题</title>
    <url>/2018/07/17/algorithm/clique/</url>
    <content><![CDATA[<hr>
<p>题目：<br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=1530" >HDU 1530: Maximum Clique<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=1435" >HDU 1435: Stable Match<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=3585" >HDU 3585: maximum shortest distance<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=1522" >HDU 1522: Marriage is Stable<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=1914" >HDU 1914: The Stable Marriage Problem<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=1373" >HDU 1373: Channel Allocation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://poj.org/problem?id=2989" >POJ &nbsp;2989: All Friends<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://poj.org/problem?id=1419" >POJ &nbsp;1419: Graph Coloring<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://poj.org/problem?id=1075" >POJ &nbsp;1075: University Entrance Examination<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>  </p>
]]></content>
      <categories>
        <category>算法</category>
        <category>算法介绍</category>
      </categories>
      <tags>
        <tag>图论</tag>
        <tag>二分图</tag>
      </tags>
  </entry>
  <entry>
    <title>【ACM】LeetCode第280场周赛 - 数组的最大与和 - 匈牙利算法/KM算法</title>
    <url>/2022/02/14/algorithm/leetcode-weekly-contest-280-4/</url>
    <content><![CDATA[<h1 id="题目："><a href="#题目：" class="headerlink" title="题目："></a><strong>题目：</strong></h1><ul>
<li><a href="https://leetcode-cn.com/problems/maximum-and-sum-of-array/"><strong>LeetCode「美团 &amp; 力扣」联合主办 第 280 场周赛 第四题 《数组的最大与和》</strong></a></li>
</ul>
<h2 id="解题思路："><a href="#解题思路：" class="headerlink" title="解题思路："></a><strong>解题思路：</strong></h2><ul>
<li>题目的本质是将数组nums中的n个数字分配到不同的篮子中，每个数字分配到每个篮子时都有一个权值（按位与运算结果值），需要将整体分配方案的权值和最大化。</li>
<li>可以明显地看出是两类物品的匹配问题，又涉及权重的最大化，故可将题目抽象为一个二分图最大权匹配问题。</li>
<li>先考虑最朴素的方法，将每个数字和每个篮子的匹配方案都枚举一遍，计算出每种方案的权值和后比较获得最大值即可。算法时间复杂度为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="19.116ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 8449.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"></path></g><g data-mml-node="mo" transform="translate(763,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mo" transform="translate(1152,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1541,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2363.2,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mi" transform="translate(3085.4,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3685.4,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4257.4,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5135.4,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(5780.4,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(6078.4,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(6563.4,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(6924.4,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(7393.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(7782.4,0)"><path data-c="21" d="M78 661Q78 682 96 699T138 716T180 700T199 661Q199 654 179 432T158 206Q156 198 139 198Q121 198 119 206Q118 209 98 431T78 661ZM79 61Q79 89 97 105T141 121Q164 119 181 104T198 61Q198 31 181 16T139 1Q114 1 97 16T79 61Z"></path></g><g data-mml-node="mo" transform="translate(8060.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>。（当然是不可行的）</li>
<li>当然，二分图匹配问题毕竟很经典了，如果能想到二分图匹配问题，就应当能想到可能存在已有算法（但是当然没学习过相关算法的话也很难现场想出解决算法）。实际上确实存在已有算法——KM算法，能够解决二分图最大权匹配问题，即找到二分图匹配方案中的权值和最大方案。</li>
<li>那么先上代码，再慢慢解释KM算法的原理（实际上我也只是听说过该算法，这次也好好学习一下）</li>
</ul>
<h2 id="代码："><a href="#代码：" class="headerlink" title="代码："></a><strong>代码：</strong></h2><ul>
<li>代码根据<a href="#refer-anchor-3">参考文章[3]</a>进行改进</li>
</ul>
<div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> {</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 建图</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">buildGraph</span><span class="params">(vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; edges, vector&lt;<span class="type">int</span>&gt;&amp; nums, <span class="type">int</span> numSlots)</span> </span>{</span><br><span class="line">        <span class="type">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        edges = vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;(n,<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(<span class="number">2</span>*numSlots));</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;n; i++) {</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>; j&lt;numSlots; j++) {</span><br><span class="line">                edges[i][j] = edges[i][j+numSlots] = (nums[i]&amp;(j<span class="number">+1</span>));   <span class="comment">// j，j+numSlots 分别表示编号为 j+1 的篮子的两个空位</span></span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// KM算法寻找最大权匹配</span></span><br><span class="line">    <span class="comment">// 在匈牙利算法的基础上增加期望度机制。</span></span><br><span class="line">        <span class="comment">// 初始化左半图每个number的期望度为该number最大可获得权值，右半图每个slot的期望度为0。</span></span><br><span class="line">        <span class="comment">// 每次匹配时，只考虑边权等于相连number和slot期望度和的边。</span></span><br><span class="line">        <span class="comment">// 当一次匹配中无法成功时，执行期望度更新操作：将涉及的所有number期望度减一、所有slot期望度加一。</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">KM</span><span class="params">(vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; edges)</span> </span>{</span><br><span class="line">        <span class="type">int</span> n = edges.<span class="built_in">size</span>(), m = edges[<span class="number">0</span>].<span class="built_in">size</span>();  <span class="comment">// 二分图两边的点数</span></span><br><span class="line">        <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">match</span><span class="params">(m, <span class="number">-1</span>)</span></span>; <span class="comment">// match[i]为teacher[i]匹配的student编号</span></span><br><span class="line">        <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">exNumber</span><span class="params">(n)</span></span>; <span class="comment">// number期望</span></span><br><span class="line">        <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">exSlot</span><span class="params">(m, <span class="number">0</span>)</span></span>; <span class="comment">// slot的期望</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i) {</span><br><span class="line">            exNumber[i] = *<span class="built_in">max_element</span>(edges[i].<span class="built_in">begin</span>(), edges[i].<span class="built_in">end</span>());</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 为每个number匹配teacher</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i) {</span><br><span class="line">            <span class="keyword">while</span>(<span class="literal">true</span>) {</span><br><span class="line">                <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">visNumber</span><span class="params">(n, <span class="literal">false</span>)</span></span>;</span><br><span class="line">                <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">visSlot</span><span class="params">(m, <span class="literal">false</span>)</span></span>;</span><br><span class="line">                <span class="keyword">if</span> (<span class="built_in">dfs</span>(i, m, edges, match, visNumber, visSlot, exNumber, exSlot)) <span class="keyword">break</span>;</span><br><span class="line">                <span class="comment">// 无法匹配降低期望</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; n; ++j) {</span><br><span class="line">                    <span class="keyword">if</span> (visNumber[j]) exNumber[j]--;</span><br><span class="line">                }</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; m; ++j) {</span><br><span class="line">                    <span class="keyword">if</span> (visSlot[j]) exSlot[j]++;</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> ans = <span class="number">0</span>;</span><br><span class="line">				<span class="comment">// 将每一对匹配的权值加和（这里通过遍历slot的匹配情况来实现）</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; m; ++i) <span class="keyword">if</span>(match[i]!=<span class="number">-1</span>) {</span><br><span class="line">            ans += edges[match[i]][i];</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 匈牙利算法寻找完美匹配</span></span><br><span class="line">    <span class="comment">// 为第i个number寻找匹配的slot。对每个可匹配slot，若已被其他number匹配，则递归为其他number寻找另外的可匹配slot；找不到则为该number匹配其他slot</span></span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">dfs</span><span class="params">(<span class="type">int</span> i, <span class="type">int</span> m, vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; edges, vector&lt;<span class="type">int</span>&gt;&amp; match, vector&lt;<span class="type">bool</span>&gt;&amp; visNumber, vector&lt;<span class="type">bool</span>&gt;&amp; visSlot, vector&lt;<span class="type">int</span>&gt;&amp; exNumber, vector&lt;<span class="type">int</span>&gt;&amp; exSlot)</span> </span>{</span><br><span class="line">        visNumber[i] = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; m; ++j) {</span><br><span class="line">            <span class="keyword">if</span> (visSlot[j]) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="type">int</span> diff = exNumber[i] + exSlot[j] - edges[i][j];</span><br><span class="line">            <span class="keyword">if</span> (!diff) {</span><br><span class="line">                visSlot[j] = <span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">if</span> (match[j] == <span class="number">-1</span> || <span class="built_in">dfs</span>(match[j], m, edges, match, visNumber, visSlot, exNumber, exSlot)) {</span><br><span class="line">                    match[j] = i;</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    }</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">maximumANDSum</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; nums, <span class="type">int</span> numSlots)</span> </span>{</span><br><span class="line">        <span class="comment">/* </span></span><br><span class="line"><span class="comment">         * 问题抽象为 “n个数字 - 2*numSlots个篮子” 的二分图最大匹配问题</span></span><br><span class="line"><span class="comment">         ** 二分图中的点：</span></span><br><span class="line"><span class="comment">         *** n个数字：nums中需要被分配的n个数字</span></span><br><span class="line"><span class="comment">         *** 2*numSlots个篮子：每个篮子最多可以放两个数字</span></span><br><span class="line"><span class="comment">         ** 二分图中的边：</span></span><br><span class="line"><span class="comment">         *** 每个数字和每个篮子间都有一条边，边权为数字与篮子编号的 按位与运算 结果，表示把该数字放到该篮子时可获得的权值</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 建图（用n*2numSlots的邻接矩阵表示图。因为后续算法中只需要考虑边权而不需要考虑点权，故只需保存边权信息。）</span></span><br><span class="line">        vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; edges;</span><br><span class="line">        <span class="built_in">buildGraph</span>(edges,nums,numSlots);</span><br><span class="line">        <span class="comment">// 计算（使用KM算法，计算最优匹配方案权值和）</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">KM</span>(edges);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></table></figure></div>

<h2 id="KM算法细节解释："><a href="#KM算法细节解释：" class="headerlink" title="KM算法细节解释："></a>KM算法细节解释：</h2><ul>
<li>建议先浏览<a href="#refer-anchor-1">参考文章[1]</a>后再阅读本段，<a href="#refer-anchor-1">参考文章[1]</a>中以简单的例子介绍了KM算法的整体流程，本段仅以笔者浅薄的知识做一些补充，相当于<a href="#refer-anchor-1">参考文章[1]</a>的进阶版。</li>
<li>KM算法本质上在匈牙利算法的基础上增加期望度机制。<ul>
<li>初始化左半图每个number的期望度为该number最大可获得权值，右半图每个slot的期望度为0。</li>
<li>每次匹配时，只考虑边权等于相连number和slot期望度和的边。</li>
<li>当一次匹配中无法成功时，执行期望度更新操作：将涉及的所有number期望度减一、所有slot期望度加一。</li>
</ul>
</li>
<li>可行性：<ul>
<li>相当于限制了参与搜索的边的集合，使得权值较大的边能被优先搜索，保证了算法可行的充分性。</li>
<li>每次降低期望度时，将本次搜索中左半图所有点期望度减1、右半图所有点期望度加1。每次降低期望度时，设涉及到的左半图点个数为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.345ex" height="1.339ex" role="img" focusable="false" viewBox="0 -442 1036.6 592"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container>，则涉及到的右半图点个数为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="6.242ex" height="1.846ex" role="img" focusable="false" viewBox="0 -666 2759 816"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2259,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container>（不搜第<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.345ex" height="1.339ex" role="img" focusable="false" viewBox="0 -442 1036.6 592"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container>个左半图点时恰好匹配，而加入该点后不匹配，因此相关左半图点刚好比相关右半图点多一个）。</li>
<li>对已被匹配的边而言，对应左半图点期望度减1，右半图点期望度加1，故这些边仍然在被搜索的边集合中。期望度更新操作后，每个左半图点相关的权值稍小的边被加入搜索集中。由于更新时以1为粒度，所以能保证搜索过程中不会漏掉边，保证了算法可行的必要性。</li>
</ul>
</li>
</ul>
<h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><div id="refer-anchor-1"></div>

<ul>
<li><a class="link" href="https://www.cnblogs.com/logosG/p/logos.html">[1] https://www.cnblogs.com/logosG/p/logos.html<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<div id="refer-anchor-2"></div>

<ul>
<li><a class="link" href="https://www.cnblogs.com/fzl194/p/8834847.html">[2] https://www.cnblogs.com/fzl194/p/8834847.html<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<div id="refer-anchor-3"></div>

<ul>
<li><a class="link" href="https://leetcode-cn.com/problems/maximum-compatibility-score-sum/solution/c-km-suan-fa-er-fen-tu-dai-quan-zui-da-p-ztmd/">[3] https://leetcode-cn.com/problems/maximum-compatibility-score-sum/solution/c-km-suan-fa-er-fen-tu-dai-quan-zui-da-p-ztmd/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>题目解析</category>
        <category>LeetCode周赛</category>
      </categories>
      <tags>
        <tag>图论</tag>
        <tag>二分图</tag>
      </tags>
  </entry>
  <entry>
    <title>【ACM】概率DP</title>
    <url>/2018/07/07/algorithm/%E6%A6%82%E7%8E%87DP/</url>
    <content><![CDATA[<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1531838590422&di=2d2c1b9a15e1da38c0fed47b0e2a9c13&imgtype=0&src=http://img0.ph.126.net/yoxBKkpzaJWi6FKb6pla7A==/6632351995281896151.png"
                      alt="概率DP"
                ><figcaption>概率DP</figcaption></figure></p>
<h2 id="剖析"><a href="#剖析" class="headerlink" title="剖析"></a>剖析</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;先思考本次要解决的问题是什么，才能对症下药。找出问题的方法则是梳理，将整个过程有逻辑地复述一遍。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;概率DP的问题有两类：求期望、求概率。此外还会用到一个工具：高斯消元。同时有经典的“正向推概率，反向推期望”思想。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;先整理DP的特点：将问题分解成子问题，通过子问题的最优解求得父问题的最优解，实际上是对爆搜的剪枝。   </p>
<h3 id="期望DP"><a href="#期望DP" class="headerlink" title="期望DP"></a>期望DP</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于求期望题，题解一般从后往前倒推。在<a class="link"   href="https://blog.csdn.net/nameofcsdn/article/details/52082746" >飞行棋<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>一题中可以看出，正向逆向都可求解，但对于终点确定的问题，逆推要简单得多。其中原因是：从“起点到达该点的期望”的理解转变为“该点到达终点的期望”，相当于把主体从前导点转移到所求点（前者用 <em>各个前导点的出现概率 * 转移概率*，后者用 *所求点出现概率 * 转移概率</em>），省去了由于前导点出现概率不同导致的麻烦。【写到这里发现对期望的递推公式还是不理解】<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除了逆推求解思想，题解一般先求出状态转移方程，但我对于该方程一直理解不好。  </p>
<hr>
<h4 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h4><h5 id="PKU-3682-King-Arthur’s-Birthday-Celebration"><a href="#PKU-3682-King-Arthur’s-Birthday-Celebration" class="headerlink" title="PKU 3682: King Arthur’s Birthday Celebration"></a><a class="link"   href="http://poj.org/problem?id=3682" >PKU 3682: King Arthur’s Birthday Celebration<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></h5><blockquote>
<p>· 天数</p>
<blockquote>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/Freshwlnd/image/blog/DP1.png"
                      alt="1"
                ><figcaption>1</figcaption></figure><br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/Freshwlnd/image/blog/DP2.png"
                      alt="2"
                ><figcaption>2</figcaption></figure>  </p>
</blockquote>
<p>· 花费  </p>
<blockquote>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/Freshwlnd/image/blog/DP5.png"
                      alt="5"
                ><figcaption>5</figcaption></figure><br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/Freshwlnd/image/blog/DP6.png"
                      alt="6"
                ><figcaption>6</figcaption></figure>  </p>
</blockquote>
</blockquote>
<h5 id="HDU-3853-LOOPS"><a href="#HDU-3853-LOOPS" class="headerlink" title="HDU 3853: LOOPS"></a><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=3853" >HDU 3853: LOOPS<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></h5><blockquote>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/Freshwlnd/image/blog/DP3.png"
                      alt="3"
                ><figcaption>3</figcaption></figure><br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/Freshwlnd/image/blog/DP4.png"
                      alt="4"
                ><figcaption>4</figcaption></figure>  </p>
</blockquote>
<hr>
<h5 id="HDU-4405-Aeroplane-chess（上文提到的飞行棋）"><a href="#HDU-4405-Aeroplane-chess（上文提到的飞行棋）" class="headerlink" title="HDU 4405: Aeroplane chess（上文提到的飞行棋）"></a><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=4405" >HDU 4405: Aeroplane chess<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>（上文提到的飞行棋）</h5><blockquote>
<p>正推  </p>
<blockquote>
<p><code>times[i] += ft(i-1,i) + ft(i-2,i) + ft(i-3,i) + ft(i-4,i) + ft(i-5,i) + ft(i-6,i);</code><br><code>ft(i,k) = (times[i] + list[i]) / 6;</code><br><em>(ft(i,k) / list[I] = (times[i] / list[i] + 1) / 6;)?</em><br>其中list[i]指到i点的概率，times[i]指到i点次数的期望。  </p>
</blockquote>
<p>逆推  </p>
<blockquote>
<p><code>times[i] = (times[i+1] + times[i+2] + times[i+3] + times[i+4] + times[i+5] + times[i+6]) / 6 + 1;</code><br><em>(times[i]/list[i] = (times[i+1] + times[i+2] + times[i+3] + times[i+4] + times[i+5] + times[i+6]) / list[i] / 6 + 1;)?</em>  </p>
</blockquote>
</blockquote>
<hr>
<h4 id="稍加总结"><a href="#稍加总结" class="headerlink" title="稍加总结(?)"></a>稍加总结(?)</h4><p>/总结不出来…/   </p>
<p>E(X) = ∑</p>
<h3 id="概率DP"><a href="#概率DP" class="headerlink" title="概率DP"></a>概率DP</h3><p>（待补充…）</p>
<hr>
<h2 id="他人博客："><a href="#他人博客：" class="headerlink" title="他人博客："></a>他人博客：</h2><p><a class="link"   href="https://blog.csdn.net/nameofcsdn/article/details/52082746" >正向推概率，反向推期望 - CSDN博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="https://blog.csdn.net/qq_37963864/article/details/79320424" >期望&amp;概率dp总结 - CSDN博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="https://blog.csdn.net/cc_again/article/details/25866971" >ACM动态规划总结 - CSDN博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>  </p>
<hr>
<p>题目目录：<br><a class="link"   href="http://poj.org/problem?id=3682" >PKU 3682: King Arthur’s Birthday Celebration<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=3853" >HDU 3853: LOOPS<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=4089" >HDU 4089: Activation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=2262" >HDU 2262: Where is the canteen<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=3949" >HDU 3949: XOR<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="http://acm.hdu.edu.cn/showproblem.php?pid=4418" >HDU 4418: Time travel<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><a class="link"   href="https://icpcarchive.ecs.baylor.edu/external/50/5070.pdf" >UVALive 5070: Awkward Lights<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>算法介绍</category>
      </categories>
      <tags>
        <tag>DP</tag>
        <tag>概率DP</tag>
      </tags>
  </entry>
  <entry>
    <title>《悉达多》—— 摘录</title>
    <url>/2023/05/22/book/book-excerpt-1/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>2022年10月疫情时期，听完“文化有限”的播客后就一直很想看这本书，终于到了2023年5月才终于开始看并看完，虽然读完一遍半后仍然一知半解，但很想把其中一些句子先摘录一下。</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><ul>
<li>（以下简介来源于播客<a href="#refer-anchor-1"><sup>[1]</sup></a>）</li>
<li>短篇小说《悉达多》，作者是诺奖得主、德国作家赫尔曼·黑塞。<ul>
<li>《悉达多》讲述了古印度贵族青年悉达多英俊聪慧，拥有人们羡慕的一切。为了追求心灵的安宁和自洽圆融，他走上了求道之路。在路上，他和好友乔文达同行又分别、做苦行僧、遇到已开悟的世尊乔达摩、在繁华的大城中结识名妓伽摩拉、学习做生意成为一名富商，让自己的心灵与肉体享受达到了顶峰，但他却依然没有找到安宁和自洽。于是他抛弃了世俗的一切，来到河边想要结束生命。在最绝望的一刹那，他突然听到了生命之河永恒的声音……经过一生探求，悉达多终于体验到万事万物的圆融统一，将自我融入瞬间的永恒之中，实现了心灵的安宁和自洽。</li>
</ul>
</li>
</ul>
<h1 id="摘录"><a href="#摘录" class="headerlink" title="摘录"></a>摘录</h1><ul>
<li>当做苦行僧的悉达多来到城市中，一无所有却自信满满的感觉非常奇妙。当他找到富商卡玛瓦斯米时，富商问出了我也非常好奇的问题：他的自信来源于哪里？<blockquote>
<p>（版本1 —— 李孟谦 译）<br>悉：“……看起来事实上是这样。每个人有取有给，这就是生活。”<br>卡：“请容我问一问：如果你身无一物，那有什么可以提供的？”<br>悉：“每个人都给得起他拥有的。猛士付出气力，商人提供货品，老师教，农夫耕，渔民渔。”<br>卡：“很好，那现在，你想付出什么？<strong>什么是你学到的，你能做的？</strong>”<br>悉：“<strong>我会思考，我会等待，我会斋戒。</strong>”<br>卡：“就这样？”<br>悉：“我想，也没别的了！”<br>卡：“那这些用处在哪里，像是斋戒……<strong>用处在哪里？</strong>”<br>悉：“斋戒十分重要，先生。当一个人没有东西吃时，斋戒就是能做的事情当中最明智的。如果悉达多没有学会斋戒，今天他任何工作都得接受，在你这里或在任何地方，因为饥饿会逼迫他。但是悉达多可以安静等待，没有任何不耐烦，没有任何困顿，他可以隐藏饥饿，笑容以对。所以，斋戒是好的。”<br>卡：“你是对的，沙门。在此稍等。”</p>
</blockquote>
</li>
<li>但读这部分内容时我正苦恼与自己每日沉迷漫画、手机，最后这段话没有什么很惊艳的表述，但给人一种从脚底蔓延到头顶的踏实感，让我不禁反问自己：“你的这些欲望是非要不可的吗？”<ul>
<li>虽然以前看到过很多对冥想的解读，但我觉得这一段是目前为止看到过最打动人的一个。也许是因为小说自有的特点，把人带入情景，用悉达多身上自带的迷人的令人向往的平静态度勾人好奇，再把答案娓娓道来，直击灵魂。</li>
</ul>
</li>
</ul>
<h2 id="补充：版本2-——-姜乙-译"><a href="#补充：版本2-——-姜乙-译" class="headerlink" title="补充：版本2 —— 姜乙 译"></a>补充：版本2 —— 姜乙 译</h2><ul>
<li>此版本中，富商名译为“迦摩施瓦弥”<blockquote>
<p>（版本2 —— 姜乙 译）<br>悉：“……世事看似如此。各有索取，各有付出。这是生活。”<br>迦：“恕我直言：如果你一无所有，你能付出什么？”<br>悉：“人人都付出他拥有的。武士付出力气，商人付出货物，教师付出学问，农民付出稻谷，渔民付出鱼蟹。”<br>迦：“非常对。只是，你付出什么？<strong>你究竟学过什么？又会什么？</strong>”<br>悉：“<strong>我会思考。我会等待。我会斋戒。</strong>”<br>迦：“就这些？”<br>悉：“我想，就是这些！”<br>迦：“这些有何用处？比如斋戒——<strong>斋戒有何益处？</strong>”<br>悉：“斋戒极好，先生。对于没有食物的人，斋戒最为明智。假如悉达多没学过斋戒，他今天就必须寻找活计。不论在你这里，还是别处。饥饿迫使他行动。而事实上，悉达多能安静地等待。他从不焦急，从不陷于窘迫。即使长时间被饥饿围困，他仍能藐视饥饿。因此，先生，斋戒极好。”<br>迦：“你说得对，沙门。请稍等片刻。”</p>
</blockquote>
</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><div id="refer-anchor-1"></div>

<p>[1]<br><a class="link"   href="https://podcasts.apple.com/cn/podcast/%E6%96%87%E5%8C%96%E6%9C%89%E9%99%90/id1482731836?i=1000583749302" >文化有限 - Vol.149 悉达多：什么是人生的自洽<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>阅读</category>
        <category>摘录</category>
      </categories>
      <tags>
        <tag>悉达多</tag>
        <tag>修行</tag>
      </tags>
  </entry>
  <entry>
    <title>《悉达多》—— 摘录2</title>
    <url>/2023/06/01/book/book-excerpt-2/</url>
    <content><![CDATA[<h1 id="🔦前言"><a href="#🔦前言" class="headerlink" title="🔦前言"></a>🔦前言</h1><ul>
<li><p>最近工作状态很差，具体表现在面对一项大而繁复的工作时迟迟不能下手。</p>
<ul>
<li>我会想象到，自己像是村里第一次准备杀猪的年轻人。走到猪圈前，推开门。看到那头猪正在吃着最后一顿饲料。那头猪很庞大，比我还高，比我还重，灰黑色的皮肤上长着稀疏的毛。尽管我拿着一把锋利的刀，但一旦站在这里，看着那头猪，就会突然觉得自己没有办法胜任这项工作。</li>
<li>尽管脑子里想象过无数次自己要怎么做：先要把那头猪引出来，然后用绳子绑住它的四条腿，让它倒在地上。然后要用刀在它的喉咙上划开一个口子，让血流出来。然后要等血流干净了，再用火把它的毛烧掉。然后要用刀把它的皮割开，把内脏取出来。然后要把内脏清洗干净，分成可以吃的和不能吃的。然后要把肉切成块，剔掉骨头。然后要用盐和香料腌制肉块，晾干或者熏制成香肠和腊肉。</li>
<li>这些事情太复杂太困难了。我不知道自己能不能做好。我怕自己会伤到自己或者伤到那头猪。我怕自己会浪费掉那头猪的血和肉。我怕自己会做出不好吃的东西。我怕自己会让家人和亲戚失望。</li>
</ul>
</li>
<li><p>看到悉达多成为一名苦行僧，我也在询问自己，是否只是心里的顾虑太多，是否只是不敢吃苦不敢挑战自己。看完这一部分后突发奇想，也许我也可以短暂地尝试苦行僧的方式，先把自己的所有顾虑、担忧乃至所有情绪，先把任务完成再说。</p>
</li>
</ul>
<h1 id="🪟摘录"><a href="#🪟摘录" class="headerlink" title="🪟摘录"></a>🪟摘录</h1><ol>
<li>当作为贵族的悉达多享受着周围人的赞美时，却觉得很空虚，他觉得自己学到了所有名家所能传授的知识，但仍然不能获得有关终极的答案，于是跟随沙门开始了苦修之路。<blockquote>
<p>悉达多从沙门处学到很多。他学会诸多克己之方法。他通过受苦，志愿受苦和战胜疼痛、饥饿、焦渴和疲惫，走向克己。<strong>他通过禅定，通过在一切表象前心神凝定走向克己。</strong></p>
<p>他学会诸多修炼之道。他曾千百次摆脱“我”。他曾整时整日停驻在无“我”中。这些修行均从“我”出发，终点却总是回归于“我”。</p>
<p>尽管悉达多千百次弃绝“我”，逗留在虚无中，化为动物、石头，回归却不可避免。重归于“我”无法摆脱。在阳光中、月华下，在遮荫处和雨中，他重新成为“我”，成为悉达多，重新忍受轮回赋予的折磨。</p>
</blockquote>
</li>
</ol>
<ul>
<li>姜乙老师的翻译很优美，从这一段文字中竟然也能轻易看懂原以为深奥的沙门修炼方式。</li>
</ul>
<ol start="2">
<li>在此之后，当他轻易地从一众沙门中脱颖而出，成为老沙门最看好的后辈时，他又对沙门的修行之路产生了质疑。因此，出现了以下与他的好友乔文达的对话：<blockquote>
<p>“你怎么看，乔文达？”在一次乞食途中，悉达多问，“你认为我们有进步吗？我们实现了目标吗？”</p>
<p>乔文达答：“我们学了不少。我们依然在学。你将成为伟大的沙门，悉达多。沙门长老常常赞叹，你学什么都快。你将成为圣人，哦，悉达多。”</p>
<p>悉达多道：“我并不这么看，我的朋友。至今我在沙门处学到的东西，乔文达，我本可以更快更便捷地学到。在花街柳巷的酒馆里，我的朋友，在脚夫和赌徒处，我都能学到。”</p>
<p>乔文达道：“悉达多你是在和我说笑。你怎么可能在那些贫乏者中学会禅定，学会屏息敛气，学会忍受饥饿和痛苦？”</p>
<p>悉达多轻声道，仿佛自言自语：“禅定是什么？什么是脱离肉体？斋戒是什么？什么是屏息敛气？<strong>那不过是逃避‘我’，是暂时从‘我’的折磨中逃出来，是对生命的虚无和痛苦的暂时麻醉。</strong>这种逃避、麻醉，即使是驱牛者也能在客栈中找到。他只消喝上几杯米酒或发酵的椰子奶就能忘掉自己。他将感受不到生活的痛苦，他被暂时麻醉，在米酒的杯盏间昏沉入睡。他同样能获得悉达多和乔文达通过长久休息才获得的弃绝肉体与停留在无‘我’中的感受。就是这样，乔文达。”</p>
<p>乔文达道：“你这样说，哦，朋友，你当然知道，悉达多不是驱车牛夫，沙门也不是酒鬼。酗酒者可以被麻醉，他可以获得短暂的逃避和休憩，但当他从幻觉中醒来时会发现一切依旧。他没有成为智者，没有积累知识，也没有进入更高的境界。”</p>
<p>悉达多含笑道：“我不知道。我从不是酒鬼，但是我，悉达多，在休息和禅定中只收获短暂的麻醉。我仍似一个在子宫内的婴孩，距离开悟、解脱十分遥远。这我知道。乔文达，这我知道。”</p>
</blockquote>
</li>
</ol>
<ul>
<li>读完这段的我尚难以理解悉达多的追求，至少对目前的我来说，是需要通过这样的禅定和修行来获取内心平静的。</li>
</ul>
<hr>
<p>你有什么关于这个问题的经验或建议吗？欢迎留言告诉我。</p>
<p>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</p>
]]></content>
      <categories>
        <category>阅读</category>
        <category>摘录</category>
      </categories>
      <tags>
        <tag>悉达多</tag>
        <tag>修行</tag>
      </tags>
  </entry>
  <entry>
    <title>【AI】AI-Infra框架初识：从vLLM到SGLang、Aibrix与Mooncake的性能革命</title>
    <url>/2025/09/03/ai/ai-infra-frameworks-introduction/</url>
    <content><![CDATA[<h1 id="背景简介：为何需要AI-Infra框架？从大模型推理的痛点说起"><a href="#背景简介：为何需要AI-Infra框架？从大模型推理的痛点说起" class="headerlink" title="背景简介：为何需要AI-Infra框架？从大模型推理的痛点说起"></a>背景简介：<strong>为何需要AI-Infra框架？从大模型推理的痛点说起</strong></h1><p>大语言模型（LLM）的兴起使其从科研领域走向了实际应用。这些强大的模型在实际部署和应用中，需要专门的“AI基础设施框架”（AI-Infra）来保障其高效、稳定地运行。这些框架是LLM从研究走向工业级应用的关键。</p>
<blockquote>
<p>上个月sglang-v0.3.0和vllm-v0.6.0前后脚发布之后（注：该文章发布时间为2024.10），就一直想总结梳理一下现在主流的大模型推理引擎。因为我觉得这也算是一个有意义的节点吧，从此开源大模型推理引擎总算是由”非常粗糙，但是能用”的阶段迈入到了”好用，稍微有那么点粗糙”的阶段。</p>
<p>大模型的推理引擎实际也就是近一两年才开始飞速发展，从最开始的tgi和vllm并驾齐驱到如今sglang、lmdeply的异军突起，整个开源社区都是非常有活力的。</p>
<p>但是正如之前所说，从长远的一个视角看如今的开源引擎实际上都还是比较粗糙的，大家都是在摸索中前进。另一方面也是因为现在全世界的目光都聚焦在llm这里，新技术的更新换代太快了，做好一个大模型的推理引擎要做的事情实在是太太太太多了。除了要支持日新月异的<strong>新模型和新硬件</strong>，还要不断关心学术界最新的paper并且想方设法落地实现。而这些新的想法可能涉及到<strong>模型结构、计算策略、调度策略、存储策略、cuda内核、硬件加速</strong>等各个层级，这就需要开发者有非常广泛的知识范围和过硬的工程能力。</p>
<p>我一直认为大模型推理引擎最难的地方就在于：对模型和硬件的广泛支持以及如何将各种角度的不同优化方法兼容实现。因为写paper的人可以只关心他自己的idea，在transformer库的基础上写个简单demo就行，但是在推理引擎里落地的时候往往就会与其它模块有冲突，需要想办法去做各种兼容。退一步说，即使没有冲突的情况，你也需要对其他基础的优化比较熟悉，你才能在这些的基础上完成新功能的开发。</p>
<p>——开源大模型推理引擎现状及常见推理优化方法 - 齐夏的文章 - 知乎 <a class="link"   href="https://zhuanlan.zhihu.com/p/755874470" >https://zhuanlan.zhihu.com/p/755874470<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</blockquote>
<p>在AI-Infra框架出现之前，大语言模型的实际部署和应用，尤其是推理环节，面临着一系列严峻的挑战。这些挑战不仅关乎性能，也关乎成本和效率，它们是催生AI-Infra框架的根本原因。</p>
<h2 id="1-1-GPU显存挑战：显存占用与内存碎片化"><a href="#1-1-GPU显存挑战：显存占用与内存碎片化" class="headerlink" title="1.1 GPU显存挑战：显存占用与内存碎片化"></a><strong>1.1 GPU显存挑战：显存占用与内存碎片化</strong></h2><p>大语言模型的核心是Transformer架构，其推理过程大致分为两个阶段：预填充（Prefill）和解码（Decode）。在解码阶段，模型需要逐个生成新的词元（token），而每一次生成，都需要访问前面所有词元的“键值缓存”（KV Cache），这部分数据占据了大量的GPU显存<a href="#refer-anchor-1"><sup>[1]</sup></a>。随着模型规模和用户请求数量的增加，GPU的显存常常爆满<a href="#refer-anchor-1"><sup>[1]</sup></a>。</p>
<p>更棘手的问题是内存碎片化。传统的推理方法在为每个用户会话分配KV Cache时，会预留一个连续的、固定的内存块。然而，用户请求的文本长度是动态的，当会话结束或内容比预分配的短时，就会产生大量无法被其他请求利用的零散显存碎片。这导致了显存资源的巨大浪费，严重影响了GPU的利用率。</p>
<h2 id="1-2-吞吐量挑战：处理大规模并发请求的挑战"><a href="#1-2-吞吐量挑战：处理大规模并发请求的挑战" class="headerlink" title="1.2 吞吐量挑战：处理大规模并发请求的挑战"></a><strong>1.2 吞吐量挑战：处理大规模并发请求的挑战</strong></h2><p>除了显存问题，另一个核心挑战是吞吐量瓶颈，即单位时间内能够处理的请求数量。传统的推理架构在处理并发请求时效率低下。例如，串行批处理（static batching）会等待一组请求全部完成输入后，再一起进行推理计算。如果批处理中的某个请求很长，其他所有请求都必须等待它完成，这导致了GPU计算资源在大部分时间内处于闲置状态，整体吞吐量无法有效提升<a href="#refer-anchor-1"><sup>[2]</sup></a>。</p>
<p>此外，传统的无状态推理架构在处理LLM应用时面临性能瓶颈：每次请求被随机路由到不同的计算实例，导致KV Cache无法有效复用、多轮对话上下文频繁重建、系统提示词重复处理，这严重影响了用户体验和系统效率<a href="#refer-anchor-1"><sup>[3]</sup></a>。这表明，通用的云计算架构在LLM这种特定工作负载面前，不再是最优解。</p>
<h2 id="1-3-复杂应用场景挑战：从简单对话到程序化调用"><a href="#1-3-复杂应用场景挑战：从简单对话到程序化调用" class="headerlink" title="1.3 复杂应用场景挑战：从简单对话到程序化调用"></a><strong>1.3 复杂应用场景挑战：从简单对话到程序化调用</strong></h2><p>早期的大模型应用以简单的单轮对话为主。但随着应用的发展，LLM的使用方式变得更加复杂，例如LLM参与多轮规划、推理以及与外部环境的交互等场景<a href="#refer-anchor-1"><sup>[4]</sup></a>。这些新的使用模式不再是简单的单轮对话形式，而是需要包含多个LLM调用，这些调用之间穿插着控制流，并且需要接收和产生结构化的输入和输出（比如JSON格式）<a href="#refer-anchor-1"><sup>[4]</sup></a>。</p>
<p>传统的推理引擎主要针对单次、无状态的推理进行优化，难以高效地处理这种复杂的“程序化调用”（LM Programs）范式。开发者必须在外部手动管理状态、编排调用顺序，这不仅繁琐，而且难以实现端到端的性能优化<a href="#refer-anchor-1"><sup>[4]</sup></a>。</p>
<h1 id="脉络梳理：AI-Infra框架的演进脉络与核心解法"><a href="#脉络梳理：AI-Infra框架的演进脉络与核心解法" class="headerlink" title="脉络梳理：AI-Infra框架的演进脉络与核心解法"></a>脉络梳理：<strong>AI-Infra框架的演进脉络与核心解法</strong></h1><p>针对前面提到的三大痛点，AI-Infra框架领域出现了一系列解决方案。</p>
<h2 id="2-1-vLLM：内存管理上的创新"><a href="#2-1-vLLM：内存管理上的创新" class="headerlink" title="2.1 vLLM：内存管理上的创新"></a><strong>2.1 vLLM：内存管理上的创新</strong></h2><blockquote>
<p>vllm原本只是作为PagedAttention的一个开源实现，但发展到今天已经成为llm推理引擎的标杆了。</p>
</blockquote>
<p>vLLM是AI-Infra框架中一个代表性的框架<a href="#refer-anchor-1"><sup>[5]</sup></a>，团队来自UC Berkeley。</p>
<ul>
<li><p><strong>技术：</strong>&#x5B83;率先对底层推理效率进行了优化。vLLM的核心贡献在于其独创的  <strong>PagedAttention</strong>技术，这一技术旨在高效管理注意力键和值的内存<a href="#refer-anchor-1"><sup>[6]</sup></a>。vLLM将KV Cache分割成多个离散的“块”（block），这些“块”可以根据需要动态地分配和管理。通过这种方式，vLLM解决了KV Cache显存碎片化的问题，显著提高了显存的利用率，使得GPU能够同时处理更多的并发请求，从而大幅提升了整体吞吐量<a href="#refer-anchor-1"><sup>[6]</sup></a>。</p>
</li>
<li><p><strong>优势：</strong>&#x76;LLM有着大量且稳定的开发者，Github上Contributors已经1500+人了，相比于SGLang的663人、Aibrix的75人、TensorRT的79人、Mooncake的84人，vLLM的开发人员投入是最高的。因此vLLM对模型的支持和对硬件的支持都是最完善的，以及各种功能也往往是最齐全的。<a href="#refer-anchor-1"><sup>[14]</sup></a></p>
</li>
</ul>
<p>vLLM的出现，让大模型的在线服务效率达到了一个全新的高度，也为后续的框架发展奠定了基础<a href="#refer-anchor-1"><sup>[7]</sup></a>。目前，vLLM的社区活跃度是最高的，github上issue和pr都很多，且大量paper都是以vLLM作为baseline来开发demo。</p>
<h2 id="2-2-SGLang：面向复杂应用场景的编程范式"><a href="#2-2-SGLang：面向复杂应用场景的编程范式" class="headerlink" title="2.2 SGLang：面向复杂应用场景的编程范式"></a><strong>2.2 SGLang：面向复杂应用场景的编程范式</strong></h2><p>SGLang也来自UC Berkeley，但是跟vLLM是不同的一拨人，核心团队基本都是交大的<a href="#refer-anchor-1"><sup>[14]</sup></a>（另有说法为：很多人都是vLLM的作者<a href="#refer-anchor-1"><sup>[4]</sup></a>）。</p>
<p>当vLLM解决了底层的显存和吞吐量问题后，SGLang将关注点提升到了更高层面的应用场景<a href="#refer-anchor-1"><sup>[4]</sup></a>。它专注于解决前文提到的“复杂应用场景：程序化调用”挑战，即如何让开发者能够像编写传统软件一样，编排复杂的LLM应用逻辑<a href="#refer-anchor-1"><sup>[4]</sup></a>。</p>
<ul>
<li><p><strong>技术：</strong>&#x53;GLang的核心思想是采用一种<strong>编译器设计</strong>的理念。它引入了一个“前端语言”和“后端运行时”协同设计的模式，允许开发者在框架内直接编写多步LLM调用和控制流，例如循环和条件判断<a href="#refer-anchor-1"><sup>[8]</sup></a>。这使得LLM能够更高效地处理工具使用、多轮推理和结构化生成等任务<a href="#refer-anchor-1"><sup>[8]</sup></a>。SGLang的这种设计，可以从根本上优化多对多的输入输出，并进行端到端的性能优化<a href="#refer-anchor-1"><sup>[4]</sup></a>。SGLang通过其RadixAttention技术，实现了对KV Cache的高效复用<a href="#refer-anchor-1"><sup>[8]</sup></a>。</p>
</li>
<li><p><strong>优势：</strong>&#x53;GLang的代码可拓展性很高，主流功能都有支持的情况下，代码比vLLM清晰简单很多，这对于二次开发来说是很重要的。社区活跃度虽然比不上vLLM，但是作者都很积极地回复issue。<a href="#refer-anchor-1"><sup>[14]</sup></a></p>
</li>
</ul>
<p>SGLang的出现，标志着AI-Infra框架开始从单纯的“性能优化”走向“应用范式创新”，它让LLM成为了一个可以被深度集成到复杂软件系统中的“计算单元”<a href="#refer-anchor-1"><sup>[4]</sup></a>。</p>
<h2 id="2-3-Aibrix与Mooncake：面向大规模部署的系统级创新"><a href="#2-3-Aibrix与Mooncake：面向大规模部署的系统级创新" class="headerlink" title="2.3 Aibrix与Mooncake：面向大规模部署的系统级创新"></a><strong>2.3 Aibrix与Mooncake：面向大规模部署的系统级创新</strong></h2><p>当LLM的应用从单机走向大规模集群部署时，新的挑战随之出现。vLLM和SGLang主要解决了单机或少量GPU环境下的效率问题，但面对大规模集群，就需要新的系统级解决方案。Aibrix和Mooncake的出现正是为了解决这一问题，它们将关注点从“引擎内部”转移到了“集群系统层面”<a href="#refer-anchor-1"><sup>[10]</sup></a>。</p>
<p><strong>Aibrix（来自字节跳动）</strong>&#x662F;一个云原生的开源框架，其核心使命是简化和优化大规模LLM在云环境中的部署<a href="#refer-anchor-1"><sup>[11]</sup></a>。它并非一个全新的推理引擎，而是一个协同vLLM等引擎运行的“控制平面”（Control Plane）<a href="#refer-anchor-1"><sup>[5]</sup></a>。Aibrix负责集群层面的资源调度、自适应扩缩容、负载均衡以及智能路由等任务<a href="#refer-anchor-1"><sup>[11]</sup></a>。根据一项实验数据，Aibrix的扩缩容响应时间可加速82%<a href="#refer-anchor-1"><sup>[5]</sup></a>。此外，Aibrix还引入了针对低秩适配（LoRA）模型的高密度管理，支持动态调度和加载LoRA适配器<a href="#refer-anchor-1"><sup>[11]</sup></a>。</p>
<p><strong>Mooncake（为Kimi服务的平台，由MoonshotAI提供，论文获FAST’25最佳论文奖）</strong>&#x5219;是一个专门为LLM推理场景设计的<strong>分布式KV Cache存储系统</strong><a href="#refer-anchor-1"><sup>[10]</sup></a>。它解决了在集群环境中，KV Cache无法在不同计算节点之间高效共享和复用的问题。Mooncake的核心是其“全局缓存+分离式推理架构”（KVCache-centric disaggregated architecture），它将预填充和解码的计算集群与KV Cache的存储集群分离<a href="#refer-anchor-1"><sup>[12]</sup></a>。通过聚合集群中未被充分利用的CPU、DRAM甚至SSD资源，Mooncake形成了一个统一的分布式内存池，供所有节点共享KV Cache<a href="#refer-anchor-1"><sup>[10]</sup></a>。这种设计使得计算资源可以根据负载动态增减，而KV Cache则可以在独立的存储池中持久化，并被所有节点复用，这对于长上下文、多轮对话场景尤其重要，能显著提升吞吐量和资源利用率<a href="#refer-anchor-1"><sup>[12]</sup></a>。</p>
<p>Aibrix和Mooncake的出现，反映了LLM应用已经进入大规模工业化生产阶段，关注点从单纯的性能，扩展到了成本、可扩展性和服务质量。</p>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://pic1.zhimg.com/v2-9c4fc47e5c35538026efc1d247d5ea4c_1440w.jpg"
                      alt="图1：Airbrix"
                ><figcaption>图1：Airbrix</figcaption></figure></p>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://pic2.zhimg.com/v2-6b57ab25c4f74cabe76ce186d7f630a9_1440w.jpg"
                      alt="图2：Mooncake"
                ><figcaption>图2：Mooncake</figcaption></figure></p>
<h1 id="框架横向对比：各自的定位与优劣"><a href="#框架横向对比：各自的定位与优劣" class="headerlink" title="框架横向对比：各自的定位与优劣"></a><strong>框架横向对比：各自的定位与优劣</strong></h1><p>通过以上分析，我们可以看到AI-Infra框架的主要生态系统。为了更清晰地理解它们的定位和特点，本节将通过表格形式对几个主要框架进行对比。同时，我们还引入一个来自硬件厂商的代表——NVIDIA的TensorRT-LLM，来展示不同的技术路径。</p>
<h2 id="主流AI-Infra框架能力对比"><a href="#主流AI-Infra框架能力对比" class="headerlink" title="主流AI-Infra框架能力对比"></a><strong>主流AI-Infra框架能力对比</strong></h2><table>
<thead>
<tr>
<th><strong>框架名称</strong></th>
<th><strong>核心解决问题</strong></th>
<th><strong>关键技术</strong></th>
<th><strong>典型应用场景</strong></th>
<th><strong>优点</strong></th>
<th><strong>局限性</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>vLLM</strong></td>
<td>单机显存管理</td>
<td>PagedAttention，连续批处理</td>
<td>高性能API服务，单机部署</td>
<td>吞吐量高，易用性强，社区活跃<a href="#refer-anchor-1"><sup>[6]</sup></a></td>
<td>主要为单机引擎，集群扩展能力有限</td>
</tr>
<tr>
<td><strong>SGLang</strong></td>
<td>复杂应用编程与结构化生成</td>
<td>编译器设计，RadixAttention</td>
<td>复杂Agent，工具调用，多轮对话</td>
<td>支持复杂逻辑编排，编程范式友好<a href="#refer-anchor-1"><sup>[8]</sup></a></td>
<td>相对vLLM，底层性能优化空间可能略小</td>
</tr>
<tr>
<td><strong>Aibrix</strong></td>
<td>大规模集群资源管理与扩展</td>
<td>LLM专用自适应扩缩容，高效LoRA管理</td>
<td>大规模企业级生产环境部署</td>
<td>系统级优化，弹性高，降低成本<a href="#refer-anchor-1"><sup>[5]</sup></a></td>
<td>非核心推理引擎，需与vLLM等配合使用<a href="#refer-anchor-1"><sup>[5]</sup></a></td>
</tr>
<tr>
<td><strong>Mooncake</strong></td>
<td>分布式KV Cache与长上下文</td>
<td>KVCache分离式架构</td>
<td>长上下文场景，多机KV Cache共享</td>
<td>高效利用集群资源，支持超长上下文<a href="#refer-anchor-1"><sup>[12]</sup></a></td>
<td>纯缓存系统，需与引擎配合使用<a href="#refer-anchor-1"><sup>[10]</sup></a></td>
</tr>
<tr>
<td><strong>TensorRT-LLM</strong></td>
<td>极致单机性能与低延迟</td>
<td>量化，层/张量融合，CUDA内核优化</td>
<td>实时交互应用，边缘设备部署</td>
<td>性能高，延迟低，针对NVIDIA硬件深度优化<a href="#refer-anchor-1"><sup>[13]</sup></a></td>
<td>强硬件（NVIDIA）依赖性，通用性差<a href="#refer-anchor-1"><sup>[13]</sup></a></td>
</tr>
</tbody></table>
<p>从上表可以看出，这些框架并非相互替代，而是在不同层级上进行互补。</p>
<ul>
<li><p>vLLM和SGLang是“引擎层”的框架，专注于模型执行效率和应用逻辑；</p>
</li>
<li><p>而Aibrix和Mooncake则是“系统层”的框架，专注于集群管理和资源调度；</p>
</li>
<li><p>TensorRT-LLM则代表了一种由硬件厂商主导的、从底层进行优化的路径，它通过对NVIDIA硬件的深度适配，实现了超高的性能，但代价是牺牲了通用性和跨硬件的兼容性<a href="#refer-anchor-1"><sup>[13]</sup></a>。</p>
</li>
</ul>
<p>这种分层发展的趋势，反映了AI-Infra领域发展的成熟度。当底层引擎的性能问题得到解决后，开发者们会将目光投向更高层面的应用编程和大规模部署，而这些新挑战又催生了新一轮的框架创新。</p>
<hr>
<hr>
<ul>
<li>希望这篇博客对你了解AI-Infra框架有所帮助！如果你有任何问题或需要进一步的讨论，欢迎随时交流。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="🗺️参考文献"><a href="#🗺️参考文献" class="headerlink" title="🗺️参考文献"></a>🗺️参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://ppio.com/blogs/post/da-mo-xing-tui-li-cheng-ben-mei-nian-jiang-di-10bei-de-mi-mi-yi-wen-liao-jie-vllm-sglangdeng-zhu-liu-tui-li-yin-qing" >[1] 大模型推理成本每年降低10倍的秘密：一文了解vLLM、SGLang等主流推理引擎 - PPIO<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://blog.csdn.net/lqfarmer/article/details/140906949" >[2] 从vLLM到大模型推理的最新进展_vllm复现-CSDN博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://aws.amazon.com/cn/blogs/china/accelerating-inference-on-llm-with-amazon-sagemaker-sticky-sessions/" >[3] 利用Amazon SageMaker Sticky Session 实现大语言模型推理加速 | 亚马逊AWS官方博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://aijishu.com/a/1060000000476318" >[4] SGLang：LLM推理引擎发展新方向- 极术社区- 连接开发者与智能计算 …<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://www.infoq.cn/article/ncbudc3vvp8kignttiof" >[5] 字节跳动开源AIBrix：填补云原生大模型推理“系统层”空白 - InfoQ<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://vllm.hyper.ai/docs/" >[6] 欢迎来到vLLM！ | vLLM 中文站<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://www.high-flyer.cn/blog/continuous-batching/" >[7] Continuous Batching：一种提升LLM 部署吞吐量的利器 - 幻方<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://blog.csdn.net/2401_85280106/article/details/147835433" >[8] 学习笔记：主流大模型框架对比分析（Ollama、vLLM、SGlang …,  <i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://qwen.readthedocs.io/zh-cn/latest/deployment/sglang.html" >[9] SGLang - Qwen - Read the Docs<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://docs.lmcache.ai/kv_cache/mooncake.html" >[10] Mooncake | LMCache<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://arxiv.org/html/2504.03648v1" >[11] AIBrix: Towards Scalable, Cost-Effective Large Language Model Inference Infrastructure<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://github.com/kvcache-ai/Mooncake" >[12] Mooncake is the serving platform for Kimi, a leading LLM service provided by Moonshot AI. - GitHub<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://developer.nvidia.cn/tensorrt" >[13] NVIDIA TensorRT - NVIDIA 开发者<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://zhuanlan.zhihu.com/p/755874470" >[14] 2024年-开源大模型推理引擎现状及常见推理优化方法 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://aibrix.readthedocs.io/latest/community/research.html" >[15] Research Collaboration - AIBrix - Read the Docs<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://doi.org/10.1145/3600006.3613165" >[16] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient Memory Management for Large Language Model Serving with PagedAttention. In Proceedings of the 29th Symposium on Operating Systems Principles (SOSP ‘23). Association for Computing Machinery, New York, NY, USA, 611–626.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://zhuanlan.zhihu.com/p/27872556474" >[17] 【深度解读FAST’25最佳论文Mooncake】：存储为中心的大语言模型推理架构 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link"   href="https://zhuanlan.zhihu.com/p/25874756271" >[18] 字节跳动开源AIBrix：一个可扩展、经济高效的vLLM控制平面 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>AI基础设施</tag>
        <tag>推理优化</tag>
        <tag>vLLM</tag>
        <tag>SGLang</tag>
      </tags>
  </entry>
  <entry>
    <title>【CPN】算力网络工业界现状</title>
    <url>/2023/08/30/literature/CPN/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><ul>
<li>“算力网络“是“以网络为中心”的多种融合资源供给网络计算模型，将“新计算”（云计算、边缘计算、泛在计算）的算力，通过“新联接”（无处不在的网络）整合起来，实现算力的灵活按需使用。 泛在、异构的算力资源，支持中心云、边缘云，多云资源的统一注册接入，为算力运营层屏蔽多云差异。</li>
<li>与传统云计算的区别，是将横向上各个地域的计算资源、纵向上云边端各个层级的计算资源进行整合融合，以一个整体的形式为用户提供服务。</li>
<li>简单调研了国内外各个大厂在该方面的产品，简单做一个汇总。</li>
</ul>
<h1 id="华为云-1"><a href="#华为云-1" class="headerlink" title="华为云[1]"></a>华为云<a href="#refer-anchor-1"><sup>[1]</sup></a></h1><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://siteprod-s3-cdn.kyligence.io/2021/12/1640859274-Huawei_Video_Poster.jpg" alt="华为云"><figcaption>华为云</figcaption></figure></p>
<h2 id="🎤关键词"><a href="#🎤关键词" class="headerlink" title="🎤关键词"></a>🎤关键词</h2><ul>
<li>东数西算、全球存算网</li>
</ul>
<h2 id="🔨产品简介"><a href="#🔨产品简介" class="headerlink" title="🔨产品简介"></a>🔨产品简介</h2><ul>
<li>华为云在“构建全球存算网”“加速应用现代化”“使能产业上云”三个方面开展了创新实践。</li>
<li>为满足未来数字经济发展对海量算力和存储的需求，华为云构建了<strong>全球存算网KooVerse</strong>，为客户提供全球一致体验的计算、存储、网络等基础设施服务。<ul>
<li>数据管理方面，华为云KooVerse通过CloudOcean、CloudSea和CloudLake三层架构，打造30ms的时延覆盖圈，以满足企业业务的不同时延要求。<ul>
<li>在贵州、内蒙古、安徽等地建设了CloudOcean云核心枢纽，规划建设的服务器规模均达到百万台以上，并通过科技创新与自然优势相结合，为客户提供更加充沛、绿色、高效的云服务。</li>
</ul>
</li>
<li>算力管理方面，华为云还提出了KooVerse Regionless架构，让应用自动地运行在多Region数据中心，从而进一步发挥不同Region基础设施带来的优势，提高应用的运行效率。</li>
</ul>
</li>
</ul>
<h2 id="🧠产品特点"><a href="#🧠产品特点" class="headerlink" title="🧠产品特点"></a>🧠产品特点</h2><ul>
<li>构建全球存算网，让算力无处不在，让数据高效存储</li>
</ul>
<h1 id="阿里云-2"><a href="#阿里云-2" class="headerlink" title="阿里云[2]"></a>阿里云<a href="#refer-anchor-2"><sup>[2]</sup></a></h1><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://picx.zhimg.com/v2-55a246097596e85a2700e2623714078e_720w.jpg?source=172ae18b" alt="阿里云"><figcaption>阿里云</figcaption></figure></p>
<h2 id="🎤关键词-1"><a href="#🎤关键词-1" class="headerlink" title="🎤关键词"></a>🎤关键词</h2><ul>
<li>东数西算、云网协同、泛在、云网络</li>
</ul>
<h2 id="🔨产品简介-1"><a href="#🔨产品简介-1" class="headerlink" title="🔨产品简介"></a>🔨产品简介</h2><ul>
<li>落实东数西算，需要推进云网协同和算力网络建设，而算力网络本质是解决全局算力资源接入和调度的问题，根据业务需求，在云、网、边之间按需分配和灵活调度计算资源、存储资源以及网络资源的新型信息基础设施。因此，应对算力的泛在化、多样化、服务化，网络调度需要更加弹性、更加敏捷、更加智能。<ul>
<li>算力网络首先要解决的是全网算力资源和应用的连接问题。将现有的网络基础设施和新型算力网络进行统一融合，实现一网接入各级算力资源。这对网络提出了两点新的诉求：一是需要网络无处不达，提供从中线到边缘以及更多的全场景的接入能力让算力资源可以便捷接入；二是需要提供一致的网络体验、一致的管理能力，覆盖从接入网络到跨地域互联网络再到云上网络，从而保障应用连接一致的丝滑体验。</li>
<li>算力网络也要解决算力资源和算力需求不均衡的问题。现有的算力主要由中心算力枢纽、边缘算力集群和其他算力节点组成，算力的分布从架构、地域上存在一定的不均衡性。因此，需要算力网络提供跨域弹性调度的能力，连接云/本地-边-端多级算力池，并能够快速进行跨域扩展。另一方面，算力网络还要具备带宽的弹性扩展能力，来承载多种算力应用场景的宽带宽需求，例如SLA的高可靠性、规模的伸缩性、时段的高峰性等。</li>
</ul>
</li>
</ul>
<h2 id="🧠产品特点-1"><a href="#🧠产品特点-1" class="headerlink" title="🧠产品特点"></a>🧠产品特点</h2><ul>
<li><strong>洛神云网络</strong>是阿里云飞天云操作系统核心组件。<ul>
<li>飞天洛神云网络的发展和未来方向，与算力网络的愿景不谋而合。</li>
<li>算力网络从底层的算力资源池出发，进行算力标准化和算力抽象；通过应用感知的算力调度来进行统一算力服务，来支撑顶层的算力交易平台服务行业应用。对应到洛神云网络的技术架构，最底层的完整覆盖应用-云-边-端一体的算力网络产品。在之上的云企业网的全球化智能云网调度，通过深度融合应用的云网络产品能力，已经支撑了公共服务、行业创新、科研教育等客户服务。其中，任意规模的分钟级全网链路监测可以实时监测算力节点在网情况，刷新全网算力资源地图；毫秒级虚拟网络拓扑查询可以快速排除算网故障，提高算力在网时间和使用效率。可以说，阿里云飞天洛神云网络，是算力网络架构的有力探索。</li>
</ul>
</li>
</ul>
<h1 id="亚马逊-3"><a href="#亚马逊-3" class="headerlink" title="亚马逊[3]"></a>亚马逊<a href="#refer-anchor-3"><sup>[3]</sup></a></h1><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/Amazon_Web_Services_Logo.svg/2880px-Amazon_Web_Services_Logo.svg.png" alt="亚马逊"><figcaption>亚马逊</figcaption></figure></p>
<h2 id="🎤关键词-2"><a href="#🎤关键词-2" class="headerlink" title="🎤关键词"></a>🎤关键词</h2><ul>
<li>全球云基础设施</li>
</ul>
<h2 id="🔨产品简介-2"><a href="#🔨产品简介-2" class="headerlink" title="🔨产品简介"></a>🔨产品简介</h2><ul>
<li>近年来，越来越多的中国企业选择了扬帆出海，针对全球市场开展业务和布局，这自然也对企业的IT架构提出了更为严苛的要求。</li>
<li>亚马逊云科技可以提供从中心到边缘的多种产品的解决方案，包括覆盖全球的基础架构，快速部署稳定系统的能力，以及全面支持全球各个国家和地区业务合规能力。</li>
</ul>
<h2 id="🧠产品特点-2"><a href="#🧠产品特点-2" class="headerlink" title="🧠产品特点"></a>🧠产品特点</h2><ol>
<li><p>无处不在的云服务：截至目前为止，亚马逊云科技在全球拥有31个区域的99个可用区，覆盖了245个国家和地区。其提供的高度安全可靠的云基础架构，让创新能够快速抵达每一个角落，为客户提供支持业务创新的算力，并且能够很好地支持客户的全球化布局战略，让客户可以随时随地使用一致的基础设施、服务、API和工具。</p>
</li>
<li><p>快速部署可靠系统的能力：从理论上来说，所有的功能模块都有可能出故障。亚马逊云科技虽然不能完全避免故障的发生，但是可以通过区域隔离，多可用区设计、控制面和数据面解耦、蜂窝架构、随机分片、服务责任模型、运营就绪审查、安全持续部署、COE纠错流程等多种努力，尽可能地将风险降至最低。</p>
</li>
<li><p>支持全球各个国家和地区业务合规能力：亚马逊云科技支持143项安全标准与合规认证，拥有超过300种安全合规服务，几乎可以满足全球所有监管机构的合规性要求，从而能够帮助各行各业的客户更方便快速地搭建满足全球各地安全和合规要求的架构。</p>
</li>
</ol>
<h1 id="微软-4"><a href="#微软-4" class="headerlink" title="微软[4]"></a>微软<a href="#refer-anchor-4"><sup>[4]</sup></a></h1><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://img-blog.csdnimg.cn/20210310122406194.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2FjaHVhbjIwMTU=,size_16,color_FFFFFF,t_70" alt="微软云"><figcaption>微软云</figcaption></figure></p>
<h2 id="🎤关键词-3"><a href="#🎤关键词-3" class="headerlink" title="🎤关键词"></a>🎤关键词</h2><ul>
<li>多云与混合云</li>
</ul>
<h2 id="🔨产品简介-3"><a href="#🔨产品简介-3" class="headerlink" title="🔨产品简介"></a>🔨产品简介</h2><ul>
<li><strong>Azure Arc</strong>是微软混合云解决方案的最新进展。 2022年3月10日，微软宣布计划在2022年上半年，面向中国市场推出Azure Arc混合云与多云管理解决方案，结合此前已经发布的Azure Stack系列混合云解决方案，可为中国企业构建无处不在的云，进而提供数字化转型路径。</li>
<li>如今，公司都在努力控制和治理跨数据中心、多个云和边缘的日益复杂的环境。每个环境和云都有自己的一套管理工具，新的 DevOps 和 ITOps 运营模型可能很难跨资源实施。</li>
<li>Azure Arc 通过提供一致的多云和本地管理平台来简化治理和管理。</li>
<li>Azure Arc 提供了一种集中、统一的方式来：<ul>
<li>通过将现有的非 Azure 和/或本地资源投影到 Azure 资源管理器中，共同管理整个环境。</li>
<li>管理虚拟机、Kubernetes 群集和数据库，就像它们在 Azure 中运行一样。</li>
<li>使用熟悉的 Azure 服务和管理功能，无论资源位于何处。</li>
<li>继续使用传统的 ITOps，同时引入 DevOps 实践来支持环境中的新云原生模式。</li>
<li>将自定义位置配置为已启用 Azure Arc 的 Kubernetes 群集和群集扩展之上的抽象层。</li>
</ul>
</li>
</ul>
<h2 id="🧠产品特点-3"><a href="#🧠产品特点-3" class="headerlink" title="🧠产品特点"></a>🧠产品特点</h2><ul>
<li>一致的多云和本地管理</li>
</ul>
<hr>
<ul>
<li><p>本文仅对国内外情况做了简单概览（实际上作者也觉得有些浅显且随便了），后续有机会再对该内容进行细化完善，如果你有更多信息也欢迎在评论区补充！</p>
</li>
<li><p>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</p>
</li>
<li><p>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</p>
</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.huaweicloud.com/news/2022/20221107090434705.html">[1] 华为云：构筑行业云底座，一切皆服务<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link" href="https://developer.aliyun.com/article/992433">[2] 阿里云：智能云网络，助力算网架构新探索<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link" href="https://zhuanlan.zhihu.com/p/644631455">[3] 亚马逊云科技：云服务是支持数字创新的关键生产力<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link" href="https://azure.microsoft.com/en-us/products/azure-arc#overview">[4] Azure Arc：随时随地保护、开发和运营基础结构、应用和 Azure 服务。<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>业界现状</category>
      </categories>
      <tags>
        <tag>CPN</tag>
      </tags>
  </entry>
  <entry>
    <title>论文记录 Quantifying the adaptability of workflow-based service compositions</title>
    <url>/2020/10/17/literature/Quantifying-the-adaptability-of-workflow-based-service-compositions/</url>
    <content><![CDATA[<h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><p>本篇博客主要为方便日后复习论文，也为了在初读论文阶段捋清自己的思路<br>阅读本篇论文的预想步骤：</p>
<ol>
<li>看abstract，针对关键词向自己提出几个问题</li>
<li>根据问题决定阅读顺序，带着问题阅读</li>
<li>翻译关键句，记录论文内容要点及框架结构</li>
<li>分析论文中句子间、段落间的逻辑关系</li>
</ol>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><h2 id="翻译"><a href="#翻译" class="headerlink" title="翻译"></a>翻译</h2><p>（逐字逐句翻译能让我避免“自以为懂了”，熟悉后可逐渐省略这一步）（还能加强自己对英语逻辑的理解）<br><strong>Service composition</strong> 是多种 Web-accessible 服务的集成，它引入了一个开放性问题，即创造的软件系统会被部署在不确定运行环境下，这种不确定性包括需求、用户参数选择、部件服务频繁发生等。在这种不稳定的环境下，对设计这类系统时的<strong>适应性（adaptability）</strong>的考虑是必要的。过去已经有很多人努力使 service compositions 变得更adaptable，但是很少有人关注对adaptability的衡量。这篇paper提出了一组量化 service compositions 的 adaptability 的度量，它们都是根据 the adaptive WS-BPEL-based frameworks 规定的。这些度量考虑到了两个adaptability维度：the structure variability 和 the binding variability。Structure variability 意味着对 the composition workflow 运行时间的改变，Binding variability 意味着服务的动态绑定。我们通过一个case study来评估这种度量，其中使用了一些文献中记载的基于不同适应性的 WS-BPEL-based frameworks 所规定的 traval booking process。最终确定，这种度量对于大范围的service compositions 及他们的 frameworks都很合适。另外我们也制造了一个辅助工具以自动完成度量的计算。使用这种度量，service compositions 及他们的frameworks 的adaptability能够被评估与比较。这对于设计制作adaptability至上的灵活性与稳定性并存的服务有着巨大的便利。</p>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ol>
<li>啥是 service compositions，中文如何翻译？有什么特点？</li>
<li>structure variability and binding variability 分别如何翻译？衡量的是什么方面？为什么这样划分？</li>
</ol>
<h1 id="小反思"><a href="#小反思" class="headerlink" title="小反思"></a>小反思</h1><ol>
<li>不想做的时候，先做5min试试</li>
</ol>
]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>服务组合</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记10-前沿-深度学习集群存算统一调度</title>
    <url>/2023/06/08/literature/literatureNotes10/</url>
    <content><![CDATA[<h1 id="x1f4d6-《SiloD-A-Co-design-of-Caching-and-Scheduling-for-Deep-Learning-Clusters》"><a href="#x1f4d6-《SiloD-A-Co-design-of-Caching-and-Scheduling-for-Deep-Learning-Clusters》" class="headerlink" title="📖《SiloD: A Co-design of Caching and Scheduling for Deep Learning Clusters》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《SiloD: A Co-design of Caching and Scheduling for Deep Learning Clusters》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>随着深度学习（DL）成为一个越来越重要的工作负载，现在主要的云平台提供了深度学习训练的服务。云平台上的深度学习训练通常遵循存储和计算分离的传统。<ul>
<li>深度学习训练作业在GPU集群上运行，并读取托管在单独集群中的训练数据，提供AWS S3或Azure Blob Storage等存储服务。<ul>
<li>这样的设置将存储服务与计算服务解耦，使得解决方案是模块化且简单的。</li>
<li>然而，我们的经验表明，计算和存储服务之间的远程IO可能成为一个瓶颈，特别是随着新一代GPU（如NVIDIA H100）的引入。因此，利用训练集群中的本地存储作为缓存来缓解瓶颈是有益的。</li>
</ul>
</li>
<li>为了缓解潜在的瓶颈，训练集群通常利用其本地存储作为缓存来减少来自存储集群的远程 I/O。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>现有的深度学习调度器无法考虑不同训练作业中的各种缓存影响。这可能会显著降低调度质量。<ul>
<li>（缓存调度器忽略对作业性能考虑）现有的深度学习调度器不管理存储资源，即缓存子系统的运行独立于DL作业调度，对整个集群的作业性能并不了解。</li>
<li>（作业调度器忽略对缓存影响考虑）同时，最先进的深度学习调度器也没有意识到来自缓存子系统的影响。且他们专注于各自不同的优化目标（如<strong>作业完成时间（JCT）</strong>、<strong>公平性</strong>或<strong>集群利用率</strong>）来仲裁计算资源（例如GPU和CPU）。</li>
<li>这样的解耦设计导致了非最优的集群性能。<ul>
<li>例如，当有限的缓存和远程IO成为瓶颈时，一个被集群调度器认为具有高性能的训练作业可能会受到严重影响。这种高估导致了调度质量的下降。这就需要对集群调度和缓存子系统进行共同设计。</li>
</ul>
</li>
</ul>
</li>
<li>传统上，联合设计调度器和缓存是不难的，但对于深度学习调度器存在以下挑战使系统设计进一步复杂化：<ul>
<li>首先，如前所述，深度学习调度器有不同的调度目标。每个调度策略的临时解决方案都会增加设计的复杂性，并且难以扩展。</li>
<li>其次，深度学习训练表现出高度多样化的性能模式：不同的工作带来不同的缓存和IO需求。</li>
</ul>
</li>
<li>我们发现，由于缓存策略忽略了调度的影响，即使是有深度学习意识的缓存系统也可能表现出糟糕的性能。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>我们提出了SiloD，这是第一个<strong>共同考虑了计算资源（如GPU）和存储资源（包括缓存和远程IO）全集群资源分配</strong>的深度学习调度框架。</p>
<ul>
<li>SiloD将缓存和远程IO视为同等重要的对象，可以在一个统一的调度框架中整合不同的最先进的深度学习调度策略。</li>
<li>SiloD 开发了一个增强且通用的作业性能估算器，以帮助不同的调度人员共同考虑存储和计算资源分配的影响，同时保留各自的调度目标。<ul>
<li>尽管目标不同，但大多数深度学习调度器都需要一定的性能估计器。不同策略的调度决策是基于使用不同性能估计器的工作性能估计。</li>
<li>尽管对于不同的训练作业来说，数据访问模式和计算模式是高度多样化的，但在每个单独的作业中都是高度稳定和可预测的。这使得SiloD可以通过进一步利用数据加载和计算的流水线执行，得出统一的性能估计方法。<ul>
<li>SiloD增强的性能估计器将联合性能估计转化为一个两步过程。它首先估计数据加载是否会成为整个训练的瓶颈。如果是这样，SiloD将使用IOPerf，这是一个我们引入的性能估计器，用于分析存储的影响，以估计IO瓶颈下的工作性能。IOPerf利用深度学习训练的独特访问模式，在给定缓存和远程IO分配的情况下，得出一个封闭式的分析模型。该分析模型能够捕捉到不同训练作业的高度多样化的性能模式，从而得出多样化的缓存和IO需求。性能感知调度器可以利用分析模型来利用多样性来进一步优化他们的调度目标。</li>
</ul>
</li>
</ul>
</li>
<li>SiloD增强的性能估计器被整合到不同的调度策略中，并用于做出调度决策。通过这种方式，SiloD能够增强不同的最先进的深度学习调度器，以联合执行缓存和远程IO分配，同时保留这些调度策略的原始目标。</li>
</ul>
</li>
<li><p>综上所述，本文有以下贡献。</p>
<ul>
<li>我们提出了一个统一的集群调度框架，该框架扩展了最先进的深度学习调度器，以联合调度计算和存储资源，同时保留原始调度目标。</li>
<li>我们揭示了作业性能和存储资源之间的闭合关系，可以增强现有集群调度器的性能估计器，以准确预测计算和存储交互的影响。</li>
<li>我们在SiloD的框架中实现了最先进的调度策略，使用真实的GPU集群和高保真模拟，显示了作业完成时间、集群利用率和公平性的明显改善。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们在Alluxio和Kubernetes的基础上实现了SiloD，大约分别有3000和2500行代码。在96GPU集群和Azure的存储服务上进行的大量跟踪驱动实验以及高保真模拟表明，通过共同调度计算、缓存和远程IO资源，可以大大提升DL训练的最先进调度策略的性能。</li>
<li>评估表明，与独立运行的缓存系统和集群调度程序的不同组合相比，SiloD 将平均作业完成时间、集群利用率和公平性分别提高了 7.4 倍、2.57 倍和 1.89 倍。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>现有工作尚未有考虑计算和存储联合调度的？还是说在深度学习领域尚未有，且深度学习领域存在独特问题？</li>
</ol>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/abs/10.1145/3552326.3567499">[1] Zhao H, Han Z, Yang Z, et al. SiloD: A Co-design of Caching and Scheduling for Deep Learning Clusters[C]//Proceedings of the Eighteenth European Conference on Computer Systems. 2023: 883-898.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>智算管理</tag>
        <tag>调度</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记1-前沿-模拟器加速算法</title>
    <url>/2023/05/17/literature/literatureNotes1/</url>
    <content><![CDATA[<h1 id="x1f4d6-《A-Parallel-Algorithm-to-Accelerate-DEVS-Simulations-in-Shared-Memory-Architectures》"><a href="#x1f4d6-《A-Parallel-Algorithm-to-Accelerate-DEVS-Simulations-in-Shared-Memory-Architectures》" class="headerlink" title="📖《A Parallel Algorithm to Accelerate DEVS Simulations in Shared Memory Architectures》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《A Parallel Algorithm to Accelerate DEVS Simulations in Shared Memory Architectures》</h1><blockquote>
<p>序言：</p>
<blockquote>
<p> 写这个系列的目的是督促自己养成阅读论文的习惯，有疏漏或错误之处欢迎指出和讨论。</p>
</blockquote>
</blockquote>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>建模和仿真（M&amp;S）成为表示各个学科问题和进行科学探索的重要工具。尽管已经开发了许多M&amp;S方法，但离散事件模拟（其中系统行为被建模为连续时间内事件的时间顺序）现在广泛用于研究各种各样的问题。</li>
<li>正式的M&amp;S方法允许精确定义模型，进行正式检查并构建更易于验证的模拟器。特别是，离散事件系统规范（DEVS）形式化为离散事件M&amp;S的开发提供了正式的理论框架。</li>
<li>在不同研究领域模拟复杂的DEVS模型的需求不断增长，导致执行时间增加。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>为了解决模拟时间过长问题，已经多次尝试使用并行离散事件模拟（PDES）方法，实现DEVS的并行执行。然而，在实践中，这些算法会导致复杂的仿真架构，并产生与零前瞻循环和正确性相关的各种问题。</li>
<li>[<a href="#refer-anchor-2">2</a>]中提出了一种加速 DEVS 仿真的不同方法，该方法允许并行执行仿真协议。这种方法背后的主要思想是通过并行执行同时发生的事件来允许简单且无错误的算法。<ul>
<li>在这种方法中，作者确定了仿真协议可以并行执行的两种情况：<ul>
<li>1）当两个或多个组件执行其输出功能时;</li>
<li>2）当两个或多个组件执行其状态转换功能时。</li>
</ul>
</li>
<li>然而，这种方法在实际应用中显示出有限的加速。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>提出了一种在并行共享内存架构上执行离散事件系统规范（DEVS）仿真的新算法。<ul>
<li>通过并行执行PDEVS仿真协议中的所有任务来执行并行离散事件仿真。该算法的工作原理是在共享内存架构上的不同内核之间分配计算，与分布式内存系统相比，共享内存计算机体系结构可以有效地使用系统资源并且具有较低的通信延迟。</li>
<li>（在现有方法的基础上，提供额外并行执行机会）</li>
</ul>
</li>
<li>在本文方法中，完整的算法并行执行，在所有场景中都能获得与顺序版本相同的结果。<ul>
<li>思路是分解任务并将它们分配给一组加速执行的线程。每个任务完成后，线程将同步以确保在启动新任务之前完成任务。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>展示了一组使用合成基准的实验结果，以及使用两个独立计算机架构的真实场景。获得的结果显示了算法将模拟加速多达八倍。<ul>
<li>使用为蜂窝DEVS模型设计的基准和真实世界的案例研究，其中真实案例研究是一个流行病学模型，模拟疾病如何在人群中传播。</li>
</ul>
</li>
<li>此外，实验表明，当增加使用的 CPU 内核数量时，算法能够持续扩展。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>离散事件系统规范（DEVS）是什么样的标准？与现有的云计算模拟器如CloudSim之间的关系是什么？</li>
<li>核心思路是什么？还没看懂。</li>
</ol>
<h2 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h2><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10068737">[1] G. G. Trabes, G. A. Wainer and V. Gil-Costa, “A Parallel Algorithm to Accelerate DEVS Simulations in Shared Memory Architectures,” in IEEE Transactions on Parallel and Distributed Systems, vol. 34, no. 5, pp. 1609-1620, May 2023, doi: 10.1109/TPDS.2023.3256083.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/7914577">[2] B. P. Zeigler, “Using the Parallel DEVS Protocol for General Robust Simulation with Near Optimal Performance,” in Computing in Science &amp; Engineering, vol. 19, no. 3, pp. 68-77, May-June 2017, doi: 10.1109/MCSE.2017.52.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>模拟器</category>
      </categories>
      <tags>
        <tag>模拟器</tag>
        <tag>并行加速</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记12-前沿-分散式联合调度</title>
    <url>/2023/07/06/literature/literatureNotes12/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Megha-Decentralized-Federated-Scheduling-for-Data-Center-Workloads》"><a href="#x1f4d6-《Megha-Decentralized-Federated-Scheduling-for-Data-Center-Workloads》" class="headerlink" title="📖《Megha: Decentralized Federated Scheduling for Data Center Workloads》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Megha: Decentralized Federated Scheduling for Data Center Workloads》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>数据中心的规模和异构性不断增加，导致了联合集群的发展，如KubeFed、Hydra和Pigeon，它们联合了单个数据中心集群。<ul>
<li>为了满足不断增长的规模需求，组织正在投资拥有数十万台机器的数据中心。这些数据中心根据应用程序或实用程序进一步划分为集群。此基础设施的高利用率可带来更高的投资回报。为了实现高利用率，数据中心中的资源必须作为可共享的统一池呈现给用户，并且必须支持来自该池的细粒度分配。</li>
<li>由于最近工作负载中普遍存在的异构性和复杂性，调度和资源分配是非同寻常的问题。为了有效地管理大量工作节点，调度框架正在转向联合架构，其中顶级调度程序做出由独立集群调度程序强制执行的高级调度决策。Hydra 和 Pigeon 是两个采用联合架构的调度程序。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>调度程序大致可分为集中式、分布式、混合式和分层式调度程序。<ul>
<li>集中式调度程序，如 YARN，可以做出最佳决策，因为它们具有系统的全局视图。然而，正如先前的研究表明随着数据中心规模的增加，后续处理和收集大量状态会导致瓶颈的形成，因此这些调度程序无法实现所需的调度吞吐量。</li>
<li>像Sparrow这样的分布式架构依赖于概率来找到具有可用资源的机器。对于每个任务，Sparrow 执行随机采样并将探针插入工作队列，以选择排队时间最短的机器。此方法中的调度开销微不足道。但是，当数据中心负载很高时，选择可用机器的可能性非常低。因此，依赖于随机抽样的分布式调度程序在高利用率条件下性能不佳。</li>
<li>与Megha最相似的建筑是Pigeon。<ul>
<li>Pigeon将数据中心划分为更小的组，每个组有一个Master。分布式调度程序在Master节点之间均匀分配作业中的任务。</li>
<li>在Megha中，GM类似于分布式调度程序，LM类似于Master节点。</li>
<li>但是，这两种体系结构之间存在三个主要区别。<ul>
<li>首先，Pigeon不执行细粒度的资源分配。它将工作线程划分为称为插槽的固定资源封装。这种粗粒度的分配将导致资源的碎片化和浪费。</li>
<li>其次，Pigeon使用加权公平排队和预留来避免长时间的作业匮乏，并确保较低的短作业延迟。Megha 不区分工作类型。然而，由于其分散的性质，Megha 实现了低分配时间，并确保防止任何类别的工作出现线头阻塞和饥饿。</li>
<li>第三，Pigeon中的组一旦形成是固定的，即分区方案没有灵活性的余地。Megha 允许使用灵活的分区在数据中心的任何地方安排任务。这样可以更好地利用数据中心的资源，尤其是在存在放置约束的情况下，这些限制限制了可以运行任务的合格计算机的数量。</li>
</ul>
</li>
</ul>
</li>
<li>Hydra 是一个联合资源管理框架，由 Microsoft 作为 Apollo 的继任者创建，以支持部署在其数据中心的工作负载所需的每秒高调度决策。<ul>
<li>Hydra 将其大型集群划分为较小的 YARN 子集群。因此，每个子群集都有一个资源管理器 （RM），用于决定任务放置并执行资源分配。</li>
<li>Hydra 引入了一个名为 AM-RM 代理的组件，它允许任务跨越多个子集群。</li>
<li>在Megha中，全局主节点类似于 AM-RM 代理，而本地主节点扮演 RM 的角色。但是，由于每个 Megha GM 都维护整个系统的全局视图的（可能过时的）本地副本，因此每次任务请求到达时都不需要联系集群管理器（LM）。</li>
</ul>
</li>
<li>混合调度器（如 Mercury、Hawk 和 Eagle）使用两组调度程序：<ul>
<li>一组用于需要资源保证的任务的集中式调度程序，</li>
<li>另一组用于延迟敏感任务的分布式调度程序。</li>
<li>但是，这些调度程序遇到了与前面提到的分布式调度程序相同的问题。</li>
</ul>
</li>
<li>PCSsampler 通过缓存响应探测器时收到的状态信息来扩展基于随机采样的方法。<ul>
<li>缓存状态的有用性在很大程度上取决于探测的工作线程。<ul>
<li>在高负载的大型集群中，查找具有可用槽的工作线程可能需要多轮探测，从而导致高调度开销。</li>
</ul>
</li>
<li>另一方面，Megha 的 GM 在每次启动请求后收集有关整个 LM 集群的部分状态信息。GM 还使用来自 LM 的定期检测信号更新其存储的全局状态。 Megha 通过让 LM 验证它们来确保其所有决策都是最佳的。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>在我们的论文中，我们介绍了Megha，一个分散的全局调度程序，它使用最终一致性和灵活的分区来克服现有调度程序的局限性。<ul>
<li>Megha 采用灵活的集群逻辑分区来分配其调度负载，确保以非常低的调度开销满足工作负载的要求。它使用分布式全局调度程序，该调度程序不依赖于集中式数据存储，而是具有最终一致性，这与使用分层体系结构或依赖于集中式数据库的其他调度程序不同。<ul>
<li>Megha 具有联合架构，并将数据中心划分为较小的集群，每个集群由本地主节点 （LM） 控制。</li>
<li>它通过将负载分发到多个顶级全局主节点 （GM） 来实现高调度吞吐量。</li>
<li>每个 GM 使用系统资源的最终一致的全局视图来做出调度决策。</li>
<li>LM 验证 GM 的决策，并将任务部署到它们处理的集群的工作节点上。</li>
</ul>
</li>
</ul>
</li>
<li>我们的主要贡献如下。我们：<ul>
<li>定义分配时间并将其分解为众多组件。我们还分析了不同调度方法中每个组件对分配时间的贡献。</li>
<li>引入一种新颖的去中心化框架的设计，该框架使用最终一致性和动态分区来克服现有方法的局限性。</li>
<li>演示与集中式调度程序和分布式调度程序（Sparrow）相比，使用我们的方法调度的任务分配时间的改进。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们对Megha的实验表明，它可以在资源分配时间短的情况下安排任务，同时考虑到资源需求和放置约束 - 大约几十毫秒。<ul>
<li>我们的实验是使用真实世界的生产轨迹进行的，以评估Megha的任务分配速度，并将其与集中式和分布式调度方法进行比较。</li>
<li>结果表明，Megha 可以实现与基于随机抽样的分布式调度程序 Sparrow 相当的中位数分配时间。</li>
<li>Megha 还报告了比 Sparrow 好两个数量级的 99th 百分位分配时间。</li>
<li>这些实验还演示了如何通过最终一致的全局状态满足任务放置约束，同时报告比集中式方法更少的分配时间。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>使用全局中心-局部分散的模式时，所需时间情况如何？能否推广至全球大数据中心架构？</li>
</ol>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10041383">[1] M. Thiyyakat, S. Kalambur and D. Sitaram, “Megha: Decentralized Federated Scheduling for Data Center Workloads,” 2023 15th International Conference on COMmunication Systems &amp; NETworkS (COMSNETS), Bangalore, India, 2023, pp. 278-286, doi: 10.1109/COMSNETS56262.2023.10041383.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>调度</tag>
        <tag>多云</tag>
        <tag>分散式调度</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记13-前沿-可信虚拟机迁移</title>
    <url>/2023/07/07/literature/literatureNotes13/</url>
    <content><![CDATA[<h1 id="x1f4d6-《A-high-applicability-heterogeneous-cloud-data-centers-resource-management-algorithm-based-on-trusted-virtual-machine-migration》"><a href="#x1f4d6-《A-high-applicability-heterogeneous-cloud-data-centers-resource-management-algorithm-based-on-trusted-virtual-machine-migration》" class="headerlink" title="📖《A high-applicability heterogeneous cloud data centers resource management algorithm based on trusted virtual machine migration》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《A high-applicability heterogeneous cloud data centers resource management algorithm based on trusted virtual machine migration》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>随着云计算技术的不断发展和成熟，云数据中心（CDC）的规模和数量也在不断扩大。这越来越引起人们对CDC高能耗问题的关注。<ul>
<li>随着虚拟化、并行处理和分布式处理技术的成熟，云计算作为一种新型的互联网计算模式正变得非常流行。根据服务模式，云计算主要分为三个级别：IaaS（基础设施即服务），PaaS（平台即服务）和SaaS（软件即服务）。通过云计算服务，用户可以通过按量付费的方式自由使用计算、存储等服务，根据自己的需求灵活调整资源大小。云服务提供商进一步扩大了CDC的规模，以满足云用户不断增长的性能需求。然而，大规模的CDC不可避免地会消耗大量能量。</li>
</ul>
</li>
<li>动态虚拟机（VM）整合是降低能耗的一种有前途的方法。<ul>
<li>虚拟机迁移作为一种虚拟机整合技术，可以有效提高物理机利用率，优化CDC调度流程。</li>
<li>通过虚拟机迁移提高利用率和 PM 数量，最终降低 CDC 的能耗。<ul>
<li>通过虚拟机迁移，在 CDC 中运行的云任务将集成到少量 PM 中，从而关闭空闲的 PM 以降低能耗。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，在现有的研究中，大多数虚拟机集成算法都旨在提高PM的利用率。PM的过度利用可能会增加在其上运行的虚拟机之间对共享资源的竞争。结果，这些虚拟机的性能下降，云任务的执行时间增加甚至中断。<ul>
<li>现有学者对虚拟机迁移算法进行了研究，但这些算法没有考虑以下问题：<ol>
<li>首先，以前的算法在没有考虑集群异构性的情况下解决了齐次聚类的映射问题。</li>
<li>其次，之前的算法规范化了虚拟和PM的属性。然而，在归一化过程中，权重参数的差异导致结果出现显着偏差。因此，应在实际环境中详细考虑 VM 和 PM 的多维属性。</li>
<li>第三，之前的研究没有考虑虚拟机迁移带来的性能损失，这是迁移过程中不可忽视的重要因素。PM的高利用率和低利用率都会产生影响。</li>
</ol>
<ul>
<li>因此，为了确保 VM 的性能，应为 PM 利用率设置上限。</li>
<li>同时，由于空闲状态下PM的功耗仍约为满载功耗的70%，因此关闭空闲PM或利用率低的PM可以降低功耗。</li>
</ul>
<ol start="4">
<li>最后，在降低CDC功耗方面，这些算法在虚拟机整合后往往负载均衡效果较差。</li>
</ol>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>在这项研究中，首先分析了影响PM能耗的众多因素以及CDC的整体架构。</p>
</li>
<li><p>其次，研究了PM利用率对CDC能耗的影响以及虚拟机迁移造成的性能损失。</p>
</li>
<li><p>第三，研究了虚拟机的多维特征和CDC的异构特征，提出了一维多维可信虚拟机迁移规则。</p>
</li>
<li><p>然后，根据上述规则和CDC架构，提出一种基于可信虚拟机迁移（HTVM2）的高适用性异构CDC资源管理算法。</p>
<ul>
<li>该算法不仅解决了同构和异构CDC的一维虚拟机迁移问题，还解决了多维虚拟机的迁移问题。</li>
<li>这提高了虚拟机迁移的成功率，降低了 CDC 的能耗，并在确保虚拟机性能的同时改善了负载平衡。</li>
</ul>
</li>
<li><p>最后，利用本研究建立的验证平台对算法进行了验证。</p>
</li>
<li><p>本文的主要贡献如下：</p>
<ol>
<li>系统分析虚拟机迁移对云任务和PM性能的影响，同时确定PM利用率的上限和下限。</li>
<li>全面分析了能源消耗对多维和异质性CDC的影响。基于此，提出了一维多维可信虚拟机迁移规则。</li>
<li>基于上述规则提出了HTVM2算法。为了验证算法的有效性，CloudSim中嵌入了由虚拟机生成器、PM发生器和虚拟机初始化模块组成的仿真验证平台，以模拟CDC的真实环境。最后，利用CloudSim验证了HTVM2算法的效果。</li>
</ol>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>利用CloudSim将算法与随机映射算法和比较模块一起实现，模拟VM在CloudSim中的初始部署，验证所提HTVM2算法的效果。通过对比分析，HTVM2算法与GLBC、DTVS和OVMP算法相比，显著提高了虚拟机的迁移成功率和PM的利用率。此外，还减少了使用的 PM 数量，并改善了负载平衡。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>一维/多维具体指什么？是否有例子？</li>
<li>可信在其中的意义是什么？<ul>
<li>指的是防止“迁移过程中数据丢失导致的任务失败”。与预期不符。</li>
</ul>
</li>
<li>如何保障可信的？可信的具体目标是什么？</li>
</ol>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.sciencedirect.com/science/article/pii/S0957417422002275?via=ihub">[1] Bin Liang, Xiaoshe Dong, Yufei Wang, Xingjun Zhang, A high-applicability heterogeneous cloud data centers resource management algorithm based on trusted virtual machine migration, Expert Systems with Applications, Vol. 197, 2022, 116762, ISSN 0957-4174, https://doi.org/10.1016/j.eswa.2022.116762.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>虚拟机</tag>
        <tag>迁移</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记14-前沿-云虚拟机可信</title>
    <url>/2023/07/07/literature/literatureNotes14/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Cloud-virtual-machine-lifecycle-security-framework-based-on-trusted-computing》"><a href="#x1f4d6-《Cloud-virtual-machine-lifecycle-security-framework-based-on-trusted-computing》" class="headerlink" title="📖《Cloud virtual machine lifecycle security framework based on trusted computing》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Cloud virtual machine lifecycle security framework based on trusted computing》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>作为云计算平台的基础组件，虚拟机（VM）面临着众多的安全威胁。<ul>
<li>虚拟机（VM）凭借其灵活性和可扩展性的优势，已成为云计算环境中租户服务部署的主要模式。</li>
<li>虚拟机作为独立的计算实体，除了面临传统的安全威胁外，还面临一些云计算特有的安全威胁，即专门针对虚拟环境不同状态的安全威胁（例如，共存攻击、数据安全威胁、针对虚拟机存储的攻击以及针对虚拟机迁移的攻击）。直观地讲，为了实现安全的环境，需要对虚拟机的各个状态进行全面的保护，即本文所说的生命周期安全保护。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，现有的解决方案往往侧重于解决虚拟机特定状态下的威胁。<ul>
<li>最近，一些有前途的方法被提出来解决虚拟机在生命周期不同阶段面临的安全问题。这些方法通过在虚拟机的生命周期中采用特定方法来发挥作用，包括<ul>
<li>（a）身份验证和数据加密，利用隔离技术来保护虚拟机的CPU和内存上下文； </li>
<li>（b）实现代理，在VM中安装代理来实现访问控制、加密、完整性验证等安全功能；</li>
<li>（c）保护镜像的完整性，通过保护镜像文件的完整性为VM提供安全性；</li>
<li>（d）扫描更新，利用优化存储部署技术对虚拟机进行细粒度的扫描更新。</li>
</ul>
</li>
<li>然而，上述方法存在一些主要局限性。<ul>
<li>首先，密码学机制可以减轻虚拟机面临的安全威胁，但保证存储和授权中使用的密钥的机密性和安全性仍然是一个悬而未决的问题。</li>
<li>其次，这些方法侧重于保护虚拟机特定状态的安全，但并未在虚拟机的整个生命周期中保护虚拟机。</li>
<li>第三，现有方案经常忽略生命周期的一些微妙但重要的状态（例如迁移和快照的状态）。</li>
<li>最后，无法检查和验证虚拟机的可信状态，这意味着无法实现对虚拟机运行状态的安全评估。</li>
</ul>
</li>
</ul>
</li>
<li>幸运的是，可信计算技术可以通过为虚拟机创建可信环境来克服这些问题。通过将密钥存储在可信平台模块 (TPM) 中来实现密钥的安全存储。此外，可信计算环境为在虚拟机的整个生命周期中保护虚拟机提供了基础。此外，还可以通过可信计算来检查和验证虚拟机运行状态的安全性，从而实现适当的安全评估。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>在本文中，我们研究了虚拟机的安全威胁，旨在提出一种使用可信计算的全面生命周期保护方案，以实现从硬件 TPM 到虚拟机的可信链内的完美安全。这是建立在许多安全要求较高的云平台已经采用可信计算原理的基础上的。<ul>
<li>我们首先提出了一种新颖的VM生命周期模型，其中根据VM的不同状态划分不同的生命周期状态。然后，我们讨论所提出的生命周期模型实现健全性和安全性的条件和要求，表明为了实现这些目标，虚拟机的每个状态都需要关注并满足某些要求。</li>
<li>基于该模型，我们进一步研究了虚拟机的安全保护方法，并提出了一种使用可信计算的新解决方案。主要思想是通过将可信链从硬件TPM延伸到VM初始启动器，再延伸到VM的应用程序，将VM建立为可信计算环境。同时，通过建立物理可信基础并与虚拟机实例实现可信关联，保证虚拟可信平台模块（vTPM）实例的安全性和合法性。</li>
</ul>
</li>
<li>简而言之，本文的主要贡献如下。<ul>
<li>我们提出了一种基于可信计算的虚拟机生命周期安全保护框架，其中生命周期的状态根据虚拟机的不同状态进行划分。所提出的框架可以为每个州提供可靠的安全性和可靠性。同时，实现了虚拟机运行状态的深度认证方法。</li>
<li>根据可信虚拟机生命周期和安全保护框架，对所提出的框架进行了全面的复杂性和安全性分析。分析结果表明，该框架能够构建可信环境，保证虚拟机整个生命周期的安全可靠。</li>
<li>为了说明可行性和可用性，我们在真实的基于OpenStack的云计算环境上进行了实验。结果表明，该框架实现了虚拟机可信信息的集中管理能力，并在整个虚拟机生命周期中提供完整的安全保护。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>理论分析表明，我们提出的框架可以为虚拟机在所有状态下提供全面的安全性。</li>
<li>此外，实验结果表明，与一些最先进的方案相比，所提出的框架是可行的并且实现了更高水平的安全性。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>可信计算下具体运行流程是什么样的？周期性检测？对每一次交互都进行检测？</li>
<li>VMI 技术在本文中如何使用？有什么好处？</li>
</ol>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/8698209">[1] X. Jin, Q. Wang, X. Li, X. Chen and W. Wang, “Cloud virtual machine lifecycle security framework based on trusted computing,” in Tsinghua Science and Technology, vol. 24, no. 5, pp. 520-534, October 2019, doi: 10.26599/TST.2018.9010129.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>虚拟机</tag>
        <tag>可信</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记15-经典-大规模调度</title>
    <url>/2023/07/19/literature/literatureNotes15/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Scaling-Large-Production-Clusters-with-Partitioned-Synchronization》"><a href="#x1f4d6-《Scaling-Large-Production-Clusters-with-Partitioned-Synchronization》" class="headerlink" title="📖《Scaling Large Production Clusters with Partitioned Synchronization》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Scaling Large Production Clusters with Partitioned Synchronization》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>近年来，<strong>计算机集群的规模显着增长</strong>。<ul>
<li>如今，一个集群可能拥有 10 万台机器，每天执行数十亿个任务，尤其是短任务。因此，管理集群中资源利用率的调度程序也需要升级才能在更大规模的情况下工作。</li>
<li>在阿里巴巴，我们运营着大型集群，每个集群包含数万台机器。每天都有数十亿个任务在集群中提交、调度和执行。集群调度程序（简称调度程序）管理集群中的机器和任务。调度器根据任务的资源需求（例如CPU、内存、网络带宽），使用各种调度算法将任务与合适的资源匹配，并在调度效率、调度质量、资源利用率、任务的公平性和优先级等多个调度目标之间进行复杂的权衡。平衡这些目标的能力在很大程度上取决于技术和业务因素，因此因公司和集群而异。</li>
</ul>
</li>
<li>然而，在大型生产集群中升级调度器（中央系统组件）是一项艰巨的任务，因为我们需要确保集群的稳定性和鲁棒性，例如要保证用户透明度，并且需要其他集群组件和现有的调度策略保持不变。<ul>
<li>由于近年来我们业务的快速增长，我们在扩展调度程序（类似于 YARN）的集中式架构方面面临着严峻的挑战，因为我们的集群中的任务和机器大幅增加。如今，我们的一些集群的规模接近 100k 台机器，平均任务提交率约为 40k 任务/秒（在某些月份甚至更高）。这种规模完全超出了单个调度器的容量，升级到分布式调度器架构是不可避免的。</li>
</ul>
</li>
<li>我们需要一种分布式调度器架构的设计，该架构可以<strong>处理集群规模和任务提交率的规模（可扩展性）</strong>，同时<strong>实现低延迟和高质量的调度</strong>。所提出的设计<strong>还需要满足两个硬约束</strong>（§2）：向后兼容性和无缝用户透明度。来自这些约束的调度程序的鲁棒性和稳定性对于我们的生产环境至关重要。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>我们调查了现有的调度程序设计，发现大多数都无法处理我们生产集群的规模，或者可能会危及它们的稳健性。<ul>
<li>集群调度程序已被广泛研究，我们在第 3 节中讨论了现有调度程序对于集群环境和工作负载的适用性。<ul>
<li>其中，Omega 中描述的共享状态调度器架构较符合需求<ul>
<li>Omega 能够处理我们的集群大小并满足<strong>两个硬约束</strong>，因为它需要最少的侵入性架构更改。<ul>
<li>在 Omega 中，<ul>
<li>主节点维护集群状态，该状态指示集群中每台机器的资源可用性。</li>
<li>有多个调度程序，每个调度程序通过定期与主副本同步来维护集群状态的本地副本。</li>
<li>每个调度程序根据（可能是陈旧的）本地状态乐观地调度任务，并向主节点发送资源请求。</li>
<li>由于多个调度程序可能请求同一块资源，这会导致调度冲突。主节点将资源授予第一个请求资源的调度程序，其他调度程序将需要重新调度其任务。</li>
</ul>
</li>
</ul>
</li>
<li>Omega 在<strong>可扩展性、低延迟和高调度质量</strong>方面仍不满足需求，<ul>
<li>当任务提交率较高时，调度冲突和重新调度开销会导致高延迟，我们在第 4 节中使用分析模型和模拟对此进行了验证。我们的结果表明，对优质资源的争夺和本地状态的陈旧性是造成高调度延迟的两个主要因素，因为它们都会大大增加调度冲突。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>我们分析了一种遵循共享状态架构的最合适的设计，它的局限性导致我们提出了一种细粒度的陈旧状态共享设计，称为分区同步（ParSync）。<ul>
<li>在第 5 节中，我们提出分区同步（ParSync）来减轻“对优质资源的争夺”和“本地状态的陈旧性”这两个因素的负面影响。 <ul>
<li>ParSync 将集群状态划分为 N 个部分（N 是调度程序的数量），这样每个调度程序每次都会同步 1/N 的不同分区，而不是整个状态。因此，在任何时候，每个调度程序都有 1/N 分区的新视图，并且可以首先将其任务调度到这些分区。<ul>
<li>这显着减少了对高质量资源的争用（与其他调度程序）。</li>
<li>根据分区同步的时间，调度程序知道其分区的陈旧程度；因此，算法设计者现在可以通过调整对更新分区的偏好来更好地平衡调度延迟和调度质量。</li>
</ul>
</li>
<li>我们还设计了一种自适应策略，可以在降低调度延迟和提高调度质量之间进行动态选择。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>ParSync 具有维持生产集群稳健性所需的简单性，同时实现高调度效率和扩展质量。<ul>
<li>我们在§6中验证了ParSync以及基于ParSync开发的各种调度算法的有效性。</li>
</ul>
</li>
<li>ParSync已在我们的生产集群中部署并稳定运行。<ul>
<li>ParSync已经部署在阿里巴巴最新版本的分布式集群调度器Fuxi 2.0中，并且在我们的生产集群中稳定运行，每个生产集群包含数千到10万台机器。</li>
</ul>
</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.usenix.org/conference/atc21/presentation/feng-yihui">[1] Feng Y, Liu Z, Zhao Y, et al. Scaling large production clusters with partitioned synchronization[C]//2021 USENIX Annual Technical Conference (USENIX ATC 21). 2021: 81-97.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>调度</tag>
        <tag>大规模</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记17-前沿-大规模强化学习组合优化</title>
    <url>/2023/11/02/literature/literatureNotes17/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Combinatorial-Optimization-Meets-Reinforcement-Learning-Effective-Taxi-Order-Dispatching-at-Large-Scale》"><a href="#x1f4d6-《Combinatorial-Optimization-Meets-Reinforcement-Learning-Effective-Taxi-Order-Dispatching-at-Large-Scale》" class="headerlink" title="📖《Combinatorial Optimization Meets Reinforcement Learning: Effective Taxi Order Dispatching at Large-Scale》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Combinatorial Optimization Meets Reinforcement Learning: Effective Taxi Order Dispatching at Large-Scale》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>网约车已经盛行。网约车平台的核心是出租车订单调度，包括为每个订单推荐合适的司机。<ul>
<li>网约车服务的核心是出租车订单调度，网约车平台将出租车乘车订单（即需求）分配给适当的出租车司机（即供应）。有效和高效的大规模订单调度对于城市网约车的整体效用（例如，总收入）和服务质量（例如，旅行成本和等待时间）至关重要。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>以前的工作使用纯组合优化解决方案进行出租车调度，由于需求和供应的复杂动态以及调度决策之间的时间依赖性，在实践中会受到影响。<ul>
<li>从数学上讲，订单调度可以建模为二分匹配问题。具体来说，驱动因素和订单被建模为二分图两侧的节点，两个节点之间的边表示潜在的分配。因此，查找司机和订单之间的调度决策将转换为计算二分匹配。从组合优化的角度来看，二分匹配公式自然会得出解决方案。尽管进行了数十年的研究，但基于组合优化的纯策略在实践中仍然<strong>无法提供理论上声称的性能</strong>。实证研究表明，许多方法甚至无法击败简单的贪婪算法。这是因为组合优化解决方案通常是短视的，并且会根据强有力的假设做出回应，从而阻止它们在现实世界的网约车中应对以下挑战。<ul>
<li>需求和供应的复杂<strong>动态</strong>。大多数组合优化解决方案过度简化了需求和供给的空间分布，例如，假设遵循齐普夫定律的潜在驱动因素，或者根据历史数据拟合一些已知的独立相同分布。在实践中，由于高峰时段、天气、事件等多种因素，出租车需求可能非常不规律和波动。由于驾驶员的怠速巡航，供应也可能在空间中反复无常，这很难建模和预测。</li>
<li>调度决策之间的<strong>时间依赖性</strong>。组合优化方法倾向于假设独立决策。然而，以前的调度决策可能会影响以后的调度决策，因为先前调度的司机可能会在以后出现在其分配的订单的目的地附近，这可能会改变后续调度时间范围内的供应分配。</li>
</ul>
</li>
</ul>
</li>
<li>最近的研究试图将数据驱动的方法引入组合优化，希望从历史数据中获得的知识有助于克服这些挑战。在这些尝试中，强化学习的采用显示出巨大的前景，但目前的采用是单向集成，限制了潜在的性能提升。<ul>
<li>最近的努力利用数据挖掘技术来预测需求和供应，而不是根据订单调度的简化分布假设进行回复。 <ul>
<li>然而，由于这些方法在后续调度中忽略了前期调度对供应分布的影响，因此其预测往往会偏离实际预测，从而限制了其有效性。</li>
</ul>
</li>
<li>一些先驱研究提出将一批调度决策作为顺序决策问题进行联合优化，可以通过强化学习来解决。在强化学习设置中，平台从供需和调度决策的大历史数据中学习给定时间段的最佳调度策略。此设置不仅消除了对供需的预先假设，而且还明确考虑了调度之间的依赖关系。<ul>
<li>然而，作为将组合优化与强化学习相结合的早期探索，现有的提案缺乏系统的设计来优化这两种范式之间的相互作用。例如，都只应用强化学习来增强组合优化。这种单向集成限制了潜在的性能提升。此外，强化学习的数据驱动性质可能会给组合优化带来不利影响，甚至会危及性能。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>在这项工作中，提出了 Learning To Dispatch（LTD），这是一种系统化的解决方案，允许强化学习和组合优化的协同整合，用于大规模出租车订单调度。为了有效地将强化学习增强为组合优化，采用在线学习的方式，使学习到的调度策略适应当前情况。为了避免强化学习中的冷启动问题，设计了一种组合疗法，即驾驶员调度。还提出了优化方法，以优化在大规模环境中应用强化学习的效率。<ul>
<li>证明了在线学习和出租车调度的必要性，以使强化学习与组合优化协同工作，并设计相应的算法。<ul>
<li>研究了将强化学习与组合优化相结合的问题和解决方案，以用于出租车订单调度。证明了在线学习和出租车调度的必要性，以便强化学习与组合优化协同工作，以实现有效的出租车调度。据我们所知，我们率先探索将这两种方法相结合的网约车服务的最佳实践。</li>
</ul>
</li>
<li>设计了许多技巧来更有效地计算二分匹配。<ul>
<li>设计了许多技巧来更有效地计算二分匹配。通过采用共享值函数和近似，大大减小了值函数的大小，有助于更好地探索。还使用广度优先搜索将二分图拆分为几个部分，以提高执行效率。这些加速度使算法适用于大规模、高频的调度操作。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>在一家大型网约车平台开发的模拟器上根据真实历史数据进行实验。<ul>
<li>广泛的评估表明，我们的双向集成在效用和效率方面比所有基线高出 36.4% 和 42.0%。我们还比最先进的方法高出28.7%在效用上。</li>
<li>该作品的初版获得了KDD杯2020强化学习轨道订单调度任务的冠军。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>本文中是否考虑网约车的移动性与路径？还是抽象成一个无关移动的资源？<ul>
<li>看起来是后者，那么是否可以迁移到云计算场景？</li>
</ul>
</li>
<li>大规模带来的挑战是什么？论文如何解决的？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9611023">[1] Y. Tong, D. Shi, Y. Xu, W. Lv, Z. Qin and X. Tang, “Combinatorial Optimization Meets Reinforcement Learning: Effective Taxi Order Dispatching at Large-Scale,” in IEEE Transactions on Knowledge and Data Engineering, vol. 35, no. 10, pp. 9812-9823, 1 Oct. 2023, doi: 10.1109/TKDE.2021.3127077.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>AI</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
        <tag>大规模</tag>
        <tag>组合优化</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记16-经典-大规模强化学习</title>
    <url>/2023/10/31/literature/literatureNotes16/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Algorithms-or-Actions-A-Study-in-Large-Scale-Reinforcement-Learning》"><a href="#x1f4d6-《Algorithms-or-Actions-A-Study-in-Large-Scale-Reinforcement-Learning》" class="headerlink" title="📖《Algorithms or Actions? A Study in Large-Scale Reinforcement Learning》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Algorithms or Actions? A Study in Large-Scale Reinforcement Learning》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>大型状态和动作空间对于强化学习非常具有挑战性。<ul>
<li>强化学习旨在开发通用智能体，它通过直接作用于问题动作空间来学习。然而，随着状态和动作空间变大，学习代理很难获得高性能。</li>
</ul>
</li>
<li>但是，在许多领域中，有一组可用的算法，用于估计给定状态（state）的最佳动作（action）。<ul>
<li>许多领域都有针对特定问题量身定制的现有算法，并且代理可以依赖算法池来代表其行事。</li>
</ul>
</li>
<li>因此，智能体可以直接学习<strong>从状态到操作（from states to actions）</strong>或<strong>从状态到算法（from states to algorithm）</strong>的性能最大化映射。<ul>
<li>然而，考虑到有限的计算资源，存在一个重要的冲突：我们应该<strong>学习动作（learn over actions）</strong>，训练强化学习代理以发现要采取的最佳动作，还是应该<strong>学习算法（learn over algorithms）</strong>，尝试发现最佳算法来估计在每个状态下的最佳动作？</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>先前关于抽象动作强化学习的工作已经表明：在学习算法时可能无法实现最优策略，尽管它可能会加速强化学习过程。</li>
<li>然而，目前还不清楚何时应该首选每种方法。</li>
<li>此外，当状态空间也非常大时，拥有一组算法可能仍然无法直接应用强化学习技术。特别是，实时策略游戏是人工智能研究的一个重大挑战，因为它们具有巨大的动作和状态空间。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>在这项工作中，<ul>
<li>我们研究了这种困境的几个方面，显示了在有限数量的训练迭代中，<strong>学习算法优于动作（learning over algorithms to outperform over actions）</strong>的充分条件。<ul>
<li>评估可用算法是否有足够的强度，评估算法和动作集大小之间的关系，以及可能的底层算法创建过程。</li>
</ul>
</li>
<li>我们提出了合成实验来进一步研究这些系统。合成实验进一步发展了我们的结论。</li>
<li>最后，我们提出了一种函数逼近方法，证明了在复杂领域（实时战略游戏）中学习算法的有效性。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们的算法学习模型提供了由理论分析支持的新颖指南。综合实验表明，相对性能随着动作和算法集大小的增加而增加。我们还引入了一种函数逼近方法，用于学习 RTS 游戏中的算法，其性能显着优于最先进的基于搜索的玩家。合成实验和 RTS 实验的源代码分别位于：<a class="link" href="https://github.com/andertavares/syntheticmdps">https://github.com/andertavares/syntheticmdps<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 和 <a class="link" href="https://github.com/SivaAnbalagan1/micrortsFA%E3%80%82">https://github.com/SivaAnbalagan1/micrortsFA。<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>学习算法指的是什么？具体流程如何？在一堆算法里选择一个？</li>
<li>能否学习算法和学习动作相结合？</li>
</ol>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.ijcai.org/proceedings/2018/377">[1] Rocha Tavares A, Anbalagan S, Soriano Marcolino L, et al. Algorithms or actions?: A study in large-scale reinforcement learning[C]. International Joint Conferences on Artificial Intelligence, 2018.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>AI</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
        <tag>云计算</tag>
        <tag>大规模</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记18-经典-地理分布式云调度</title>
    <url>/2023/11/04/literature/literatureNotes18/</url>
    <content><![CDATA[<h1 id="x1f4d6-《A-hierarchical-structure-for-optimal-resource-allocation-in-geographically-distributed-clouds》"><a href="#x1f4d6-《A-hierarchical-structure-for-optimal-resource-allocation-in-geographically-distributed-clouds》" class="headerlink" title="📖《A hierarchical structure for optimal resource allocation in geographically distributed clouds》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《A hierarchical structure for optimal resource allocation in geographically distributed clouds》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li><p>由于云计算中用户对各种资源的需求不断增长，优化资源分配是云环境中最重要的挑战之一。如今，大型云服务提供商通过建立大量地理分布的数据中心，为用户提供具有特定服务质量（QoS）的各种云服务，从而提高了性能，与传统数据中心相比，<strong>可靠性更高，成本更低，通信延迟更低</strong>。</p>
<ul>
<li>然而，云提供商面临的最重要挑战是通过考虑<ul>
<li>（1）满足用户需求（目标）和</li>
<li>（2）其资源限制</li>
</ul>
</li>
<li>来管理资源，这对<strong>提供商的利用率</strong>和<strong>用户满意度</strong>产生重要影响。<ul>
<li>在地理上分散的云中，这一挑战比集中式云更复杂，因为数据中心规模小（？），具有合格资源的候选数据中心数量多，导致通信延迟很大。此外，在地理位置分散的云中，有时需要多个数据中心来响应用户请求，因为一个数据中心可能没有足够的资源来满足请求。因此，分配器必须考虑多个按地理位置分布的数据中心。</li>
</ul>
</li>
<li>通过考虑服务级别协议 （SLA） 中规定的用户要求和资源提供的服务质量 （QoS），可以实现最佳资源分配。由于某些用户需求（目标）与其他一些用户需求（目标）发生冲突，因此在选择资源时需要在它们之间进行最佳权衡。<ul>
<li>具体而言，在本文中，面临的挑战是考虑一个数据中心中存在足够数量的请求资源的可能性，数据中心之间存在大量候选资源，以及包括响应时间、成本、 一方面减少网络流量，另一方面提高可靠性和可用性。云管理员应根据每个数据中心的可用虚拟机提供的服务质量 （QoS） 和用户要求，考虑云配置文件，选择一组数据中心，以便能够托管虚拟机（虚拟机）。</li>
</ul>
</li>
<li>因此，从所有可能的排列中找到一个或多个排列组合，获得这样的权衡是一个复杂且NP困难的问题，因为我们可能会提出许多具有所需QoS的资源排列（选择）。</li>
</ul>
</li>
<li><p>本文考虑的用户要求是资源的可用性和可靠性应最大化，资源成本和响应时间应最小化，以及网络流量最小化。</p>
<ul>
<li>需求的最大化和最小化相互冲突；因此，需要在它们之间进行权衡。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>解决此类问题的一种方法是使用多目标启发式算法，在本文这项研究中也使用了该算法。</li>
<li>现有研究已经提出了各种算法来分配数据中心的虚拟机，目的是降低能耗和网络感知。但是，这些算法通常被提议用于传统数据中心。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>提出了分层架构。本文采用单纯形线性规划（SLP）方法和GrEA两种资源选择方法的分层结构，其中分层结构用于表示分布式数据中心之间的连接，该方法用于在数据中心之间选择最优资源。<ul>
<li>分层结构最重要的功能是防止在数据中心发生请求累积，从而提高查找最佳 VM 的速率。</li>
</ul>
</li>
<li>考虑了多种服务质量用户需求。在大多数关于地理分布云的研究中，为了优化资源选择，考虑了一种用户需求；但是，在本研究中，数据中心是根据四种用户需求以及网络流量选择的：考虑了最大限度地提高可用性和可靠性以及最小化成本、响应时间和流量的目标。<ul>
<li>由于满足所提出的目标在云环境中很重要，因此本研究将这些目标于流量考虑因素一并关注。在选择虚拟机时，将追求以下目标：<ul>
<li>用户可以根据他/她的要求支付尽可能低的费用，</li>
<li>云提供商可以提供尽可能高的可靠性，</li>
<li>云提供商可以提供尽可能高的可用性，</li>
<li>根据用户和提供商之间的距离，可以存在尽可能短的延迟时间，从而实现尽可能短的响应时间，</li>
<li>尽可能少的流量。</li>
</ul>
</li>
<li>在上述目标中，”可能性”指的是考虑一个项目与其他项目之间的关系，即在相互冲突的目标之间进行权衡。为了在相互冲突的目标之间提供最佳权衡，通常使用多目标启发式算法。</li>
</ul>
</li>
<li>考虑了多个用户请求。在大多数研究中，一次考虑一个用户的请求，但这项工作会同时处理多个用户的请求。</li>
<li>提高了用户满意度。本研究通过使用 LP 算法来选择地理位置分散的数据中心，并使用称为 GrEA 的多目标算法来选择所选数据中心中的 VM，从而实现了这一点。为了分析所提出的方法，考虑了 6 个工作负载，包括 3 个模拟工作负载和 3 个真实工作负载。</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们的结果显示，在用户冲突需求和资源利用率之间进行了 92% 的最佳权衡。</li>
<li>此外，与相关研究相比，绩效指标覆盖率和最大价差指数表现出更强的表现。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>地理分布式云的“可靠性更高”体现在什么方面？</li>
<li>这篇文章站在什么角度？中介？</li>
<li>该架构具体如何调度？</li>
<li>优化目标是什么？“服务质量”具体指什么？如何权衡？</li>
<li>为什么 Introduction 敢断言“和集中式云相比数据中心规模小”？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.sciencedirect.com/science/article/pii/S0167739X17328844">[1] Hasan Ziafat, Seyed Morteza Babamir, A hierarchical structure for optimal resource allocation in geographically distributed clouds, Future Generation Computer Systems, Volume 90, 2019, Pages 539-568<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>跨地域</tag>
        <tag>资源调度</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记19-经典-大规模云计算系统智能学习调度</title>
    <url>/2023/11/07/literature/literatureNotes19/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Deep-and-reinforcement-learning-for-automated-task-scheduling-in-large-scale-cloud-computing-systems》"><a href="#x1f4d6-《Deep-and-reinforcement-learning-for-automated-task-scheduling-in-large-scale-cloud-computing-systems》" class="headerlink" title="📖《Deep and reinforcement learning for automated task scheduling in large-scale cloud computing systems》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Deep and reinforcement learning for automated task scheduling in large-scale cloud computing systems》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>无可否认，云计算正在成为当今主要工作负载的主要计算和存储平台。从物联网和工业 4.0 工作负载到大数据分析和决策工作，云系统每天都会收到大量需要同时有效映射到云资源的任务。<ul>
<li>云计算是一个基于互联网的平台，向用户和公司大规模提供软件、数据库、服务器、存储、分析和网络等计算服务。云计算主要因其降低运营成本的能力和始终在线的可用性而受到赞誉。物联网 (IoT) 在许多应用（例如智能交通系统、医疗保健管理等）以及相关应用中的日益普及前所未有的海量数据的产生导致人们越来越依赖云技术以资源高效且经济高效的方式存储和分析此类数据。</li>
<li>云计算以虚拟机 (VM) 的形式在虚拟平台上运行所有这些应用程序，其中每个资源维度（例如 CPU、内存、带宽等）都在不同的 VM 之间划分。这些应用程序需要以并行方式执行，以便有效地利用不同的云资源。</li>
</ul>
</li>
<li>因此，需要一种合适的任务调度机制，既能最大限度地减少任务执行延迟，又能最大限度地减少云资源利用率。<ul>
<li>需要规划和排序不同应用程序的执行，以保证最佳的资源利用率和执行性能。由于云平台上需要同时调度的应用程序<strong>数量巨大</strong>，手动分配这些应用程序变得越来越困难。这是一项几乎不可能完成的任务。</li>
</ul>
</li>
<li>最近，出现了云自动化的概念，以减少大规模云计算工作负载中的人工干预并改善资源管理。<ul>
<li>云自动化是一个新兴概念，它利用人工智能领域的蓬勃发展，最大限度地减少调度和管理云计算工作负载的手动工作。它包括设计在虚拟化之上执行的自动化技术和工具。云环境在资源分配和管理方面做出实时决策。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>云计算环境中的任务调度主题已在文献中得到广泛讨论。目前的调度方法可以分为两大类，即传统方法和智能方法。<ul>
<li>传统方法侧重于调整和扩展传统调度方法，例如先进先出、最短作业优先 (SJF)、循环 (RR)、min-min 和 max-min，以适应云计算设置。传统方法的主要限制是它们只能支持有限数量的参数（例如，完工时间）进行优化。这使得它们不适合云计算环境，在云计算环境中，任务Makespan和CPU、内存和带宽成本等许多参数需要同时优化。</li>
<li>另一方面，智能方法利用模糊逻辑、粒子群优化 (PSO) 和遗传算法 (GA) 等人工智能技术来设计更可靠的调度技术，同时优化多个参数。然而，与传统方法类似，智能调度方法通过在接收到特定任务时尝试优化一系列参数来以离线方式运行。这会导致执行时间较长，从而导致物联网和大数据分析任务等延迟关键型任务效率低下。</li>
</ul>
</li>
<li>最近，人们进行了许多尝试，以利用机器学习（尤其是深度学习）领域的蓬勃发展来实现云系统中资源管理流程的自动化。这些方法主要基于检查虚拟机的历史资源数据以预测未来工作负载的想法。目标是改善资源管理并避免供应不足和过度的情况。<ul>
<li>在本文中，我们研究了四种深度学习和强化学习方法的应用，以实现云上任务调度过程的自动化。</li>
<li>在这项工作的初步版本中，我们提出了一种智能技术，可以帮助云提供商以最小化资源利用率和总体成本的方式安排任务。</li>
<li>本文基于并扩展了我们之前的工作，通过设计、开发和比较不同的云自动化模型，使云提供商能够在可用云资源上自动调度大规模工作负载，同时最大限度地减少任务、执行延迟和云资源利用率。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>在本文中，我们利用云自动化这个概念，提出了四种基于深度强化学习的调度方法，以自动化将大规模工作负载调度到云计算资源上的过程，同时减少资源消耗和任务等待时间。目标是分析和确定最合适的技术，以最好地提高任务执行性能，同时最大限度地降低云系统上的资源成本。<ul>
<li>这些方法是：强化学习（RL）、深度 Q 网络、循环神经网络长短期记忆（RNN-LSTM）以及深度强化学习与 LSTM 相结合（DRL-LSTM）。<ul>
<li>第一种调度方法基于强化学习（RL）。<ul>
<li>我们的 RL 网络的状态空间代表了托管任务的虚拟机上的可用资源量，包括 RAM、CPU、磁盘存储和带宽。动作空间表示接收到的任务集的调度。奖励函数（在我们的例子中是成本）代表在虚拟机上执行任务的 RAM、CPU、磁盘存储、带宽和等待时间的成本。</li>
</ul>
</li>
<li>第二种调度方法使用深度 Q 网络 (DQN)。 <ul>
<li>DQN 是一种深度强化学习 (DRL) 方法，它采用神经网络来近似 Q 值（即最大化奖励函数的状态-动作对）。</li>
</ul>
</li>
<li>第三种调度方法基于长短期记忆 (LSTM)，这是一种循环神经网络 (RNN) 架构。 <ul>
<li>RNN-LSTM 的主要思想是跟踪任务的资源需求与虚拟机上的可用资源之间的历史长期依赖关系，以提取每个状态-动作对对最终执行成本的影响。从技术上讲，我们的 RNN-LSTM 单元由一个单元和三个门组成。该单元是 LSTM 的内存部分，因为它跟踪输入组件之间存在的依赖关系（在我们的例子中是调度任务的资源要求和虚拟机的资源规范）。输入门负责确定新值足以保留在存储单元中的有用程度。另一方面，遗忘门确定现有值应保留在存储单元中或丢弃的程度。最后，输出门决定了应该利用存储单元中的某个值来计算 LSTM 单元的输出激活函数的程度。</li>
</ul>
</li>
<li>第四种也是最后一种调度方法是 DRL-LSTM，使用 DQN 和 LSTM 的 DRL 组合。<ul>
<li>具体来说，添加 LSTM 单元作为 DRL 的第一层，以帮助捕获数据中的长期历史依赖性。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>使用 Google Cloud Platform 的真实数据集进行的实验表明，DRL-LSTM 的性能优于其他三种方法。实验还表明，与最短作业优先 (SJF) 相比，DRL-LSTM 将 CPU 使用成本降至 67%，与循环 (RR) 和改进的粒子群优化 (PSO) 方法相比，CPU 使用成本降低高达 35% 。此外，我们的 DRL-LSTM 解决方案与 SJF 相比，将 RAM 内存使用成本降低了 72%，与 RR 相比，降低了 65%，与改进的 PSO 相比，降低了 31.25%。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>创新性在于？</li>
<li>说是大规模，为啥不比较时间？</li>
<li>任务长什么样？价格与什么有关？不同决策为什么会有不同的成本？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.5919">[1] Rjoub, G, Bentahar, J, Abdel Wahab, O, Saleh Bataineh, A. Deep and reinforcement learning for automated task scheduling in large-scale cloud computing systems. Concurrency Computat Pract Exper. 2021; 33:e5919. https://doi.org/10.1002/cpe.5919<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
        <tag>调度</tag>
        <tag>大规模</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记20-经典-深度强化学习</title>
    <url>/2023/11/09/literature/literatureNotes20/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Deep-Reinforcement-Learning-with-Double-Q-Learning》"><a href="#x1f4d6-《Deep-Reinforcement-Learning-with-Double-Q-Learning》" class="headerlink" title="📖《Deep Reinforcement Learning with Double Q-Learning》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Deep Reinforcement Learning with Double Q-Learning》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>众所周知，流行的 Q 学习算法在某些条件下会高估动作值。<ul>
<li>强化学习的目标是通过优化<strong>累积的未来奖励信号</strong>来学习顺序决策问题的良好策略。 </li>
<li>Q 学习（Watkins 1989）是最流行的强化学习算法之一，但众所周知，它有时会学习到不切实际的高动作值，因为它包含对估计动作值的最大化步骤，这往往更喜欢高估而不是低估的值。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>以前不知道在实践中这种高估是否普遍，它们是否会损害绩效，以及它们是否通常可以预防。<ul>
<li>在之前的工作中，高估被归因于不够灵活的函数逼近（Thrun and Schwartz 1993）和噪声（van Hasselt 2010，2011）。<ul>
<li>在本文中，我们统一了这些观点，并表明当动作值不准确时，无论近似误差的来源如何，都可能会发生高估。当然，不精确的价值估计是学习过程中的常态，这表明高估可能比以前意识到的更为常见。</li>
</ul>
</li>
<li>如果确实发生高估，是否会对实践中的表现产生负面影响，这是一个悬而未决的问题。过度乐观的价值估计本身并不一定是一个问题。如果所有值都一致较高，那么相对行动偏好就会被保留，我们不会期望最终的政策会变得更糟。此外，众所周知，有时保持乐观是有好处的：面对不确定性保持乐观是一种众所周知的探索技巧（Kaelbling et al. 1996）。然而，如果高估不统一并且不集中在我们希望了解更多信息的状态，那么它们可能会对最终政策的质量产生负面影响。 Thrun 和 Schwartz（1993）给出了具体的例子，其中这会导致次优的政策，甚至是渐近的。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>在本文中，我们肯定地回答了所有这些问题。<ul>
<li>特别是，我们首先表明，将Q学习与深度神经网络相结合的最新DQN算法在Atari 2600领域的某些游戏中遭受了严重的高估。<ul>
<li>为了测试在实践中和规模上是否出现高估，我们研究了最近的 DQN 算法的性能（Mnih 等人，2015）。 DQN 将 Q 学习与灵活的深度神经网络相结合，并在大量确定性 Atari 2600 游戏上进行了测试，在许多游戏中达到了人类水平的表现。在某些方面，这种设置是 Q 学习的最佳情况，因为深度神经网络提供了灵活的函数逼近，具有低渐近逼近误差的潜力，并且环境的确定性可以防止噪声的有害影响。也许令人惊讶的是，我们发现即使在这种相对有利的环境中，DQN 有时也会大大高估动作的价值。</li>
</ul>
</li>
<li>然后，我们表明，在表格设置中引入的双 Q 学习算法背后的思想可以推广到大规模函数逼近。我们提出了对DQN算法的特定调整，并表明所得到的算法不仅减少了观察到的高估，而且这也导致了在几场比赛中更好的性能。<ul>
<li>我们证明了首次在表格设置中提出的双 Q 学习算法（van Hasselt 2010）可以推广到任意函数逼近，包括深度神经网络。我们用它来构建一个名为 Double DQN 的新算法。该算法不仅可以产生更准确的价值估计，而且可以在多个游戏中获得更高的分数。这表明，高估 DQN 确实会导致政策较差，而减少 DQN 是有益的。此外，通过改进 DQN，我们在 Atari 领域获得了最先进的结果。</li>
</ul>
</li>
</ul>
</li>
<li>本文有五个贡献。<ul>
<li>首先，我们展示了为什么 Q 学习在大规模问题中可能过于乐观，即使这些问题是确定性的，因为学习固有的估计误差。</li>
<li>其次，通过分析雅达利游戏的价值估计，我们发现这些高估在实践中比之前承认的更为常见和严重。</li>
<li>第三，我们已经证明，可以大规模使用双 Q 学习来成功减少这种过度乐观，从而实现更加稳定和可靠的学习。</li>
<li>第四，我们提出了一种称为 Double DQN 的具体实现，它使用 DQN 算法的现有架构和深度神经网络，而不需要额外的网络或参数。</li>
<li>最后，我们证明了 Double DQN 找到了更好的策略，在 Atari 2600 域上获得了最佳结果。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们证明了 Double DQN 找到了更好的策略，在 Atari 2600 域上获得了最佳结果。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>强化学习的基础逻辑是什么？“累积的未来奖励信号（cumulative future reward signal）”是什么含义？</li>
<li>为什么会导致高估动作的奖励？具体过程如何？</li>
<li>对强化学习的细节了解太少，该从什么地方开始学习？比如从向他人介绍论文的角度介绍强化学习的逻辑？或先提出一个算法再在实践时学习</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.5555/3016100.3016191">[1] Hado van Hasselt, Arthur Guez, and David Silver. 2016. Deep reinforcement learning with double Q-Learning. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI’16). AAAI Press, 2094–2100.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>AI</category>
      </categories>
      <tags>
        <tag>深度强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记2-经典-CloudSimPlus</title>
    <url>/2023/05/17/literature/literatureNotes2/</url>
    <content><![CDATA[<h1 id="x1f4d6-《CloudSim-Plus-A-cloud-computing-simulation-framework-pursuing-software-engineering-principles-for-improved-modularity-extensibility-and-correctness》"><a href="#x1f4d6-《CloudSim-Plus-A-cloud-computing-simulation-framework-pursuing-software-engineering-principles-for-improved-modularity-extensibility-and-correctness》" class="headerlink" title="📖《CloudSim Plus: A cloud computing simulation framework pursuing software engineering principles for improved modularity, extensibility and correctness》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《CloudSim Plus: A cloud computing simulation framework pursuing software engineering principles for improved modularity, extensibility and correctness》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>云计算是一种成熟的技术，可以按需提供计算资源，目前面临一些挑战。<ul>
<li>主要挑战包括：<ul>
<li>共享资源的管理、能源消耗、负载平衡、资源配置和分配以及服务级别协议 （SLA） 的履行。</li>
</ul>
</li>
</ul>
</li>
<li>尽管云提供了按需收费模式，但在实际基础设施中实施大规模实验是昂贵、耗时的，限制了实验的可重复性，并且由于不受控制的环境而损害了测量。由于这些固有的复杂性，新的模型和算法主要通过云模拟来试验。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>学界已开发了几种用于云计算的模拟工具，使用最广泛的是CloudSim，这是一个用于云计算的通用且可扩展的模拟框架。</li>
<li>有助于广泛采用CloudSim的特征是：<ul>
<li>（i）它是用Java（一种广泛使用的编程语言）开发的;</li>
<li>（ii） 该项目是开源的，允许其他开发人员做出贡献;</li>
<li>（iii）它是第一个开源的专用云模拟框架;</li>
<li>（iv）它为创建模拟场景提供了极大的灵活性，其中每个场景都必须使用Java代码而不是使用僵化的图形工具来实现。</li>
</ul>
</li>
<li>存在以下缺点：<ul>
<li>（i） 文件有限;</li>
<li>（ii） 危及可维护性、可扩展性和测试的重复代码数量;</li>
<li>（iii） 缺乏功能/集成测试，这对于确保模拟器的正确性和有效性很重要;</li>
<li>（iv）缺乏设计模式来改进软件工程和面向对象设计的几个指标;</li>
<li>（v）不符合某些软件工程实践和建议，如SOLID原则;</li>
<li>（vi） 缺乏更有条理的一揽子结构，无法更好地理解项目并使之成为模块化;</li>
<li>（vii）缺乏更好的类结构，允许第三方开发人员在框架中实现缺失的功能，而无需更改核心类。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>这项工作介绍了CloudSim Plus，这是一个开源模拟框架，追求符合软件工程原则和面向对象设计，以提供可扩展，模块化和准确的工具。<ul>
<li>它基于CloudSim框架，旨在改进几个工程方面，例如可维护性，可重用性和可扩展性。</li>
<li>它的主要贡献是：<ul>
<li>（i）改进了类层次结构和代码，这更容易理解;</li>
<li>（ii）更多地应用可重用性原则;</li>
<li>（iii）全面审查和改进守则文件;</li>
<li>（iv）重新调整项目模块和包的结构，以简化使用并改进关注点分离（SoC）原则;</li>
<li>（v）增加集成测试以涵盖整个模拟场景;</li>
<li>（vi）官方网站上详细描述的全新功能集。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>这项工作展示了CloudSim Plus的优势，它的特殊功能，它如何确保更高的准确性，扩展设施和使用简单性。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>这类模拟器相关论文，是否与一般的方法性论文的结构有所区别？审稿人对这类论文的要求是怎样的？如果想写一篇模拟器相关论文，应该怎么写？<blockquote>
<p>本文结构：<br>  引言 -&gt; 相关工作 -&gt; CloudSim Plus 概述（目标分析，特性简介） -&gt; 架构（整体设计及主要类） -&gt; 与现有方案相比的改进 -&gt; 特性和优势详解 -&gt; 使用方法</p>
</blockquote>
</li>
</ol>
<h2 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h2><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/7987304">[1] M. C. Silva Filho, R. L. Oliveira, C. C. Monteiro, P. R. M. Inácio and M. M. Freire, “CloudSim Plus: A cloud computing simulation framework pursuing software engineering principles for improved modularity, extensibility and correctness,” 2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM), Lisbon, Portugal, 2017, pp. 400-406, doi: 10.23919/INM.2017.7987304.（CCF-C）<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>模拟器</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记21-经典-深度强化学习云调度</title>
    <url>/2023/11/09/literature/literatureNotes21/</url>
    <content><![CDATA[<h1 id="x1f4d6-《DRL-cloud-Deep-reinforcement-learning-based-resource-provisioning-and-task-scheduling-for-cloud-service-providers》"><a href="#x1f4d6-《DRL-cloud-Deep-reinforcement-learning-based-resource-provisioning-and-task-scheduling-for-cloud-service-providers》" class="headerlink" title="📖《DRL-cloud: Deep reinforcement learning-based resource provisioning and task scheduling for cloud service providers》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《DRL-cloud: Deep reinforcement learning-based resource provisioning and task scheduling for cloud service providers》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>云计算已成为学术界和工业界颇具吸引力的计算范例。<ul>
<li>云计算已经成为一种令人信服且强大的范式，它通过互联网以服务形式提供对可配置计算资源共享池的无所不在的按需访问。</li>
</ul>
</li>
<li>通过虚拟化技术，拥有数据中心的云服务提供商（CSP）可以将物理服务器构建为虚拟机（VM），为用户提供服务、资源和基础设施。<ul>
<li>虚拟化是云计算的基础技术，它使多个操作系统能够在同一物理平台上运行，并将服务器构建为虚拟机（VM）。云服务提供商 (CSP) 使用虚拟机来提供基础架构、平台和资源（例如 CPU、内存、存储等）。</li>
</ul>
</li>
<li>以盈利为导向的CSP通过向用户收取服务接入费和虚拟机租赁费，降低能耗和电费，从而提高利润率。<ul>
<li>在云计算范式中，CSP 受到向用户<strong>收取云服务访问、资源使用和虚拟机租赁费用</strong>的好处的激励，而用户则被可根据自己的要求<strong>降低其在计算、时间和能耗方面支出</strong>的好出所吸引。</li>
</ul>
</li>
<li>CSPs面临的主要挑战是数据中心能源成本最小化。<ul>
<li>尽管谷歌应用引擎（GAE）和亚马逊弹性计算云（EC2）等许多知名的CSP取得了成功，但数据中心耗电量方面巨大的能源成本是一个严峻的挑战。预计到2020年，数据中心每年的用电量约为1400亿千瓦时，每年的电费费用为130亿美元。因此，为了提高利润率，同时减少碳足迹，实现可持续发展和节约型社会，最大限度地减少大型光热发电的数据中心电力消耗势在必行。</li>
<li>根据<a href="#refer-anchor-2">[2]</a>，数据中心的能源使用有两个重要特征：<ul>
<li>（i）服务器在低利用率下往往更加能源效率低下（大多数服务器的最佳能源效率利用率在70％到80％之间）， </li>
<li>（ii） 服务器在空闲模式下可能会消耗大量电量。</li>
</ul>
</li>
<li>因此，可以应用<strong>服务器整合和负载平衡</strong>，通过有选择地关闭闲置服务器并提高活动服务器的利用率水平来提高整体能源效率。同时，应一致满足服务级别协议（SLA）中的协议，该协议由 CSP 和用户就隐私、安全、可用性和补偿进行协商。</li>
<li>降低能源消耗和电力成本对通信服务提供商来说是一个挑战，原因有两个：<ul>
<li>首先，由于<strong>服务器规模庞大</strong>，每天的传入<strong>请求数量巨大</strong>，而且两者仍在增长，因此支出控制的<strong>可扩展性</strong>至关重要。</li>
<li>其次，由于用户请求模式可能会在短期（一天之内）和长期（从月/年到月/年）发生<strong>变化</strong>，因此需要能源和电力成本降低方法的<strong>适应性和自学习能力</strong>。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/e66e7d5f13606230ea1d2f8eaf2812c996e8a655/2-Figure1-1.png" alt="System model of the cloud platform and structure for DRL-Cloud."><figcaption>System model of the cloud platform and structure for DRL-Cloud.</figcaption></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>先前的工作提出了各种算法来通过资源供应（RP）和/或任务调度（TS）来降低能源成本。然而，他们存在：<ul>
<li><strong>可扩展性问题</strong>；</li>
<li>或者<strong>没有考虑具有任务依赖性的TS</strong>，而这是确保任务正确并行执行的关键因素；</li>
<li>它们的离线算法在处理大尺寸输入和适应变化（例如，处理不同的用户请求模式）方面存在困难。</li>
</ul>
</li>
<li>最近提出的深度强化学习（DRL）技术在玩 Atari 和围棋游戏中取得了成功，通过利用深度神经网络，对具有高维状态空间和低维动作空间的复杂控制问题具有出色的解决能力。受此启发，N. Liu 等人应用DRL（部分）解决云计算中的资源分配问题，无需对具有数据依赖性的任务进行详细调度，这对于保证任务正确执行至关重要。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了全面解决能源成本降低问题，我们提出了DRL-Cloud框架，这是第一个基于DRL的高度可扩展和适应性强的RP和TS系统，能够处理大规模数据中心和不断变化的用户请求，可最大限度地降低拥有大量服务器、每天接收大量用户请求的大型 CSP 的能源成本。<ul>
<li>基于深度 Q 学习的两级 RP-TS 处理器旨在通过学习不断变化的环境（例如用户请求模式和实际电价）来自动生成最佳的长期决策。通过目标网络、经验回放、探索和利用等训练技术，所提出的 DRL-Cloud 实现了极高的能源成本效率、低拒绝率以及快速收敛的低运行时间。</li>
<li>在本文中，使用了由分时定价（TOUP）和实时定价（RTP）组成的一般类型的现实定价策略。此外，还使用Pay-As-You-Go计费协议（如GAE和EC2中的那样）。所有截止日期都是硬性截止日期，如果违反硬性截止日期，任务将被拒绝。 </li>
</ul>
</li>
<li>DRL-Cloud由两个主要部分组成：<ul>
<li>i）用户请求接受并解耦为作业队列和任务就绪队列； </li>
<li>ii）通过我们基于 DRL 的两级 RP-TS 处理器实现能量成本最小化，并通过深度 Q 学习中的训练技术（例如目标网络和经验回放）保证快速收敛。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/e66e7d5f13606230ea1d2f8eaf2812c996e8a655/3-Figure2-1.png" alt="The structure of the DRL-Cloud framework"><figcaption>The structure of the DRL-Cloud framework</figcaption></figure></li>
</ul>
</li>
</ul>
<p>创新点：</p>
<ol>
<li>将 DRL 应用于 RP 和 TS。据我们所知，这是<strong>第一篇</strong>提出基于 DRL 的 RP 和 TS 系统的论文，以最大限度地降低具有大规模数据中心和大量具有依赖性的用户请求的 CSP 的能源成本。基于 DRL 的两级 RP-TS 处理器被设计为通过从不断变化的环境中学习，自动生成最佳动作，以长期获得最低的能源成本，其多级结构使所提出的 DRL-Cloud 具有高效率和高可扩展性。 </li>
<li>半马尔可夫决策过程(SMDP) 制定。云资源分配和能源成本最小化问题是基于半马尔可夫决策过程制定的，因为DRL-Cloud接收到的用户请求会提高随机性，数据中心的资源利用状态可以制定为MDP。 RP-TS处理器的两个阶段都定义了状态空间和动作空间，这两个空间都很大但有限。 </li>
<li>收敛速度快，适应性强。所提出的DRL-Cloud可与训练算法完全并行，这使我们的系统具有鲁棒性、高效性和稳定演进的能力。利用经验回放和目标网络等训练技术，使得DRL-Cloud在0.5秒以内收敛，具有高适应性和低运行时间。 </li>
<li>运行时间极短，能源成本极低。与 FERPTS（考虑历史资源分配和当前服务器利用率的最先进方法之一）相比，DRL-Cloud 实现了高达 3 倍的能源成本效率改进，同时保持高达 2 倍的较低用户请求拒绝率（硬期限违规）率）并减少高达 92 倍的运行时间。与以运行时间极短着称的 Roundrobin 方法相比，DRL-Cloud 的运行时间减少了 12 倍，能源成本效率提高了 2 倍，拒绝的用户请求减少了 15 倍。</li>
</ol>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>与最先进的节能算法之一相比，所提出的 DRL-Cloud 实现了高达 320% 的能源成本效率提升，同时保持较低的平均废品率。对于具有 5, 000 台服务器和 200, 000 个任务的 CSP 设置示例，与快速循环基准相比，建议的 DRL-Cloud 实现了高达 144% 的运行时间减少。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>考虑能耗和考虑价格是不是能归纳为一个意思？</li>
<li>没说现有 DRL 的研究有什么不足？</li>
<li>本文对于背景需求的描述非常清晰。阅读其他论文时也应当注意梳理其需求，自己写背景时也应当仿照该文的逻辑。</li>
<li>本文的图画得很好看。</li>
<li>需要总结：1）相同/相似背景文章对需求、场景、目标的定义；2）相同/相似技术（DRL）在优势方面的表述。</li>
<li>两阶段 DRL 分别在干什么？是否会导致局部最优？</li>
<li>服务器空闲模式下的计费没考虑？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/8297294">[1] M. Cheng, J. Li and S. Nazarian, “DRL-cloud: Deep reinforcement learning-based resource provisioning and task scheduling for cloud service providers,” 2018 23rd Asia and South Pacific Design Automation Conference (ASP-DAC), Jeju, Korea (South), 2018, pp. 129-134, doi: 10.1109/ASPDAC.2018.8297294.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link" href="https://link.springer.com/book/10.1007/978-3-031-01761-2">[2] L. A. Barroso, J. Clidaras and U. Hölzle, “The datacenter as a computer: An introduction to the design of warehouse-scale machines”, Synthesis lectures on computer architecture, vol. 8, no. 3, pp. 1-154, 2013.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>深度强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记22-前沿-深度强化学习节能任务调度</title>
    <url>/2023/11/11/literature/literatureNotes22/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Energy-Efficient-Joint-Task-Assignment-and-Migration-in-Data-Centers-A-Deep-Reinforcement-Learning-Approach》"><a href="#x1f4d6-《Energy-Efficient-Joint-Task-Assignment-and-Migration-in-Data-Centers-A-Deep-Reinforcement-Learning-Approach》" class="headerlink" title="📖《Energy-Efficient Joint Task Assignment and Migration in Data Centers: A Deep Reinforcement Learning Approach》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Energy-Efficient Joint Task Assignment and Migration in Data Centers: A Deep Reinforcement Learning Approach》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>数据中心的节能任务调度是一个关键问题，引起了人们的广泛关注。<ul>
<li>随着云计算的快速发展，越来越多的任务可以提交到数据中心进行处理。</li>
<li>数据中心的严重问题之一是巨大的能源消耗，这会导致高昂的运营成本和大量的二氧化碳（CO2）排放。对于像谷歌这样的大公司来说，能源成本降低 3% 可以转化为超过 100 万美元的成本节约。<strong>统计结果显示，当服务器以非常低的负载运行时，会浪费大量能源。</strong>因此，设计高能效的任务调度算法来降低数据中心的能耗是必不可少的。</li>
</ul>
</li>
<li>但是，任务执行时间是混合的，在实际数据中心中很难估计。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>现有工作明显忽略了在任务到达时间做出的调度决策可能会导致能源浪费或资源闲置。<ul>
<li>在节能任务调度领域，研究人员专注于到达时间的任务分配。<ul>
<li>提交新任务时，会将该任务分配给适当的服务器，然后服务器为其启动虚拟机 （VM） 或容器。任务分配可以被认为是一种经典的箱打包问题，有几种启发式算法被设计用于广泛的应用，如循环和最佳拟合。</li>
<li>在相关文献中，基于深度强化学习（DRL）的算法被设计用于分配任务以实现高性能。以前的一些工作研究了节能任务迁移。在运行时，可以在虚拟机或容器中运行的任务动态迁移到其他服务器进行整合。通过这种方式，可以释放更多的服务器并切换到睡眠模式。</li>
</ul>
</li>
<li>然而，很少有关于<strong>联合任务分配和迁移的研究</strong>能够在任务的整个生命周期内实现更好的能源效率。<ul>
<li>一方面，由于数据中心的任务时长通常遵循<strong>长尾分布</strong>，因此长时间运行的任务只占任务总数的一小部分，但消耗了大量的资源。<ul>
<li>仅执行任务分配并不能确保这些长时间运行的任务的能源效率，因为它很难区分长时间运行的任务的到达时间，或者将它们分配给几台服务器进行整合。当任务工作负载减少时，运行时间较短的任务会提前完成，而长时间运行的任务则在服务器上运行，从而导致能源浪费。</li>
</ul>
</li>
<li>另一方面，数据中心正在运行大量<strong>短期任务</strong>，迁移大量短期任务的成本从几秒钟到几分钟不等，这极大地影响了这些短期运行任务的性能。<ul>
<li>由于任务运行时的估计误差很大，在到达时很难区分长时间运行的任务和短期运行的任务，这使得混合持续时间的任务调度更具挑战性。总之，以前的工作对整个生命周期中混合持续时间的任务调度不够重视。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>以往基于DRL技术的数据中心资源分配工作主要需要对深度神经网络（DNN）进行大量的离线训练，存在以下缺点：<ul>
<li>（1）需要大量的工作负载跟踪和精心生成的状态转换配置文件来对混合持续时间任务进行建模。</li>
<li>（2）集装箱资源需求的过渡概率在相对较短的时间内（如1天）是准静态的。几天前收集的历史数据很难反映当前场景的特征，因此在线培训至关重要。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>为了填补这些空白，本文共同考虑了混合持续时间任务的分配和迁移，提出了混合持续时间任务调度问题。</p>
<ul>
<li>任务分配和迁移过程是一系列相关的计划决策。为了反映不同时间调度决策之间的相关性，将调度问题建模为马尔可夫决策过程（MDP）问题。考虑到数据中心中许多同时运行的任务，MDP 问题具有巨大的状态空间。为了处理如此大规模的MDP问题，我们选择了DRL，它可以处理复杂控制问题的巨大状态空间作为底层技术。</li>
</ul>
</li>
<li><p>进一步地，设计了一种新颖的节能任务调度算法。任务分配可以提高资源利用率，当长时间运行的任务在低负载服务器中运行时，需要迁移。</p>
<ul>
<li>为了满足时变资源需求，避免DNN繁重的离线训练，我们提出了一种基于在线DRL的任务调度算法（ODTS），该算法由任务分配策略和任务迁移策略组成。<ul>
<li>任务分配策略在任务到达时将任务分配给适当的服务器。提出了各种优化，使 DNN 以在线方式进行训练。<ul>
<li>首先，为了更好地评估每个分配决策，奖励被表述为分配前后平均功率之间的差值。</li>
<li>然后，为了实现在线训练，采用权重共享结构来减少DNN参数的数量，并应用排序模块来识别服务器状态的不同排列。</li>
<li>此外，通过高效探索加快收敛速度，生成训练数据，缓解稀疏奖励问题。</li>
</ul>
</li>
<li>此外，ODTS启发式地选择几个已经执行了很长时间的任务，以减少同时迁移所有任务的动作空间。<ul>
<li>然后，应用建议的任务迁移策略，以选择适当的服务器来迁移每个选定的任务。</li>
<li>最后，为了消除各种任务工作负载的影响，奖励被重新表述为CPU利用率除以平均功耗的积分，而不是能耗和QoS等的线性组合。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>贡献可以总结如下：</p>
<ul>
<li>1）为了高效地调度数据中心的混合持续时间任务，我们在任务的整个生命周期中共同考虑任务分配和迁移。我们制定了任务调度问题，并进一步将其建模为MDP问题。</li>
<li>2）为了解决MDP问题，设计了一种基于DRL的算法。此外，为了满足时变资源需求，我们优化了DNN结构，重新制定了奖励，采用高效的动作选择，并生成训练数据，以实现在线训练。</li>
<li>3）我们实施ODTS并评估性能。实验表明，在几乎相同的服务质量（QoS）和相同的迁移时间下，所提算法在能耗方面平均比现有基线算法高出14%。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>对真实世界数据的实验表明，所提出的算法在能耗方面比现有基线平均高出 14%，同时保持相同的服务质量 （QoS） 水平并实现在线训练。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li></li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9903901">[1] J. Lou, Z. Tang and W. Jia, “Energy-Efficient Joint Task Assignment and Migration in Data Centers: A Deep Reinforcement Learning Approach,” in IEEE Transactions on Network and Service Management, vol. 20, no. 2, pp. 961-973, June 2023, doi: 10.1109/TNSM.2022.3210204.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>深度强化学习</tag>
        <tag>任务调度</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记23-前沿-基于模仿学习的在线车载边缘计算任务调度</title>
    <url>/2023/11/12/literature/literatureNotes23/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Imitation-Learning-Enabled-Task-Scheduling-for-Online-Vehicular-Edge-Computing》"><a href="#x1f4d6-《Imitation-Learning-Enabled-Task-Scheduling-for-Online-Vehicular-Edge-Computing》" class="headerlink" title="📖《Imitation Learning Enabled Task Scheduling for Online Vehicular Edge Computing》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Imitation Learning Enabled Task Scheduling for Online Vehicular Edge Computing》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>车载边缘计算（VEC）是一种基于车联网的有前途的范式，可为终端用户提供计算资源，减<strong>轻蜂窝网络</strong>的繁重流量负担。<ul>
<li>随着智慧城市的建立和物联网技术的发展，智慧交通、娱乐资源共享、公共安全、应急等具有位置和时延要求的服务和应用正在迅速增加。每天都有海量数据产生，对灵活的网络管理和计算资源有均衡的需求。车载边缘计算（VEC）有望通过将计算密集型任务迁移到网络边缘来应对车联网（IoV）的挑战。路侧单元（RSU）是一种沿道路部署的基础设施，为各种车辆提供网络接入。</li>
<li>为了建设绿色城市，有效利用能源，为过往车辆提供无缝服务，VEC必须制定<strong>节能政策</strong>。根据名为SMARTer2030的研究报告，利用信息和通信技术引起的二氧化碳排放量正以平均每年6%的速度增长。到2020年底，它们将占全球排放量的12%。此外，纯电动汽车和混合动力汽车将在不久的将来主导汽车市场。因此，网络运营商和车辆的巨大能源需求促使我们研究VEC网络的节能政策。</li>
<li>目前，VEC的框架可分为 “基于基础设施的VEC” 和 “无基础设施的VEC两种”。<ul>
<li>对于前者，VEC 服务器总是与 <strong>RSU</strong> 合并以缓存内容或提供计算资源。</li>
<li>对于后者，可以探索<strong>移动和停放车辆</strong>中的<strong>闲置资源</strong>来支持VEC。由于无基础设施的VEC不需要额外的网络部署，可以有效整合闲置的网络资源，因此近年来越来越受到关注。</li>
</ul>
</li>
<li>尽管<strong>无基础设施的VEC</strong>可以为道路上的用户提供卸载服务，但在<strong>高度动态</strong>的车辆网络中应仔细设计<strong>任务调度</strong>策略。<ul>
<li>这是因为车载应用总是需要<strong>实时响应</strong>，如何满足VEC网络中对延迟敏感的任务，以及如何在<strong>服务时间有限的动态服务器</strong>之间调度它们，成为一个主要问题。</li>
<li>然而，考虑到动态提供方服务器的服务时间有限，为无基础设施的VEC设计解决方案是相当困难的。一般来说，网络中参与的车辆可以分为两类，即服务提供车辆（SPV）和服务需求车辆（SDV）。前者充当资源提供者，提供计算服务；后者可以访问网络服务并将任务卸载到 SPV。我们交替提及“SPV”和“VEC服务器”这两个术语，因为VEC服务器是由SPV在我们设计的算法中形成的。</li>
</ul>
</li>
</ul>
</li>
<li>在本文中，我们考虑了一个具有动态拓扑结构、不稳定连接和不可预测运动的 VEC 网络。<ul>
<li>车内车辆可以将计算任务卸载到由车载资源形成的可用相邻 VEC 集群，目的是最大限度地<strong>降低系统能耗并满足任务延迟限制</strong>。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>对于在线任务调度，现有的研究要么设计启发式算法，要么利用机器学习，例如深度强化学习（DRL）。然而，这些算法对于大规模网络来说<strong>搜索效率低，收敛速度慢，效率不够高</strong>。</li>
<li>包括多个SPV和SDV在内的<strong>无基础设施VEC</strong>面临的挑战可以总结如下：<ul>
<li>1）现有研究总是允许 SDV 将其任务卸载到相邻的 SPV，或者将多个副本发送到 SPV 进行处理，以保证任务延迟约束。<ul>
<li>但一方面，单纯将任务分流给邻居可能会导致 SPV <strong>负担不平衡，资源利用率低</strong>。</li>
<li>另一方面，发送多个副本会<strong>浪费大量网络资源</strong>。因此，如何有效管理 SPV 上的闲置资源亟待深入研究。</li>
</ul>
</li>
<li>2）在无基础设施的 VEC 中，SPV 定期向周围的 SDV 广播其信息，包括位置、速度和移动方向，SDV 根据这些信息安排其任务。<ul>
<li>但是，频繁的信息交换会造成较大的<strong>通信开销</strong>，应减少这种开销以提高通信效率。</li>
</ul>
</li>
<li>3）对于在线任务调度，传统算法总是采用启发式搜索策略。<ul>
<li>然而，在这种高度动态的网络拓扑结构中，它们可能具有<strong>较低的搜索效率和较高的计算复杂性</strong>。</li>
<li>此外，有限的服务时间、不稳定的VEC服务和动态的车辆运动使得在线任务调度具有相当大的<strong>挑战性</strong>。因此，有必要通过考虑这些不同的参数来找到一种灵活的策略来解决任务调度问题。</li>
</ul>
</li>
<li>4）通常，深度强化学习（DRL）用于解决复杂环境下的任务调度问题。<ul>
<li>然而，基于 DRL 的算法通常<strong>收敛速度较慢</strong>。此外，由于角色不稳定、运动不确定性和车辆数量庞大等原因导致网络状态的频繁演化，导致 DRL 的状态和动作空间超大。学习算法计算延迟大，导致学习过程中数百万步的网络性能极差，这是在线调度所不能接受的。因此，有必要设计一种收敛速度快的基于学习的算法来保证在线系统性能。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>我们提出了一种基于模仿学习的在线任务调度算法，该算法在初始阶段具有接近最优的性能。特别是，专家可以通过离线几个样本求解制定的优化问题来获得最优调度策略。对于在线学习，我们按照专家的演示来训练代理策略，理论上具有可接受的绩效差距。</p>
<ul>
<li>针对上述挑战，本文提出了一种在线VEC算法，命名为IELTS。<ul>
<li>对于第一个挑战，我们建立了VEC模型，并将任务调度问题表述为优化问题。RSU 用于帮助在不同服务器之间调度任务，充当路由器或网关的角色。我们的解决方案仍然没有基础设施，因为它不需要 RSU 来缓存或处理 SDV 的计算任务。在此基础上，分析 SPV 在 RSU 覆盖中的服务能力，并通过整合其闲置资源进行聚类。</li>
<li>为了应对第二个挑战，每个 RSU 都用于维护集群级别信息，而 SPV 级别信息则在其集群内进行维护。因此，SPV 和 RSU 之间的通信开销可以大大降低。</li>
<li>为了解决最后两个挑战，我们设计了一种基于模仿学习的方法，以克服传统算法带来的搜索效率低、收敛速度慢等缺点。实际上，模仿学习是一种机器学习方法，允许智能体模仿参考策略（或专家的演示），这些策略是原始问题的有效解决方案。由于时间复杂度高，参考策略无法直接在线执行。因此，应制定学习政策，以便通过培训过程进行模仿。据我们所知，本文是研究高动态VEC网络中边界仿真学习的在线任务调度问题的早期努力。</li>
</ul>
</li>
</ul>
</li>
<li><p>我们的贡献可以总结如下：</p>
<ul>
<li>我们首先通过考虑通信和计算资源建立系统模型，并将任务调度问题表述为优化问题。为了解决公式化的问题，我们将其分解为两个子问题，即资源聚合和任务调度，目的是将任务分配给合适的SPV集群。</li>
<li>为了解决第一个子问题，我们分析了本地SPV在RSU覆盖中的服务能力，通过分析，我们发现聚类SPV可以建模为M/G/K/N在服务期间排队系统。在此基础上，可以通过考虑形成的聚类来对所制定的优化问题进行变换。然后，通过模仿专家的策略进行基于集群的任务调度，可以解决第二个子问题，其中收敛时间可以大大缩短。</li>
<li>我们以理论的方式分析了算法的性能，并证明了我们的算法可以达到与专家提供的性能差距。此外，我们还推导了我们设计的任务调度算法的能耗上限。据我们所知，这项工作在通过模仿学习解决VEC网络中的任务调度问题方面做出了早期努力。</li>
<li>我们基于包含真实世界出租车轨迹的数据集进行实验。性能结果表明，该算法在平均能耗、本地SPV任务处理率和平均任务执行延迟方面均有优势，与启发式在VEC服务器和远程云之间调度任务的基准相比，提高了50%以上。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>性能结果表明，我们的解决方案具有显著优势，与基准相比，改进了 50% 以上。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li></li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9151371">[1] X. Wang, Z. Ning, S. Guo and L. Wang, “Imitation Learning Enabled Task Scheduling for Online Vehicular Edge Computing,” in IEEE Transactions on Mobile Computing, vol. 21, no. 2, pp. 598-611, 1 Feb. 2022, doi: 10.1109/TMC.2020.3012509.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>深度强化学习</tag>
        <tag>任务调度</tag>
        <tag>车联网</tag>
        <tag>边缘计算</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记24-经典-大规模智算集群任务调度</title>
    <url>/2023/11/14/literature/literatureNotes24/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Job-scheduling-for-large-scale-machine-learning-clusters》"><a href="#x1f4d6-《Job-scheduling-for-large-scale-machine-learning-clusters》" class="headerlink" title="📖《Job scheduling for large-scale machine learning clusters》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Job scheduling for large-scale machine learning clusters》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>随着现代平台上运行的机器学习 (ML) 和深度学习 (DL) 应用程序的快速增长，满足应用程序性能要求（例如按时完成和确保准确性）至关重要。<ul>
<li>机器学习 (ML) 和深度学习 (DL) 技术的快速普及和发展为未来铺平了道路，智能应用程序可以帮助人们完成生活、工作和学习等个人任务，以及更广泛的社区目标，例如例如更高效的交通、有效的医疗保健和其他活动。<ul>
<li>例如，科学家使用机器学习技术来预测病毒（例如 2020 年中国武汉的冠状病毒）在人群中的传播情况，以及飓风（例如 2019 年的飓风多里安）的路径，以便在受影响地区及时采取预防措施。</li>
</ul>
</li>
<li>许多公司（例如亚马逊和谷歌）和学术组织现在为用户提供训练机器学习模型的平台。如<a href="#refer-anchor-fig1">图1</a> 所示，ML 作业被提交到 ML 集群并放入作业队列中，等待分配给服务器。</li>
<li>作业总是有<strong>性能要求（例如截止日期和准确性）</strong>。<ul>
<li>例如，预测飓风路径的机器学习作业必须在飓风登陆前的某个时间以较高的预测精度完成，以最大程度地避免损坏和人员伤亡。</li>
</ul>
</li>
</ul>
</li>
<li>因此，确保 ML 集群中所有正在运行和等待的 ML 作业<strong>及时完成而不降低其准确性性能</strong>至关重要。</li>
<li>近年来，ML 和 DL 模型变得越来越深、越来越大，这极大地增加了作业完成时间（JCT）。</li>
</ul>
<div id="refer-anchor-fig1"></div>

<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/af9806c22e8b78d9d995c5f8f85cf7bf367a873a/1-Figure1-1.png" alt="Figure 1: ML job cluster"><figcaption>Figure 1: ML job cluster</figcaption></figure></p>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>为此，研究人员提出了几种用于 ML 集群的作业调度器。然而，之前提出的调度程序<strong>都没有考虑 ML 模型并行性</strong>，尽管它已被提议作为提高运行大规模 ML 和 DL 作业效率的方法。<ul>
<li>为了满足日益大规模的机器学习或深度学习应用的高可扩展性要求，人们提出了模型并行性，其中对机器学习模型进行分区，多个分区并行运行。<ul>
<li>随着 ML 和 DL 模型的规模迅速增长，模型并行的作业调度程序越来越有必要，以帮助减少作业的 JCT，同时保证高度的准确性。</li>
</ul>
</li>
<li>然而，据我们所知，尽管之前对 ML 集群中的作业调度进行了研究，但之前提出的调度程序都<strong>无法同时处理模型和数据并行性</strong>。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>作业调度系统应满足以下要求。</p>
<ul>
<li>1）首先，它应该<strong>降低带宽成本</strong>，这可能是增强 JCT 时分布式 ML 作业的瓶颈，因为任务之间需要频繁的数据传输。<ul>
<li>例如，对于数据并行作业，GPU 之间的通信开销为每个小批量 970MB-3168MB，对于模型并行作业，GPU 之间的通信开销为每个小批量 784MB-1037MB。</li>
</ul>
</li>
<li>2）其次，它应该<strong>同时提高 JCT 和准确性</strong>，因为两者对于 ML 工作都很重要。<ul>
<li>例如，飓风路径预测工作时间紧迫，而且需要高精度以避免损坏和人员伤亡。</li>
</ul>
</li>
<li>3）第三，应考虑工作的紧迫性和准确性要求，<strong>确定工作的优先顺序</strong>。<ul>
<li>例如，飓风路径预测对时间要求严格，精度要求很高，但年度人员流动预测具有时间容忍性，不需要非常高的精度。</li>
</ul>
</li>
<li>第四，当系统过载时，它仍然可以提供<strong>作业期限保证</strong>或低JCT。</li>
</ul>
</li>
<li><p>综上所述，MLFS的目标是最小化平均JCT，最大化平均作业精度，最大化满足截止日期和精度要求的作业数量，并最小化带宽成本。</p>
</li>
<li><p>在本文中，我们提出了一种基于 ML 作业特征的作业调度系统（MLFS），用于运行<strong>数据并行和模型并行</strong> ML 作业的 ML 集群。此外，MLFS <strong>还适用于**</strong>仅数据并行** ML 作业和<strong>仅模型并行</strong> ML 作业。  </p>
<ul>
<li>MLFS 的新颖之处在于它智能地利用了 ML 作业的空间/时间特征。<ul>
<li>1）MLFS 首先使用启发式调度方法，考虑这些特征来确定作业队列排序的任务优先级，以提高 JCT 和准确性性能。为了减轻过载服务器的额外负载，它还会考虑任务优先级来选择从服务器移出的任务并将其放入要重新调度的队列中。<ul>
<li>首先，不同的任务（针对不同的模型分区）单独运行，并且任务对最终作业延迟和准确性（即空间特征）有不同的影响。<ul>
<li><blockquote>
<p>例如，在ML模型分区图（或任务依赖图）中，如果一个任务有更多的依赖任务，或者它的依赖任务位于离该任务更近的层中，那么它应该更早运行，以在作业截止日期之前改善作业延迟和准确性。</p>
</blockquote>
</li>
<li><blockquote>
<p>此外，模型分区大小（通过 ML 模型参数的数量来衡量）会影响最终的准确性结果 - 较大的大小会产生较高的影响，反之亦然。</p>
</blockquote>
</li>
</ul>
</li>
<li>其次，机器学习作业通常会运行多次迭代，早期迭代比后期迭代对准确性的影响更大（即时间特征）。因此，早期迭代中的任务应该具有更高的优先级来运行，反之亦然。</li>
</ul>
</li>
<li>2）它使用启发式调度方法的数据来训练深度强化学习 (RL) 模型。强化学习模型训练好后，就会切换到强化学习方法，自动做出作业调度决策。</li>
<li>3）此外，当系统过载时，MLFS具有系统负载控制方法，可以根据任务优先级从过载的服务器中选择任务转移到负载不足的服务器上，并智能地终止那些在所需精度性能上产生很少的任务，这有​​助于提高JCT以及工作截止日期前的准确性。</li>
</ul>
</li>
<li>它使用启发式调度方法的数据来训练深度强化学习 (RL) 模型。强化学习模型训练好后，就会切换到强化学习方法，自动做出作业调度决策。</li>
<li>此外，MLFS还具有系统负载控制方法，可以根据任务优先级从过载的服务器中选择任务移动到负载不足的服务器上，并在系统过载时智能地删除对所需精度性能影响很小或没有改善的任务，以提高JCT以及工作截止日期的准确性。</li>
</ul>
</li>
<li><p>MLFS 由以下组件组成：</p>
<ul>
<li>(1)基于机器学习特征的启发式任务调度(MLF-H)。 <ul>
<li>MLFH 根据空间/时间 ML 作业特征和计算特征（例如截止日期、等待时间、剩余作业时间）确定任务优先级，以提高 JCT 和准确性。对准确性和 JCT 贡献更大的任务被赋予更高的优先级。任务的优先级用于在存在具有可用资源的服务器时对任务进行排队和分配任务。</li>
<li>MLF-H还通过考虑任务优先级和其他因素来<strong>选择从过载服务器中迁移出的任务</strong>来处理过载服务器，并将这些任务与队列中等待的任务一起重新调度。 MLF-H在从过载的服务器中选择迁移任务以及选择主机服务器来分配任务时，进一步尝试充分利用资源并降低带宽成本。</li>
</ul>
</li>
<li>(2)基于ML特征的强化学习任务调度(MLF-RL)。 <ul>
<li>MLFS 最初运行 MLF-H 一段时间，并使用数据训练深度 RL 模型，然后在模型训练良好时切换到 MLF-RL。给定正在运行和等待的任务以及节点，MLF-RL根据其状态选择任务从过载节点中移出，并为所选任务和队列中的等待任务确定目标节点或队列，以实现上述目的目标。</li>
</ul>
</li>
<li>(3)基于机器学习特征的系统负载控制(MLF-C)。<ul>
<li>当系统过载时，作业在作业截止日期前会出现高 JCT 和低准确度的情况。一旦达到所需的精度（基于用户的选择），MLF-C 可以<strong>停止运行或生成任务</strong>，以减轻系统工作负载，从而在作业截止日期前提高 JCT 和精度。 MLF-C还采用了最佳ML迭代停止方法，即找到迭代停止训练，以在最小化迭代次数的同时获得最大精度。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们在 AWS 上使用 Pytorch 进行了真实实验，并基于真实工作负载跟踪进行了大规模模拟。</li>
<li>大量的实验结果表明，与最先进的方法相比，MLFS 具有优越的性能及其每个组件的有效性，可将 JCT 降低高达 53%，完工时间降低高达 52%，准确性提高高达 64%。</li>
<li>我们在 Github 中开源了我们的代码<a href="#refer-anchor-2"><sup>[2]</sup></a>。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>多目标优化是如何处理的？</li>
<li>任务排序的几种优先级是如何分析的？为什么不考虑其他而考虑这几个因素？</li>
<li>为什么要使用启发式算法和深度强化学习算法结合的方式？这种结合方式能够借鉴到所有场景吗？还是有所限制？</li>
<li>调度与迁移兼顾的方案有什么好处？是否会带来额外开销？能否借鉴到其他场景？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3386367.3432588">[1] Haoyu Wang, Zetian Liu, and Haiying Shen. 2020. Job scheduling for large-scale machine learning clusters. In Proceedings of the 16th International Conference on emerging Networking EXperiments and Technologies (CoNEXT ‘20). Association for Computing Machinery, New York, NY, USA, 108–120. https://doi.org/10.1145/3386367.3432588<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link" href="https://github.com/hiddenlayer2020/">[2] Source Code. https://github.com/hiddenlayer2020/ ML- Job- Scheduler- MLFS.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>任务调度</tag>
        <tag>智算集群</tag>
        <tag>待精读</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记25-前沿-基于多智能体图强化学习的大规模机器学习集群调度</title>
    <url>/2023/11/16/literature/literatureNotes25/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Large-Scale-Machine-Learning-Cluster-Scheduling-via-Multi-Agent-Graph-Reinforcement-Learning》"><a href="#x1f4d6-《Large-Scale-Machine-Learning-Cluster-Scheduling-via-Multi-Agent-Graph-Reinforcement-Learning》" class="headerlink" title="📖《Large-Scale Machine Learning Cluster Scheduling via Multi-Agent Graph Reinforcement Learning》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Large-Scale Machine Learning Cluster Scheduling via Multi-Agent Graph Reinforcement Learning》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>在大型 GPU 集群中<strong>高效调度分布式深度学习（DL）作业</strong>对于资源效率和作业性能至关重要。<ul>
<li>深度学习 （DL） 正在为当今的各种服务提供动力，这些服务遍布计算机视觉、语言处理、推荐系统等领域。在大型数据集上学习现代深度学习模型（又称深度学习作业）通常使用<strong>分布式训练框架</strong>（如 MXNet 或 Tensorflow）进行，并使用多个 GPU 运行。</li>
<li>如今，许多领先的 IT 公司都运营着大型机器学习（ML）集群，其中运行大量 DL 作业来学习各种 ML 模型。<ul>
<li><strong>集群调度器</strong>负责为此类集群中的深度学习工作负载生成调度策略，其决策对于<strong>有效利用</strong>非常昂贵的硬件资源和<strong>模型学习探险</strong>至关重要。例如，如果由于资源碎片或负载均衡的目的而无法完全托管在同一服务器上，分布式作业（使用 PS 架构）的 worker 和参数服务器 （PS） 可以根据调度程序的放置决策分布到不同的服务器上。针对这些任务的高效放置策略可以<strong>加快训练速度</strong>并<strong>提高集群吞吐量</strong>，尤其是在具有各种 DL 工作负载的大规模集群中。</li>
</ul>
</li>
</ul>
</li>
<li>虽然作业之间的服务器共享提高了资源利用率，但由于资源争用，并置的 DL 作业之间会发生干扰。<ul>
<li>许多现有的调度程序经常忽略的主要问题是：虽然在同地 DL 作业之间<strong>共享服务器可以提高资源利用率</strong>，但由于<strong>资源争用而会发生作业间干扰</strong>。<ul>
<li>在同一台服务器中，作业共享资源，例如 PCIe 总线（用于 CPU 和 GPU 之间的频繁通信）、QPI（用于 CPU 之间的插槽间）、I/O 和 CPU 内核；在服务器之间，作业共享网络带宽和交换机容量。</li>
<li>训练不同深度学习模型的作业具有独特的资源特征。例如，训练VGG16需要更多的网络I/O来实现通信梯度；CTC由于词嵌入生成，因此会占用大量 CPU。</li>
<li>这意味着，<strong>不同的作业共址</strong>将导致不同程度的干扰，这促使集群运营商将<strong>低干扰水平的作业放在同一位置</strong>，以最大限度地提高训练性能。</li>
</ul>
</li>
</ul>
</li>
<li>在当今包含数千台 GPU 服务器的集群中，由于工作负载<strong>规模庞大</strong>，运行单个调度程序来及时有效地管理所有到达作业具有挑战性。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>文献中已经讨论了干扰感知调度的潜力，包括基于显式干扰建模的白盒方法和具有强化学习的黑盒调度器。<ul>
<li>一些<strong>白盒研究</strong>建立了<strong>显式干扰模型</strong>来预测共置的性能下降，例如，对于MapReduce任务、具有I/O争用的VM任务等。<ul>
<li>纯白盒解决方案在很大程度上<strong>依赖于性能模型的精度</strong>，这通常需要深入研究每个应用程序的执行并仔细优化系数。</li>
<li><strong>通用性</strong>将是一个问题，因为这种启发式方法缺乏对各种工作负载类型、服务器配置和数据中心拓扑的适应性。</li>
</ul>
</li>
<li>其他<strong>基于 DNN 的方法</strong>使用大量历史跟踪来学习共置 ML 作业的干扰水平，或者为调度器配备强化学习 （RL） 模型，通过探索和反馈来改进工作安置策略。<ul>
<li>RL 调度器不需要详细的分析干扰建模，但经常面临<strong>可扩展性问题</strong>：在拥有数千台 GPU 服务器的大规模 DL 集群中，学习使用一个 RL 调度器调度繁重的工作负载需要时间，并且可能无法收敛到良好的策略。</li>
</ul>
</li>
</ul>
</li>
<li>此外，<strong>跨机通信</strong>对于分布式训练作业的性能也很重要。有效的调度策略<strong>应了解链路状态和拓扑结构</strong>。<ul>
<li>例如，应避免拥塞链接，以便与深度学习作业中的战略任务放置进行梯度同步。</li>
<li>生产集群中使用的<strong>现有调度器在很大程度上是拓扑忽略的</strong>。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了<strong>减轻作业间干扰</strong>，<strong>降低通信开销</strong>，我们设计了一个可扩展的大规模深度学习集群作业调度框架，采用多个RL调度器来协同决定新提交作业的放置位置。也就是说，提出了一个<strong>多智能体强化学习（MARL）调度框架</strong>，以协同学习细粒度的工作安置策略，以实现<strong>最小化工作完成时间（JCT）</strong>的目标。<ul>
<li>我们框架中的每个调度程序都是一个学习代理，它对其<strong>本地集群拓扑</strong>和<strong>工作负载信息</strong>进行编码，以学习放置策略，通过与其他调度程序交换观察结果来最大限度地减少平均作业完成时间。</li>
<li>为了实现<strong>拓扑感知布局</strong>，我们提出的框架使用<strong>分层图神经网络</strong>对数据中心拓扑和服务器架构进行编码。</li>
<li>针对<strong>不同位置缺乏对应的精确奖励样本</strong>的问题，进一步设计了<strong>作业干扰模型</strong>，用于预测面对不同同地的干扰水平，用于MARL调度员的训练。</li>
</ul>
</li>
<li>具体贡献有：<ul>
<li>▹ 我们<strong>验证了</strong>具有代表性的局部保留和拥堵意识工作安置的<strong>低效率</strong>，并<strong>分析了</strong>不同工作在不同共址情况下的<strong>干扰水平</strong>。<ul>
<li>我们没有使用启发式干扰模型来实现干扰规避，而是采用多智能体强化学习（MARL）模型来调度深度学习工作负载，从而实现对未知环境（以前没有经历过的干扰情况）的更好<strong>通用性</strong>，并确保调度器的<strong>可扩展性</strong>。</li>
</ul>
</li>
<li>▹ 我们<strong>设计了</strong>一个分层图神经网络 （GNN），<strong>对拓扑信息进行编码</strong>，以捕获集群/数据中心拓扑、服务器架构和链路状态。<ul>
<li>按照 GNN 层次结构，调度员通过与其他调度员交换来聚合本地观测值，并做出拓扑感知的作业安置决策。</li>
</ul>
</li>
<li>▹ 我们还通过干扰模型<strong>量化了</strong>同地深度学习作业的<strong>性能下降</strong>。<ul>
<li>干扰模型解决了 RL 调度器离线训练阶段所需的与不同位置相对应的精确性能样本的普遍缺乏问题。借助推理模型，调度程序能够学习细粒度的放置策略，即将作业的每个 worker/PS 放置到哪个 GPU 组（即连接到同一 CPU 的 GPU）上。</li>
</ul>
</li>
<li>▹ 我们进行了广泛的跟踪驱动评估，以将我们的框架与不同工作负载和集群设置下的代表性调度方案进行比较。<ul>
<li>结果表明，在数千台具有不同配置的 GPU 服务器的情况下，我们的解决方案在平均作业完成时间方面实现了至少 20% 的改进。与使用单个 RL 调度器相比，MARL 实现了更好的策略收敛和更快的策略学习速度。</li>
<li>我们还在 Kubernetes 上实现了一个原型，这进一步验证了所提框架的有效性。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>测试平台和跟踪驱动的评估表明，我们的调度器框架在平均 JCT 方面比代表性调度方案高出 20% 以上，并且适应各种机器学习集群拓扑。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>RL 的可扩展性问题是如何解决的？</li>
<li>GNN 的作用和优势在于？</li>
<li>什么情况下需要量化模型？解决的是什么问题？如何解决的？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9667106">[1] X. Zhao and C. Wu, “Large-Scale Machine Learning Cluster Scheduling via Multi-Agent Graph Reinforcement Learning,” in IEEE Transactions on Network and Service Management, vol. 19, no. 4, pp. 4962-4974, Dec. 2022, doi: 10.1109/TNSM.2021.3139607.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
        <tag>多智能体</tag>
        <tag>图强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记27-前沿-跨地域资源预留调度</title>
    <url>/2023/11/23/literature/literatureNotes27/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Characterizing-and-orchestrating-VM-reservation-in-geo-distributed-clouds-to-improve-the-resource-efficiency》"><a href="#x1f4d6-《Characterizing-and-orchestrating-VM-reservation-in-geo-distributed-clouds-to-improve-the-resource-efficiency》" class="headerlink" title="📖《Characterizing and orchestrating VM reservation in geo-distributed clouds to improve the resource efficiency》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Characterizing and orchestrating VM reservation in geo-distributed clouds to improve the resource efficiency》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li><strong>云提供商</strong>通常从不同地理区域的多个数据中心构建<strong>地理分布式云</strong>，为不同位置的租户提供服务。<ul>
<li>公共云提供商通常在<strong>不同的地理区域构建多个数据中心</strong>，为不同地点的租户提供服务。数据中心中的硬件资源通常被组织成资源池，云提供商通常提供<strong>不同的虚拟机（VM）类型</strong>供租户选择。由于不同的能源费用和虚拟机性能，这些区域和虚拟机类型通常具有不同的资源成本系数。</li>
</ul>
</li>
<li>运行大规模应用的<strong>租户</strong>，往往会根据其在靠近终端用户的区域的峰值负载来预留资源，以应对不断变化的应用负载，<strong>浪费了大量资源</strong>。<ul>
<li>这些地理分布式云通常托管<strong>大型应用程序</strong>，例如流视频应用程序（如 YouTube）和社交网络应用程序（如 Twitter 和 Facebook）。此类面向租户的应用程序的<strong>实际负载</strong>经常由于计划外负载峰值或每日负载模式而<strong>动态变化</strong>，需要不同数量的资源来实现严格的服务质量（QoS）。</li>
<li>为此，当前的云（例如 AWS、Azure、Google Cloud）允许租户在首选区域中<strong>预留</strong>具有首选规格的虚拟机。<strong>租户</strong>经常<strong>申请</strong>根据<strong>靠近最终用户的云区域</strong>中可能的峰值负载来预留虚拟机。</li>
</ul>
</li>
</ul>
<h2 id="🤺挑战"><a href="#🤺挑战" class="headerlink" title="🤺挑战"></a>🤺挑战</h2><ul>
<li><p>因此，我们描述了生产公共地理分布式云中排名靠前的租户的 VM 请求模式，并在 4 个月内从云的前 20 个租户中开源了 VM 请求跟踪。特征分析表明，大型租户的资源使用在时序、地域、虚拟机类型等维度上具有不同的时空模式，并具有不同租户间调峰的潜力，从而进一步降低资源预留成本。</p>
<ul>
<li>在本文中，我们首先分析了具有 17 个区域的生产地理分布式云中这些租户的资源（CPU 核心和内存空间）预留模式。<ul>
<li>我们观察到租户指定的资源预留策略导致两个主要问题。<ul>
<li>1）首先，租户往往只在短时间内使用所有预留资源，预留资源造成巨大的资源浪费。例如，在我们的地理分布式云中，最多 68.6% 的预留资源在一个区域中实际使用，而在最坏的情况下只有 1.0% 的预留资源被使用（第 4.1 节）。</li>
<li>2）其次，预留通常放置在靠近最终租户的昂贵区域或昂贵的VM类型上，昂贵区域/VM类型上的资源可能被不必要地预留（第4.2节）。在地理上接近且具有类似性能的更便宜的区域/VM 类型上保留“刚好够用”的资源是有益的，同时仍然确保所需的服务级别协议 (SLA)。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>下图显示了我们跟踪的 84379 个租户的资源使用百分比（核心 × 小时）。据观察，前 20 位租户使用了所有资源使用量的 54.3%。虽然少数大型租户使用了很大比例的资源，但通过说服他们以较低的价格和有保证的 SLA 允许灵活的跨数据中心虚拟机预留/调度，有机会大大提高地理分布式云的资源效率。</p>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/2-Figure1-1.png" alt="图 1. 在我们的地理分布式云中按降序排列的租户的聚合资源使用情况。"><figcaption>图 1. 在我们的地理分布式云中按降序排列的租户的聚合资源使用情况。</figcaption></figure></p>
<ul>
<li><p>利用上述机会并非易事，因为大型租户的资源使用表现出<strong>不同的</strong> <strong>时间</strong>（第 5.1 节）和<strong>空间</strong>（第 5.2 节）<strong>模式</strong>。</p>
<ul>
<li>1）<strong>时间模式</strong>呈现租户随时间的资源使用量。<ul>
<li>例如，视频应用程序通常具有每日负载模式，而社交网络应用程序具有突发新闻的突发请求模式。</li>
</ul>
</li>
<li>2）<strong>空间模式</strong>显示了租户在不同区域和虚拟机类型上的资源使用模式。<ul>
<li>例如，租户可以将虚拟机部署在靠近最终用户的多个区域，以实现较短的响应延迟，或者部署在满足性能要求的各种规格的虚拟机上。</li>
</ul>
</li>
</ul>
</li>
<li><p>此外，我们还观察到一些大租户具有<strong>互补的时间和空间资源使用模式</strong>。</p>
<ul>
<li>当某个租户使用少量资源时（实际预留大量资源），其他一些租户会使用其预留的大部分资源，反之亦然。这是因为这些租户通常运行不同的应用程序，并且他们的最终用户具有不同的访问行为。通过将这些互补租户的资源编排在地理分布式云的同一区域，可以进一步降低资源预留成本。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>在<strong>数据中心内部的任务调度</strong>方面，人们提出了一系列的工作来调度VM、容器和函数，分类为：<ul>
<li>1）集中式</li>
<li>2）分布式：<ul>
<li>两级式</li>
<li>状态共享式</li>
</ul>
</li>
<li>3）混合式</li>
<li>他们的共同目标是在低延迟调度决策下寻求高调度质量。这些调度程序专注于数据中心内的任务级调度，因此它们不能应用于在地理上预留资源和调度虚拟机。（？）</li>
</ul>
</li>
<li>在<strong>地理分布式任务调度</strong>方面，大部分工作集中在管理不同数据中心之间的<strong>网络流量</strong>。 <ul>
<li>Yugong通过项目放置、表复制和作业外包来管理网络流量，以节省公共网络带宽。 </li>
<li>Taiji通过将网络流量路由建模为分配问题，在地理上分配流量对象，以满足服务级别目标。 </li>
<li>Gaia消除了数据中心之间无关紧要的通信，同时保持了机器学习算法的正确性。 </li>
<li>ELIS和Nautilus在数据中心和边缘之间部署微服务时优化了公共网络中的网络流量，以实现更好的服务延迟。</li>
<li>然而，这些工作都没有考虑<strong>数据中心不同资源成本下的资源预留</strong>，没有以最小化计算资源预留成本为目的。（？）</li>
</ul>
</li>
<li>此外，当前的云提供商根据<strong>云租户指定</strong>的最大需求量和实例位置来预留资源。但云租户大多数时候<strong>无法充分利用</strong>预留资源，且预留位置可能资源成本系数较高，导致资源预留成本巨大。</li>
<li>此外，纳拉亚南等人提出了一种地理分布式容量规划策略来优化部署成本，但<strong>为每个租户独立编排资源</strong>，导致资源效率较差。</li>
<li>综上所述，迄今为止对公有云资源管理和任务调度的研究缺乏对大型商业提供商大租户时空格局关键特征的透彻理解。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>从技术上讲，要提高资源效率，需要解决三个挑战。</p>
<ul>
<li>1）首先，要<strong>准确预测</strong>租户的<strong>资源使用模式</strong>，以便为租户预留“刚够用”的资源。</li>
<li>2）其次，为了避免在高成本区域或虚拟机类型上不必要地预留过多资源的情况，考虑到<strong>租户的空间资源使用模式</strong>，<strong>跨区域资源编排器</strong>需要仔细地将每个租户的预留资源分配到不同的区域/虚拟机类型。</li>
<li>3）最后，由于应用程序的<strong>负载偶尔会爆发</strong>，因此需要<strong>在线调度机制</strong>来快速为租户分配更多资源。</li>
</ul>
</li>
<li><p>基于此，我们提出了一种名为ROS的资源预留和虚拟机请求调度方案，以在满足虚拟机分配请求的同时最大限度地降低资源预留成本。</p>
</li>
<li><p>因此，我们进一步提出了一种名为 <strong>ROS</strong> 的<strong>运行时方案</strong>来<strong>编排地理分布式云中的资源</strong>。 ROS<strong>根据多个租户的时间和空间资源使用模式</strong>来优化它们的资源编排。 </p>
<ul>
<li>ROS 包括<strong>负载模式预测器</strong>、<strong>跨区域资源协调器</strong>和<strong>突发感知调度器</strong>来解决上述挑战。<ul>
<li>1）<strong>预测器</strong>使用不同的预测方法来预测大租户的资源使用情况。</li>
<li>2）考虑到区域/虚拟机类型的不同成本以及大租户的互补性，<strong>编排器</strong>将预测的负载模式作为输入，将预留资源编排到不同区域/虚拟机类型上，以降低总体部署成本。</li>
<li>3）<strong>在线调度器</strong>对VM请求进行调度，并对运行时的突发请求和不规则请求进行补偿。</li>
</ul>
</li>
</ul>
</li>
<li><p>我们将贡献总结如下：</p>
<ul>
<li>• 我们的生产地理分布式云的开源虚拟机请求数据集。该数据集包括前 20 个租户在 4 个月内的 VM 请求跟踪。据我们所知，这是地理分布式云中第一个大型租户的虚拟机请求数据集。</li>
<li>• 对我们生产级地理分布式云中的虚拟机请求进行全面分析。从分析中获得的见解确定了通过跨区域预留和调度来降低资源预留成本的机会。</li>
<li>• 资源编排和调度方案的设计。该方案在满足虚拟机请求的同时，最大限度地降低了资源预留成本。仿真结果表明，它可以降低总体部署成本和预留资源。</li>
</ul>
</li>
<li><p>我们的主要贡献是开源跟踪以及对地理分布式云中大型租户的虚拟机使用模式的全面分析。 ROS是基于分析而设计的，也具有多项技术新颖性。</p>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们根据痕迹进行了模拟，结果表明，ROS 使整体部署成本降低了 75.4%，预留资源降低了 60.1%。我们在生产地理分布式云中采用了 ROS，并显示出与模拟相似的性能。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>为什么面向数据中心内的任务调度架构不能应用于面向跨数据中心的调度？</li>
<li>本文最终采用的架构如何？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/abs/10.1145/3542929.3563490">[1] Jiuchen Shi, Kaihua Fu, Quan Chen, Changpeng Yang, Pengfei Huang, Mosong Zhou, Jieru Zhao, Chen Chen, and Minyi Guo. 2022. Characterizing and orchestrating VM reservation in geo-distributed clouds to improve the resource efficiency. In Proceedings of the 13th Symposium on Cloud Computing (SoCC ‘22). Association for Computing Machinery, New York, NY, USA, 94–109. https://doi.org/10.1145/3542929.3563490<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>大规模</tag>
        <tag>跨地域</tag>
        <tag>资源调度</tag>
        <tag>待精读</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记11-前沿-多数据中心迁移</title>
    <url>/2023/06/11/literature/literatureNotes11/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Carbon-Management-of-Multi-Datacenter-Based-On-Spatio-Temporal-Task-Migration》"><a href="#x1f4d6-《Carbon-Management-of-Multi-Datacenter-Based-On-Spatio-Temporal-Task-Migration》" class="headerlink" title="📖《Carbon Management of Multi-Datacenter Based On Spatio-Temporal Task Migration》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Carbon Management of Multi-Datacenter Based On Spatio-Temporal Task Migration》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>随着地理分布式数据中心（DC）的大规模部署和云服务需求的激增，其高能耗和碳污染问题日益严重。因此，减轻发展中国家碳足迹的有害影响已成为一项重大挑战。<ul>
<li>云计算技术的快速发展促进了地理分布式数据中心（geo-distributed dc）的建立和互联，满足了数据处理爆发式增长的需求，提供了无中断服务。<ul>
<li>例如，亚马逊在 25 个地理区域部署了大规模数据中心，以支持 80 个可用区，谷歌在美洲、亚洲和欧洲放置了超过 18 个数据园区来扩展其云服务平台。</li>
</ul>
</li>
<li>云计算基础设施的激增增加了巨大的电力负荷，使碳污染变得更加严重。<ul>
<li>据估计，到2025年，DC的能源消耗将占全球碳排放量的2.3%，大约相当于航空业的总排放量，到2040年将增加到14%。</li>
</ul>
</li>
<li>电力负荷的持续增长迫使云服务提供商（CSP）探索降低排放水平的方法。风能和光伏（PV）等可再生能源（RES）产生的排放量远低于化石能源，易于获取和自动再生。因此，CSP正在将RES引入DC的供电系统，以缓解能源紧张。<ul>
<li>谷歌在美洲、欧洲和亚洲签署了 30 多个绿色电力项目，并从 5GW 以上的风能和光伏电站采购能源;位于犹他州鹰山的Facebook DC将由容量为122 MW的光伏发电厂供电。</li>
</ul>
</li>
</ul>
</li>
<li>然而，可再生能源支持云的挑战正在逐渐浮出水面：RES的时变输出是高度间歇性和波动性的，而由于请求的随机到来，工作量也相当随机，表现出<strong>供需的双重不确定性</strong>，这与可靠性要求（例如，正常运行时间Tier IV）一起限制了DC的绿色发展，并不可避免地依赖传统的化石能源。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>云服务需求激增带来的巨大能源消耗和碳污染激发了许多学者的动力：<ul>
<li>1）通过灵活的负荷调节策略提高能源使用效率。<ul>
<li>初步探索了直流电内部的部分负荷，并利用其可控性进行电源管理。动态电压/频率缩放（DVFS）技术已经过充分研究，通过根据用户请求密度调整服务器的工作电压和频率来避免服务器中不必要的电源。</li>
<li>冷却中的节能是通过应用机器学习算法来解决的，例如，谷歌使用DeepMind节省了40%的冷却成本。相关工作提出了制冷、IT 负载和电能存储的需求响应协作，以调制 DC 的实时功耗。</li>
</ul>
</li>
<li>2）通过提出多种能源供应整合的方法，最大限度地提高RES的利用率。<ul>
<li>将DC作为一个整体控制目标：Dou等人将碳税视为目标函数的一部分，该函数在延迟容忍工作负载的成本和性能之间进行权衡。</li>
<li>丁等人考虑了能源价格、电网和发电机的波动风险，承诺通过建立风险和排放之间的权衡，获得电力采购、储能运营和工作量分配的规划方案。</li>
<li>然而，上述工作都没有考虑全球化DC集群的协同互动。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>这些挑战促使我们从两个角度分析配送中心的实际运营场景。<ul>
<li>一方面，通过分析RES的输出特性，我们发现不同位置的风电和光伏发电（PV）同时表现出特定的互补特性。</li>
<li>另一方面，在空间上，地理分布式 DC 之间的互连允许在不同的地理位置处理用户请求。暂时，容延迟任务的功率需求可以通过延迟或在服务级别协议（SLA）权限内激活来调整，即工作负载在时间和空间维度上都是灵活的。</li>
<li>因此，有机会通过需求响应来超越当前的最佳实践，将运营稳定性和可持续性结合起来：我们建议根据 DC 间工作负载重新分配和 DC 内部工作负载调度，将负载与 RES 可用性实时匹配。</li>
</ul>
</li>
<li>本文迈出了分析全球多区域可再生能源（RES）互补特征的第一步。有机会灵活安排工作量并跟踪RES以减少排放。<ul>
<li>整合数据中心和DC间网络，形成精细化的排放模型，权衡调度减排效果和工作量迁移的碳成本，提出时空任务迁移机制，在二维上追求低碳：本文将密集工作负载以<strong>粗粒度</strong>转移到RES充足的位置，并调整工作负载的执行时间以响应实时RES波动。因此，排放超额以互补的方式被RES转移和抵消；同时，RES的接受度得到提高。</li>
</ul>
</li>
<li>本文的贡献如下：<ul>
<li>讨论了全球分散RES的互补特性。据我们所知，这是首次尝试利用时空互补来减轻单站点RES间歇性对DC的负面影响，为碳管理的可行性奠定了基础。</li>
<li>提出了两个维度上的时空任务迁移机制。与专注于单个DC的现有研究不同，我们通过将地理分布式DC视为一个整体来应对RES的不确定性。整合多数据中心和直流间光网络，形成任务调度减排效应与迁移碳成本平衡的新型发射模型，提出时空任务迁移机制，追求空间域和时域调度的最佳实践。</li>
<li>利用解耦方法高效求解用于碳排放优化的大规模混合整数规划。针对协同发射优化，采用Benders分解算法对任务迁移决策和光路由方案进行解耦，实现全局最优解。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>利用真实数据进行的实验表明，该方法能够与RES最佳协调需求，减轻地理分布DC的碳污染，并在各种参数场景下验证其性能和适用性。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>使用的是中心式还是去中心式管理架构？<ul>
<li>中心式，在全局管理时不要求实时性，每 1min 做一次决策。而在局部要求实时性，每 4s 做一次决策。</li>
</ul>
</li>
</ol>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9627522/figures#figures">[1] T. Yang, H. Jiang, Y. Hou and Y. Geng, “Carbon Management of Multi-Datacenter Based On Spatio-Temporal Task Migration,” in IEEE Transactions on Cloud Computing, vol. 11, no. 1, pp. 1078-1090, 1 Jan.-March 2023, doi: 10.1109/TCC.2021.3130644.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>调度</tag>
        <tag>多云</tag>
        <tag>迁移</tag>
        <tag>碳管理</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记28-前沿-复杂拓扑云调度</title>
    <url>/2024/02/14/literature/literatureNotes28/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Diktyo-Network-Aware-Scheduling-in-Container-Based-Clouds》"><a href="#x1f4d6-《Diktyo-Network-Aware-Scheduling-in-Container-Based-Clouds》" class="headerlink" title="📖《Diktyo: Network-Aware Scheduling in Container-Based Clouds》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Diktyo: Network-Aware Scheduling in Container-Based Clouds》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>容器彻底改变了当前云平台中的应用部署和生命周期管理。应用程序已从单一的单体发展为松散耦合微服务的复杂图。此外，最近的应用对延迟越来越敏感，要求依赖的微服务之间的延迟更低。然而，由于微服务之间存在复杂的相互依赖关系，如何高效分配基于微服务的应用程序是一项挑战。<ul>
<li>微服务架构已逐渐成为现代云平台应用部署的事实范式。传统的大型单体被分解成多个松散耦合的微服务，独立实施和部署。随着容器的日益普及，当前云平台（如 Kubernetes (K8s)、亚马逊 AWS）中基于微服务的应用需要高效的协调策略。</li>
<li>然而，下一代应用要求依赖的微服务之间的延迟更低，从而进一步推动了云基础设施的发展。多层网络服务、物联网（IoT）、视频流服务和数据库等应用领域对延迟非常敏感，需要亚毫秒级的端到端（E2E）延迟才能正常运行。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>流行的容器编排平台中的调度策略主要是为了提高基础设施的资源效率，但对于延迟敏感型应用来说却不够。<ul>
<li>目前流行的协调平台中的调度方法主要集中在优化基础设施（如 CPU 和内存）的资源利用率上，不足以满足这些应用的严格要求，尤其是在延迟和带宽方面。K8s 是目前最流行的容器编排平台。它能自动处理容器化应用生命周期中的多个流程，包括部署和扩展。然而，K8s 中缺少网络感知调度策略，无法在容器云中对长期运行应用程序的依赖微服务进行网络感知部署。</li>
</ul>
</li>
<li>物联网和多层网络服务等应用领域将受益于在调度过程中考虑网络延迟和带宽的网络感知策略。以往的研究都是通过理论公式或基于启发式的方法来研究网络感知调度，并通过模拟或小型测试平台进行评估，因此很难将其完全应用于流行平台。<ul>
<li>减少延迟是一个首要目标，因为用户在使用多层应用时通常会遇到延迟问题，从而影响整体应用性能。这些应用通常包括数十到数百个微服务，它们之间存在复杂的相互依赖关系。<ul>
<li><strong>网络延迟</strong>通常是罪魁祸首，因为这些微服务在基础设施中调度时没有考虑延迟问题，导致分配依赖微服务的服务器之间距离过远。</li>
<li>此外，<strong>带宽</strong>优化也起着关键作用，特别是对于那些在微服务间进行大量数据传输的应用。例如，<ul>
<li>数据库应用中的多个副本可能需要频繁复制以确保数据一致性。</li>
<li>Spark 作业可能需要在映射器和还原器之间定期传输数据。<ul>
<li>节点间链路的网络容量不足会导致延迟增加或数据包丢失，从而进一步降低应用程序的服务质量（QoS）。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>网络感知调度策略，除了计算资源（如 CPU 和内存）外，还能根据延迟和带宽指标确定服务位置，这将使这些应用受益匪浅。<ul>
<li>集群节点之间链路的网络延迟和可用带宽会因节点在底层基础设施中的位置而异。在没有延迟和带宽意识的情况下，在不同节点上部署依赖性微服务会严重影响应用程序的响应时间和整体 QoS。例如，<ul>
<li>在 Redis 集群应用中，主节点需要定期与从节点同步数据。在调度过程中，需要考虑主节点和从节点之间的依赖关系。否则，主节点和从节点之间的高延迟或低带宽会导致创建、读取、更新和删除（CRUD）操作缓慢。</li>
<li>同样，在典型的多层网络应用程序（如在线精品电子商务应用程序）中也存在若干依赖关系。在远离依赖微服务的地方部署微服务实例会影响在线精品店的 E2E 延迟。</li>
</ul>
</li>
</ul>
</li>
<li>以往关于网络感知调度的研究主要集中在理论公式或基于启发式的算法，通常通过模拟或小型测试平台进行评估，从而限制了其在生产系统中的适用性。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>本文为流行的 Kubernetes（K8s）平台提出了一种名为 Diktyo 的新型网络感知框架，它能确定长期运行应用程序中依赖微服务的位置，重点是减少应用程序的端到端延迟并保证带宽预留。<ul>
<li>受 K8s 最近的调度插件架构的启发，本文为 K8s 平台提出了一个新颖的网络感知调度框架，名为 Diktyo。<ul>
<li>Diktyo 提出了额外的调度插件，旨在为 K8s 集群上调度的应用程序确定低延迟部署方案。</li>
<li>该框架通过为依赖的微服务选择网络成本低的节点，并根据之前的微服务分配选择带宽容量充足的节点，从而最大限度地减少应用程序的 E2E 延迟。</li>
<li>考虑到应用的微服务依赖性和底层基础架构拓扑，Diktyo 提供了接近最优的容器放置方式。</li>
<li>据我们所知，Diktyo超越了当前最先进的技术，因为它是在未来云原生架构中对依赖性微服务进行可扩展网络感知布局的首次尝试。</li>
</ul>
</li>
</ul>
</li>
</ul>
<ol>
<li>Diktyo 框架：</li>
</ol>
<ul>
<li>网络感知调度框架的设计与实现，该框架将控制平面（调度逻辑）与数据平面（即应用程序微服务依赖关系和集群网络拓扑）分离开来。</li>
<li>两个异步控制器管理两个自定义资源（CR），定义为 K8s 中的自定义资源定义（CRD）：<ul>
<li>AppGroup CRD 负责建立应用程序的微服务依赖关系；</li>
<li>NetworkTopology CRD 负责缓存和更新 K8s 集群拓扑底层区域和区域之间的网络成本。</li>
</ul>
</li>
<li>提议的框架已被 K8s 调度社区开源资源库接纳为替代调度器。研究人员可以使用我们的框架，在 K8s 集群中部署具有网络感知能力的应用程序，并根据当前机制评估其性能。</li>
</ul>
<ol start="2">
<li>混合整数线性规划（MILP）：</li>
</ol>
<ul>
<li>为 K8s 中的容器调度问题制定 MILP 模型，包括应用依赖图和底层集群拓扑的规格说明，以及网络延迟和带宽容量方面的不同链接。</li>
<li>K8s 允许动态配置不同的插件，以实现有关应用程序调度的不同目标。与最优解决方案相比，之前的工作尚未研究插件组合的性能。</li>
<li>我们通过评估由 MILP 公式给出的最优方案来回答这一重要问题，该方案是评估 Diktyo 框架和现有 K8s 调度插件性能的理想基准。</li>
<li>模拟结果表明，在应用程序的 E2E 延迟方面，Diktyo 明显优于现有的调度插件。</li>
</ul>
<ol start="3">
<li>插件实施：</li>
</ol>
<ul>
<li>我们为 Diktyo 框架设计了三个调度插件。这些插件的组合旨在逼近 MILP 模型给出的最优解，重点是以可扩展的方式最大限度地减少应用程序的 E2E 延迟。<ul>
<li>TopologicalSort 插件根据拓扑信息对微服务进行排序，NodeNetworkCostFit 插件根据微服务的依赖关系筛选出节点，NetworkMinCost 插件根据网络权重对节点进行评分，以确保依赖的微服务之间的低延迟。所有插件的性能都与节点和微服务的数量成对数关系。</li>
</ul>
</li>
</ul>
<ol start="4">
<li>微服务应用评估：</li>
</ol>
<ul>
<li>评估考虑了通常用作微服务基准的实际应用：一个名为 “在线精品店”（Online Boutique）的多层网络应用和一个名为 “Redis集群”（Redis cluster）的数据库应用。</li>
<li>分布式 K8s 集群的实验表明，Diktyo 使 Redis 的吞吐量提高了 22%，使在线精品店的应用响应时间平均缩短了 45%。 </li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>模拟结果表明，与默认的 K8s 调度插件相比，Diktyo 可以显著降低各种应用在不同基础设施拓扑中的网络延迟。此外，在 K8s 集群中使用微服务基准应用程序进行的实验表明，Diktyo 可以将数据库吞吐量提高 22%，将应用程序响应时间缩短 45%。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>所提出算法为什么随节点增长成对数关系？具体测试过程如何？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10111024">[1] J. Santos, C. Wang, T. Wauters and F. De Turck, “Diktyo: Network-Aware Scheduling in Container-Based Clouds,” in IEEE Transactions on Network and Service Management, vol. 20, no. 4, pp. 4461-4477, Dec. 2023, doi: 10.1109/TNSM.2023.3271415.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>待精读</tag>
        <tag>复杂拓扑</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记3-前沿-拓扑感知部署</title>
    <url>/2023/05/18/literature/literatureNotes3/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Topology-Aware-Scheduling-Framework-for-Microservice-Applications-in-Cloud》"><a href="#x1f4d6-《Topology-Aware-Scheduling-Framework-for-Microservice-Applications-in-Cloud》" class="headerlink" title="📖《Topology-Aware Scheduling Framework for Microservice Applications in Cloud》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Topology-Aware Scheduling Framework for Microservice Applications in Cloud》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>【在容器中运行的松散耦合和高度内聚的微服务正在成为应用程序开发的新范例。】云服务最近开始在架构上从单体到数百或数千个松散耦合的微服务进行重大转变。每个微服务都可以独立实现、部署和更新，而不会影响整个应用程序的完整性。因此，越来越多的团队正在采用微服务架构来提高其应用程序的可扩展性、可移植性、可维护性和可用性。</li>
<li>【与单体式应用程序相比，基于微服务架构构建的应用程序可以独立部署和扩展，这有望简化软件开发和操作。】微服务体系结构是一种设计方法，用于使用一组小型服务构建 Web 服务。每个服务都使用轻量级机制与其他服务通信，例如HTTP资源API或远程过程调用（RPC），这完全改变了传统云系统设计的假设。这也意味着微服务在提高利用率和优化服务质量 （QoS） 方面既带来了机遇，也带来了挑战。</li>
<li>然而，数据中心微服务规模和东西向网络流量的急剧增加使集群管理变得更加复杂。微服务的规模不仅会给群集管理带来巨大压力，而且级联 QoS 违规也会给 SLO（服务级别目标）带来巨大风险。<ul>
<li>基于微服务架构的应用与传统单体应用的主要区别在于，数据中心的<strong>单体应用</strong>只产生<strong>南北向流量</strong>，而云服务提供商更关心用户请求流量的负载均衡。<strong>基于微服务架构的应用程序</strong>往往会在数据中心生成更多的<strong>东西向流量</strong>，这是由微服务之间的相互调用引起的。对于此方案，数据中心中存在进一步优化的空间。微服务应用程序中的调用依赖关系可以描述为树状拓扑，为微服务应用程序的最佳部署提供了很好的机会。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>大多数云数据中心使用简单的方案来做出资源分配决策。他们经常忽略分配的资源与每个微服务的整体性能之间的关系。因此，它可能会导致在某些关键微服务上浪费宝贵的资源。</li>
<li>在大规模集群中，有一些方法（例如，过度配置，重复配置）倾向于使用性能模型，启发式方法或机器学习算法为微服务分配更多的CPU和内存。但是，这种方法有两个局限性。<ul>
<li>首先，它们忽略了微服务应用之间的特征，表明微服务的拓扑依赖关系无法利用。</li>
<li>其次，它们忽略了微服务和集群的高度动态特性。</li>
</ul>
</li>
<li>这些方法不仅无法处理动态服务级别目标（SLO）违规问题，而且当微服务更改时，它们的性能可能会降低。</li>
<li>由于微服务应用中东西向流量较大，调度优化的一个直截了当的思路是考虑微服务应用的拓扑结构。即把构成应用的微服务一起放置，降低微服务之间的通信成本和来自其他服务的网络干扰。但是，这种解决方案往往会导致微服务在主机上的聚合，数据中心的资源管理器受限于合理分配资源以提高资源利用率。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>如何有效利用微服务应用中嵌入的拓扑信息来降低服务通信开销，提高部署中的资源利用率，处理动态SLO违规是一个难题，本文主要针对这一问题进行解决。</li>
<li>本文提出一种面向微服务的拓扑感知调度框架（MOTAS），该框架通过启发式图映射算法有效地利用微服务和集群的拓扑结构来优化微服务应用程序的网络开销。所提出的框架还可以保证集群资源利用率。针对微服务的动态环境，我们提出一种基于分布式跟踪分析的机制来检测和处理微服务应用中的QoS违规行为。</li>
<li>本文的主要贡献可以概括如下：<ul>
<li><strong>拓扑感知调度算法</strong>：我们分析微服务的特征并定义微服务应用程序的配置文件。我们确定了影响微服务应用程序部署的关键参数，并定义了集群的配置文件。基于此，我们使用部署模型来描述微服务应用程序的部署，并进一步提出了一种新的算法（MOTAS），旨在通过减少资源碎片来提高资源利用率，并通过减少通信干扰来提高应用程序稳定性。</li>
<li><strong>调度框架</strong>：为了解决影响微服务应用程序SLO的两个主要动态问题，我们提出了一个拓扑感知调度框架。在框架中，我们将静态拓扑感知调度算法扩展到动态级别。我们提出了一种重新调度机制来支持微服务的结构更改，并最大限度地减少重新部署对应用程序的影响。我们引入了分布式跟踪系统来分析微服务请求响应的关键路径。基于对关键路径的监控和分析，可以实现受影响微服务的自动对账，保证微服务应用的性能。</li>
<li><strong>评估</strong>：我们在真实的群集环境中进行评估，以验证调度框架在资源利用率和服务 SLO 方面的有效性。通过与 First Fit 调度策略和 Kubernetes 默认调度策略的对比，证明了我们的拓扑感知调度策略在缩短服务响应时间、提高吞吐量和提高集群资源利用率方面具有更好的性能。此外，通过手动注入SLO违规，证明了我们的调度框架可以针对集群的动态异常有效优化微服务的部署，保证应用的服务质量。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>通过实际实验，该框架在保证集群资源利用率、降低应用端到端延迟、提高吞吐量、处理QoS违规等方面是有效的。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li><code>南北向流量</code>、<code>东西向流量</code>这种称呼的来源是什么？<blockquote>
<p>解释：<br>  南北流量（NORTH-SOURTH-TRAFFIC）：客户端到服务器之间通信的流量。<br>  东西流量(EAST-WEST-TRAFFIC)：指的是服务器和服务器之间的流量。<br>来源：<br>  该命名来自于绘制典型network diagrams的习惯。在图表中（网络拓扑图），通常核心网络组件绘制在顶部（NORTH），客户端绘制在底部（SOUTH），而数据中心内的不同服务器水平（EAST-WEST）绘制。<br>  简单理解即前者是跨层级的通信，后者是同层级的通信。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://user-images.githubusercontent.com/1940588/109765534-f7f0e980-7c2f-11eb-8a32-5460ebe6b1f2.png" alt="南北东西向流量示意图"><figcaption>南北东西向流量示意图</figcaption></figure></p>
</blockquote>
</li>
<li>文中所提的应用并非是从请求的角度看待的工作流（DAG），而是从应用角度看待的应用网络？前者是微观的瞬时的，需要根据每次运行情况调整；后者是宏观的长期的，需要根据长期运行情况调整。</li>
<li>本文是否界定“调度”与“部署”的区别？还是默认二者含义是等价的？</li>
</ol>
<h2 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h2><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10024362">[1] X. Li et al., “Topology-Aware Scheduling Framework for Microservice Applications in Cloud,” in IEEE Transactions on Parallel and Distributed Systems, vol. 34, no. 5, pp. 1635-1649, May 2023, doi: 10.1109/TPDS.2023.3238751.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>调度</tag>
        <tag>待精读</tag>
        <tag>部署</tag>
        <tag>应用拓扑</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记29-前沿-边缘多Agent深度强化学习调度</title>
    <url>/2024/02/25/literature/literatureNotes29/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Multi-agent-deep-reinforcement-learning-for-online-request-scheduling-in-edge-cooperation-networks》"><a href="#x1f4d6-《Multi-agent-deep-reinforcement-learning-for-online-request-scheduling-in-edge-cooperation-networks》" class="headerlink" title="📖《Multi-agent deep reinforcement learning for online request scheduling in edge cooperation networks》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Multi-agent deep reinforcement learning for online request scheduling in edge cooperation networks》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>边缘计算作为云计算的一种补充模式，通过在网络边缘为移动用户提供多样化服务而受到越来越多的关注。然而，日益复杂的移动应用给边缘网络带来了更大的负荷。<ul>
<li>随着新一代通信技术的发展，连接的智能设备呈指数级增长，加剧了骨干网络的拥塞。边缘计算应运而生，它通过在网络边缘提供计算、存储和内容资源，来满足智能设备产生的相对复杂的应用（也称为用户请求）。</li>
<li>边缘计算作为云计算的有力补充，可以避免对延迟敏感的用户请求进行长距离数据传输，这些请求被表示为有向无环图（DAG）。这些用户请求可以分解成一系列具有逻辑关系和时间依赖性的任务。</li>
<li>一般来说，应为这些用户请求有效调度和分配资源，以满足它们的各种约束条件。</li>
</ul>
</li>
<li>如何为<strong>并发请求</strong>提供高质量的服务处理是一项挑战，尤其是当边缘网络处于<strong>动态变化</strong>时。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>传统的<strong>离线或静态技术</strong>试图根据精确的任务执行时间和当前系统状态信息，找到基于 DAG 的请求调度问题的最优解，其中所有子任务的调度决策都是事先生成的。<ul>
<li>虽然从不同角度看，这种不考虑系统动态的策略简单有效，但通常无法实现资源优化利用的目标。<ul>
<li>一方面，边缘网络中的各种资源是分布式的，边缘节点的可用资源随时间动态变化，如何通过分布式边缘节点之间的合作提高网络性能是一个挑战。</li>
<li>另一方面，与目前大多数关注原子任务的工作不同，基于 DAG 的用户请求调度难度更大。用户请求的复杂结构和并发特性大大增加了边缘网络的工作量。</li>
</ul>
</li>
</ul>
</li>
<li>本文努力探索动态环境下的在线调度和资源分配方法，以提高分布式网络的长期性能。</li>
<li><strong>在线策略</strong>通常是动态系统中更有效的调度方法，因为它是为处理边缘系统中网络和计算资源的动态特性以及并发用户请求问题而开发的。根据运行时获得的状态信息对任务进行调度决策，动态地实现系统的全局优化。<ul>
<li>由于在线策略可以提高资源利用率，因此有研究探讨了边缘网络中在线方式的资源管理和用户请求调度优化，并提出了集中式策略和分布式策略两种主要技术。<ul>
<li>在面向<strong>集中式</strong>策略的研究中，边缘网络资源管理和用户请求调度需要完整的边缘网络环境状态信息和请求负载信息。<ul>
<li>然而，当边缘节点数量较多时，收集大规模状态信息会消耗更多网络资源。</li>
</ul>
</li>
<li>与集中式策略相比，在<strong>分布式</strong>策略中，边缘节点有自己的策略，只收集本地环境状态信息来帮助请求调度决策，这有效减轻了骨干网络的信息传输负担。<ul>
<li>但由于边缘节点的部分可观测特性，这也增加了提高边缘网络整体性能的难度。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>此外，在目前的研究中，在线调度技术都是针对单个基于 DAG 的请求，如何处理大量并发的用户请求仍是一个难题。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>为了缓解上述问题，本文研究了边缘合作网络中的在线并发用户请求调度优化问题。</p>
<ul>
<li>我们将其建模为一个<strong>在线多阶段决策问题</strong>，其中请求被划分为一组独立且逻辑相关的子任务。</li>
<li>我们提出了一种基于集中训练分布式执行的多代理深度强化学习技术，以实现边缘节点间的<strong>隐式合作</strong>调度决策策略学习。<ul>
<li>在该机制的集中训练阶段，采用了基于值分解的策略学习技术，以提高系统的长期性能；</li>
<li>而在分布式执行阶段，各边缘节点<strong>仅需本地环境状态信息</strong>（如何实现？）即可做出请求调度决策。</li>
</ul>
</li>
<li>我们提出了一种在线分布式请求调度优化机制。具体来说，<ul>
<li>首先建立一个全局任务队列，及时处理并发用户请求中可执行的部分子任务。</li>
<li>然后，应用基于间接交互的多代理深度强化学习算法，确保分布式任务调度的实施，有效降低网络中的数据传输成本，提高边缘系统的稳定性和鲁棒性。</li>
</ul>
</li>
</ul>
</li>
<li><p>本文的主要贡献总结如下：</p>
<ul>
<li>我们试图<strong>解决</strong>具有分布式资源部署特征的边缘网络中并发用户请求的<strong>调度问题</strong>。我们为提出的问题构建了一个多目标优化函数，以最小化边缘网络的长期平均延迟和能耗，同时最大化用户请求的吞吐率。</li>
<li>我们<strong>提出</strong>了一种名为 “价值分解多代理 DQN（VD-MADQN）”的在线并发用户请求<strong>调度机制</strong>。所提出的机制以集中培训和分布式执行（CTDE）的方式运行，它利用了整体环境状态信息，实现了边缘节点之间的隐式合作。</li>
<li>为了<strong>评估</strong>所提出的<strong>机制</strong>，我们基于真实世界的开源数据集进行了广泛的实验，并将其与其他基于学习的决策算法在不同的用户请求结构类型下进行了比较。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们进行了广泛的实验，仿真结果表明，所提出的机制在降低长期平均系统延迟和能耗方面优于其他请求调度机制，同时提高了系统的吞吐率。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>如何通过“仅需本地环境状态信息”实现全局调度？</li>
<li>如果每个agent只负责决定子任务放到哪个节点，谁来保证任务间的依赖关系？仅靠黑盒神经网络？</li>
<li>为什么每个时间段t内，一个agent只给每个节点分配1个任务？</li>
<li>深度强化学习可以实现仅使用有限信息做出全局较优决策？如果真如此，那这个点还挺有意思。<ol>
<li>集中训练分布执行CTDE思路下，不需要什么特殊设计就能实现全局较优决策？</li>
</ol>
</li>
<li>论文缺乏“和全局集中式方法”对比这部分实验。（好像也解释得通，因为所需信息比集中式少得多，所以不和他们比。隐含的意思是在质量方面肯定比不过。但最好肯定还是做一下实验并展现出在效率方面的优势。）</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.sciencedirect.com/science/article/pii/S0167739X22003788">[1] Yaqiang Zhang, Ruyang Li, Yaqian Zhao, Rengang Li, Yanwei Wang, Zhangbing Zhou, Multi-agent deep reinforcement learning for online request scheduling in edge cooperation networks, Future Generation Computer Systems, Volume 141, 2023, Pages 258-268.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>深度强化学习</tag>
        <tag>多智能体</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记30-前沿-ERP上云可定制SaaS</title>
    <url>/2024/03/14/literature/literatureNotes30/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Migrating-monoliths-to-cloud-native-microservices-for-customizable-SaaS》"><a href="#x1f4d6-《Migrating-monoliths-to-cloud-native-microservices-for-customizable-SaaS》" class="headerlink" title="📖《Migrating monoliths to cloud-native microservices for customizable SaaS》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Migrating monoliths to cloud-native microservices for customizable SaaS》</h1><p>发表于 JCI-1区、中科院-2区 期刊《Information and Software Technology》</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>随着云计算的趋势，企业软件供应商正在从单租户本地单体应用程序转向多租户（云原生）SaaS。<ul>
<li>迁移到微服务架构是实现遗留系统现代化的正确途径。从长远来看，迁移到微服务架构有巨大的好处，例如可维护性和可扩展性，例如，通过采用 DevOps 并受益于云原生弹性。</li>
</ul>
</li>
<li>然而，软件厂商正面临着两大相互交织的挑战：<ul>
<li>（1）如何将其单体<strong>迁移</strong>到云原生微服务；</li>
<li>（2）如何在多租户云原生 SaaS 上下文中启用特定于租户的（深度）<strong>自定义</strong>。<ul>
<li>深度定制可能会影响软件产品的任何部分，包括用户界面 （UI）、业务逻辑 （BL）、数据库模式 （DB） 或超出供应商预测的的任何组合。</li>
<li>此外，在基于云的多租户SaaS模型中，每个客户都必须运行相同的代码库（主产品），无法在不影响其他客户的情况下为一个客户定制。为每个客户运行不同的版本将直接否定多租户 SaaS 模型的任何规模经济（成本：一次开发，收益：规模化应用）。</li>
</ul>
</li>
</ul>
</li>
<li>软件供应商迫切需要一种新颖的方法，将其单体架构<strong>迁移</strong>到云原生微服务，同时仍支持多租户 SaaS 模型的<strong>深度定制</strong>。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>在本文中，我们首先探讨了当前在将企业应用程序从单体架构迁移到微服务架构时使用的行业方法，以及将应用程序从单租户过渡到多租户时使用的不同方法。<ul>
<li>通过回顾现有文献，我们发现了许多不同的方法，它们都实现了这两个目标之一，<ul>
<li>要么专注于从一种架构类型迁移到另一种架构类型，</li>
<li>要么从单租户过渡到多租户。</li>
</ul>
</li>
</ul>
</li>
</ul>
<ol>
<li>大多数现有的可定制 SaaS 方法，如依赖注入、软件产品线、中间件，只能在<strong>设计时</strong>提供<strong>预定义的定制能力</strong>。</li>
<li>主流的多租户 SaaS 供应商，如 Salesforce 和 Oracle NetSuite，提供了内置脚本语言，可进行<strong>更精细的代码级定制</strong>。为了最大限度地提高定制能力，这两家供应商都开发了非常广泛、复杂的<strong>应用程序接口</strong>和<strong>平台</strong>。</li>
</ol>
<ul>
<li>这种方式需要巨额的前期投资和对开发人员的广泛培训，这不是小型软件供应商所能承受的。</li>
</ul>
<ol start="3">
<li>最近，利用<strong>微服务架构</strong>实现<strong>多租户 SaaS 的深度定制</strong>是一个非常有前景的方向。</li>
</ol>
<ul>
<li>这些基于微服务的定制方法在如何平衡<strong>隔离（isolation）</strong>和<strong>同化（assimilation）</strong>方面各不相同。<ul>
<li>一般来说，对于任何定制方法，<strong>隔离</strong>都能保证特定租户的定制只影响单个租户，而<strong>同化</strong>则能保证定制能力可以改变主软件产品中的任何内容。</li>
<li><strong>侵入式微服务</strong>以牺牲安全性（租户隔离）为代价提供紧密的<strong>同化</strong>，</li>
<li>而被称为 MiSC-Cloud的<strong>非侵入式方法</strong>则以<strong>同化</strong>换取更高的安全性。MiSC-Cloud 通过 API 网关使用微服务协调定制。通过 API 网关，主产品的 API 和实施定制的租户特定微服务的 API 被公开，供租户特定的授权访问。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>微服务架构和多租户都为应用程序的最终用户和开发人员提供了额外的好处。结合“迁移到微服务架构”和“支持多租户自定义”这两个原则，我们可以更好地利用SaaS应用程序中的规模经济和资源共享。<ul>
<li>为此，我们的<strong>第一个贡献</strong>侧重于<strong>迁移</strong>方法，适用于目标应用程序遵循微服务架构的情况，同时还允许租户自定义业务逻辑以更好地满足他们在多租户上下文中的需求。<ul>
<li>我们的方法侧重于迁移过程中的三个阶段，<ul>
<li>1）分析应用程序并将其分解为小型边界上下文，</li>
<li>2）转换现有基础结构以适应新体系结构，并将上下文中的功能实现为单独的微服务，</li>
<li>3）最后添加必要的组件以支持多租户上下文中特定于租户的自定义。</li>
</ul>
</li>
</ul>
</li>
<li>我们的<strong>第二个贡献</strong>是将基于事件的非侵入式深度定制方法 与 同步定制方式 相结合。<ul>
<li>通过启用基于事件的非侵入式深度定制，MiSC-Cloud 框架可以协调主产品的 BL 组件（微服务）以及租户的定制微服务的执行，从而在多租户环境中获得所需的定制效果。</li>
<li>在定制微服务和主产品 BL 组件之间使用基于事件的通信不仅对微服务架构很重要，对非侵入式深度定制能力也很重要。</li>
<li>这种异步定制方式意味着定制微服务可以与主产品 BL 组件进行基于事件的通信，以实现定制目的。</li>
<li>因此，这种基于事件的深度定制方法有助于减少对主产品的 API 调用次数，而这正是软件供应商非常关心的问题。</li>
</ul>
</li>
</ul>
</li>
<li>与我们以前的工作相比，本文的主要扩展如下：<ul>
<li><ul>
<li>我们在本文中不仅介绍了迁移方法，还介绍了全面定制方法，以提供更完整的解决方案，包括从单体迁移到多租户 SaaS，然后定制目标 SaaS。</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li>我们在两个案例研究中应用了我们的全面迁移-定制方法。首先，我们将单体的 SportStore 迁移到多租户的 SportStore-aaS，然后对多租户的 SportStore-aaS 进行定制。其次，我们进一步定制了基于微服务的 eShopOnContainers。</li>
</ul>
</li>
<li><ul>
<li>我们提出了一种结合同步定制和异步定制的完整定制方法，为实现深度定制提供了灵活的途径。通过 API 调用进行的同步定制适用于用户界面定制，以及在需要时从主软件产品中查询更多 “上下文 “进行定制。通过事件协调的异步定制适用于 BL 定制，尤其是当主软件产品的微服务通过事件进行通信时。基于事件的定制有助于减少主软件产品的 API 调用次数。通过 API 调用进行的同步定制还有助于触发基于事件的定制，适用于无法使用主产品中的事件作为触发器的定制场景。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li><h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2></li>
</ul>
<ol>
<li>隔离和定制具体如何实现？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.sciencedirect.com/science/article/pii/S0950584923000848?via=ihub">[1] Espen Tønnessen Nordli, Sindre Grønstøl Haugeland, Phu H. Nguyen, Hui Song, Franck Chauvel, Migrating monoliths to cloud-native microservices for customizable SaaS, Information and Software Technology, Volume 160, 2023, 107230, ISSN 0950-5849, https://doi.org/10.1016/j.infsof.2023.107230.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>迁移</tag>
        <tag>ERP</tag>
        <tag>SaaS</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记31-经典-去中心化调度</title>
    <url>/2024/03/20/literature/literatureNotes31/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Multi-Agent-Imitation-Learning-for-Pervasive-Edge-Computing：-A-Decentralized-Computation-Offloading-Algorithm》"><a href="#x1f4d6-《Multi-Agent-Imitation-Learning-for-Pervasive-Edge-Computing：-A-Decentralized-Computation-Offloading-Algorithm》" class="headerlink" title="📖《Multi-Agent Imitation Learning for Pervasive Edge Computing： A Decentralized Computation Offloading Algorithm》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Multi-Agent Imitation Learning for Pervasive Edge Computing： A Decentralized Computation Offloading Algorithm》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>普适边缘计算是指仅依靠具有感知、存储和通信能力的边缘设备，实现点对点卸载，无需集中管理的一种边缘计算。<ul>
<li>边缘计算通过利用网络边缘的计算和存储资源来扩展传统的云计算架构。云可以安排任务由边缘设备在本地处理，而无需远程传输。</li>
<li>随着5G和网络技术的发展，终端设备已经演进，具有强大的感知、计算和存储能力，为实现普适边缘计算（无处不在的边缘计算，Pervasive Edge Computing）铺平了道路。实际上，它是一种新颖的边缘计算，它只是利用边缘设备进行计算和存储，而无需集中管理。</li>
<li>传统的边缘计算是云计算的补充，云计算和存储资源由边缘服务器提供，决策在后端做出。相比之下，普适边缘计算允许数据存储、处理和调度决策全部在网络边缘执行。因此，传统的边缘计算策略并不适合普适边缘计算环境，需要以完全去中心化的方式进行新的算法设计。</li>
<li>普适边缘计算与传统边缘计算相比带来的优势可以归纳为四个方面。<ul>
<li>1）首先，它无需基础设施即可部署和维护专用云后端。</li>
<li>2）其次，无需与云端通信，因为数据可以在用户附近处理，大大降低了传输延迟。</li>
<li>3）此外，它通过在对等设备之间实现通信而不需要互联网连接，从而独立于连接。</li>
<li>4）最后，不需要中央机构，设备可以自由地决定如何与他人协作，以及以何种方式实现可行和多样化的网络应用程序。</li>
</ul>
</li>
<li>普适边缘计算的应用从娱乐到工业的广泛应用。<ul>
<li>例如，在现场篮球比赛的现场，坐在不同位置的观众可以通过点对点通信从他们的角度与他人分享他们录制的视频。然后，通过聚合不同的片段，可以形成一个多角度观看的游戏视频。不同地点的观众可以全景观看现场比赛。另一个例子是协同驾驶，基于短距离通信技术，道路状况和事故现场的实时视频流可以直接在车辆之间共享。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>尽管普适边缘计算可以为用户带来各种优势和便利，但通过考虑普适边缘计算网络中多个设备的效用公益，设计可行的计算卸载算法具有挑战性。挑战可归纳如下：<ul>
<li>1）与传统边缘计算相比，普适边缘计算允许设备在网络边缘做出决策，而无需集中管理。设备很难仅依靠点对点通信来获取<strong>整个网络状态</strong>。因此，对于他们来说，选择合适的边缘服务器（由其他设备组成）来根据<strong>部分观察</strong>来卸载任务是具有挑战性的。受此影响，如果没有合理的任务分配策略，很难保证任务完成时间。</li>
<li>2）在多设备环境中，每个设备都打算<strong>最大限度地提高自己的效用</strong>。现有的研究总是开发博弈论模型来计算纳什均衡。对于每个设备，它都会根据系统状态的全局知识与其他设备讨价还价。然而，在无处不在的边缘计算网络中，设备<strong>无法获取全局信息</strong>，因此如何在完全去中心化的环境中保证设备的<strong>公平性</strong>值得研究。</li>
<li>3）在局部观察下，它适用于设计基于学习的方法，通过与环境的交互来获得良好的策略。但一方面，现有的无模型学习方法在<strong>起步阶段的性能总是较差</strong>，不适合在线调度。另一方面，它们的<strong>收敛速度很慢</strong>，尤其是在具有多个智能体的部分可观测环境中。因此，有必要设计一种收敛速度快且可以分散方式执行的学习方法。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>针对上述挑战，该文提出一种基于终端智能体的计算卸载算法MILP，旨在<strong>最小化设备的平均任务完成时间</strong>。它们可以将任务卸载到其他设备进行计算，也可以在本地处理它们，完全取决于他们自己的观察和决策。<ul>
<li>据我们所知，本文是研究<strong>基于多智能体模仿学习的普适边缘计算计算卸载问题</strong>的早期努力。<ul>
<li>一般来说，模仿学习是一种机器学习方法，它允许学习主体模仿专家策略，可以有效解决原始问题，但由于其时间复杂度高，无法以在线方式进行。因此，设计了一个培训过程，通过实现专家的模仿来学习代理策略。</li>
<li>此外，多智能体模仿学习允许多个智能体模仿相应专家的行为，并且可以在智能体之间达到纳什均衡。</li>
</ul>
</li>
</ul>
</li>
<li>具体而言，我们的贡献可以总结如下：<ul>
<li>1）通过考虑边缘设备的通信和计算能力，将普适边缘计算环境中的任务调度问题<strong>表述为优化问题</strong>。为了解决这一问题，我们通过指定博弈要素，如进化的玩家、状态和状态转换可能性，建立原始优化问题与随机博弈之间的关系，并将优化问题转化为奖励最大化问题。</li>
<li>2）为了<strong>解决奖励最大化问题</strong>，我们放宽了普适边缘计算网络带来的约束，提出了一种基于多智能体模仿学习的<strong>计算卸载算法</strong>，该算法允许多个学习智能体模仿相应专家的行为，以获得良好的调度策略。据我们所知，这是第一个将多智能体广义对抗模仿学习（GAIL）与普适边缘计算相结合以解决流量调度问题的工作。</li>
<li>3）为了<strong>形成专家策略</strong>，我们采用Actor-Critic和Kronecker-factored Trust Region（ACKTR）算法，在对系统状态的充分观察的基础上找到专家的最优策略。对于<strong>智能体策略</strong>，提出了一种基于部分观测值的每种设备的新神经网络模型。它全面集成了卷积神经网络（CNN）、生成对抗网络（GAN）和ACKTR来接近专家性能，并且可以在线方式执行。</li>
<li>4）我们从理论和实验两个角度证明了该算法的优越性。理论结果表明，该算法能够保证器件的公平性，并在完全和部分观测的基础上达到纳什均衡。性能结果表明，该算法在平均任务完成时间、收敛时间和卸载率方面均具有优势。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们从理论和实验两个角度证明了该算法的优越性。理论结果表明，该算法能够保证器件的公平性，并在完全和部分观测的基础上达到纳什均衡。性能结果表明，该算法在平均任务完成时间、收敛时间和卸载率方面均具有优势。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>算法调度时间多少？看起来需要多次迭代，应该速度不快？单任务执行时间又只有零点几秒，这个情况如何解释？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9197692">[1] X. Wang, Z. Ning and S. Guo, “Multi-Agent Imitation Learning for Pervasive Edge Computing: A Decentralized Computation Offloading Algorithm,” in IEEE Transactions on Parallel and Distributed Systems, vol. 32, no. 2, pp. 411-425, 1 Feb. 2021, doi: 10.1109/TPDS.2020.3023936.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>多智能体</tag>
        <tag>去中心化调度</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记32-经典-边缘博弈用户分配</title>
    <url>/2024/03/20/literature/literatureNotes32/</url>
    <content><![CDATA[<h1 id="x1f4d6-《A-Game-Theoretical-Approach-for-User-Allocation-in-Edge-Computing-Environment》"><a href="#x1f4d6-《A-Game-Theoretical-Approach-for-User-Allocation-in-Edge-Computing-Environment》" class="headerlink" title="📖《A Game-Theoretical Approach for User Allocation in Edge Computing Environment》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《A Game-Theoretical Approach for User Allocation in Edge Computing Environment》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li><p>在过去的十年中，移动和物联网 （IoT） 设备，包括手机、可穿戴设备、平板电脑等，变得越来越流行。</p>
<ul>
<li>根据爱立信的报告，预计到2023年将有约200亿台移动和物联网设备。</li>
</ul>
</li>
<li><p>移动和物联网设备的快速增长和进步推动了移动和物联网应用程序（以下统称为应用程序）的多样性和复杂性。</p>
<ul>
<li>许多应用程序资源密集、计算密集型和高能耗。</li>
</ul>
</li>
<li><p>由于计算能力和电池电量有限，移动和物联网设备运行此类应用程序变得越来越困难和不切实际。为了解决这个问题，移动和物联网设备可以将计算任务卸载到云端，以利用其可配置且强大的计算能力。</p>
</li>
<li><p>近年来，出现了需要低延迟的应用程序，例如人脸识别、自然语言处理、互动游戏等。</p>
<ul>
<li>由于通常不可预测的网络延迟和昂贵的带宽，云通常无法满足此类延迟敏感型应用程序的严格要求。这是云计算范式的一个明显弱点，因为人类对延迟非常敏感，这在广域网规模上很难减少。</li>
</ul>
</li>
<li><p>边缘计算作为促进5G移动网络的关键技术，允许将计算任务从移动和物联网设备转移到具有类似云计算能力的边缘服务器。</p>
<ul>
<li>这些边缘服务器由一台或多台物理机提供支持，部署在地理位置靠近应用用户的基站上。</li>
<li>应用程序用户可以将计算任务卸载到附近的边缘服务器，而不是云端。边缘计算范式为需要低延迟的应用程序铺平了道路。</li>
</ul>
</li>
<li><p>在过去的几年里，人们对边缘计算环境中的计算卸载进行了广泛的研究。</p>
</li>
<li><p>虽然现有的研究侧重于从边缘基础设施提供商或移动和物联网设备的角度减少延迟和/或节能，但本文从移动和物联网应用程序供应商的角度研究了一个关键问题。</p>
<ul>
<li>边缘计算范式允许移动和物联网应用程序供应商（称为<strong>应用程序供应商</strong>）在边缘基础设施提供商（例如 AT&amp;T、Telstra 等）的边缘服务器上租用计算能力，例如 CPU、内存、带宽。然后，可以将他们的服务部署在这些边缘服务器上，以低延迟为附近的应用程序用户提供服务。</li>
<li>通常，边缘服务器覆盖特定的地理区域，以便其覆盖范围内的应用程序用户可以通过无线访问连接到它。<ul>
<li>因此，边缘服务器以分布式方式部署 - 通常在蜂窝基站附近 - 以便它们可以覆盖不同的地理区域。</li>
<li>相邻边缘服务器的覆盖区域通常相交，以避免任何边缘服务器未覆盖的空白区域。</li>
<li>位于交叉区域的应用用户可以连接到附近具有足够计算容量（容量限制）（如 CPU、内存和带宽）的边缘服务器之一（邻近限制）。</li>
</ul>
</li>
<li>给定特定区域中的多个应用用户，可以通过多种方式将他们分配给覆盖该区域的边缘服务器。<ul>
<li>不适当的分配可能会导致大量应用用户未分配到任何边缘服务器。</li>
<li>因此，从应用供应商的角度来看，一个直接而重要的目标是最大限度地增加分配给边缘服务器的用户数量。</li>
<li>按照即用即付定价模式，应用供应商为从边缘基础设施提供商处租用的边缘服务器的计算能力付费。因此，应用程序供应商的另一个重要目标是最大限度地降低为应用程序用户提供服务的整体系统成本。</li>
</ul>
</li>
<li>此问题称为边缘用户分配 （EUA） 问题。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>云计算范式支持多租户，能够基于单个应用程序实例同时为多个租户提供服务。它允许多个租户比单租户更有效地共享计算资源，即为每个租户运行一个应用程序实例。<ul>
<li>例如，在相同的工作负载下，多租户 Web 应用程序比单租户 Web 应用程序实现更高的吞吐量，因为用户工作负载的整合通常可以实现高服务器利用率。</li>
</ul>
</li>
<li>边缘计算继承了云计算范式的多租户，因此允许应用程序供应商在边缘计算环境中为其EUA问题实现具有成本效益的解决方案。关键是要<strong>充分利用多租户</strong>，即将最大数量的应用用户分配给最少数量的边缘服务器。</li>
<li>在边缘计算环境中，应用程序供应商通常需要在特定区域容纳大量应用程序用户。因此，由于上述EUA问题的邻近性和容量限制，寻找集中式最优解决方案将具有高度的复杂性。而博弈论在分布式计算领域得到了广泛的应用。它是设计去中心化机制的有力工具。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>在本文中，我们介绍了EUAGame，这是一种寻找EUA问题解决方案的博弈论方法。</p>
<ul>
<li>EUAGame 通过为应用程序用户单独做出分配决策来减轻集中优化的负担，同时实现集体满意的分配解决方案。</li>
<li>此外，EUAGame 允许应用程序用户在不同的计算能力维度上指定他们的个人（通常是差异化的）兴趣。</li>
<li>EUAGame 将应用供应商的 EUA 问题建模为 EUA 博弈。在这个博弈中，每个应用程序用户都被模拟为游戏中的玩家，他们找到附近的边缘服务器来卸载其计算任务。然后，EUAGame 采用去中心化算法为应用程序用户做出分配决策，以实现博弈的纳什均衡。</li>
</ul>
</li>
<li><p>本文的主要贡献如下：</p>
<ul>
<li>我们首先将EUA问题建模为约束优化问题，并证明找到集中最优解是NP困难的。</li>
<li>为了以分布式方式解决EUA问题，我们将其表述为一个博弈，其中考虑了应用程序用户的利益，多租户的利益和整体系统成本。该博弈的目的是最大限度地增加分配的应用程序用户数量，并最大限度地降低整体系统成本，同时满足所有邻近限制和容量限制。</li>
<li>我们分析了EUA博弈，并证明这是一个承认纳什均衡的潜在博弈。</li>
<li>我们提出了一种去中心化算法，用于在EUA博弈中找到纳什均衡。</li>
<li>我们从理论和实验上分析了该算法的性能。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li><h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2></li>
</ul>
<ol>
<li>效率是否过低？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/8823046">[1] Q. He et al., “A Game-Theoretical Approach for User Allocation in Edge Computing Environment,” in IEEE Transactions on Parallel and Distributed Systems, vol. 31, no. 3, pp. 515-529, 1 March 2020, doi: 10.1109/TPDS.2019.2938944.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>边缘计算</tag>
        <tag>博弈</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记33-经典-虚拟机迁移</title>
    <url>/2024/03/31/literature/literatureNotes33/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Cost-and-Delay-Aware-Dynamic-Resource-Allocation-in-Federated-Vehicular-Clouds》"><a href="#x1f4d6-《Cost-and-Delay-Aware-Dynamic-Resource-Allocation-in-Federated-Vehicular-Clouds》" class="headerlink" title="📖《Cost-and-Delay Aware Dynamic Resource Allocation in Federated Vehicular Clouds》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Cost-and-Delay Aware Dynamic Resource Allocation in Federated Vehicular Clouds》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li><p>早期的<strong>车辆自组网（VANET）</strong>由带有车载单元的车辆组成，这些单元可以通信和共享信息以增强驾驶体验。</p>
<ul>
<li>随着越来越多地使用云计算来支持<strong>资源密集型应用程序</strong>，这些应用程序正在呈现出新的形式，否则这些应用程序将无法与车上有限的资源一起使用。</li>
</ul>
</li>
<li><p><strong>现代</strong>车辆应用程序是资源密集型的，并且具有不同的服务质量 （QoS） 要求。在这个方向上，车载云计算（VCC）已成为在云中托管此类应用程序的新范式。</p>
<ul>
<li><strong>车载云计算 （VCC）</strong> 是一种技术，其中带有网关路边单元 （RSU） 的 VANET 和云计算一起用于托管新兴的车辆应用在VCC的帮助下，可以支持实时导航、视频监控、实时交通分析、远程车辆诊断、虚拟现实和移动社交网络等多种应用。</li>
<li>然而，<strong>联网车辆的数量</strong>正在迅速增加，预计到 2023 年，约 98% 的新车将连接到互联网。预计这将大大改善安全服务以及信息娱乐应用的交付。同时，联网车辆数量的急剧增长及其高机动性对云提供商（CP）的要求构成了严峻的挑战，以满足所有请求的要求。</li>
</ul>
</li>
<li><p>在这种情况下，联合云通过将多个 CP 的数据中心 （DC） 集成到一个虚拟的单一云中，提供了一种经济高效的解决方案。在本文中，我们将 VCC 范式扩展到包括联合，其中来自多个云提供商的数据中心被汇集在一起，以支持单个提供商无法支持的应用程序。</p>
<ul>
<li>在车载网络中利用<strong>联合云</strong>为用户和车载服务提供商带来了许多好处。<ul>
<li>1）使用联合云，车辆服务提供商可以通过<strong>将过载暂时转移到相邻的 CP</strong> 来避免针对峰值工作负载的基础设施扩展。这也允许服务提供商在所需的延迟和成本要求内为更多用户提供服务，从而带来更高的收入。<strong>【提供海量资源】</strong><ul>
<li>例如，一个区域中可能有<strong>大量</strong>用户无法由单个 DC 提供服务。另一种情况是在高峰时段车辆密度突然增加。</li>
</ul>
</li>
<li>2）联合中 CP 的地理多样性还具有其他优势，例如<strong>成本效益和低延迟</strong>。<strong>【提供低价资源】</strong><ul>
<li>例如，车辆服务提供商可能以<strong>低于本地处理请求的价格</strong>从其他 CP 获取资源。这有助于CP最小化其运营成本并最大化其利润。</li>
</ul>
</li>
<li>3）联合还有助于处理<strong>移动性</strong>，这通常是通过将虚拟机 （VM） 迁移到更近的 DC 来完成的，以最大程度地减少延迟。它还有利于小型 CP 通过从其他 CP 租用资源来提供高可用性和可伸缩性。<strong>【提供动态资源】</strong></li>
</ul>
</li>
<li>在本文中，我们建议使用联邦车载云计算（FVCC）来利用上述优势来托管车载应用。</li>
</ul>
</li>
<li><p>VCC中的应用程序可以根据其延迟要求分为两类：</p>
<ul>
<li>延迟敏感型应用，如安全消息的传递，</li>
<li>以及延迟容忍型应用，如支持社交网络消息。</li>
</ul>
</li>
<li><p>对于CP来说，<strong>资源分配</strong>是一项具有挑战性的任务，其中</p>
<ul>
<li>1）必须满足应用要求，</li>
<li>2）同时将用户成本降至最低，</li>
<li>3）同时将CP的运营成本降至最低。</li>
<li>4）此外，联合中每个CP的主要目标是在满足用户QoS要求的同时实现自身利润最大化。</li>
</ul>
</li>
<li><p>由于<strong>用户移动性</strong>和<strong>车辆应用的延迟敏感性</strong>，VCC的问题变得更加具有挑战性。服务提供商需要持续监控网络延迟，并在需要时触发虚拟机迁移，以满足延迟要求。</p>
<ul>
<li>FVCC中的<strong>动态资源分配</strong>包括：1）初始VM放置和2）VM迁移，以优化系统中的资源分配。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>现有研究A考虑了<strong>移动用户</strong>，并建议将一些<strong>请求外包</strong>给云以提高可扩展性。他们将资源分配问题表述为优化问题，目的是实现成本最小化。在B中，作者试图将VCC系统的<strong>能耗成本</strong>降至最低。但是，这些工作没有考虑<strong>虚拟机迁移</strong>来处理延迟要求，而只关注优化成本。</li>
<li>C中的工作在分层云架构中提出了各种调度策略来<strong>减少延迟</strong>，但在减少延迟的同时<strong>没有考虑成本</strong>。</li>
<li>D中的工作纯粹集中在<strong>车载网络的延迟</strong>上，但没有考虑优化<strong>云中的延迟或运营成本</strong>。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>我们解决了联合车辆云中的动态资源分配问题。<ul>
<li>1）现代车辆应用对资源和延迟感知非常敏感。随着用户密度和移动性的增加，我们认为FVCC是处理此类应用程序的前进方向，而提供商则试图最大化其利润。据我们所知，文献中<strong>没有现有的工作将联合云用于车辆应用</strong>，以证明其对CP和用户的好处。</li>
<li>2）我们还从文献中观察到，大多数工作要么优化了 VCC 架构中资源分配期间的成本，要么优化了延迟（而不是在联合场景中）。我们认为，<strong>两者都应该共同优化</strong>，以满足CP和用户的目标。</li>
<li>3）此外，理想的动态分配策略应根据车辆应用程序的延迟要求<strong>对车辆应用程序进行分类</strong>，并<strong>迁移虚拟机</strong>以处理 VCC 中的移动性。</li>
<li>眼前的问题是，托管车载服务的 <strong>CP</strong> 如何在<strong>联合云环境</strong>中<strong>动态分配资源</strong>，以最大限度地<strong>降低运营成本</strong>，同时<strong>确保</strong>用户在网络上<strong>移动</strong>的<strong>延迟要求</strong>。</li>
</ul>
</li>
<li>我们工作的主要贡献总结如下：<ul>
<li>我们<strong>引入了联合车辆云计算 （FVCC） 架构</strong>，以解决跨多个 CP 的动态资源分配问题。对于拟议的架构，我们<strong>分析了处理请求时产生的端到端延迟</strong>，并提出了 CP 之间资源共享的动态定价模型。</li>
<li>我们将联合云中车载应用的动态资源分配问题<strong>表述为优化问题</strong>，目的是在满足应用时延要求的同时，最大限度地降低服务商的成本。</li>
<li>我们<strong>提出了一种成本和延迟感知的动态资源分配算法</strong>，用于对用户请求进行分类并执行在线资源分配，并在需要时迁移虚拟机（基于移动性和延迟要求）。</li>
<li>我们评估了所提出的算法，以展示联合云在满足服务提供商和最终用户需求方面的优势。<!-- * 我们提出了一种动态资源定价模型，用于在云提供商之间共享资源，并在此基础上将资源分配表述为优化问题。其目的是在满足不同车辆应用的延迟限制的同时，最大限度地降低车辆服务提供商的成本，为此提出了一种成本和延迟感知多项式时间算法。 -->

</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>与基线方法相比，所提出的算法被认为可以满足延迟要求，并显着降低提供商的成本高达 50%。</li>
<li>我们还表明，所提出的算法可以以更低的成本和更少的虚拟机迁移为90%以上的请求提供服务。它将 VM 迁移次数减少了 72%。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>单个云资源不够这个假设是否通用？还是说仅在车联网场景下适用，且此时“云资源”指的是局部数据中心？</li>
<li>用户成本最低、运营商成本最低，是两个方面？更直接地说，本文应该仅关注最小化运营商成本才对。</li>
<li>多个CP的结构下，是否存在公平性问题？多个CP利益冲突怎么办？</li>
<li>虚拟机是资源层面的管理单位，与“用户延迟要求”具有直接关系吗？作为优化目标如何解释？</li>
<li>摘要中提到的“dynamic resource pricing model”（定价模型）如何理解？本文似乎与定价没有任何关系。</li>
<li>虚拟机启动的时间很长，在本文中请求到达后供应商启动虚拟机，这不会导致超时吗？没有看到对该问题的解释。</li>
<li>到底是把请求分配给VM还是把VM分配到DC？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9430741">[1] M. Najm, M. Patra and V. Tamarapalli, “Cost-and-Delay Aware Dynamic Resource Allocation in Federated Vehicular Clouds,” in IEEE Transactions on Vehicular Technology, vol. 70, no. 6, pp. 6159-6171, June 2021, doi: 10.1109/TVT.2021.3079912<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>迁移</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记34-前沿-地理分布式成本优化调度</title>
    <url>/2024/05/07/literature/literatureNotes34/</url>
    <content><![CDATA[<h1 id="x1f4d6-《TanGo-A-Cost-Optimization-Framework-for-Tenant-Task-Placement-in-Geo-distributed-Clouds》"><a href="#x1f4d6-《TanGo-A-Cost-Optimization-Framework-for-Tenant-Task-Placement-in-Geo-distributed-Clouds》" class="headerlink" title="📖《TanGo: A Cost Optimization Framework for Tenant Task Placement in Geo-distributed Clouds》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《TanGo: A Cost Optimization Framework for Tenant Task Placement in Geo-distributed Clouds》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>云基础设施逐渐呈现地理分布的趋势，以实现全球租户的随时随地连接。<ul>
<li>将企业用户应用程序部署到共享和多区域云基础设施已成为一种新常态，以满足应用程序要求，包括延迟（例如，视频流为 100-150 毫秒）和数据主权法规（例如，欧盟 GDPR）。</li>
<li>这种地理分布式部署模式要求云提供商（例如AWS、Microsoft Azure和Google Cloud）在全球范围内构建多区域和大规模基础设施，在各大洲建立数十个数据中心，通过专门构建的高带宽光纤将它们连接到全球骨干网络中，或从ISP租用带宽。<ul>
<li>在人口稠密地区附近建造超大规模云数据中心既不环保也不经济，因为在电力传输过程中浪费了能源（例如，从美国中西部到东海岸，或从中国西部到中国东部的低成本电力供应）。云消耗的电力与服务器数量的激增和每台服务器上托管的密集型工作负载相关，一直在快速增长，占总运营成本的 60%-70%。因此，现有的云部署模式远非理想，需要一套创新的设计，以更具成本效益和环保的云部署。</li>
<li>为了实现这一雄心勃勃的目标，我们的论文旨在回答一个有意义但尚未探索的问题：是否有可能以跨区域的方式安排和安排租户任务，以便在满足所需租户/应用程序要求的同时显着降低整体电力成本？</li>
</ul>
</li>
</ul>
</li>
<li>地理分布云中租户任务的放置涉及三个关键而相互关联的因素：<strong>电价的区域差异</strong>、<strong>租户的访问延迟</strong>以及<strong>任务间流量需求</strong>，因此在多区域多租户云中实现高效的任务放置是一项艰巨的任务。<ul>
<li><strong>电价的区域差异</strong>：根据电力来源（例如水力发电、风能或天然气）和与发电厂的传输距离，位于不同地区的数据中心的电力单价可能会有很大差异。例如，高峰定价的年平均前一天为32.57/MWhintheUSNorthwestcomparedto纽约为62.71/MWh。</li>
<li><strong>租户访问延迟</strong>：指客户端与部署在云中的租户应用程序/服务之间的往返访问延迟。所需的延迟由租户任务的类型决定（例如，时间敏感型与不时间敏感型），实际延迟根据客户端和云区域之间的地理距离而有很大差异。</li>
<li><strong>任务间流量需求</strong>是指同一租户的多个任务之间所需的时延/带宽。所需的延迟/带宽还取决于租户任务的类型，例如，MapReduce 和分布式机器学习 等新计算范式需要任务之间的高带宽。如果部署在不同的位置（例如，一个在美国东部，另一个在美国南部），任务之间的大量流量可能与数据中心之间的有限带宽容量相矛盾。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>现有研究要么忽视了地区电价的差异，要么忽视了地理分布云中租户的需求，从而导致了运营成本的增加或用户服务质量的降低。<ul>
<li>例如，已经提出了一些任务放置解决方案，通过利用多个区域之间的电价差异来最小化总电力成本。但是，这些工作忽略了任务之间的各种流量需求。当应用程序对任务间通信（例如，分布式训练）提出很高的要求时，最好将任务放在同一区域，否则任务放置可以更灵活。忽视通信需求可能会导致更高的运营成本。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>我们设计了一个针对地理分布云中租户任务放置的成本优化框架，称为TanGo。<ul>
<li>其中租户可以指定他们对任务的各种需求，云提供商可以以经济高效的方式放置租户任务。</li>
<li>TanGo的核心是一种近乎最优的任务放置算法，它可以在满足所有需求和约束的同时将总成本降至最低。</li>
</ul>
</li>
<li>我们做出了以下贡献：<ol>
<li>我们提出了TanGo，这是一个成本优化框架，其中包括地理分布任务放置问题的数学模型。TanGo最大限度地降低了整体电力成本，同时满足了所有不同的需求。</li>
<li>我们将任务放置问题中的电费最小化问题表述为混合整数非线性优化问题，并给出了一个基于子模的解。我们证明了我们的算法接近最优，并受到 （1 − 1/e） 的严格近似因子的限制。</li>
</ol>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>基于真实数据集的深入模拟结果显示了我们算法的有效性，以及与通常采用的替代方案相比，电费总体减少了10%-30%。<ul>
<li>场景<ul>
<li>选择美国十个城市作为数据中心位置，用户从美国100个城市随机访问这些数据中心。</li>
<li>电力数据基于美国联邦能源监管委员会定价数据。</li>
<li>时延根据欧几里得距离获得，带宽默认都设置为50Gbps。（带宽没有价格）</li>
<li>任务使用阿里巴巴、谷歌数据集。总共有29天内2500w个任务（平均10个/s），选择其中12h任务。</li>
</ul>
</li>
<li>指标<ul>
<li>只比较了电价成本。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>带宽不收费，该假设的合理性？</li>
<li>算法性能？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10229004">[1] L. Luo, G. Zhao, H. Xu, Z. Yu and L. Xie, “TanGo: A Cost Optimization Framework for Tenant Task Placement in Geo-distributed Clouds,” IEEE INFOCOM 2023 - IEEE Conference on Computer Communications, New York City, NY, USA, 2023, pp. 1-10, doi: 10.1109/INFOCOM53939.2023.10229004.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>地理分布式</tag>
        <tag>成本优化</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记35-前沿-地理分布式云租户任务分配的成本优化</title>
    <url>/2024/05/07/literature/literatureNotes35/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Achieving-Cost-Optimization-for-Tenant-Task-Placement-in-Geo-distributed-Clouds》"><a href="#x1f4d6-《Achieving-Cost-Optimization-for-Tenant-Task-Placement-in-Geo-distributed-Clouds》" class="headerlink" title="📖《Achieving Cost Optimization for Tenant Task Placement in Geo-distributed Clouds》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Achieving Cost Optimization for Tenant Task Placement in Geo-distributed Clouds》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>和<a href="/2024/05/07/literature/literatureNotes34/" title="另一篇文章">另一篇文章</a>完全一致</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>和<a href="/2024/05/07/literature/literatureNotes34/" title="另一篇文章">另一篇文章</a>完全一致</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>和<a href="/2024/05/07/literature/literatureNotes34/" title="另一篇文章">另一篇文章</a>几乎一致</li>
<li>将原算法扩展至“任务重复部署”问题<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/11189cb2e880ea8e9326c5b753d11f771581e798/8-Figure4-1.png" alt="重复部署策略示例"><figcaption>重复部署策略示例</figcaption></figure></li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>和<a href="/2024/05/07/literature/literatureNotes34/" title="另一篇文章">另一篇文章</a>几乎一致</li>
<li>补充了重复部署测试<ul>
<li>场景：租户在不同位置有不同需求</li>
<li>对比：对比算法通过贪心选择重复部署</li>
<li>指标：重复部署数量（本方法最少）、成本（本方法最优）</li>
</ul>
</li>
<li>补充了性能测试<ul>
<li>场景：请求数量20-&gt;240</li>
<li>对比：最优IP求解器</li>
<li>指标：运行时间（本方法200个请求就需要10s）、准确度（与IP最优解损失在10%以内）</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>和<a href="/2024/05/07/literature/literatureNotes34/" title="另一篇文章">另一篇文章</a>几乎完全一致？而新增加的部分在introduction部分并未显著提及。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a href="">[1] 论文引用</a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>地理分布式</tag>
        <tag>成本优化</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记36-前沿-弹性资源调配实现实时请求更新</title>
    <url>/2024/05/08/literature/literatureNotes36/</url>
    <content><![CDATA[<h1 id="x1f4d6-《TRUST-Real-Time-Request-Updating-with-Elastic-Resource-Provisioning-in-Clouds》"><a href="#x1f4d6-《TRUST-Real-Time-Request-Updating-with-Elastic-Resource-Provisioning-in-Clouds》" class="headerlink" title="📖《TRUST: Real-Time Request Updating with Elastic Resource Provisioning in Clouds》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《TRUST: Real-Time Request Updating with Elastic Resource Provisioning in Clouds》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>在商业云中，服务提供商（例如，视频流服务提供商）从云供应商（例如Google Cloud Platform）租用资源并向云用户提供服务，从而从价格差距中获利。云用户通过将请求转发到相应的服务器来获取服务。<ul>
<li>云主要有三种角色：云供应商、服务提供商和云用户。<ul>
<li>云供应商（例如 Amazon Web Services 和 Google Cloud Platform）负责构建和维护物理服务器。他们将一定数量的 VM/容器租给每个服务提供商。</li>
<li>然后，服务提供商可以实现他们的服务，如安全、存储、审计等，也称为网络功能 （NF） 实例。</li>
<li>云用户可以根据自己的需求购买服务，从而将他们的请求调度到相应的NF。</li>
</ul>
</li>
<li>例如，VPN 服务提供商从云供应商处租用多个 VM 来实现 VPN 功能。然后，云用户可以从服务提供商处购买VPN服务，并通过将流量转发到相应的VPN来获取服务。</li>
</ul>
</li>
<li>在实践中，作为常见场景，流量动态会导致<strong>服务器过载或负载不平衡</strong>。<ul>
<li>在大规模的多租户云中，流量巨大，流量动态是一个长期存在的问题，导致NF之间的负载不均衡甚至过载，这将严重影响业务可用性和执行效率。因此，它会降低用户的 QoS。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>现有工作主要通过<strong>请求更新</strong>和<strong>弹性资源配置</strong>两种方式来处理该问题。<ul>
<li>虽然<strong>请求更新</strong>是一个免费的解决方案，但它会导致严重的延迟，导致用户的 QoS 不佳。为了处理云中的流量动态并改善 QoS，<strong>请求更新</strong>已被广泛采用，这意味着将请求转移到另一个可用的 NF。现有工作通常为NF负载均衡或最小化makespan设计请求更新方案。<ul>
<li>例如，提出了一种分布式请求调度机制，以便通过公平分配来自边缘交换机的流量来实现数据中心服务器之间的负载均衡；</li>
<li>通过基于免疫的粒子群优化算法找到在截止日期约束下降低云资源成本的最优解决方案。</li>
</ul>
</li>
<li>尽管许多工作已经设计了合理的请求更新方案来处理流量动态，但请求更新存在三个基本缺点。<ol>
<li>首先，控制器容量有限。控制器的处理速度取决于不同的因素，例如控制器的类型和控制器的位置。</li>
</ol>
<ul>
<li>例如，根据测试结果，在网络拓扑由 81 台交换机组成的网络拓扑结构下，发送 1000 条流模消息以重新路由流需要 71.2ms。</li>
<li>作为比较，相关文献还测试了更新延迟，并表明ONOS每秒可以处理40K的flow-mod消息，拓扑结构由32个交换机组成。</li>
<li>对于相同的拓扑结构，另一篇相关文献还证明了OpenDayLight（也是SDN中使用的主流控制器）每秒只能处理0.3K的flow-mod消息。</li>
<li>因此，生成大量用于请求更新的新规则将大大增加控制器的响应时间，使<strong>控制器成为网络的瓶颈</strong>。因此，控制器可能会拥塞并阻止新的到达请求，从而导致用户体验下降。</li>
</ul>
<ol start="2">
<li>其次，请求更新涉及交换机上的延迟。</li>
</ol>
<ul>
<li>相关研究指出，发送更新消息和更新交换机上的相应条目之间的持续时间可能为数十毫秒。由于过时的条目，交换机上的延迟将导致流的错误操作。</li>
</ul>
<ol start="3">
<li>最后，更新请求时存在状态不一致问题。</li>
</ol>
<ul>
<li>相关研究揭示了每个交换机上的更新延迟是异构的，异步更新操作会导致规则更新的部分执行，从而导致网络状态不一致。在瞬态循环中发送数据包、增加链路负载或绕过重要的航点（如流分类器）时，可以观察到这种不一致。</li>
<li>此外，由于 NF 需要记录已处理请求的状态，因此请求更新将带来额外的延迟和开销，以保持 NF 上请求的状态一致性。</li>
</ul>
</li>
<li>由于这三个缺点，请求更新很难保证用户在大规模云中的QoS，迫切需要替代解决方案作为补充方法。</li>
<li><strong>弹性资源配置</strong>是一种快速敏捷的解决方案，但由于服务提供商需要从云供应商处购买额外的资源，因此成本可能太高。<ul>
<li>通过启用虚拟化技术，弹性资源配置已成为处理云中流量动态的新趋势。弹性资源配置意味着系统可以添加或删除资源（如CPU内核、内存、虚拟机或容器实例），以实时适应负载变化。</li>
<li>在实践中，云供应商通常会提供几种与固定资源组合相关的合适配置类型，每个NF将选择一种资源配置类型来满足云用户的请求。<ul>
<li>例如，在 Google Cloud Platform （GCP）中，具有 4 个 CPU 内核和 15 GB 内存的虚拟机的价格为 每月 97<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="55.753ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 24643 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">具</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">有</text></g><g data-mml-node="mn" transform="translate(3000,0)"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path></g><g data-mml-node="mi" transform="translate(3500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">个</text></g><g data-mml-node="mi" transform="translate(4500,0)"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mi" transform="translate(5260,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mi" transform="translate(6011,0)"><path data-c="1D448" d="M107 637Q73 637 71 641Q70 643 70 649Q70 673 81 682Q83 683 98 683Q139 681 234 681Q268 681 297 681T342 682T362 682Q378 682 378 672Q378 670 376 658Q371 641 366 638H364Q362 638 359 638T352 638T343 637T334 637Q295 636 284 634T266 623Q265 621 238 518T184 302T154 169Q152 155 152 140Q152 86 183 55T269 24Q336 24 403 69T501 205L552 406Q599 598 599 606Q599 633 535 637Q511 637 511 648Q511 650 513 660Q517 676 519 679T529 683Q532 683 561 682T645 680Q696 680 723 681T752 682Q767 682 767 672Q767 650 759 642Q756 637 737 637Q666 633 648 597Q646 592 598 404Q557 235 548 205Q515 105 433 42T263 -22Q171 -22 116 34T60 167V183Q60 201 115 421Q164 622 164 628Q164 635 107 637Z"></path></g><g data-mml-node="mi" transform="translate(6778,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">内</text></g><g data-mml-node="mi" transform="translate(7778,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">核</text></g><g data-mml-node="mi" transform="translate(8778,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">和</text></g><g data-mml-node="mn" transform="translate(9778,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="mi" transform="translate(10778,0)"><path data-c="1D43A" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g><g data-mml-node="mi" transform="translate(11564,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(12323,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">内</text></g><g data-mml-node="mi" transform="translate(13323,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">存</text></g><g data-mml-node="mi" transform="translate(14323,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(15323,0)"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g><g data-mml-node="mi" transform="translate(16092,0)"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mi" transform="translate(17143,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(18143,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">价</text></g><g data-mml-node="mi" transform="translate(19143,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">格</text></g><g data-mml-node="mi" transform="translate(20143,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">为</text></g><g data-mml-node="mi" transform="translate(21143,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">每</text></g><g data-mml-node="mi" transform="translate(22143,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">月</text></g><g data-mml-node="mn" transform="translate(23143,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(500,0)"></path><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z" transform="translate(1000,0)"></path></g></g></g></svg></mjx-container>。</li>
</ul>
</li>
<li>之前关于弹性资源供应的研究主要集中在如何提高网络性能、增加资源容量或节能上。<ul>
<li>例如，相关研究中的作者提供了多个同时 Web 应用程序方法的自动部署和主动扩展，以提高基础设施性能，这些方法已部署在 Amazon Elastic Compute Cloud 中。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>弹性资源配置</strong>的思想在解决流量动态问题方面具有很好的希望。与<strong>请求更新</strong>解决方案相比，调整虚拟机/容器的大小只需要几十毫秒，无需担心请求状态一致性的问题。因此，可以保证用户的QoS。但是，这将增加服务提供商的成本，因为他们应该向云供应商支付更多额外的资源。</li>
<li>相比之下，使用<strong>请求更新</strong>方式，服务商无需支付额外的费用，但由于更新延迟和请求状态一致性的要求，用户的 QoS 可能会受到影响。</li>
<li>因此，我们发现这两种方法可以相互补充，以帮助服务提供商在用户QoS保证下支付更低的成本。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>在本文中，我们提出了一种新的方案，称为使用弹性资源配置（TRUST）进行实时请求更新，以帮助服务提供商在云中保证用户的QoS，从而降低成本。</p>
<ul>
<li>具体来说，由于请求更新会增加更新延迟并降低用户的 QoS，因此我们尝试在时间阈值下完成更新操作T ，这将由用户的 QoS 需求决定。例如，在蜂窝通信网络中，相关研究中表明，当传输延迟低于150ms时，仍然可以保证传播质量。</li>
</ul>
</li>
<li><p>此外，我们提出了一种基于渐进舍入的有界近似因子的高效TRUST算法。</p>
<ul>
<li>同时，我们试图将购买云资源的基础设施成本降至最低。简而言之，TRUST可以启发一种方法，帮助服务提供商在用户QoS保证方面花更少的钱。</li>
</ul>
</li>
<li><p>本文的主要贡献可归纳如下：</p>
<ol>
<li>我们综合分析了目前云端流量动态的处理方法，并展示了请求更新和弹性资源供应的优缺点。</li>
<li>我们给出了弹性资源预配（TRUST）实时请求更新的表述，可以保证用户的QoS，为服务商节省资金。据我们所知，这是第一个利用弹性资源配置和请求更新来处理流量动态的工作。</li>
<li>我们提出了一种基于随机舍入的算法。性能分析表明，我们的算法能够高概率地达到最优值。</li>
<li>我们利用真实世界的拓扑结构和数据集进行了小规模实验和大规模仿真，表明所提出的算法与最先进的解决方案相比，可以实现更优越的性能。</li>
</ol>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>无论是小规模的实验结果还是大规模的仿真结果，都表明了所提算法与现有基准相比的优异性能。<ul>
<li>指标：<ul>
<li>（1）基础设施成本;</li>
<li>（2）系统吞吐量;</li>
<li>（3）不良率;</li>
<li>（4）更新延迟;</li>
<li>（5）丢包率;</li>
<li>（6）往返时间（RTT） 和 </li>
<li>（7）流量完成时间 （FCT）。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>效率如何？</li>
<li>随机舍入算法如何应用于本场就？（核心思想：将原问题松弛，求近似最优解）</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9796788">[1] Jingzhou Wang, *Gongming Zhao, *Hongli Xu, Yangming Zhao, Xuwei Yang, He Huang, “TRUST: Real-Time Request Updating with Elastic Resource Provisioning in Clouds “, INFOCOM’22, May. 2022.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>请求调度</tag>
        <tag>资源调配</tag>
      </tags>
  </entry>
  <entry>
    <title>【AI】强化学习入门路径及优质资料</title>
    <url>/2023/12/08/ai/ai-RL-introduction/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>简单总结了学习强化学习的路径以及相关优质资料。</p>
<h1 id="🖼️前置知识——机器学习-深度学习-1"><a href="#🖼️前置知识——机器学习-深度学习-1" class="headerlink" title="🖼️前置知识——机器学习/深度学习[1]"></a>🖼️前置知识——机器学习/深度学习<a href="#refer-anchor-1"><sup>[1]</sup></a></h1><ol>
<li><p>入门推荐台大李宏毅的机器学习课程<a href="#refer-anchor-2"><sup>[2]</sup></a>。<br> <strong>优点</strong>：李宏毅老师讲课风格比较诙谐，内容清晰又不失深度。<br> <strong>缺点</strong>：课时多、涵盖内容种类太多。</p>
</li>
<li><p>吴恩达的机器学习课程<a href="#refer-anchor-3"><sup>[3]</sup></a>。<br> <strong>优点</strong>：讲课清晰，内容紧凑。<br> <strong>缺点</strong>：英文授课，中文字幕有些跳戏。</p>
</li>
</ol>
<ul>
<li>对于深度学习和机器学习有一定理解后，就有了强化学习的基础。</li>
</ul>
<h1 id="🧠基础知识——强化学习-1-4-5"><a href="#🧠基础知识——强化学习-1-4-5" class="headerlink" title="🧠基础知识——强化学习[1][4][5]"></a>🧠基础知识——强化学习<a href="#refer-anchor-1"><sup>[1]</sup></a><a href="#refer-anchor-4"><sup>[4]</sup></a><a href="#refer-anchor-5"><sup>[5]</sup></a></h1><ol>
<li><p>先推荐莫凡的强化学习入门视频<a href="#refer-anchor-6"><sup>[6]</sup></a><br> <strong>优点</strong>：课时时间都超短，且附有实现代码，配合代码复现效果更佳。<br> <strong>缺点</strong>：课时过短，很多内容消化不了，容易一知半解。</p>
</li>
<li><p>再推荐一个openai整理的的RL核心论文网站<a href="#refer-anchor-7"><sup>[7]</sup></a></p>
</li>
<li><p>论文看不懂？正常！再结合李宏毅老师的视频理解一波<a href="#refer-anchor-8"><sup>[8]</sup></a></p>
</li>
<li><p>David Silver的课程<a href="#refer-anchor-9"><sup>[9]</sup></a>也非常棒！PPT和授课内容都非常棒。视频可以找到中文版字幕。</p>
</li>
<li><p>内容还是太过零碎化？实体强化学习”圣经“来一本。（《强化学习（第2版）》<a href="#refer-anchor-10"><sup>[10]</sup></a>）</p>
</li>
<li><p>推荐先看看OpenAI Spinning Up<a href="#refer-anchor-11"><sup>[11]</sup></a>，内容较少读得快、且条理比较清晰，后面提到的两个案例库都根据Spinningup的数学符号来写的，方便大家对照代码。</p>
</li>
<li><p>另外几个系统的进阶课程<a href="#refer-anchor-12"><sup>[12]</sup></a><a href="#refer-anchor-13"><sup>[13]</sup></a></p>
</li>
<li><p>王树森老师的课程，讲得很不错<a href="#refer-anchor-14"><sup>[14]</sup></a>。</p>
</li>
<li><p>周博磊老师，也是这个领域非常厉害的老师，课程详细全面<a href="#refer-anchor-15"><sup>[15]</sup></a>。</p>
</li>
</ol>
<h1 id="🔨实践资料——代码库-1-4"><a href="#🔨实践资料——代码库-1-4" class="headerlink" title="🔨实践资料——代码库[1][4]"></a>🔨实践资料——代码库<a href="#refer-anchor-1"><sup>[1]</sup></a><a href="#refer-anchor-4"><sup>[4]</sup></a></h1><p>尝试运行与实现基础算法，可以帮助你更好地理解对应的基础知识，这里有两个相关的RL案例库：</p>
<ol>
<li>一个是面向产品化而提供高层抽象：RLzoo-面向产品化的RL库<a href="#refer-anchor-16"><sup>[16]</sup></a>（会有一些大型RL案例会放到这里）；</li>
<li>另一个是面向科研而提供浅层抽象：TL-面向科研的RL库<a href="#refer-anchor-17"><sup>[17]</sup></a>（有常用RL方法的论文列表）。</li>
</ol>
<p>最后放个大的：Paper with Code<a href="#refer-anchor-18"><sup>[18]</sup></a>。</p>
<ul>
<li>Papers with Code 是一个包含机器学习论文及其代码实现的网站。 大多数论文都是有GitHub代码的，这个网站对机器学习方向做了任务分类，检索对应的论文、数据、代码和精度榜单一目了然。</li>
<li>目前，网站已包含114,474 篇带代码的论文、 11,915 个基准测试、 4,574 个任务、 15,541 个数据集。<blockquote>
<p>Papers with Code 的使命是创建一个免费和开放的资源 机器学习论文、代码、数据集、方法和评估表。<br>The mission of Papers with Code is to create a free and open resource with Machine Learning papers, code, datasets, methods and evaluation tables.</p>
</blockquote>
</li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1">

<p><a class="link"   href="https://www.zhihu.com/question/353476712/answer/883189174" >[1] 求问强化学习的学习路线？ - 盛夏的果核的回答 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-2">

<p><a class="link"   href="https://www.bilibili.com/video/av35932863/?from=search&seid=3183765777770933150" >[2] 机器学习-李宏毅(2019) Machine Learning-bilibili<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-3">

<p><a class="link"   href="https://www.bilibili.com/video/av9912938?from=search&seid=4863540311864515527" >[3] 机器学习（Machine Learning）- 吴恩达（Andrew Ng）-bilibili<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-4">

<p><a class="link"   href="https://www.zhihu.com/question/277325426/answer/767807599" >[4] 强化学习怎么入门好？ - 董豪的回答 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-5">


<p><a class="link"   href="https://www.zhihu.com/question/275906449/answer/2843223015" >[5] 强化学习怎么入门？ - 阿路阿路的回答 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-6">

<p><a class="link"   href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/" >[6] morvanzhou-强化学习视频<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-7">

<p><a class="link"   href="https://spinningup.openai.com/en/latest/spinningup/keypapers.html" >[7] 强化学习-关键性论文<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-8">

<p><a class="link"   href="https://www.bilibili.com/video/av24724071/?p=1" >[8] 李宏毅深度强化学习(国语)课程(2018)-bilibili=<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-9">

<p><a class="link"   href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" >[9] Teaching<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-10">

<p><a class="link"   href="http://product.dangdang.com/27926613.html" >[10] 《强化学习（第2版）》（加）Richard S. Sutton（理查德·桑顿）【简介_书评_在线阅读】 - 当当图书<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-11">

<p><a class="link"   href="https://link.zhihu.com/?target=https://spinningup.openai.com/en/latest/" >[11] OpenAI - Spinning Up<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-12">

<p><a class="link"   href="https://link.zhihu.com/?target=https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs" >[12] UCL course: Advanced DL and RL<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-13">

<p><a class="link"   href="https://link.zhihu.com/?target=https://katefvision.github.io/" >[13] Deep RL and Control<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-14">

<p><a class="link"   href="https://search.bilibili.com/all?vt=76593277&keyword=%E7%8E%8B%E6%A0%91%E6%A3%AE%20%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0&from_source=webtop_search&spm_id_from=333.1007&search_source=5" >[14] 强化学习课程-王树森-bilibili<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-15">

<p><a class="link"   href="https://www.bilibili.com/video/BV1LE411G7Xj/?spm_id_from=333.337.search-card.all.click" >[15] 强化学习课程-周博磊-bilibili<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-16">

<p><a class="link"   href="https://link.zhihu.com/?target=https://github.com/tensorlayer/RLzoo" >[16] RLzoo：面向产品化的RL库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-17">

<p><a class="link"   href="https://link.zhihu.com/?target=https://github.com/tensorlayer/tensorlayer/tree/master/examples/reinforcement_learning" >[17] TL：面向科研的RL库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>

<div id="refer-anchor-18">

<p><a class="link"   href="https://paperswithcode.com/" >[18] Paper with Code<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</div>
]]></content>
      <categories>
        <category>技术</category>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记37-前沿-联合请求更新和弹性资源调配</title>
    <url>/2024/05/08/literature/literatureNotes37/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Joint-Request-Updating-and-Elastic-Resource-Provisioning-With-QoS-Guarantee-in-Clouds》"><a href="#x1f4d6-《Joint-Request-Updating-and-Elastic-Resource-Provisioning-With-QoS-Guarantee-in-Clouds》" class="headerlink" title="📖《Joint Request Updating and Elastic Resource Provisioning With QoS Guarantee in Clouds》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Joint Request Updating and Elastic Resource Provisioning With QoS Guarantee in Clouds》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>和<a href="/2024/05/08/literature/literatureNotes36/" title="另一篇文章">另一篇文章</a>一致</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>和<a href="/2024/05/08/literature/literatureNotes36/" title="另一篇文章">另一篇文章</a>一致</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>和<a href="/2024/05/08/literature/literatureNotes36/" title="另一篇文章">另一篇文章</a>一致</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>和<a href="/2024/05/08/literature/literatureNotes36/" title="另一篇文章">另一篇文章</a>一致</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>…</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10144446">[1] Gongming Zhao, Jingzhou Wang, *Hongli Xu, Yangming Zhao, Xuwei Yang, He Huang, “Joint Request Updating and Elastic Resource Provisioning With QoS Guarantee in Clouds”, IEEE/ACM Transactions on Networking (ToN), 2023<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>请求调度</tag>
        <tag>资源调配</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记38-前沿-全球覆盖网络混合弹性云</title>
    <url>/2024/07/01/literature/literatureNotes38/</url>
    <content><![CDATA[<h1 id="x1f4d6-《XRON-A-Hybrid-Elastic-Cloud-Overlay-Network-for-Video-Conferencing-at-Planetary-Scale》"><a href="#x1f4d6-《XRON-A-Hybrid-Elastic-Cloud-Overlay-Network-for-Video-Conferencing-at-Planetary-Scale》" class="headerlink" title="📖《XRON: A Hybrid Elastic Cloud Overlay Network for Video Conferencing at Planetary Scale》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《XRON: A Hybrid Elastic Cloud Overlay Network for Video Conferencing at Planetary Scale》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>视频会议在我们的社会中正变得越来越流行和重要。<ul>
<li>我们经营着全球最大的视频会议服务之一，拥有<strong>数亿用户</strong>。我们的大多数顶级商业客户都是<strong>跨国公司</strong>，他们依靠我们的服务来举办国际在线会议，以进行常规的公司管理和各种商业活动。这就要求我们提供全球规模的视频会议服务。我们将视频会议集群作为容器部署在合作云提供商的全球不同云区域。地理分布式部署可确保我们的用户能够访问附近的视频会议服务。我们将全球各地的视频会议集群互联起来，形成在广域网中传输视频会议流量的网络基础设施。</li>
</ul>
</li>
<li>质量和成本是视频会议服务的两个关键考虑因素。云平台通常提供具有不同成本和性能特征的网络层。<ul>
<li>服务提供商在选择网络层来构建基础设施时面临着两难选择–<ul>
<li><ol>
<li>依靠互联网链路的质量较差。<strong>互联网链路</strong>成本低廉，但在视频会议严格的质量要求下，通过互联网链路直接连接集群实际上远不能令人满意。</li>
</ol>
</li>
<li><ol start="2">
<li>而使用优质链路又会带来过高的成本。云提供商通常会建立自己的<strong>专用数据中心间网络</strong>，或从互联网服务提供商处<strong>租用专用链路</strong>，并将其作为高级网络层公开。使用高级链路可以满足视频会议的需求，但成本过高。</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>叠加网络（overlay network）是研究了几十年的经典课题。<ul>
<li>我们认为，除了在现实世界中构建和部署全球级系统的工程贡献之外，XRON 的关键技术贡献在于设计了一种混合和弹性的重叠网络，这使得 XRON 有别于之前的叠加网络。</li>
</ul>
</li>
<li>早期的叠加网络（如 RON）仅使用互联网链接来实现弹性。这不足以对突然的性能下降做出快速反应。天真地根据全局视图更新重叠路径的速度要比视频会议所需的速度慢一个数量级。<ul>
<li>XRON 利用混合网络资源对性能下降做出快速反应。</li>
</ul>
</li>
<li>就弹性而言，虽然最近也有利用弹性云资源的云重叠（如 Skyplane），但其目标不同：XRON 是为对延迟敏感的视频会议服务而设计的，而 Skyplane 则是为吞吐量密集型大容量数据传输而设计的。这就引入了一系列不同的设计约束和解决方案，包括基于预测的主动资源扩展、可扩展的实时链路状态监控和快速的分布式数据平面反应。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>我们提出了 XRON，这是一种混合弹性云覆盖网络，用于我们的全球级视频会议服务。XRON 与以往的覆盖网络不同，它有两个显著特点。<ul>
<li>首先，XRON 是<strong>混合</strong>的，即利用<strong>互联网链路</strong>和<strong>优质专用链路</strong>同时实现高质量和低成本。<ul>
<li>问题1：互联网链接的关键问题是不稳定性。互联网链路的延迟和损耗率会在短时间内大幅飙升（第 2.2 节）。虽然这种突然的峰值对于大容量数据传输等吞吐量密集型服务来说不是问题，但对于对延迟敏感的视频会议服务来说，却会严重影响用户体验。<ul>
<li>解决1：XRON 在大多数情况下依靠互联网链路实现低成本，并在性能暂时下降时迅速将互联网链路切换为优质链路或其他高质量互联网链路，以保证始终如一的高质量。</li>
</ul>
</li>
<li>利用<strong>覆盖路径</strong>（<em>overlay path</em>），通过中间云区域转发视频会议流量，从而获得比直接路径更好的质量。【这句话在这里的逻辑没懂】</li>
</ul>
</li>
<li>其次，XRON 是<strong>弹性</strong>的，即利用弹性云资源，根据实时需求自适应地扩展容量。<ul>
<li>问题1：视频会议的流量需求随时间而变化（第2.3节）。过度配置覆盖网络会带来不必要的成本，而配置不足又无法满足高峰时段的需求。<ul>
<li>解决1：XRON 采用了无服务器计算中的资源弹性理念。它减轻了叠加运营商的资源调配负担。通过添加或删除云中的容器，可以动态扩展覆盖网络的容量。</li>
</ul>
</li>
<li>问题2：虽然云平台可根据资源使用情况提供反应式自动缩放，但对于对延迟敏感的视频会议服务（第2.3节）来说，这种方式太慢了。<ul>
<li>解决2：我们利用应用知识建立了一个预测模型，可以准确预测视频会议服务的未来流量需求。XRON 会主动扩展资源，避免因扩展缓慢而导致服务质量下降。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>XRON 利用混合链路和弹性云资源实现高质量和低成本。XRON 的原则性设计由数据平面（§4）和控制平面（§5）组成。<ul>
<li>XRON 的数据平面结合了主动探测和被动跟踪功能，用于可扩展的链路状态监控，根据异构双向链路质量使用非对称转发，并在控制平面不参与的情况下对突发的链路性能下降做出快速反应。<ul>
<li>数据平面包括一组分布在云区域的XRON网关，用于传输视频会议流量。网关将基于采样的主动探测和被动跟踪相结合，实现了对大型覆盖网络的可扩展链路状态监控（§4.1）。</li>
<li>数据平面的流量转发是非对称的，视频流的两个方向可以使用不同的路径，以利用异构双向链路质量（§4.2）。</li>
<li>数据平面使用分布式反应机制，在链路质量突然下降时，在本地快速更新覆盖路径（§4.3）。</li>
</ul>
</li>
<li>XRON 的控制平面根据应用知识预测视频流量，并利用可扩展算法计算全局转发路径和反应计划。<ul>
<li>控制平面是一个逻辑上集中的控制器，负责决定重叠网络的资源规模和转发路径。控制器利用特定领域的预测模型来准确预测未来的视频流量需求（§5.1）。</li>
<li>根据对重叠网络的全局了解，控制器使用可扩展的两步控制算法计算每个区域的网关数量及其转发表（§5.3）。</li>
<li>控制器还会计算备份路径，以实现快速的数据平面反应（§5.4）。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>XRON 是一套生产系统，自 2022 年 8 月开始部署，用于支持 DingTalk 视频会议服务。XRON 的覆盖节点部署在全球 11 个阿里云区域。</li>
<li>在线生产统计数据显示，与仅使用公共互联网链路相比，XRON 可将视频停滞率和音频不流畅率分别降低 77% 和 65.2%。与仅使用高级链接相比，XRON 可降低高达 79% 的成本。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>提供了一个地理分布式云的实际应用场景————跨国视频会议。</li>
<li>写作模式很独特，不是先提出问题再提解决方法，而是先提解决方法的两大特点再引出相关方案问题。核心挑战其实是“不混合”，辅助挑战是“不弹性”。</li>
<li>中间提到“利用<em>overlay path</em>来获得比直接路径更好的质量”似乎又逻辑断层，和上下文脱节。</li>
<li>调度的资源对象是什么？是网络链路中的带宽分配？</li>
<li>什么情况下延迟会上升？</li>
<li>大规模是否对负载预测带来挑战？</li>
<li>根据这篇论文总结，大规模跨地域云场景（或者说东数西算计划）在未来可能的模式有哪些？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3603269.3604845">[1] Bingyang Wu, Kun Qian, Bo Li, Yunfei Ma, Qi Zhang, Zhigang Jiang, Jiayu Zhao, Dennis Cai, Ennan Zhai, Xuanzhe Liu, and Xin Jin. 2023. XRON: A Hybrid Elastic Cloud Overlay Network for Video Conferencing at Planetary Scale. In Proceedings of the ACM SIGCOMM 2023 Conference (ACM SIGCOMM ‘23). Association for Computing Machinery, New York, NY, USA, 696–709. https://doi.org/10.1145/3603269.3604845<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>全球视频会议</tag>
        <tag>叠加网络</tag>
        <tag>地理分布式云</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记39-前沿-图神经网络预测应用延迟</title>
    <url>/2024/07/01/literature/literatureNotes39/</url>
    <content><![CDATA[<h1 id="x1f4d6-《PERT-GNN-Latency-Prediction-for-Microservice-based-Cloud-Native-Applications-via-Graph-Neural-Networks》"><a href="#x1f4d6-《PERT-GNN-Latency-Prediction-for-Microservice-based-Cloud-Native-Applications-via-Graph-Neural-Networks》" class="headerlink" title="📖《PERT-GNN: Latency Prediction for Microservice-based Cloud-Native Applications via Graph Neural Networks》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《PERT-GNN: Latency Prediction for Microservice-based Cloud-Native Applications via Graph Neural Networks》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>使用微服务架构的云原生应用正在迅速取代传统的单体应用。<ul>
<li>微服务架构是云原生领域的一个重要软件开发框架。它将应用程序构建为一个小型、独立、自足的服务集合，可以独立部署和管理。与单体框架相比，微服务框架具有灵活扩展资源的优势。</li>
<li>图 1 显示了一个由多个微服务组成微服务调用图（MCG）的社交网络应用程序。用户客户端通过 API 端点向应用程序发送 API 调用请求。然后会调用具有专用功能的微服务来满足用户的特定请求。当应用程序的负载不断增加时，服务提供商可以定位并扩展负载较重的单个微服务，而不是扩展整个应用程序。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/bca68a52f24941269bed015a37b25df1d0954de0/2-Figure1-1.png" alt="图1"><figcaption>图1</figcaption></figure></li>
</ul>
</li>
<li>为了满足端到端 QoS 保证并提升用户体验，必须为每个组件微服务配置足够的资源，以处理传入的 API 调用。准确预测基于微服务的应用的延迟对于优化资源分配至关重要，而由于微服务之间的复杂依赖关系和固有的随机性，预测延迟具有极大的挑战性。<ul>
<li>尽管具有灵活性，但微服务架构在生产环境中提供端到端 QoS 保证方面带来了巨大挑战，因为单个用户请求需要由<strong>数百个细粒度微服务</strong>处理。</li>
<li>如今的生产集群通常会<strong>过度配置</strong>资源以提供此类保证，这很容易导致整体资源利用率低下，例如，阿里巴巴微服务集群的 CPU 利用率低至 20%。因此，设计更高效的资源扩展解决方案来满足 QoS 保证变得至关重要。</li>
<li>微服务的资源扩展主要有两种方法：被动式和主动式。<ul>
<li>被动式方法根据系统的性能反馈实时调整资源。</li>
<li>相比之下，前瞻性方法是建立预测模型，提前估算不同资源配置下用户请求的尾端（如第 95 百分位数）端到端延迟，然后选择最佳配置。</li>
<li>被动式解决方案虽然易于实施，但很容易造成违反 QoS 的情况，因为获得端到端反馈可能为时已晚，无法进行扩展，尤其是在呼叫链很长的情况下。因此，近年来，主动式扩展往往是微服务更有前途的方法。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>为了解决这个问题，人们设计了各种基于微服务调用图的预测器。然而，微服务调用图没有考虑到特定于应用程序接口的信息，无法捕捉重要的时间依赖性，也无法扩展到大规模应用。<ul>
<li>实现高效主动扩展的能力在很大程度上取决于对尾端到端延迟的准确预测，但这仍然具有相当大的挑战性。<ul>
<li>首先，同一应用中的组件微服务之间会形成<strong>复杂的交互</strong>。一个微服务的响应会极大地影响其下游微服务，进而影响整个跟踪的端到端延迟。因此，如果不能捕捉到微服务之间的复杂依赖关系，就会导致预测不准确。</li>
<li>其次，尾部延迟因其固有的<strong>随机性而不稳定</strong>，因为它考虑的是最坏的情况。如图 2 所示，虽然社交网络应用程序的工作量在整个一周内会发生周期性变化（图 2a），但中位延迟（响应时间）却保持在 13 毫秒到 17 毫秒之间（图 2b，橙色曲线）。相比之下，第 95 百分位数的延迟时间波动较大，介于 60ms 和 510ms 之间（图 2b，蓝色曲线）。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/bca68a52f24941269bed015a37b25df1d0954de0/2-Figure2-1.png" alt="图2"><figcaption>图2</figcaption></figure></li>
</ul>
</li>
</ul>
</li>
<li>在文献中，很多人致力于捕捉微服务及其操作之间的复杂依赖关系，以预测尾端到端延迟。特别是，这些著作主要采用深度神经网络来模拟基于整个 MCG 的依赖关系。然而，基于 MCG 的预测器存在以下三个局限性。<ul>
<li>1）MCG 不具备 <strong>API 感知能力</strong>，包含<strong>大量无关信息</strong>，可能导致预测结果不理想。在给定的 API 调用中，只有 MCG 中的一小部分微服务参与其中。例如，如图 1 所示，readTimeline 与发送到 MediaNGINX 的 API 调用的执行无关。如果不过滤噪声，延迟预测将非常不准确。此外，对于大型应用而言，如果无法捕获具有 API 感知的相关微服务，很容易产生大量计算开销。</li>
<li>2）MCG 是一种静态图，无法捕捉<strong>调用之间的时间动态</strong>。例如，PostStorageService 微服务随后会调用另外两个微服务，但 MCG 不会显示<strong>哪个微服务先被调用</strong>。此外，MCG 也不会区分这两个微服务是<strong>并行调用还是顺序调用</strong>。</li>
<li>3）MCG 无法识别<strong>运行时动态</strong>。对于相同的 API 调用，运行时动态可能因<strong>输入参数</strong>的不同而不同。例如，/api/home-timeline/read API 调用可以使用或不使用 userId 参数。这将影响是否调用 UserTimelineMongoDB:find 微服务操作，进而影响 /api/home-timeline/read API 调用的端到端延迟。但是，MCG 无法包含这些信息，因为它使用单个静态图将所有运行时行为耦合在一起。</li>
</ul>
</li>
<li>由于这些局限性，目前的预测器预测准确率较低，导致违反服务质量和浪费资源。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了解决这个问题，我们引入了 PERT-GNN，这是一个图神经网络（GNN）模型，可根据给定时间内的 API 调用和资源利用率预测基于微服务的应用的端到端延迟。PERT-GNN 是一种通用模型，适用于任何基于微服务的应用，只需将具有节点特征和/或图特征的图作为输入即可。在这项工作中：<ul>
<li><strong>图</strong>（Span/PERT）是由分布式跟踪工具（如 Jaeger）收集的轨迹构建而成的。详见第 3 章。</li>
<li><strong>节点特征</strong>是指应用程序中每个微服务组件的资源利用率（CPU/内存/磁盘/网络负载）。这些特征由数据遥测工具（如 Prometheus）定期采集。</li>
<li><strong>图特征</strong>指的是 API 调用的类型、跟踪的时间戳以及历史请求数/响应时间的时间序列。</li>
</ul>
</li>
<li>PERT-GNN 可感知应用程序接口，并能在给定的应用程序接口调用中纳入微服务之间的时间依赖性。我们的贡献总结如下：<ul>
<li>1）为了解决局限性（1）-（2），我们提出了一种基于程序评估和审查技术（PERT）的新设计，以构建可<strong>感知应用程序接口</strong>并能<strong>捕捉微服务之间时间依赖关系</strong>的图。图的构建由数据驱动，基于分布式跟踪工具（如 Jaeger）收集的原始微服务跟踪数据，无需任何人工干预。</li>
<li>2）为解决局限性（3），我们提出了一种通用图混合方法，可识别同一 API 调用的不同<strong>运行时动态</strong>。这样，我们就能在同一个应用程序接口调用中确定不同运行时动态的相关微服务之间的关系。</li>
<li>3）我们提出的 PERT-GNN 是一种基于transformer的 GNN，它通过捕捉微服务的结构和位置信息，预测微服务应用的不同端到端延迟百分位数，并进行端到端训练。</li>
</ul>
</li>
<li>PERT-GNN 利用程序评估和审查技术（PERT）从应用程序先前的执行轨迹中观察组件微服务的交互或依赖关系。然后，我们根据生成的 PERT 图构建图神经网络，并使用图转换器方法将延迟预测任务表述为有监督的图回归问题。PERT-GNN 可以捕捉不同微服务跟踪的复杂时间因果关系，从而为各种应用提供更准确的延迟预测。</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>基于常见基准和大规模阿里巴巴微服务踪迹生成的数据集进行的评估表明，PERT-GNN 的性能远远优于其他模型。特别是，PERT-GNN 能够以低于 12% 的平均绝对百分比误差预测微服务应用的延迟。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>现有集群利用率低的原因是“过度配置资源”吗？阿里巴巴没有使用负载预测技术吗？如果没有，原因是什么？</li>
<li>面向的是单个应用内部的复杂关系，多个应用之间是否存在关联关系？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3580305.3599465">[1] Da Sun Handason Tam, Yang Liu, Huanle Xu, Siyue Xie, and Wing Cheong Lau. 2023. PERT-GNN: Latency Prediction for Microservice-based Cloud-Native Applications via Graph Neural Networks. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD ‘23). Association for Computing Machinery, New York, NY, USA, 2155–2165. https://doi.org/10.1145/3580305.3599465<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>负载预测</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记4-前沿-内存数据库性能</title>
    <url>/2023/05/24/literature/literatureNotes4/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Exploring-Fine-Grained-In-Memory-Database-Performance-for-Modern-CPUs》"><a href="#x1f4d6-《Exploring-Fine-Grained-In-Memory-Database-Performance-for-Modern-CPUs》" class="headerlink" title="📖《Exploring Fine-Grained In-Memory Database Performance for Modern CPUs》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Exploring Fine-Grained In-Memory Database Performance for Modern CPUs》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>现代CPU为高性能计算平台集成了越来越多的内核和大尺寸缓存，有利于内存数据库提高并行处理能力和缓存局部性，探索不同 CPU 架构的内存数据库性能特征对于内存数据库设计和优化非常重要。<ul>
<li>最先进的CPU具有多种架构，两个主要路线图是以计算为中心或以缓存为中心的设计，例如大内核数和大高速缓存大小 （AMD x86）、中等内核数和高速缓存大小 （Intel x86）、大内核数和中等高速缓存大小 （ARM）。<ul>
<li>以计算为中心的 CPU 架构更喜欢将更多内核与小芯片和分解的大型 L3 缓存（如 AMD 罗马/米兰和 ARM CPU）集成；</li>
<li>以缓存为中心的 CPU 架构将中等内核与中等大小的单片 L3 缓存（如英特尔 Icelake CPU）集成在一起。</li>
</ul>
</li>
</ul>
</li>
<li>内核和内存之间的“内存墙”差距是内存数据库的主要瓶颈，不同的内核和缓存架构旨在提高内存访问吞吐量并减少内存延迟。<ul>
<li>从软件角度来看，查询处理性能受多种因素主导，例如运算符性能、处理模型或不同的运算符实现。</li>
<li>从硬件角度来看，CPU 架构也会以不同的性能模式对性能产生很大影响，例如，join 运算符通常受共享 L3 缓存 （LLC） 的影响，而 GROUP-BY 运算符的性能通常由私有缓存主导。</li>
<li>因此，对于内存数据库，应该回答以下两个问题：<ul>
<li>（1）内存数据库在不同架构的CPU上性能如何，不同性能的原因是什么？</li>
<li>（2） 如何通过 CPU 架构感知设计提高内存数据库性能？对于 CPU 供应商来说，性能特征可以阐明哪种 CPU 架构可以更好地提高内存中数据库性能。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>内存数据库算法通常是硬件感知设计，最具代表性的路线图是硬件遗忘非分区哈希连接和硬件感知基数分区哈希连接，前者更喜欢大而有效的共享L3缓存，而后者则依赖于私有缓存效率。这些比较研究阐明了如何根据底层硬件调整软件性能。近年来出现了许多扩展研究，例如Xeon Phi，GPU，和FPGA平台的优化。</li>
<li>NPO 和 PRO 算法被广泛接受为连接基准，而实际 OLAP 要求存在一些缺点。<ul>
<li>首先，工作量不够具有代表性。</li>
<li>其次，连接算法不够。</li>
<li>第三，结论不够。</li>
<li>最后，对硬件与连接算法之间的相关性探讨不够。</li>
<li>因此，扩展联接算法、真实风格的工作负载、多联接实现以及发现不同架构 CPU 的联接性能模式是本工作的首要目标。</li>
</ul>
</li>
<li>对于系统设计来说，孤立地比较数据库算子是不够的，本工作的第二个目标是构建一个完整的数据库算子基准，对全工作负载进行全面评估，模拟数据库引擎的性能。</li>
<li>本工作的最后一个目标是构建一个框架来评估数据库工作负载在指定架构 CPU 上的运行情况。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>在本文中，开发了一个细粒度的内存数据库基准测试，以评估不同CPU上每个操作的性能，以探索CPU硬件架构如何影响性能。</li>
<li>在本文中，重点讨论三个问题：<ul>
<li>（1）评估最先进的内存数据库在不同架构CPU上的性能，探索哪种CPU架构更适合内存数据库;</li>
<li>（2）通过细粒度的关系算子基准，我们进一步探讨了CPU架构如何影响每个基础算子的性能，以解释为什么核心数和缓存大小不能主导性能;</li>
<li>（3）通过细粒度增量实验，我们试图找出每个运营商在不同CPU上的强弱性能区域，这些CPU以CPU架构和微缓存架构为主。为了回答这三个问题，我们设置了宏观和微观基准实验来收集第一手的性能信息，以探索CPU硬件架构与内存数据库算子实现之间的强相关性。</li>
</ul>
</li>
<li>贡献：<ul>
<li>第一个贡献是提出具有宏和微观内存数据库基准的 CPU 性能评估框架。内存数据库对 CPU 硬件很敏感，可以评估不同设计如何影响性能。</li>
<li>第二个贡献是发现了一些与流行观点相反的发现：<ul>
<li>（1）具有更多内核的CPU可能无法达到内存数据库的更高性能，缓存局部性起着重要作用;</li>
<li>（2）扩大缓存大小未必接近高性能，微缓存架构问题;</li>
<li>（3）在查询计划中选择性能较高的算子实现可能不会产生更高的性能，查询处理模型主导了多个算子的处理效率。</li>
</ul>
</li>
<li>第三个贡献是开发细粒度的算子基准，给出从简单的单算子查询到复杂的多维OLAP查询的综合数据库性能评估。细粒度的实验结果说明了受不同CPU架构影响的性能特征。操作性能与 CPU 架构之间的相关性可以阐明如何设计 CPU 架构感知算法以及如何为数据库工作负载设计 CPU 架构。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>与众所周知的内核数和更大的缓存大小可以实现更高性能的结论不同，我们发现微缓存架构在内核数和缓存大小相反的背景下发挥着重要作用，中等大小的共享单片 L3 缓存优于大型分解 L3 缓存。</li>
<li>实验还表明，根据不同的CPU架构和微缓存架构，预测不同CPU上的算子性能是困难的，并且每个算子的不同实现并不总是高低，交错的强弱性能区域受CPU硬件架构的影响。<ul>
<li>英特尔 x86 CPU 代表以高速缓存为中心的处理器设计，而 AMD x86 和 ARM CPU 代表以计算为中心的处理器设计，SSB 的 OLAP 基准实验发现，与 AMD x86 CPU 相比，具有矢量处理模型的 OmniSciDB 和 OLAP 加速器在英特尔 x86 CPU 上表现良好，并且基于 JIT 兼容的 Hyper 更喜欢 AMD x86 CPU 而不是英特尔 x86 CPU。在内存数据库算法设计和平台选择中，应考虑增加内核或改进缓存局部性的 CPU 路线图。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>结论是什么？原因是什么？能否在我们的工作中利用上这些结论？</li>
<li>内存数据库的应用情况如何？和普通数据库的关系？</li>
</ol>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10086665/figures#figures">[1] Z. Liu et al., “Exploring Fine-Grained In-Memory Database Performance for Modern CPUs,” in IEEE Transactions on Parallel and Distributed Systems, vol. 34, no. 6, pp. 1757-1772, June 2023, doi: 10.1109/TPDS.2023.3262782.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>内存数据库</tag>
        <tag>性能刻画</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记40-前沿-针对云原生的尾部延迟优化CPU架构</title>
    <url>/2024/07/01/literature/literatureNotes40/</url>
    <content><![CDATA[<h1 id="x1f4d6-《μManycore-A-Cloud-Native-CPU-for-Tail-at-Scale》"><a href="#x1f4d6-《μManycore-A-Cloud-Native-CPU-for-Tail-at-Scale》" class="headerlink" title="📖《μManycore: A Cloud-Native CPU for Tail at Scale》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《μManycore: A Cloud-Native CPU for Tail at Scale》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>微服务正在成为一种流行的云计算范式。<ul>
<li>云计算的模式正在发生转变，大型单体应用正在被许多轻量级、松散耦合的微服务所取代。</li>
<li>在这些 “云原生 “工作负载中，每个微服务都作为单独的程序实现和部署，并执行应用程序的部分逻辑，如 HTTP 连接终止、键值服务、协议路由或广告服务。</li>
<li>这种可组合的应用设计简化了开发过程，实现了编程语言和框架的异构性。此外，每个微服务都可以在多个应用程序之间共享，同时可以独立于其他微服务进行扩展和更新。亚马逊、Netflix、阿里巴巴、Twitter、Uber、Facebook 和谷歌等所有主要云提供商都在采用这种新模式。此外，管理微服务工作负载的开源环境（如 Kubernetes 和 Docker Compose）也大量涌现。</li>
</ul>
</li>
<li>微服务环境执行的是典型的短服务请求，这些请求通过远程过程调用（通常是跨机器）进行交互，并受到严格的尾延迟限制。<ul>
<li>微服务环境具有新的特点，会影响其运行平台的系统和硬件架构。<ul>
<li>具体来说，应用程序中的微服务请求通常是<strong>短时间运行</strong>的，并可能在不同的机器上执行。不同微服务的请求不共享内存状态，而是通过<strong>远程过程调用（RPC）进行交互</strong>。</li>
<li>此外，请求的工作集较小，经常被<strong>突发调用</strong>，执行前经常在队列中等待。</li>
<li>最后，应用程序的分解会对单个服务设定<strong>严格的亚毫秒级延迟服务级别目标（SLO）</strong>。因此，虽然减少平均延迟和提高吞吐量很重要，但这些环境中的关键性能目标现在是最大限度地减少尾部延迟（例如，提高第 99 百分位数响应）。在基于微服务的新兴部署方法（如功能即服务（FaaS）环境）中也发现了许多此类特性。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li><p>相比之下，当前的处理器是为传统的单体应用而设计的。它们支持全局硬件高速缓存一致性，提供大型高速缓存，采用微体系结构以实现长时间运行、可预测的应用（如高级预取），并进行了优化，以最大限度地减少平均延迟而非尾部延迟。</p>
<ul>
<li>目前的处理器并不是专门为这些环境设计的。事实上，多核处理器为支持<strong>全局硬件缓存一致性</strong>投入了大量的硬件和设计复杂性。它们拥有大型高速缓存来捕获长期运行应用程序的工作集。相对而言，它们并<strong>不关心支持短时间运行的 RPC 通信程序</strong>。相反，它们针对长期运行、可预测的应用程序进行了微体系结构优化，如高级预取器和分支预测器。这些优化措施大大增加了硬件的复杂性，对于微服务来说，充其量只能起到微不足道的作用。</li>
<li>也许最重要的是，目前的处理器经过高度优化，最大限度地减少了程序或事务的平均延迟，而<strong>忽略了尾部延迟的考虑</strong>。</li>
</ul>
</li>
<li><p>应该如何改变处理器的设计，使其符合微服务的要求呢？</p>
<ul>
<li>首先，应该重新考虑一些会带来<strong>设计复杂性但微服务几乎不需要</strong>的硬件优化，如全局硬件缓存一致性。</li>
<li>其次，应全面优化以<strong>减少尾端延迟</strong>。优化既要针对影响所有请求的低效问题，也要针对可能影响部分请求的基于争用的开销。</li>
</ul>
</li>
<li><p>虽然最终产生的处理器在通用负载方面没有竞争力，但它可以成为微服务密集型数据中心的首选 CPU。</p>
</li>
<li><p>为了更具体地说明问题所在，我们首先分析了 阿里巴巴 的生产级微服务跟踪和 DeathStarBench 的微服务应用。</p>
<ul>
<li>我们的分析表明，突发的服务请求会产生高需求期，在高需求期很可能会出现长时间的等待队列。</li>
<li>此外，请求的大部分时间都被阻塞，等待完成对存储的访问或对其他服务的调用。在此期间，CPU 会频繁地进行上下文切换，从而带来开销。</li>
<li>此外，内核之间由服务发起的消息会受到互连网络（ICN）的延迟，经常会出现争用延迟，从而进一步增加尾部延迟。</li>
<li>最后，虽然请求的工作集很小，但微服务却受益于附近的大型内存池，该内存池存储了每个微服务的最多读取状态。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了解决这一不平衡问题，本文提出了μManycore，一种针对云原生微服务工作负载进行了高度优化的处理器架构。μManycore 不是加速器，它保留了通用处理器的功能，尽管对于单片应用来说可能不那么有竞争力。<ul>
<li>基于对微服务应用的特征分析，我们设计了基于芯片组的 μManycore。尽量减少不必要的微架构，降低开销以减少尾部延迟。<ul>
<li>μManycore不支持全包硬件缓存一致性，而是通过多个小型硬件缓存一致性域（称为 “村”）来构建。微服务被分配到各个村落。几个村落和一个内存芯片组（存储最多读取的状态）组成一个群集。</li>
<li>集群通过<strong>叶刺 ICN</strong> 互联。这种拓扑结构在任何两个集群之间都有许多冗余的低跳数路径，因此可以最大限度地减少具有相同源集群和目标集群的多条信息之间的争用，并减少尾部延迟。（相当于原本只有一条大路，后来变成了很多小路。那么小路为什么比大路快？）</li>
<li>为了尽量减少调度开销，μManycore 在硬件中对服务请求进行排队、去排队和调度。</li>
<li>最后，为了尽量减少频繁切换上下文的开销，内核包括保存和恢复进程状态的硬件支持。</li>
</ul>
</li>
</ul>
</li>
<li>本文的贡献如下：<ul>
<li>1）描述传统处理器中的微服务工作负载行为。</li>
<li>2）提出μManycore，一种针对微服务工作负载高度优化的处理器架构。</li>
<li>3）对 μManycore 进行评估，将其与两个传统服务器级多核处理器进行比较：一个功率相同，一个面积相同。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们的模拟结果表明，μManycore 可为微服务工作负载提供高性能。我们将 1024 核的 μManycore 与两个传统的服务器级多核进行了比较：一个具有与 μManycore 相同的功率，一个具有与 μManycore 相同的面积。<ul>
<li>与使用等功率传统多核的集群相比，使用 μManycore 的 10 台服务器集群的平均延迟降低了 3.7 倍，吞吐量提高了 15.5 倍，更重要的是，尾部延迟降低了 10.4 倍。</li>
<li>与采用等功耗传统多核的集群相比，也取得了类似的良好效果。最后，包上叶脉 ICN、硬件请求调度和硬件上下文切换对提高微服务工作负载的性能非常有效。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>多核处理器架构如何实验？仅通过模拟实验是否会导致结果与实际不符？</li>
<li>在落地方面的可行性很需要考虑，“设计的芯片结构是否符合现实”，“是否能够真正落地到硬件”都是需要有足够的芯片相关背景知识才能不出常识性错误。</li>
<li>在落地方面的必要性也值得考虑，当且仅当微服务应用确实成为主流，且有数据支撑现有CPU架构对性能影响极大的前提下，该问题才值得成为真问题。因此作者的introduction和motivation部分非常重要。（看到在introduction的最后几段，说明了数据是来源于对阿里巴巴等应用的分析）</li>
<li>写作结构很规范，背景、问题、创新说得很清楚，读者理解难度很低，值得学习。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3579371.3589068">[1] Jovan Stojkovic, Chunao Liu, Muhammad Shahbaz, and Josep Torrellas. 2023. ΜManycore: A Cloud-Native CPU for Tail at Scale. In Proceedings of the 50th Annual International Symposium on Computer Architecture (ISCA ‘23). Association for Computing Machinery, New York, NY, USA, Article 33, 1–15. https://doi.org/10.1145/3579371.3589068<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>CPU架构</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记41-前沿-混合部署统一调度+资源竞争感知</title>
    <url>/2024/07/01/literature/literatureNotes41/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Understanding-and-Optimizing-Workloads-for-Unified-Resource-Management-in-Large-Cloud-Platforms》"><a href="#x1f4d6-《Understanding-and-Optimizing-Workloads-for-Unified-Resource-Management-in-Large-Cloud-Platforms》" class="headerlink" title="📖《Understanding and Optimizing Workloads for Unified Resource Management in Large Cloud Platforms》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Understanding and Optimizing Workloads for Unified Resource Management in Large Cloud Platforms》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>为了充分利用计算资源，谷歌和阿里巴巴等云计算提供商选择将在线服务与批量处理应用共置于数据中心。<ul>
<li>在当今的大规模数据中心中，实现<strong>高资源利用率</strong>的一种常见方法是将<strong>对延迟敏感（LS）的应用</strong>（如微服务）和<strong>尽力而为（BE）的应用</strong>（如批处理作业）共用同一个集群。</li>
<li>为了便于管理不同类型的应用，谷歌、微软和阿里巴巴等云提供商在过去十年中采用了<strong>混合调度</strong>，分别实施了用于管理 BE 和 LS 的调度器。<ul>
<li>例如，阿里巴巴构建了 Sigma 调度器，用于调度长期运行的 LS，同时保留了 Fuxi 调度器，用于调度由许多具有复杂依赖关系的小型任务组成的 BE 作业。通过为 LS 和 BE 设计定制策略，混合调度试图在应用性能方面实现两全其美。</li>
</ul>
</li>
</ul>
</li>
<li>通过实施统一的资源管理策略，不同类型的复杂计算作业以一致的方式请求资源，这有助于数据中心实现<strong>全局最优调度，提供更高质量的计算能力</strong>。<ul>
<li>混合调度的一个基本缺陷是，一个工作负载调度器做出看似独立的调度决策，而不管另一个工作负载调度器是否并存，从而导致<strong>次优调度结果</strong>。数据中心管理系统通常会为每个调度器<strong>保留一定的资源</strong>，这很容易导致整体利用率低下。</li>
<li>为了缓解这些限制，数据中心已开始通过单一调度框架从混合调度发展到<strong>统一调度</strong>，如 Google Borg、阿里巴巴统一资源管理系统和 Facebook Twine。<ul>
<li>在这种新的调度模式下，不同应用的资源请求由系统统一调度，以实现所有应用之间的<strong>全局调度协调</strong>。</li>
<li>同时，统一调度器可以<strong>全面了解数据中心资源</strong>，提高利用率和调度质量。</li>
</ul>
</li>
</ul>
</li>
<li>虽然统一调度可以实现更高的资源利用率，但<ul>
<li>1）在统一调度下，任务通常在容器中运行，更容易受到干扰。然而，现有的统一调度器<strong>并未明确量化任务性能（考虑干扰）</strong>。</li>
<li>2）需要确保各种应用的性能与传统混合调度下的性能相当。统一调度对调度效率提出了很高的要求，即大规模数据中心中所有任务的实时调度，如 Google Borg 每小时需要调度超过 25 万个任务请求。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>要设计出满足所有这些要求的统一调度器，关键是要深入了解统一调度的特点，但迄今为止还没有人进行过这样的分析研究。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>为了理解这种新的调度模式，本文首先对阿里巴巴的统一调度工作负载进行了深入研究。我们的研究侧重于资源利用率、应用运行性能和调度可扩展性的表征。</p>
<ul>
<li>具体来说，我们分析了阿里巴巴数据中心超过一百万个 pod 在八天内的工作负载。我们分析了 LS 和 BE 应用程序中任务（在容器中运行）的资源使用指标。该特性分析产生了几个有趣的观察结果。</li>
<li>我们观察到，<ul>
<li>1）虽然在统一调度下通过削峰填谷使得计算资源明显超额，但阿里巴巴数据中心的<strong>资源利用率仍然很低</strong>。<ul>
<li>统一调度通过在适当的时间精心调度 BE 应用程序，将填谷和削峰结合在一起，不仅能为 LS 工作负载提供性能保证，还能在 LS 工作负载较低时提高利用率。</li>
<li>尽管进行了峰值负载转移，但总体资源利用率仍然很低，即平均不到 30%。</li>
</ul>
</li>
<li>2）同时，pod 在等待 CPU 和内存资源时仍会出现<strong>较长的调度延迟</strong>，而且调度延迟呈<strong>重尾分布</strong>。</li>
<li>3）此外，现有的资源使用预测器往往会<strong>严重高估资源使用情况</strong>。<ul>
<li>数据中心调度程序通常会超量分配资源，让一台机器上的资源请求总和超过其容量，从而提高资源效率。实现这一目标的关键是准确预测每台物理机器的实际资源使用情况。</li>
<li>我们量化了业界提出的各种现有预测方法在阿里巴巴生产工作负载上的表现。量化结果表明，这些方法会导致<strong>严重的高估</strong>，这表明在统一调度的背景下，需要更多资源效率更高的预测方法。</li>
</ul>
</li>
<li>4）同时，同一应用中的任务表现相当一致，任务的运行性能可以很好地反映相应物理主机上的<strong>资源争用情况</strong>。<ul>
<li>我们还对 BE 和 LS 应用程序的 pod 性能进行了分析，结果表明它们与物理主机上的 pod <strong>资源使用情况和资源争用情况高度相关</strong>。</li>
<li>此外，同一应用程序中 pod 的行为相当一致，这表明可以根据先前的历史记录获得单个应用程序的概况，从而预测 pod 的性能。因此，可以在线使用机器学习算法来预测每个 pod 的行为，从而产生更高效的调度结果。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>基于这些观察结果，我们在本文中设计了一种统一的数据中心调度程序 Optum，用于提高整体资源利用率，同时确保每个应用程序的良好性能。Optum 为每个应用程序维护两个配置文件，即 pod 资源使用情况和 pod 运行性能。性能配置文件还能捕捉资源干扰。</p>
<ul>
<li>Optum 提出了一个调度统一任务请求的优化问题，旨在平衡利用率和资源争用之间的权衡。<ul>
<li>Optum 采用了一种更精确的预测器来预测每台物理机上未来的资源使用情况。该预测器背后的原理是，来自不同应用程序的任意两个 pod 的总资源使用峰值远远低于这两个 pod 的峰值之和。因此，预测器会将所有 pod 对资源使用情况的估计值结合起来，从而得出更准确、更紧凑的预测结果。</li>
</ul>
</li>
<li>Optum 还实施了高效的启发式方法，以可扩展的方式解决优化问题。<ul>
<li>Optum 基于应用配置文件和资源使用预测器，建立了一个全局优化框架，以最大限度地提高数据中心的整体资源利用率和所有 pod 因资源争用而导致的性能下降之间的差值。为解决这一问题，Optum 设计了可扩展的解决方案，能够以较小的开销生成调度决策。</li>
</ul>
</li>
</ul>
</li>
<li><p>总结而言，我们在本文中做出了以下贡献：</p>
<ul>
<li>1）我们对大规模数据中心的统一调度进行了全面研究。我们的研究揭示了有关资源使用和 pod 性能的一些有趣现象。此外，我们的研究还强调了现有资源使用预测器在资源过度承诺方面的低效率。</li>
<li>2）我们设计了一种新的统一数据中心调度器，它能很好地平衡资源利用率、pod 性能和调度可扩展性之间的权衡。</li>
<li>3）我们利用阿里巴巴数据中心的生产工作负载进行了大规模实验，证明了我们设计的调度器与现有解决方案相比的优越性。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>大规模实验证明，与最先进的统一调度方案相比，Optum 可节省多达 15% 的资源，且不会降低性能。<ul>
<li>我们开发了一个跟踪驱动的测试平台来评估 Optum。它模拟了一个由大约 6000 台服务器组成的数据中心，其配置与阿里巴巴数据中心的配置相同，这些数据中心在实际工作负载下运行。</li>
<li>评估结果表明，与最先进的统一调度程序相比，Optum 可将资源利用率提高 15%，同时所有 pod 的性能保持不变。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>在阿里，Sigma是专用于延迟敏感型LS应用调度，Fuxi是专用于尽力而为BE应用调度？按此理解，Fuxi2.0的调度对象全是BE应用？还是Fuxi2.0已经进化为统一调度了？</li>
<li>混合部署带来了什么问题？统一调度带来了什么问题？会导致性能下降？是否能打一些比方来说明这个问题。</li>
</ol>
<ul>
<li>几个阶段间的逻辑关系应该是：独立部署:混合调度-&gt;混合部署:混合调度-&gt;混合部署:统一调度。</li>
<li>调度质量逐步上升（更能找到全局较优解、提高资源利用率），调度效率逐步下降（求解空间越来越大）。</li>
<li>同时，对于新颖的混合部署，难以避免任务间干扰，甚至还没人能够较好地量化这种干扰，所以也很难找到实际全局最优解。</li>
</ul>
<ol start="3">
<li>负载预测器的核心亮点是什么？</li>
</ol>
<ul>
<li>现有负载预测器都忽略资源争用，因此导致高估资源需求。</li>
<li>不存在资源争用时，同一应用的多个pod资源使用情况很稳定，可以作为Base。</li>
</ul>
<ol start="4">
<li>阿里的文章真是措辞严谨、逻辑通顺、内容充实细节丰富。包括前面的Fuxi2.0，都是常看常新的文章，很值得学习。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3552326.3587437">[1] Chengzhi Lu, Huanle Xu, Kejiang Ye, Guoyao Xu, Liping Zhang, Guodong Yang, and Chengzhong Xu. 2023. Understanding and Optimizing Workloads for Unified Resource Management in Large Cloud Platforms. In Proceedings of the Eighteenth European Conference on Computer Systems (EuroSys ‘23). Association for Computing Machinery, New York, NY, USA, 416–432. https://doi.org/10.1145/3552326.3587437<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>混合部署</tag>
        <tag>资源竞争</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记42-前沿-微服务依赖强度预测</title>
    <url>/2024/07/02/literature/literatureNotes42/</url>
    <content><![CDATA[<h1 id="x1f4d6-《AID-Efficient-Prediction-of-Aggregated-Intensity-of-Dependency-in-Large-scale-Cloud-Systems》"><a href="#x1f4d6-《AID-Efficient-Prediction-of-Aggregated-Intensity-of-Dependency-in-Large-scale-Cloud-Systems》" class="headerlink" title="📖《AID: Efficient Prediction of Aggregated Intensity of Dependency in Large-scale Cloud Systems》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《AID: Efficient Prediction of Aggregated Intensity of Dependency in Large-scale Cloud Systems》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>服务可靠性是云提供商必须应对的关键挑战之一。在云系统中，计划外的服务故障可能会对其附属服务造成严重的连锁影响，从而降低客户满意度。<ul>
<li>服务可靠性是云提供商必须应对的关键挑战之一。</li>
<li>目前的普遍做法是开发和部署小型、独立、松散耦合的云微服务，这些微服务共同满足用户的请求。服务于相同目的的微服务被称为云服务。微服务之间通过定义明确的 API 进行通信。这种架构被称为微服务架构。微服务架构因其可靠性和灵活性而被云系统广泛采用。在这种架构下，Kubernetes 等微服务管理框架将负责管理微服务的生命周期。开发人员可以专注于应用逻辑，而不是资源管理和故障恢复等烦人的任务。</li>
<li>尽管微服务管理框架提供了自动故障恢复机制，但<strong>计划外的服务故障仍可能造成严重的连带影响</strong>。例如，提供基本请求路由功能的关键服务发生故障时，会影响云服务的调用、减缓请求处理速度并降低客户满意度。因此，快速准确地评估服务故障的影响对云系统的运行和维护至关重要。了解了影响范围，可靠性工程师就能更加重视对其他服务影响更大的服务。</li>
</ul>
</li>
<li>准确有效地预测连锁影响对云系统的运行和维护至关重要。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>现有方法可通过分布式跟踪来确定一项服务是否依赖于另一项服务，但之前没有任何工作<strong>侧重于判别云服务之间的依赖程度</strong>。<ul>
<li>失败的服务只会影响调用它的服务。换句话说，服务调用会导致服务间的依赖关系。最近的许多方法建议<strong>使用服务的依赖关系来近似估算其故障影响</strong>。云系统中的所有服务和依赖关系共同构建了一个有向服务图，也称为依赖关系图。<ul>
<li>Dapper 和 Jaeger 等工业跟踪框架可以很好地解决云系统中一个服务是否依赖于另一个服务的问题。</li>
<li>通过使用这些框架，调用者和被调用者服务之间的所有调用都可以被记录为由跨度组成的跟踪。每次调用的属性（如持续时间、状态、调用服务名称、时间戳等）都记录在每个跨度中。根据跨度，当前的依赖关系检测方法将依赖关系视为二进制值，表示一个服务是否调用了另一个服务。</li>
</ul>
</li>
<li>然而，仅用<strong>二元依赖关系</strong>来模拟服务关系是不够精确的。<ul>
<li>为了说明现有方法的不足，我们首先对亚马逊网络服务和华为云的故障进行了实证研究。</li>
<li>我们指出，基于二元依赖关系进行故障诊断和恢复是低效的。<ul>
<li>这是因为云服务的<strong>不同依赖关系会对云服务产生不同的影响</strong>。在没有任何优先级的情况下手动检查不同的依赖关系是低效的，尤其是在依赖关系数量可能很大的云系统中。</li>
</ul>
</li>
<li>基于这一观点，我们认为，如果能以连续值的形式来衡量依赖性，并以此来表示这种<strong>依赖性的强度</strong>，则会有所帮助。<ul>
<li>具体来说，通过检查依赖于故障服务且依赖强度值较大的服务，值班工程师（OCE）可以更有可能找到系统故障的根本原因。通过恢复对故障服务依赖性强的服务，可以更快地恢复整个系统。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>在本文中，我们调查了两个云提供商的中断情况和故障诊断程序，从而提出了依赖强度的定义。我们将两个服务之间的依赖强度定义为被调用服务的状态对调用服务的影响程度。</li>
<li>然后，我们提出了端到端的方法 AID，这是第一种预测云服务间依赖强度的方法，以进行级联故障预测。<ul>
<li>1）AID 首先从跨度中生成一组候选依赖对。</li>
<li>2）然后，AID 用从跨度中汇总的多变量时间序列来表示每个云服务的状态。利用服务表示法，AID 计算每个候选配对的调用方和被调用方状态之间的相似性。<ul>
<li>根据时间戳和服务名称将每个跨度分配到不同的固定长度箱中。我们计算每个分段中所有跨度的统计数据，作为该分段的关键性能指标（KPI）。一项服务的关键性能指标构成一个多变量时间序列，将被视为服务状态的代表。对于每个候选依赖对，我们会计算该依赖对中两个服务状态之间的相似度。</li>
</ul>
</li>
<li>3）最后，AID 对相似度进行汇总，得出一个统一值，作为依赖关系的强度。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>为了展示 AID 的有效性，我们在两个数据集上对 AID 进行了评估。一个是模拟数据集，另一个是工业数据集。<ul>
<li>在模拟数据集上，我们部署了开源微服务基准系统 trainticket，模拟用户请求并收集跟踪数据。</li>
<li>对于工业数据集，我们从生产云系统中收集跟踪数据。</li>
</ul>
</li>
<li>然后，我们在数据集上对 AID 进行评估，并将其性能与几种基线进行比较。<ul>
<li>实验结果表明，我们提出的方法可以准确测量依赖关系的强度，其性能优于基线方法。</li>
<li>此外，我们还展示了我们的方法在大型生产云系统中的成功应用。</li>
<li>此外，我们还发布了两个数据集，以促进未来的研究。</li>
</ul>
</li>
<li>这项工作的主要贡献如下：<ul>
<li>a. 我们提出了 AID，这是第一种量化不同服务之间依赖强度的方法。</li>
<li>b. 评估结果表明了所提方法的有效性和效率。</li>
<li>c. 我们发布了一个模拟数据集和一个来自生产云系统的工业数据集，以促进未来的研究。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>以往微服务划分工作中，所关注“逻辑独立性”难道不属于“判别云服务之间的依赖程度”吗？</li>
</ol>
<ul>
<li>本文的侧重点应该是动态依赖关系的预测，而传统研究更多是静态的。</li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/abs/10.1109/ASE51524.2021.9678534">[1] Tianyi Yang, Jiacheng Shen, Yuxin Su, Xiao Ling, Yongqiang Yang, and Michael R. Lyu. 2022. AID: efficient prediction of aggregated intensity of dependency in large-scale cloud systems. In Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering (ASE ‘21). IEEE Press, 653–665. https://doi.org/10.1109/ASE51524.2021.9678534<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>依赖</tag>
        <tag>预测</tag>
        <tag>数据集</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记43-前沿-可解释级联依赖感知资源管理</title>
    <url>/2024/07/02/literature/literatureNotes43/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Sinan-ML-Based-and-QoS-Aware-Resource-Management-for-Cloud-Microservices》"><a href="#x1f4d6-《Sinan-ML-Based-and-QoS-Aware-Resource-Management-for-Cloud-Microservices》" class="headerlink" title="📖《Sinan: ML-Based and QoS-Aware Resource Management for Cloud Microservices》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Sinan: ML-Based and QoS-Aware Resource Management for Cloud Microservices》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>云应用正逐渐从大型单体服务转向大量松散耦合的专用微服务。<ul>
<li>近年来，云应用已逐渐从单体服务转变为由数百个单一用途和松散耦合的微服务组成的图。这种转变正变得越来越普遍，亚马逊、Twitter、Netflix 和 eBay 等大型云提供商已经采用了这种应用模式。</li>
</ul>
</li>
<li>尽管微服务在促进开发、部署、模块化和隔离方面具有优势，但由于它们之间的依赖关系会带来反向压力效应和级联式 QoS 违规行为，因此会使资源管理变得更加复杂。<ul>
<li>尽管微服务具有模块化、灵活开发和快速迭代等优势，但它也带来了新的系统挑战，尤其是在资源管理方面。因为微服务依赖关系的<strong>复杂拓扑结构加剧了排队效应</strong>，并引入了难以及时发现和纠正的<strong>级联服务质量（QoS）违规行为</strong>。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>当前的集群管理器是为<strong>单体应用</strong>或由<strong>几个管道层组成的应用</strong>而设计的，其表现力不足以捕捉微服务的复杂性。鉴于 EBay、Netflix、Twitter 和亚马逊等越来越多的生产型云服务现在都设计成了微服务，解决它们的资源管理难题已成为当务之急。</li>
<li>我们采用数据驱动的方法来解决微服务给资源管理带来的复杂性问题。在以前的工作中，类似的机器学习（ML）驱动方法已经有效地解决了<strong>大规模系统的资源管理问题</strong>。遗憾的是，这些系统并不能直接适用于微服务，因为它们是为单体服务设计的，因此没有考虑到微服务之间的<strong>依赖关系对端到端性能的影响</strong>。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>我们介绍的 Sinan 是一款数据驱动的集群管理器，适用于交互式云微服务，具有在线和QoS感知功能。<ul>
<li>Sinan 不要求用户或云操作员推断微服务之间依赖关系的影响，而是利用一组可扩展且经过验证的机器学习模型来确定微服务之间的依赖关系对性能的影响，并以保持端到端尾部延迟目标的方式为每个层分配适当的资源。<ul>
<li>Sinan 首先使用一种高效的空间探索算法来检查可能的资源分配空间，尤其是重点关注会导致违反服务质量的角落情况。<ul>
<li>这就产生了一个用于训练两个模型的训练数据集：一个用于详细预测短期性能的卷积神经网络（CNN）模型，以及一个用于评估长期性能演变的助推树模型。</li>
<li>这两个模型的结合使 Sinan 既能检查资源分配的近期结果，又能考虑到系统在建立队列时的惯性，其准确性高于同时检查两个时间窗口的单一模型。</li>
</ul>
</li>
<li>Sinan 可在线运行，根据服务的运行状态和端到端服务质量目标动态调整每层资源。</li>
<li>最后，”Sinan”是作为一个集中式资源管理器实施的，它对集群和应用状态具有全局可见性，每个节点的资源代理可跟踪每个层的性能和资源利用率。</li>
</ul>
</li>
<li>此外，”Sinan”中的技术是可以解释的，这意味着云运营商可以从智能模型中获得如何更好地部署和设计应用程序的见解，从而降低不可预测的性能。<ul>
<li>我们展示了 Sinan 模型的可解释性优势，深入探讨了这些模型对大规模系统设计的启示。具体来说，我们以 Redis 的日志同步为例，说明 Sinan 帮助确定了数十个相互依赖的微服务中性能不可预测的根源，从而表明该系统可以为集群提供实用而有洞察力的解决方案，因为集群的规模使得以往的经验方法变得不切实际。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们使用 DeathStarBench 中的两个端到端应用对 Sinan 进行了评估，这两个应用是用交互式微服务构建的：一个社交网络和一个酒店预订网站。</li>
<li>我们将 Sinan 与传统的经验方法（如自动扩展）和之前基于队列分析的多层服务调度研究（如 PowerChief）进行了比较。</li>
<li>我们证明，无论在性能还是资源效率方面，Sinan 都优于之前的研究成果，能在不同负载模式下成功满足两个应用的 QoS 要求。<ul>
<li>在较简单的酒店预订应用中，Sinan 平均节省了 25.9%的资源，比其他满足 QoS 的方法最多节省了 46.0% 的资源。</li>
<li>在更复杂的社交网络服务中，抽象应用的复杂性更为重要， Sinan 平均可节省 59.0% 的资源，最高可节省 68.1%，基本上每秒可容纳两倍的请求量，而无需更多资源。</li>
</ul>
</li>
<li>我们还在谷歌计算引擎（GCE）上对约 100 个容器实例进行了大规模实验，验证了 Sinan 的可扩展性，并证明在本地集群上部署的模型只需稍作调整即可在 GCE 上重复使用，而无需重新训练。</li>
<li>我们的研究表明，”Sinan”总能满足服务质量要求，同时还能保持较高的集群利用率，这与之前导致性能不可预测或牺牲资源效率的工作形成了鲜明对比。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>本文对现状的介绍很简单，也不像传统结构在introduction最后部分总结创新点。但本文的实验非常充分，介绍也很详细，也许是因为这个亮点导致前面的缺点可以被忽略？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3445814.3446693">[1] Yanqi Zhang, Weizhe Hua, Zhuangzhuang Zhou, G. Edward Suh, and Christina Delimitrou. 2021. Sinan: ML-based and QoS-aware resource management for cloud microservices. In Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS ‘21). Association for Computing Machinery, New York, NY, USA, 167–181. https://doi.org/10.1145/3445814.3446693<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>可解释ML</tag>
        <tag>资源管理</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记44-前沿-影子资源利用</title>
    <url>/2024/07/03/literature/literatureNotes44/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Not-All-Resources-are-Visible-Exploiting-Fragmented-Shadow-Resources-in-Shared-State-Scheduler-Architecture》"><a href="#x1f4d6-《Not-All-Resources-are-Visible-Exploiting-Fragmented-Shadow-Resources-in-Shared-State-Scheduler-Architecture》" class="headerlink" title="📖《Not All Resources are Visible: Exploiting Fragmented Shadow Resources in Shared-State Scheduler Architecture》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Not All Resources are Visible: Exploiting Fragmented Shadow Resources in Shared-State Scheduler Architecture》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>随着云计算的快速发展，集群规模和任务并行性的不断提高对大规模调度能力提出了更高的要求。<ul>
<li>近年来，随着云计算市场的快速发展，集群规模不断扩大，有些集群包含成千上万台机器，并部署在各种云服务上，包括虚拟机、容器、微服务和功能即服务平台。此外，百万级并发提交和执行秒级甚至毫秒级任务，导致对低开销、高利用率和高可扩展性调度架构的需求不断上升。考虑到大规模调度的价值和挑战，谷歌、微软和阿里巴巴等许多 IT 公司都投入了大量资金和工程力量开发此类系统。</li>
</ul>
</li>
<li>为此，共享状态调度器架构以其高扩展性和高利用率成为大规模调度的流行解决方案。在这种架构中，中央资源状态视图会定期向分布式调度器更新全局集群状态，以便进行并行调度。<ul>
<li>鉴于单片调度架构的低可扩展性和两级调度器的低利用率，共享状态调度架构因其高可扩展性和并行调度能力，已成为大规模集群调度中广泛使用的解决方案。</li>
<li>在这种架构中，中央资源状态视图会定期向分布式调度器更新全局集群状态，调度器会并行地对接收到的任务做出分配决策。</li>
<li>基于最初的共享状态设计，主要云提供商提出并实施了各自的共享状态调度系统，以实现更低的调度延迟、更低的冲突、更高的吞吐量和更高的可扩展性。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，调度器获得更广泛资源视图的代价是间歇性的陈旧状态，使得调度器在下一次视图更新之前无法看到被释放的资源。本文将这些转瞬即逝的资源片段称为影子资源。当前的共享状态解决方案忽视或未能系统地利用影子资源，导致无法充分利用这些隐形资源。<ul>
<li>然而，硬币都有两面，共享状态架构也有其不足之处。除了通常研究的调度冲突和调度延迟问题外，周期性全局状态更新设计导致分布式调度器的状态间歇性陈旧，这在以前很少被提及和研究。<ul>
<li>被释放的资源只对中央状态视图可见，但对所有并行调度器不可见，直到下一次视图更新，这就变成了转瞬即逝的资源片段，被定义为影子资源。</li>
<li>隐藏的影子资源超出了正常调度器的调度范围，对共享状态集群造成了极大的浪费。</li>
</ul>
</li>
<li>然而，之前关于共享状态架构的研究主要集中在通过先进的调度策略和技术更有效地管理可见资源，而忽略了对不可见影子资源的挖掘和利用。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>在本文中，我们通过理论建模和大量实验对影子资源进行了深入分析。<ul>
<li>更糟糕的是，空间和时间粒度越来越轻。<ul>
<li>一方面，任务的资源需求也低于传统的资源消耗型单体应用。</li>
<li>另一方面，由于云原生技术的出现，短期任务的数量也在不断增加。</li>
<li>从图 1 中我们对来自谷歌云（Google Cloud）和阿里巴巴云（Alibaba Cloud）大规模集群的跟踪统计分析来看，任务的资源需求和执行时间近似符合指数分布，这与之前的研究结果一致。<ul>
<li>图 1 (a) 显示了谷歌云中任务的 CPU 和内存需求，每个任务的平均资源需求约为 0.5% - 1.0%。</li>
<li>图 1（b）显示了阿里云中任务的执行时间，任务的时间粒度最近变得越来越细。</li>
</ul>
</li>
<li>传统的长期批量工作负载逐渐转向对延迟敏感的短期任务。时空趋势导致资源变化更加频繁和精细，加剧了隐形资源浪费。</li>
</ul>
</li>
<li>影子资源很宝贵，但却很难利用。<ul>
<li>对实际集群中影子资源的理论和实验分析表明，影子资源的数量受视图更新间隔时间（又称更新延迟）和任务平均执行时间的影响，占集群中总体分配资源的 2%-13%，这对于提高资源利用率来说是相当可观和宝贵的。</li>
</ul>
</li>
<li>然而，有两个障碍阻碍了影子资源的利用，需要灵活透明的解决方案。<ul>
<li>首先，稍纵即逝的碎片化特性需要一种灵活的挖掘机制。</li>
<li>其次，既要利用影子资源，又要避免干扰正常调度，这一点至关重要。</li>
</ul>
</li>
<li>在这项工作中，我们认为共享状态架构需要仔细考虑影子资源。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/591292145f6d069212f307f3bf3440598257b70e/2-Figure1-1.png" alt="图1"><figcaption>图1</figcaption></figure></li>
</ul>
</li>
<li>本文首先增强了共享状态架构的可视性，以支持集群中影子资源的挖掘和利用。为此，我们提出了资源挖掘器（RMiner），它是共享状态架构的一个混合和背面兼容的调度子系统，由三个合作组件组成：<ul>
<li>(1) 影子资源管理器，用于高效检测和组织集群中的影子资源；</li>
<li>(2) RM 过滤器，用于选择合适的任务来匹配转瞬即逝的碎片；</li>
<li>(3) RM 调度器，用于以适当的方式将影子资源分配给 RM 任务。</li>
<li>此外，我们还通过利用视图更新和实际分配之间的影子资源（又称资源等待延迟），探索了更激进的资源挖掘方法。针对集群管理的不同目标，RMiner 灵活地采用了两种资源挖掘模式：SafeRM 和 SmartRM，以平衡资源利用率最大化和冲突最小化。</li>
</ul>
</li>
<li>总之，本文做出了以下贡献：<ul>
<li>a. 我们发现了共享状态调度架构中的隐形片段资源机会，并对其进行了理论和实验分析。</li>
<li>b. 我们介绍了 RMiner，这是共享状态架构的一个新颖子系统，用于提高当前设计的空间和时间可见性。RMiner 挖掘和利用不可见的影子资源，并进一步增强了管理的积极性和灵活性。</li>
<li>c. 我们构建并优化了 RMiner 的工业集群模拟器，结果表明，它能以较小的开销大幅提高集群性能。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>为了全面评估 RMiner，我们在工业集群模拟器和开源跟踪工具的基础上进行了跟踪驱动实验。</li>
<li>我们模仿现实的共享状态调度过程，并使用高保真任务执行跟踪作为输入。<ul>
<li>我们的研究表明，RMiner 的性能优于传统的共享状态调度器，资源利用率最高可达 5.8%，总体吞吐量最高可达 28%，作业等待时间最高可达 59.9%。</li>
<li>更具体地说，我们可以利用高达 112% 的影子资源，而冲突和调度开销仅增加不到 3%。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>研究现状部分忽略了<a href="/2023/07/19/literature/literatureNotes15/" title="Fuxi2.0">Fuxi2.0</a>的分区同步，这篇工作与其关联是什么？是正交的（互不干扰，互相弥补）吗？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/abs/10.1145/3620678.3624650">[1] Xinkai Wang, Hao He, Yuancheng Li, Chao Li, Xiaofeng Hou, Jing Wang, Quan Chen, Jingwen Leng, Minyi Guo, and Leibo Wang. 2023. Not All Resources are Visible: Exploiting Fragmented Shadow Resources in Shared-State Scheduler Architecture. In Proceedings of the 2023 ACM Symposium on Cloud Computing (SoCC ‘23). Association for Computing Machinery, New York, NY, USA, 109–124. https://doi.org/10.1145/3620678.3624650<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>状态共享架构</tag>
        <tag>感知</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记45-前沿-字节跳动统一调度架构Gödel</title>
    <url>/2024/07/04/literature/literatureNotes45/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Godel-Unified-Large-Scale-Resource-Management-and-Scheduling-at-ByteDance》"><a href="#x1f4d6-《Godel-Unified-Large-Scale-Resource-Management-and-Scheduling-at-ByteDance》" class="headerlink" title="📖《Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance》</h1><p>2023 年 Virginia大学、字节跳动团队 发表于 CCF-B 类云计算顶级会议 SoCC。</p>
<blockquote>
<p>系列博客：</p>
<ol>
<li><a href="/2024/07/04/literature/literatureNotes45/" title="Gödel-初步略读笔记">Gödel-初步略读笔记</a></li>
<li><a href="/2025/05/16/literature/literatureNotesIntensive4/" title="Gödel-相关工作发展脉络梳理">Gödel-相关工作发展脉络梳理</a></li>
<li><a href="/2025/05/21/literature/literatureNotesIntensive5/" title="Gödel-研究方案梳理">Gödel-研究方案梳理</a></li>
<li><a href="/2025/06/18/literature/literatureNotesIntensive6/" title="Gödel-实验梳理">Gödel-实验梳理</a>
</li>
</ol>
</blockquote>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>在过去几年中，由于业务增长迅速，ByteDance 的计算基础架构规模显著扩大。<ul>
<li>在字节跳动，为了满足豆瓣和 TikTok 等快速增长的业务需求，我们在<strong>全球范围</strong>内运营着由<strong>数十个大型集群</strong>组成的超大规模计算基础设施。此外，每天都有<strong>数以亿计的容器化任务</strong>在这些集群中提交和执行。</li>
<li>因此，如何及时调度这些任务并充分利用高弹性的底层计算资源，是我们近年来面临的一个日益严峻的挑战。</li>
</ul>
</li>
<li>我们的生产环境在数据中心拥有异构的机器和不同的工作负载，它们有着不同的<strong>资源需求</strong>和<strong>服务水平协议（SLA）</strong>。例如，<ul>
<li>1）微服务、在线推理和数据库等关键业务服务；</li>
<li>2）大量数据分析或机器学习（ML）模型训练等低优先级工作。</li>
<li>值得注意的是，这些工作负载对<strong>拓扑结构的偏好</strong>也各不相同。以我们业界领先的生态推荐系统为例，<ul>
<li>该在线推荐服务依赖于一系列预先训练好的 ML 模型，这些模型始终存储在内存中，以降低获取延迟。</li>
<li>因此，这类工作负载通常需要专门占用专用的 NUMA 节点，或者与其他非内存密集型任务共享一个 NUMA 节点。</li>
</ul>
</li>
</ul>
</li>
<li>因此，在集群中调度任务时，我们必须考虑到<strong>所有要求</strong>。遗憾的是，我们发现在现有的协调平台上，要满足所有约束条件并同时保持较高的资源利用率相当具有挑战性。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>我们对生产调度系统的主要要求是在异构机器上调度各种工作负载（如表 1 所列），提高资源利用率，跟上每个计算集群不断增长的机器规模，并实现高吞吐量。</li>
<li>使用事实上的开源调度器并不能满足我们的所有要求，例如 <ul>
<li>1）<strong>Kubernetes</strong>，它能为微服务提供灵活的资源分配/亲和性，但存在可扩展性问题；</li>
<li>2）<strong>YARN</strong>，更适合需要复杂调度语义（即 Gang 调度）的批处理作业，但缺乏对微服务的支持。</li>
</ul>
</li>
<li>学术界研究了不同的调度系统，如单体调度器、两级调度器和分散式多调度器，但每种调度系统在实现我们的生产目标方面都有不足之处。<ul>
<li>3）<strong>单体调度器</strong>面临高吞吐量的挑战，而且难以添加定制的调度策略。</li>
<li>4）<strong>两级调度器</strong>采用资源管理器在不同调度器之间划分资源，但这种悲观的锁定方式会损害资源间的资源弹性。</li>
</ul>
</li>
<li>为了满足超大规模的增长，一些业务部门采用了运行不同调度系统（如 Kubernetes、YARN）的方式来管理自己的计算基础架构堆栈，这造成了两大痛点：不同业务部门之间的资源日益分散，不同业务优先级的工作负载之间的资源弹性不足。不同业务群组之间的隔离（及其计算基础设施管理）导致计算资源利用效率低下，无法长期满足业务增长需求。<ul>
<li>5）在 ByteDance，在 Gödel 之前，我们在同一个计算集群上<strong>同时运行 Kubernetes 和 YARN</strong>，由资源管理器在它们之间调度资源。<ul>
<li>这种方法提高了我们的资源利用率，但在调度器之间转移资源会降低弹性，影响吞吐量。</li>
</ul>
</li>
<li>6）Borg、Omega 及其开源实现 Kubernetes 提出的<strong>分散式多调度器</strong>（也叫状态共享调度器）可以使用不同的调度器，每个调度器都可以访问整个计算集群，并使用乐观并发控制解决调度冲突。<ul>
<li>然而，Kubernetes 解决节点级冲突是为了防止资源超用（over-commit），这在调度周期中为时已晚，会降低吞吐量和集群规模。</li>
</ul>
</li>
</ul>
</li>
<li>从我们之前的经验和学术研究中，我们发现需要建立一个<strong>统一的调度器</strong>，它可以为不同的工作负载及其调度策略提供丰富的<strong>语义支持</strong>，可以<strong>横向扩展</strong>以满足我们的吞吐量和可扩展性需求，还可以<strong>共同定位</strong>工作负载以提高资源利用率。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/2-Table1-1.png" alt="表1"><figcaption>表1</figcaption></figure></li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了应对这些挑战，我们提出了一个名为 Gödel 的资源管理和调度系统。<ul>
<li>它为所有业务部门提供了一个统一的计算基础设施，以便在统一的资源池下运行各种工作负载。它将各种工作负载集中在每台机器上，以实现更好的资源利用率和弹性。</li>
<li>Gödel 基于 Kubernetes（事实上的开源容器编排系统）构建，但其核心调度器使用全局共享状态调度器进行了重新发明。相应地，我们还大幅增强了其周边组件。通过替换或增强重要组件，实现适应大规模的各种工作负载。</li>
</ul>
</li>
<li>本文的贡献如下：<ul>
<li>（1）我们引入了一种统一异构资源的<strong>新模式</strong>，以共同定位在线和离线工作负载，从而在超大规模上提供更好的拓扑亲和性、更高的资源弹性和更低的运营开销。</li>
<li>（2）我们在 Kubernetes 的基础上设计并实现了名为 Gödel 的新型资源管理和调度系统。我们对 Kubernetes 进行了多项优化和增强，以提高调度性能。</li>
<li>（3）我们在 ByteDance 的多个数据中心部署了 Gödel，这些数据中心拥有数万台机器，除了在模拟环境中进行密集测试外，我们还在实际工作负载下进行了评估。对 Gödel 的详细评估证明了它的实用性以及如何实现我们的目标。我们的结果表明，Gödel 在各种调度方案中都实现了卓越的性能和效率。</li>
</ul>
</li>
<li>本文报告了我们使用 Gödel 的设计和实施情况。此外，本文还讨论了我们在 ByteDance 大规模生产中开发和运行 Gödel 的经验教训和最佳实践。</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>在 Bytedance 的生产环境中构建一个新的调度程序，以适应超大规模的异构资源和工作负载，是一个极具挑战性的过程。</li>
<li>在生产中，它可以管理拥有数万台机器的集群，总体资源利用率超过 60%，调度吞吐量高达每秒 5000 个 pod。<ul>
<li>自2021年以来，Gödel已被部署到字节舞团的多个生产集群中，每个集群都有<strong>数万个节点</strong>。</li>
<li>它的性能符合预期，并表现出良好的稳定性、可扩展性和弹性。</li>
<li>我们在模拟测试平台和生产环境中对其进行了评估。评估结果表明，Gödel 在持续处理在线和离线作业方面优于 vanilla Kubernetes，同时提供了更高的调度吞吐量。<ul>
<li>具体来说，我们可以在单个 Gödel 集群上实现高达 <strong>5000 pods/second 的吞吐量</strong>，同时保持约 <strong>60% 的总体资源利用率</strong>。</li>
<li>对于内存敏感型工作负载，在 Gödel 启用的拓扑感知调度的帮助下，<strong>数据获取延迟降低了 20% 以上</strong>。</li>
<li>此外，与我们的传统部署模式相比，Gödel 可以在<strong>几分钟内（而不是几小时或几天）</strong>在关键业务服务和低优先级工作之间<strong>转移计算资源</strong>，以应对突发的流量变化，无需人工干预。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>未来还有很大的改进空间。</li>
<li>1）目前，调度器、调度程序和粘合剂所使用的过渡阶段都<strong>持久存在 ETCD</strong> 中（通过 API 服务器）。我们正在研究使用<strong>内存中缓存</strong>来处理过渡状态，预计其扩展能力将超过 ETCD，吞吐量也将提高近一倍，达到每秒 10,000 个 pod。</li>
<li>2）此外， Gödel 调度程序的设计基于乐观并发控制，<strong>降低冲突率</strong>对提高吞吐量至关重要。目前，我们观察到的冲突率平均为 1%，而在最糟糕的情况下（集群分配率超过 90%）则为 5%。我们的目标是实现 0.1% 的冲突率。</li>
<li>3）此外，我们还在努力将节点和 pod <strong>智能分配dispatching到不同的调度器</strong>，以减少冲突并更好地平衡各调度器之间的负载。</li>
<li>4）最后，我们正在积极研究并在生产中部署 Gödel <strong>重调度程序</strong>。重调度器用于监控正在运行的 pod，并采取抢占式行动来减少碎片和资源争用，从而为关键工作负载实现更高的服务质量。重调度程序中实施的一些措施包括对突发工作负载的 CPU 和内存利用率进行节流，平衡集群以实现统一的网络和功耗，以及减少高分配集群中的碎片问题。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>该场景中也提到“复杂拓扑”的困难，但它的角度是“ML工作流结构下前后任务可以利用 NUMA 架构降低传输延迟”。这和以往的工作流调度有什么区别？有什么特殊难点？</li>
<li>本文对于难点的总结似乎不够精炼。每一种调度架构的缺点之间有什么逻辑关系（乍一看很乱）？和我们以前总结的是否有不同？带来了什么独特的挑战？</li>
<li>本文攻击了“分散式架构/状态共享架构”（Borg、Omega），所谓“调度周期中为时已晚（which is too late in the scheduling cycle）”是什么意思？为什么攻击之后还是采用了“乐观并发控制调度”，与状态共享架构有什么区别？</li>
<li>“共同定位”工作负载的意思是什么？是指迁移吗？还是伸缩？还是迁移+伸缩？<ul>
<li>原文为“co-locate online and offline workloads”，因此本表述的重点在于对象为“混合作业”的统一管理，而非具体的动作——迁移或伸缩操作。</li>
</ul>
</li>
<li>根据实验判断，最终实践时每个集群内部署了一个 Gödel。对于背景中提到的“在<strong>全球范围</strong>内运营着由<strong>数十个大型集群</strong>组成的超大规模计算基础设施”，在多个集群之间的调度是怎么实现的？如果是用字节的 KubeAdmiral，那么和 Gödel 是如何兼容的？是否会存在额外的问题（例如多个集群间不均衡）？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3620678.3624663">[1] Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>统一调度</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记46-经典-两层资源结构下长期流式工作负载的调度与伸缩联合</title>
    <url>/2024/07/06/literature/literatureNotes46/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Elastic-Scheduling-for-Microservice-Applications-in-Clouds》"><a href="#x1f4d6-《Elastic-Scheduling-for-Microservice-Applications-in-Clouds》" class="headerlink" title="📖《Elastic Scheduling for Microservice Applications in Clouds》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Elastic Scheduling for Microservice Applications in Clouds》</h1><p>2021 年发表于 CCF-A 类顶级期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>微服务广泛用于灵活的软件开发。近年来，容器由于启动速度快、开销低等特点，成为微服务的首选部署技术。<ul>
<li>如今，基于云的软件开发，如SaaS（软件即服务），已经变得越来越流行，因为它提高了业务敏捷性并降低了软件维护成本。然而，业务需求的多样性和云的弹性要求软件架构具有高扩展性和快速开发。</li>
<li>与传统架构相比，微服务通过构建具有独立生命周期的服务和降低服务的粒度，缩短了开发周期，降低了固有的复杂性，提高了可扩展性。因此，微服务被广泛用于商业软件，如Netflix。</li>
<li>一般来说，部署在云中的应用需要满足性能要求，比如响应时间，同时也要尽可能降低云资源的成本。因此，任务调度和自动扩展是云中基于微服务的应用程序需要解决的关键问题。</li>
</ul>
</li>
<li>但是，容器层使云中的任务调度和自动扩展变得复杂。<ul>
<li>在微服务系统中，容器由于其快速启动和低开销而成为部署微服务实例的首选技术。然而，容器层也给自动扩展带来了新的挑战。</li>
<li>1）云提供商以虚拟机的形式提供资源，具有不同的配置，形成带有容器的两层资源结构。它需要同时在容器层和虚拟机层上进行扩展，而传统的扩展算法仅适用于单层结构（虚拟机或容器）。</li>
<li>2）由于同一虚拟机中的容器共享镜像，因此新添加的容器可以部署在托管相应镜像的虚拟机上，从而减少镜像拉取时间和容器的启动时间。</li>
<li>因此，缩放算法需要充分利用现有镜像来提升缩放性能，并且需要考虑这两个因素来缩放虚拟机，然后将实例放置在虚拟机上。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>现有算法不适应由虚拟机和容器组成的两层结构，并且经常忽略流式工作负载。在文献中，任务调度和自动伸缩有不同的方法来有效利用云中的计算资源。<ul>
<li>1）在<strong>任务调度</strong>中，应用程序被描述为一个工作流，主要主题是调度任务在多个实例上的执行以优化makespan。当实例不足以满足性能要求时，算法将使用云资源<strong>创建新实例</strong>，以实现性能和成本之间的权衡。<ul>
<li>但是，<strong>扩展规则通常很简单</strong>，无法满足更复杂的扩展要求，例如，在由容器和虚拟机 （VM） 组成的<strong>两层结构</strong>中进行扩展。</li>
</ul>
</li>
<li>2）<strong>自动伸缩</strong>通过阈值或强化学习或构建性能预测模型来建立规则，并确定满足性能标准的资源量。<ul>
<li>与任务调度相比，自动伸缩算法<strong>侧重于构建伸缩规则</strong>，但会<strong>简化或忽略任务调度</strong>。</li>
<li>事实上，不同的调度策略会导致对资源的不同需求，需要不同的扩容方案。不结合调度的扩容算法的预测结果与调度的实际资源量是有区别的。这种差异可能会因<strong>资源预配不足而导致性能下降</strong>，或者由于<strong>过度预配而导致不必要的额外成本</strong>。</li>
</ul>
</li>
<li>因此，我们积极将云中微服务弹性伸缩与任务调度相结合，在最大限度降低服务部署成本的同时，获得准确的扩容资源需求，满足业务性能要求。</li>
</ul>
</li>
<li>目前，云中的大多数调度算法都假设单一工作流执行，并根据当前工作流或预先设置的参数做出扩展决策，而忽略了<strong>流式工作负载的动态特性</strong>。<ul>
<li>在流式工作负载中，调度算法需要<strong>重复执行</strong>才能服务于<strong>连续提</strong>交的工作流，并且算法<strong>无法提前知道所有工作流的特征</strong>，例如任务的执行时间。</li>
<li>由于任务的执行时间<strong>在运行时会波动</strong>，因此调度算法在<strong>当前时刻</strong>做出的<strong>最优</strong>扩容决策，如新服务实例的配置和数量，并<strong>不能保证全局最优</strong>。</li>
<li>因此，调度算法需要做出长期优化的决策，以保证流式工作负载下的系统性能。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为此，本文提出了一种基于最常见的按需模型将任务调度与自动扩展集成在一起的 Elastic Scheduling for Microservices （ESMS）。ESMS旨在最大限度地降低虚拟机的成本，同时满足最后期限限制。具体来说，<ul>
<li>1）首先，我们将微服务的任务调度问题定义为具有截止时间约束的成本优化问题，并提出了一种<strong>基于统计的策略</strong>来确定流式工作负载下的适当<strong>容器配置</strong>。</li>
<li>2）然后，我们提出了一种基于截止时间分布和紧迫性的启发式任务调度算法，该算法在考虑容器镜像的影响的情况下，该算法可以<strong>分配任务</strong>并确定用于放大的<strong>实例的类型和数量</strong>。</li>
<li>3）最后，为了实现虚拟机和容器的两层扩展，新容器的部署问题被描述为可变大小的箱装问题（VSBPP），我们将<strong>新容器到虚拟机的映射</strong>建模为一个可变大小的 bin 打包问题，并求解它以实现虚拟机和容器的集成扩展。</li>
</ul>
</li>
<li>本文的主要贡献如下。<ul>
<li>a. 我们提出了一种集任务调度和自动伸缩于一体的微服务弹性调度算法。采用紧急调度算法获取调度方案，准确确定需要扩容的新实例。然后通过两层缩放算法获得缩放方案。</li>
<li>b. 为了提高微服务流式工作负载下的利用率，我们设计了一种基于统计信息的配置求解算法。生成的配置用于创建新容器并分配截止时间，以提高截止时间分布的准确性。</li>
<li>c. 为了解决虚拟机和容器的两层伸缩问题，我们考虑了容器镜像对任务调度中容器初始化时间的影响。将自动伸缩问题构造为VSBPP，以获得虚拟机的最优伸缩方案和容器部署，最小化虚拟机成本。</li>
<li>d. 通过对实际工作流应用的仿真实验，验证了所提出的算法在满足期限和虚拟机成本的比例上优于三种具有代表性的任务调度和自动扩展算法。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们使用真实世界的工作流程应用程序（例如蒙太奇）和维基百科访问跟踪进行基于模拟的实验。与现有算法（例如ProLiS）相比，ESMS被证明能够降低租赁成本，并获得满足最后期限限制的最高成功率。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>首先，我们计划研究如何为基于微服务的系统构建一个<strong>广义的性能模型</strong>，以准确预测不同配置的每个微服务的响应时间。</li>
<li>其次，本文重点关注云中的水平缩放。将进一步研究<strong>水平缩放和垂直缩放的结合</strong>。</li>
<li>第三，考虑到云资源的多样性，<strong>其他计费模式</strong>，如Spot，将是我们的研究方向之一。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>两层结构和一层结构的区别，带来了什么挑战？<ol>
<li>两层结构下可以通过共享镜像提高伸缩效率。</li>
<li>两层结构需要考虑长期影响（例如出于共享镜像等原因，当前虚机在未来可能会被大量容器共享，则需要多分配一些资源）。【这一点文中没说】</li>
</ol>
</li>
<li>流式工作负载带来了什么挑战？<ol>
<li>需要额外考虑时间因素，求解在未来的全局最优而非当下的全局最优。</li>
</ol>
</li>
<li>本文的现状逻辑有些复杂，现状不足的层次是什么样的？<ol>
<li>研究问题：主流两类研究分别仅考虑任务调度和自动伸缩，而未联合考虑。前者在伸缩策略上过于简单，后者在工作流感知上过于简单。（似乎前者的能力范围能够覆盖后者，没说后者的策略不适用于两层结构，如果直接把两者结合是不是就解决问题了？）</li>
<li>研究对象-请求：仅考虑一次性执行的工作流任务。没有考虑长时间优化。</li>
<li>研究对象-资源：仅考虑单层结构，没有考虑容器-虚机两层映射优化。</li>
</ol>
</li>
<li>对于每一个不足是如何解决的？<ol>
<li>二者联合考虑（好像没说明难点）</li>
<li>得看具体算法才知道如何解决第二个问题（TODO）</li>
<li>得看具体算法才知道如何解决第三个问题（TODO）</li>
</ol>
</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/abstract/document/9149819">[1] S. Wang, Z. Ding and C. Jiang, “Elastic Scheduling for Microservice Applications in Clouds,” in IEEE Transactions on Parallel and Distributed Systems, vol. 32, no. 1, pp. 98-115, 1 Jan. 2021, doi: 10.1109/TPDS.2020.3011979.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>微服务</tag>
        <tag>伸缩</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记47-经典-局部性波动感知的高度动态工作负载预测</title>
    <url>/2024/07/08/literature/literatureNotes47/</url>
    <content><![CDATA[<h1 id="x1f4d6-《FAST-A-forecasting-model-with-adaptive-sliding-window-and-time-locality-integration-for-dynamic-cloud-workloads》"><a href="#x1f4d6-《FAST-A-forecasting-model-with-adaptive-sliding-window-and-time-locality-integration-for-dynamic-cloud-workloads》" class="headerlink" title="📖《FAST: A forecasting model with adaptive sliding window and time locality integration for dynamic cloud workloads》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《FAST: A forecasting model with adaptive sliding window and time locality integration for dynamic cloud workloads》</h1><p>2022 年发表于 CCF-A 类期刊 TSC。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>工作负载预测器作为主动服务运营管理框架的关键组成部分而受到关注。但是，云应用程序的请求和资源工作负载是高度动态的。<ul>
<li>越来越多的应用和服务部署到云平台，如谷歌云、亚马逊AWS、阿里云等。为此，服务提供商和管理者需要确保以尽可能低的成本满足与用户签署的服务级别协议 （SLA） 要求。</li>
<li>然而，由于云环境的高度动态性，云服务经常表现出资源配置不足和过度配置，从而导致违反 SLA 和成本效率低下。因此，提出了主动服务运营管理技术，通过工作负载预测方法提前做出运行时决策和分配，确保服务质量（QoS）和成本效益。</li>
<li>MAPE 循环是一种用于服务运营管理的四步方法，包括监控、分析、计划和执行。<ul>
<li>监控是收集云应用的历史请求工作负载（例如，请求到达和调用）、资源工作负载（例如，CPU、内存、磁盘和网络）和 QoS 指标（例如，响应时间和吞吐量）；</li>
<li>分析是预测未来的工作负载，实时分析是否满足SLA；</li>
<li>计划是做出适当的业务运营管理决策，避免QoS下降和成本低效；</li>
<li>最后，执行是使用部署、伸缩、调度和迁移等技术实现相应的运行时操作。</li>
</ul>
</li>
<li>因此，作为 MAPE 循环中的关键步骤，工作负载预测对于确保可靠的应用程序性能和合理的资源使用至关重要。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，现有的云应用工作负载准确预测方法仍存在诸多不足。</li>
<li>现有方法将原始工作负载分解为趋势、季节性和随机部分，相应地建立模型，然后组合所有输出以生成结果。事实上，随机分量通常具有显著的异方差性和噪声，对模型精度的提高几乎没有影响，甚至有负面影响。<ul>
<li>1）高易失性的云工作负载：以时间序列形式存储的工作负载数据通常具有<strong>高度易失性</strong>，因此仅基于原始工作负载系列很难保证模型的准确性。</li>
<li>2）模型观察窗口的大小：滑动窗口的大小直接影响模型的精度。大多数现有方法使用<strong>固定大小窗口</strong>，无法适应高度动态的工作负载。</li>
<li>局部预测因子的整合策略：大多数现有方法通常采用<strong>加权平均或简单的基于误差的策略</strong>，而不关注<strong>局部预测因子随时间的变化</strong>行为差异。因此，集成模型的优势没有得到最大化。</li>
</ul>
</li>
<li>值得注意的是，具有时间序列分解的工作负载预测技术侧重于<strong>高度波动的云工作负载</strong>，流行的分解技术包括 STL、小波变换和EMD，它们通常将原始工作负载序列分解为多个组件，例如趋势、季节性和随机组件。并基于各分量分别建立预测模型，进一步组合联合预测模型。</li>
<li>然而，相关工作表明，<strong>随机分量具有显著的异方差性和噪声</strong>，对模型精度的提高影响最小，甚至为负。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>以高动态的云工作负载（如请求和资源工作负载）为研究对象，提出了一种新型的集成工作负载预测模型FAST，具有自适应滑动窗口和时间局部性集成组件。<ul>
<li>在我们的模型中，趋势和季节性成分被视为宏观工作负载变化，微观工作负载变化是通过自适应滑动窗口算法获得的。该算法考虑了趋势相关性、时间相关性和工作负载的随机波动，用于在线回归，以实现更高的精度和更低的开销；</li>
<li>对于基于误差的整合策略，提出了局部预测行为的时间局部性概念，并开发了一种用于模型集成的多类回归算法。</li>
</ul>
</li>
<li>具体贡献如下：<ul>
<li>a. 该文提出一种在线集成工作负载预测模型（FAST），该模型提出了一种新的综合思路，即学习工作负载的宏观和微观变化，从而解决了基于分解工作负载或原始工作负载的现有集成模型的精度不足问题。</li>
<li>b. 该文提出一种自适应滑动窗口方法（ASW），该方法充分考虑了不同工作负载变化与适当窗口大小的关系，包括趋势相关性、时间相关性和随机波动，以更低的时间开销提高了模型精度。</li>
<li>c. 针对基于误差的整合策略，该文提出一种考虑局部预测行为时间局部性的多类回归加权算法的时间局部性积分方法（TLI），以提高模型预测的准确性和泛化性。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>最后，我们对 Google 集群跟踪数据集进行了实验，结果表明 FAST 在动态工作负载方面比所有其他最先进的模型具有更高的准确性。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>为了进一步提高FAST在不同预测场景下的自适应能力，值得进一步研究不同多类回归算法适应更集成的预测模型的能力，最终实现<strong>多类回归算法的自动选择和构建</strong>。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>啥是高度易失性？</li>
<li>本文发现的核心问题是什么？<ul>
<li>随机分量波动性大，但也有一定局部规律。如果不感知这种规律，<strong>直接使用随机分量</strong>会导致模型学到错误的规则，<strong>不使用随机分量</strong>会导致存在误差。</li>
<li>通过滑动窗口模式，能够根据随机分量是否存在规律而动态调整被使用的随机分量时间长度。</li>
</ul>
</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/abstract/document/9729573">[1] B. Feng, Z. Ding and C. Jiang, “FAST: A Forecasting Model With Adaptive Sliding Window and Time Locality Integration for Dynamic Cloud Workloads,” in IEEE Transactions on Services Computing, vol. 16, no. 2, pp. 1184-1197, 1 March-April 2023, doi: 10.1109/TSC.2022.3156619.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>负载预测</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记48-经典-缺乏历史数据的容器共性个性特征捕捉负载预测</title>
    <url>/2024/07/09/literature/literatureNotes48/</url>
    <content><![CDATA[<h1 id="x1f4d6-《COIN-A-Container-Workload-Prediction-Model-Focusing-on-Common-and-Individual-Changes-in-Workloads》"><a href="#x1f4d6-《COIN-A-Container-Workload-Prediction-Model-Focusing-on-Common-and-Individual-Changes-in-Workloads》" class="headerlink" title="📖《COIN: A Container Workload Prediction Model Focusing on Common and Individual Changes in Workloads》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《COIN: A Container Workload Prediction Model Focusing on Common and Individual Changes in Workloads》</h1><p>2022 年发表于 CCF-A 类期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>最近，容器已成为云应用的主要部署形式。 要确保应用程序的服务质量（QoS）和成本效益，并满足与用户签订的服务水平协议（SLA），准确预测容器工作量至关重要。 <ul>
<li>如今，软件作为人们生产和生活中的必要工具，正变得越来越复杂。 对于用户来说，他们希望软件的响应速度更快、稳定性更高。 为了实现软件生产与用户体验之间的平衡，以微服务架构思想和容器化技术为核心的云原生（cloud-native）已成为主流的应用实现和部署模式。 微服务架构旨在将复杂的应用程序拆解为功能单一的服务，从而降低应用程序的耦合度。 <ul>
<li>容器是一种内核级虚拟化技术，与虚拟机相比，它不再需要管理程序的支持，因此具有更高的性能和效率。 因此，通过容器化技术实现的微服务架构能以更快的速度交付、部署、迁移和扩展应用程序，从而实现应用程序的持续集成、持续交付和持续部署。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，面对容器工作负载预测中数据不足导致的模型不可用、动态工作负载变化导致的模型不适应、工作负载模式多变导致的模型非泛化等多重挑战，现有方法尚未提供统一有效的解决方案。 <ul>
<li>云原生带来的显著优势之一是<strong>弹性</strong>，云提供商提供适当的应用运行时管理技术，如自动缩放、弹性调度、容器迁移和工作负载平衡，以确保应用行为和资源利用率。 <ul>
<li>然而，当前大多数应用运行时管理技术都是作为<strong>被动机制</strong>运行的，基于规则的触发通常会造成资源利用过度或不足，从而导致违反服务水平协议和低成本高效率。 因此，有人提出了<strong>工作负载预测技术</strong>来指导云应用的主动运行时管理。</li>
</ul>
</li>
<li>目前，有关<strong>容器工作负载预测</strong>方法的研究相对较少。 而且，在预测容器中运行的应用程序的工作负载方面，现有方法仍面临多重挑战。<ul>
<li>1）<strong>数据不足导致模型不可用</strong>（无历史经验）： 由于云中每个容器的启动和关闭时间相对较短，因此很难甚至不可能<strong>提前为预测</strong>容器收集足够的历史工作负载数据。 当预测的容器<strong>没有或只有少量历史数据</strong>时，由于需要足够的历史数据，大多数现有方法通常都无法使用。 </li>
<li>2）<strong>动态工作负载变化导致的模型适应不良</strong>（无历史经验）：由于容器工作负载是动态和流式的，新的工作负载数据可能是预测模型<strong>从未遇到过和学习过的</strong>。 现有的大多数方法都是离线生成的，无法确保模型面对动态工作负载变化时的适应性。 </li>
<li>3）<strong>工作负载模式变化导致的模型非概括性</strong>（历史经验不是一直适用）：由于云环境和服务的动态性、应用和用户请求的多样性以及云资源的弹性供应，云工作负载通常会随着时间的推移而呈现<strong>不同的模式</strong>。 没有任何一种模式适合所有云工作负载模式。 现有方法大多使用单一模型或确定性模型结构，这就很难确保模型对不同工作负载模式的通用性。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了解决上述挑战，我们提出了一种新颖的容器工作负载预测模型（COIN），它基于<strong>迁移学习和在线学习</strong>，将容器工作负载的<strong>共性（COmmon）和个性（INdividual）变化</strong>结合起来。 具体来说，<ul>
<li>1）一方面，COIN 在云中寻找与预测容器<strong>相似度最高且历史数据充足</strong>的 N 个容器，根据 N 个选定容器的工作负载数据<strong>离线训练 N 个预测模型</strong>，并将其转移到预测容器的工作负载共性变化中进行估算；具体来说，每个预测模型都由一个模型池提供，模型池可以根据每个模型的历史准确性动态选择合适的模型。<ul>
<li>此外，我们还提出了一种面向真实云场景的容器相似度计算算法，该算法结合了容器的静态和动态信息，全面刻画了容器之间的相似度。 </li>
</ul>
</li>
<li>2）另一方面，COIN 会单独建立一个<strong>在线预测模型</strong>，以估计预测容器的个别工作负载变化，增量生成方法使其能够适应动态的工作负载变化。（难点在哪？）</li>
<li>基于迁移学习和在线学习的思想，N 个针对常见工作量变化的离线预测模型和针对个别工作量变化的在线预测模型相结合，形成了最终的联合模型。 </li>
</ul>
</li>
<li>本文的主要贡献如下：<ul>
<li>a. 针对容器数据不足、工作负载动态变化和工作负载模式多变等问题，提出了一种结合容器工作负载共性和个性变化的联合容器工作负载预测模型（COIN），以确保其可用性、适应性和通用性。 此外，基于COIN和容器编排平台Kubernetes，设计并实现了一种主动式容器运行时管理系统框架。 </li>
<li>b. 提出了一种面向真实云场景的容器相似度计算算法，该算法结合容器的静态和动态信息，全面刻画了容器之间的相似度。 </li>
<li>c. 基于现有工作中的两个公开数据集，进行了一系列实验，结果表明COIN比现有的先进方法具有更好的准确性。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>通过基于两个公开数据集的实验，COIN 模型的准确率高于现有的先进解决方案，证明了我们提出的模型的有效性和鲁棒性，为容器工作量预测提供了一种新的解决方案。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>COIN算法的未来发展方向主要包括三个方面。<ul>
<li>1）首先，我们提出的模型中<strong>局部预测变量的动态权重分配</strong>只是基于近期预测误差的平方和，可以进一步探索更复杂、更鲁棒的基于误差的权重分配策略。</li>
<li>2）其次，我们提出的模型中的<strong>容器静态相似度计算指标</strong>对于容器化应用来说比较全面和<strong>通用</strong>，可能并不完全适用于所有云场景。因此，对于无服务器应用、基于虚拟机的应用等<strong>特殊云场景</strong>，需要根据应用场景和特点，进一步探索更有针对性的指标。</li>
<li>3）第三，<strong>数据噪声</strong>确实使生成预测模型变得困难。因此，如何实现数据去噪和工作负载预测的正确结合，在优化其准确性的同时，确保预测模型能够应用于真实的云环境，是一个值得研究的问题。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>本文核心难点是什么？<ol>
<li>当前容器缺乏历史数据（由于模式各异、运行时间短）。需要找到合适的历史数据作为补充。</li>
<li>历史数据通用性不强，还需要实时更新预测模型。（难在哪？）</li>
</ol>
</li>
<li>本文核心难点如何解决？<ol>
<li>刻画“相似性”，找到最合适的历史数据。</li>
<li>？</li>
</ol>
</li>
<li>实时更新预测模型的难点在于什么？如何解决的？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/abstract/document/9870561">[1] Z. Ding, B. Feng and C. Jiang, “COIN: A Container Workload Prediction Model Focusing on Common and Individual Changes in Workloads,” in IEEE Transactions on Parallel and Distributed Systems, vol. 33, no. 12, pp. 4738-4751, 1 Dec. 2022, doi: 10.1109/TPDS.2022.3202833.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>负载预测</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记5-前沿-DRL异构计算适配</title>
    <url>/2023/05/25/literature/literatureNotes5/</url>
    <content><![CDATA[<h1 id="x1f4d6-《A-Framework-for-Mapping-DRL-Algorithms-With-Prioritized-Replay-Buffer-Onto-Heterogeneous-Platforms》"><a href="#x1f4d6-《A-Framework-for-Mapping-DRL-Algorithms-With-Prioritized-Replay-Buffer-Onto-Heterogeneous-Platforms》" class="headerlink" title="📖《A Framework for Mapping DRL Algorithms With Prioritized Replay Buffer Onto Heterogeneous Platforms》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《A Framework for Mapping DRL Algorithms With Prioritized Replay Buffer Onto Heterogeneous Platforms》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>尽管深度强化学习（DRL）最近在自动驾驶汽车、机器人和监控中取得了成功，但训练DRL代理需要大量的时间和计算资源。<ul>
<li>在 RL 中，代理与环境迭代交互以改进其策略，以便最大化沿轨迹的预期累积奖励。该策略在类 RL 中表示为查找表，而在深度强化学习 （DRL） 中表示为神经网络。</li>
<li>训练DRL代理非常耗时，因为它需要通过与环境交互和梯度更新来更新表示为神经网络的策略来收敛（例如，AlphaGo）。</li>
</ul>
</li>
<li>最先进的并行DRL框架采用由并行执行者、集中式学习器和优先级经验回放池（Prioritized Replay Buffer）组成的通用架构，如图1（a）所示。<ul>
<li>并行执行者同时从环境中收集数据，并将数据插入到优先级经验回放池中。</li>
<li>集中式学习器从优先经验回放池中采样数据，并执行随机梯度下降 （SGD）以更新策略。</li>
<li>学习后的新优先级由优先级经验回放池更新。每个数据点的优先级与损失函数成正比，采样分布与优先级成正比。缓冲区中每个数据点的优先级存储在 K-ary Sum 树数据结构，可以在O(logN)时间复杂度内完成，其中N是经验回放池中的数据点总数。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/71/10123122/10093111/zhang1-3264823-small.gif" alt="图1"><figcaption>图1</figcaption></figure></li>
</ul>
</li>
<li>具有优先级经验回放池的 DRL 的计算基元包括环境仿真、神经网络推理、从优先级经验回放池采样、更新优先级经验回放池和神经网络训练。运行这些基元的速度因各种 DRL 算法（如深度 Q 网络和深度确定性策略梯度）而异。这使得 DRL 算法的固定映射效率低下。</li>
<li>由 CPU、FPGA 和 GPU 组成的异构平台有望加速DRL算法。这是因为运行关键 DRL 基元的速度在不同的 DRL 算法之间有很大差异。例如，<ul>
<li>在 FPGA 上训练小尺寸神经网络比在 CPU 和 GPU 上训练更快，而在 GPU 上训练大尺寸神经网络比在 CPU 和 FPGA 上训练更快。</li>
<li>小批量采样在 FPGA 上比在 CPU 和 GPU 上更快，而大批量采样在 GPU 上比在 CPU 和 FPGA 上更快。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>最近的一些工作集中在DRL算法的硬件加速上。<ul>
<li>之前的工作要么专注于开发没有硬件加速细节的DRL算法的并行范式，要么仅限于特定的DRL算法加速。</li>
<li>此外，现有的工作都没有有效地支持内存绑定的原语，如优先重播缓冲区。由于内存瓶颈，这会在这些现有框架实现的吞吐量与同构平台提供的峰值吞吐量之间产生性能差距。</li>
</ul>
</li>
<li>在我们之前的工作中，提出了具有优先重放缓冲区的DRL算法到CPU-FPGA异构平台的映射。当优先重放缓冲器和学习器适合FPGA的片上资源时，该设计可实现最先进的训练吞吐量。<ul>
<li>但是，它无法处理片上资源不足以满足优先重放缓冲区和学习器的情况。</li>
</ul>
</li>
<li>为了在更广泛的场景中实现最先进的训练吞吐量，在本文中，我们提出了一个框架，用于将具有优先级重放缓冲区的DRL算法映射到CPU-GPU-FPGA异构平台上，以实现给定DRL算法及其输入参数的卓越训练吞吐量。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>在这项工作中，我们提出了一个框架，用于将 DRL 算法映射到由多核 CPU、FPGA 和 GPU 组成的异构平台上。<ul>
<li>CPU 适用于复杂控制流的计算；</li>
<li>GPU 适用于大数据并行计算，</li>
<li>FPGA 适用于内存访问量大、数据依赖细粒度的计算。</li>
</ul>
</li>
<li>我们为 CPU、FPGA 和 GPU 上的每个基元提供了单独的加速器。我们提出了设计空间探索，在给定的DRL算法中选择最佳映射，从而使整体训练吞吐量最大化。此外，我们放宽了优先级更新和在优先级经验回放池中执行的采样之间的数据依赖关系，以完全隐藏 CPU、FPGA 和 GPU 之间数据传输造成的延迟，而不会牺牲使用目标 DRL 算法学习的代理获得的奖励。</li>
<li>具体而言，我们的主要贡献是：<ul>
<li>首先，我们为 CPU、FPGA 和 GPU 上的每个基元开发特定的加速器。</li>
<li>其次，我们放宽优先级更新和在优先级经验回放池中执行的采样之间的数据依赖关系。通过这样做，可以完全隐藏 CPU、FPGA 和 GPU 之间数据传输造成的延迟，而不会牺牲使用目标 DRL 算法学习的代理获得的奖励。</li>
<li>最后，给定 DRL 算法规范，我们的设计空间探索会根据分析性能模型自动选择各种基元的最佳映射。</li>
</ul>
</li>
<li>具体而言，我们的主要贡献是：<ul>
<li>在 CPU 上，我们利用 OpenMP 在优先经验回放池的采样和优先级更新中利用数据并行性。我们使用 PyTorch 进行神经网络训练。</li>
<li>在 GPU 上，我们开发了一个定制的 CUDA 内核，用于基于并行求和缩减的采样和优先级更新。我们使用 PyTorch 和 CuDNN 后端进行神经网络训练。</li>
<li>在 FPGA 上，我们开发了一个通用的面向吞吐量的学习模块，该模块利用了神经网络模型并行性和数据并行性。我们为重放管理模块 （RMM） 开发了一个通用加速器模板，该模板利用库并行性并可扩展到大批量大小。我们提议的 RMM 支持并行插入、并行采样和并行优先级更新 K-ary Sum 树。我们通过以下方式优化片上数据访问的性能：<ul>
<li>专用的可变精度定点数据格式，用于在 RMM 中存储优先级值;</li>
<li>分区支持无冲突并行数据访问的 K-ary Sum 树;</li>
<li>流水线重放操作，允许并发访问存储 K-ary Sum 树。</li>
</ul>
</li>
<li>为了隐藏用于训练的异构加速器之间的数据传输导致的延迟，我们放宽了优先级更新和优先级经验回放池中采样之间的数据依赖关系。我们凭经验表明，在广泛使用的基准环境中，具有和不具有数据依赖性的DRL算法之间经过训练的代理的性能差异可以忽略不计。</li>
<li>我们提出了一种设计空间探索和设计自动化工作流程，该工作流程在给定任意DRL算法的情况下，以最佳方式选择每个组件到 CPU-GPU-FPGA 异构系统上的映射。</li>
<li>对于广泛使用的DRL算法，包括 DQN 和 DDPG，与基线映射相比，我们的框架生成的映射在训练吞吐量方面表现出高达997.3×的加速。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>在广泛使用的基准环境中，我们的实验结果表明，与同一异构平台上的基线映射相比，训练吞吐量提高了 997.3×。与最先进的分布式强化学习框架RLlib相比，我们实现了 1.06x~ 训练吞吐量提高 1005×。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><h3 id="1-什么是优先级经验回放池？"><a href="#1-什么是优先级经验回放池？" class="headerlink" title="1. 什么是优先级经验回放池？"></a>1. 什么是优先级经验回放池？</h3><ul>
<li>当我们使用Q-learning算法进行在线方式学习时，会存在两个问题<a href="#refer-anchor-2"><sup>[2]</sup></a>：<ul>
<li>1.交互得到的样本序列存在一定相关性（在线学习场景下往往刚得到一个样本就将其用于训练）。而机器学习模型对训练样本的假设是独立、同分布的，上述场景下的样本序列打破了这种独立同分布特性，因此效果不佳。</li>
<li>2.交互样本使用的效率过低。因为每次要使用一定的时间获取一个batch的样本才能完成一次训练，所以对样本的获取是有些慢的，且在线学习场景下往往会将学习后的样本直接丢弃，导致利用效率不高。</li>
</ul>
</li>
<li>因此提出经验回放池结构：用一块有限大小的内存来存储智能体一段时间内和环境交互得<br>到的经验（ <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="14.223ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 6286.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(1196.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1640.9,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(562,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(2508.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(2952.9,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(3742.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(4186.8,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(502,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5897.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container> 元组），每次神经网络需要输入时，会从经验回放池中随机选择一个大小为 minibatch 的经验样本。但是，由于使用随机选择方法，有价值的经验和一般的经验会被以同样的频率回放，可能导致学习效率有限，因此最新研究提出使用基于优先级的经验回放机制。<a href="#refer-anchor-3"><sup>[3]</sup></a>。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://img-blog.csdnimg.cn/2019060510082610.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21hcXVuZmk=,size_16,color_FFFFFF,t_70" alt="经验回放池示意图"><figcaption>经验回放池示意图</figcaption></figure></li>
</ul>
<h3 id="2-FPGA是如何使用的？先自行编码成固定的逻辑，再作为通用组件使用？"><a href="#2-FPGA是如何使用的？先自行编码成固定的逻辑，再作为通用组件使用？" class="headerlink" title="2. FPGA是如何使用的？先自行编码成固定的逻辑，再作为通用组件使用？"></a>2. FPGA是如何使用的？先自行编码成固定的逻辑，再作为通用组件使用？</h3><h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10093111">[1] C. Zhang, Y. Meng and V. Prasanna, “A Framework for Mapping DRL Algorithms With Prioritized Replay Buffer Onto Heterogeneous Platforms,” in IEEE Transactions on Parallel and Distributed Systems, vol. 34, no. 6, pp. 1816-1829, June 2023, doi: 10.1109/TPDS.2023.3264823.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link" href="https://blog.csdn.net/maqunfi/article/details/90897587">[2] 强化学习模型-Priority Replay Buffer<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link" href="https://cardwing.github.io/files/131270027-%E4%BE%AF%E8%B7%83%E5%8D%97-%E9%99%88%E6%98%A5%E6%9E%97.pdf">[3] 侯跃南, “深度强化学习中基于优先级的经验回放机制研究,” 南京大学本科毕业论文, 2017<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>异构计算</category>
      </categories>
      <tags>
        <tag>DRL</tag>
        <tag>异构计算</tag>
        <tag>经验回放池</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记49-前沿-异构感知的资源配置、调度、伸缩联合</title>
    <url>/2024/07/10/literature/literatureNotes49/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Heterogeneity-aware-Proactive-Elastic-Resource-Allocation-for-Serverless-Applications》"><a href="#x1f4d6-《Heterogeneity-aware-Proactive-Elastic-Resource-Allocation-for-Serverless-Applications》" class="headerlink" title="📖《Heterogeneity-aware Proactive Elastic Resource Allocation for Serverless Applications》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Heterogeneity-aware Proactive Elastic Resource Allocation for Serverless Applications》</h1><p>2024 年发表于 CCF-A 类期刊 TSC。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>无服务器计算是一种流行的云计算模式，它提供按需分配资源和”即用即付”的应用执行方式。<ul>
<li>无服务器计算通过实现弹性扩展、按需配置和经济高效的执行，简化了工作流应用程序的管理。开发人员可以专注于业务开发，而云服务提供商（CSP）则负责处理创建、部署和扩展等任务。这使得无服务器计算成为实施复杂工作流的一个极具吸引力的选择。</li>
</ul>
</li>
<li>相关工作评估了无服务器计算为复杂工作流带来的成本效益。然而，应用和服务器正变得<strong>越来越异构</strong>，工作负载模式也更加多变，<ul>
<li><strong>应用</strong>复杂性包括业务拓扑、功能数量、功能和非功能属性，</li>
<li><strong>服务器</strong>复杂性包括服务器软硬件类型和物理架构；</li>
<li><strong>工作负载模式</strong>复杂性包括请求到达、变化趋势和变化幅度。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>因此，如何分配异构工作流是 CSP 面临的一项重大挑战，CSP 可能会以次优方式为应用程序分配资源，从而违反服务质量 (QoS) 目标（如响应时间和成本预算），并产生额外的基础设施成本。需要解决现有问题：<ul>
<li><ol>
<li><strong>资源配置估算不准确、效率低</strong>：<strong>大多数方法</strong>使用实验室测试、简单统计、人工经验或详尽搜索来<strong>估算资源配置</strong>。这些方法忽略了运行时日志，导致动态和异构场景中的供需不匹配。<strong>少数方法</strong>使用历史或现场日志，面对同质服务器或应用程序。这些方法假设有足够的日志可用，但无法确保模型的可用性。此外，现场日志收集效率较低，导致初始化时间过长。</li>
</ol>
</li>
<li><ol start="2">
<li><strong>功能间的高延迟间接通信方式</strong>：当今的服务器采用非统一内存访问架构（NUMA），但<strong>通信时间往往被忽视</strong>，尽管它对数据密集型应用非常重要。有些方法通过<strong>考虑功能间通信</strong>来优化工作流执行时间。不过，这些方法只采用外部存储作为通信介质，或者缺乏介质按需选择。</li>
</ol>
</li>
<li><ol start="3">
<li><strong>被动扩展服务器导致资源就绪时间过长</strong>：CSP 可根据应用需求扩展服务器，以优化资源成本、能源和资源就绪时间。大多数方法假设服务器持续激活或<strong>被动扩展</strong>。少数方法采用基于回归的方法（如 ARIMA 和 LSTM）来估计请求到达数，这些方法使用连续值，无法捕捉<strong>特定时段内的突然变化</strong>。而高度波动的请求到达数很容易造成高估或低估的问题。</li>
</ol>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>因此，我们提出了异构感知的主动无服务器工作流弹性分配方法（PLOEA）来解决这些问题，从<strong>配置估计</strong>到<strong>实例分配</strong>再到<strong>服务器扩展</strong>，在满足开发者个性化需求的同时降低了 CSP 的基础设施成本，并保持了无服务器计算中的透明管理。具体来说，<ul>
<li>我们为异构工作流应用提出了一种<strong>资源配置估算</strong>方法，该方法建立了一个集合多任务专家分类器，用于分析个性化和共性资源需求模式，确保估算的准确性和效率。</li>
<li>此外，我们还为多个应用提出了<strong>分组分配</strong>策略，通过考虑分配的紧迫性、功能之间的通信亲和性以及服务器的多核架构，优化实例的时空分布。</li>
<li>此外，我们还提出了一种<strong>主动式服务器弹性扩展</strong>方法，该方法可感知工作负载特征，包括工作负载水平、趋势和幅度变化，并将其与 CSP 的注意力差异相结合，以指导服务器扩展规模。</li>
</ul>
</li>
<li>主要贡献如下<ul>
<li>1）我们提出了一种<strong>工作流资源配置估算</strong>方法，利用随机森林构建多任务专家分类器，并行识别服务器类型与资源容量之间的双目标耦合关系，避免了大量搜索，并集成了分类器分析单个和多源共性资源需求模式，避免了对部分日志的敏感性。</li>
<li>2）我们提出了一种<strong>时空联合实例分配</strong>算法，该算法考虑了功能分配紧迫性、功能间通信亲和性和服务器 NUMA 架构。它通过启发式排序、分组、检查和分配具有三种通信介质的实例，优化了开发人员满意度和 CSP 成本。</li>
<li>3）我们提出了一种<strong>前瞻性服务器弹性扩展</strong>方法，该方法采用融合 GRU 模型，利用工作负载水平、趋势和振幅特征预测工作负载模式。该方法动态分配注意力权重以指导缩放大小，解决了对可变工作负载模式不敏感的问题。</li>
<li>4）通过一系列实验，证明了 PLOEA 在预测精度、平均满意度、服务器租用成本和运行开销方面的优势。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>最后，基于公共数据集的实验证明，与现有方法相比，PLOEA 能提供更好的服务质量和成本效益。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>未来，我们计划开发一个<strong>无服务器编排系统</strong>，实现对 Docker 实例或 WebAssembly 实例之间的三种通信介质的支持，以实现我们的 PLOEA 方法的应用。</li>
<li>此外，我们还计划研究funcion实例的<strong>动态迁移</strong>，以避免面临更多动态云环境的实例在运行时出现资源竞争和资源短缺。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>serverless场景的特点是什么？</li>
</ol>
<ul>
<li>更异构：应用、服务器、工作负载模式三个方面。</li>
</ul>
<ol start="2">
<li>三个现状不足之间的关系是什么？</li>
</ol>
<ul>
<li>时间顺序：先设定所需资源量，再调度资源位置，最后动态伸缩。</li>
</ul>
<ol start="3">
<li>核心难点是什么？似乎不够亮？</li>
<li>调度与伸缩是否冲突？还是说是长期的请求？三者联合是否存在额外难点？</li>
<li>也许一篇好论文亮点不止在于“发现新问题”，也在于“巧妙地解决问题”，不过从这篇文章的引言似乎还看不出来解法的巧妙性，还需要进一步精读。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10382635">[1] B. Feng, Z. Ding, X. Zhou and C. Jiang, “Heterogeneity-aware Proactive Elastic Resource Allocation for Serverless Applications,” in IEEE Transactions on Services Computing, doi: 10.1109/TSC.2024.3350711.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>伸缩</tag>
        <tag>资源配置</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记52-前沿-多种运行时动态调整</title>
    <url>/2024/07/12/literature/literatureNotes52/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Adaptive-Selecting-Algorithm-for-Runtime-Types-of-Microservices》"><a href="#x1f4d6-《Adaptive-Selecting-Algorithm-for-Runtime-Types-of-Microservices》" class="headerlink" title="📖《Adaptive Selecting Algorithm for Runtime Types of Microservices》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Adaptive Selecting Algorithm for Runtime Types of Microservices》</h1><p>2024 年发表于 CCF-B 类会议 ICWS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>近年来，无服务器计算在微服务领域越来越受欢迎。与有服务器计算相比，无服务器计算因其资源弹性和按需分配的特点，大大减少了开发人员的开支。<ul>
<li>无服务器计算最近得到了快速发展，它使开发人员能够专注于编码和部署应用程序，而无需管理底层服务器基础设施。这种计算模式在微服务领域获得了广泛的应用和认可。</li>
<li>然而，无服务器计算存在冷启动时间长、函数调用延迟高等问题，导致服务性能不尽如人意。</li>
</ul>
</li>
<li>在当今的云环境中，由于用户行为的动态性和微服务的复杂性，微服务的工作负载表现出明显的波动性，使其变得错综复杂和不稳定。此外，微服务具有多样性，<strong>对资源的需求和执行时间各不相同</strong>。在<strong>单一运行时类型</strong>下，微服务只能实现次优的服务质量和成本效益。<ul>
<li>根据部署方式和运行环境，微服务可分为以下两种运行时类型。<ul>
<li>1）<strong>服务器式</strong>：服务器式是指在预先配置好的服务器环境中部署微服务。在这种计算模式下，微服务通常会在服务器启动时加载并保持运行，以便<strong>及时响应请求</strong>。当微服务需要处理连续请求并需要长期执行，从而确保更高的稳定性时，服务器式计算就非常适合。这种部署模式虽然能快速响应调用，但也会导致资<strong>源闲置时间延长</strong>，造成严重的资源浪费。</li>
<li>2）<strong>无服务器式</strong>：无服务器式是一种新颖的云计算服务模式。无服务器平台根据请求的工作量动态分配资源。处理完请求后，平台通常会释放运行时资源，以优<strong>化资源利用率</strong>。无服务器运行时通常更适合处理离散的工作负载模式。然而，与有服务器计算相比，无服务器计算存在一些缺点，例如<strong>冷启动时间较长、服务性能较差</strong>等。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>由于工作负载是动态的，微服务会随着时间的推移对不同的运行时类型表现出不同的需求，而现有方法却忽略了这一点。<ul>
<li>现有研究大多<strong>侧重于在单一运行时类型</strong>中部署微服务，而没有充分利用两种类型的优势。</li>
<li>有些研究考虑<strong>采用两种类型</strong>，但忽略了微服务运行时环境的可变性。因此，它们无法及时适应不同的运行时环境，也无法自动切换和调度微服务的运行时类型。</li>
<li>此外，现有研究中的算法大多对工作负载模式进行了简单化的表述，缺乏对微服务中<strong>流式和离散工作负载模式</strong>的显著特点的考虑。这导致部署和调度策略的灵活性和适应性不足。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>因此，我们提出了微服务运行时类型自适应选择算法，该算法可优化云服务提供商（CSP）的资源使用，确保开发人员的应用程序高效执行。<ul>
<li>具体来说，该算法通过分析微服务的工作负载模式、资源需求和执行效率，将微服务动态切换到最佳运行时类型。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们在真实集群上进行了实验，证明该算法能提高微服务的服务质量，同时改善其成本效率。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>在未来的研究中，我们希望在更广泛的场景中验证所提出的自适应选择算法的切换效果，以促进其在实际微服务中的应用。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>这篇研究的核心关注点是什么？</li>
</ol>
<ul>
<li>Serverful和Serverless运行时模式各有优缺点，应当互相弥补。（静态选择）</li>
<li>工作负载在不同时间的需求不同，因此还需要动态调整运行时模式。（动态选择）<ul>
<li>需要将工作负载模式分类，从而确定哪种模式下适合哪种运行时模式。（本文中分为流式工作负载模式、离散工作负载模式）</li>
</ul>
</li>
<li>但如何选择恰当的模式是一个问题。</li>
</ul>
<ol start="2">
<li>本文只是短论文，但所关注的问题非常有意思，期待未来的长文工作介绍具体细节。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a href="">[1] Adaptive Selecting Algorithm for Runtime Types of Microservices</a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>serverless</tag>
        <tag>运行时</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记53-前沿-实时任务边缘各类设备组网</title>
    <url>/2024/07/16/literature/literatureNotes53/</url>
    <content><![CDATA[<h1 id="x1f4d6-《RIDIC-Real-Time-Intelligent-Transportation-System-With-Dispersed-Computing》"><a href="#x1f4d6-《RIDIC-Real-Time-Intelligent-Transportation-System-With-Dispersed-Computing》" class="headerlink" title="📖《RIDIC: Real-Time Intelligent Transportation System With Dispersed Computing》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《RIDIC: Real-Time Intelligent Transportation System With Dispersed Computing》</h1><p>2024 年发表于 CCF-B 类期刊 IEEE Transactions on Intelligent Transportation Systems。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>现代交通大数据具有高容量、高速度、高多样性等特点，开发用于数据分析的智能交通系统越来越具有挑战性。<ul>
<li>现代交通行业的快速发展使得构建智能交通系统来分析海量交通数据并基于分析做出适当的决策变得越来越具有挑战性。基于交通数据的分析有利于驾驶员和行人，因为智能系统可以做出更准确和个性化的时间表，并提高交通管理部门的效率。</li>
<li>交通数据具有以下特点：高流量、高速度、多样化。<ul>
<li><strong>高流量</strong>：由于各种数据源包括智能汽车和摄像头、路边摄像头等，生成的交通数据对智能系统<strong>准确及时</strong>地处理这些数据提出了挑战。</li>
<li><strong>高速度</strong>：由于车辆和行人的移动速度很高，因此处理速度也很高。</li>
<li><strong>多样化</strong>：虽然我们可以组织一个集群来处理海量工作负载，但这些对象的多样性使集群不稳定，增加了为本地集群提供计算能力的难度。</li>
</ul>
</li>
<li>因此，通过探索智能设备的计算能力，构建智能交通系统，推动交通管理边界成为当务之急。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>当前的交通系统求助于云计算来部署其应用程序。<ul>
<li>云计算的蓬勃发展和广泛应用，为交通数据处理系统的设计提供了更多重要的机遇和可能性。主流云计算以平台即服务（PaaS）为特色，在中央服务器上部署系统和软件，并向外部提供服务。大量的交通数据被传输到数据中心进行进一步分析，如驾驶员违规检测和事故警告和处理。<ul>
<li>传统的<strong>云计算</strong>将数据传输到中央服务器进行处理，给它们带来了巨大的压力。</li>
<li><strong>边缘计算</strong>将计算卸载到边缘服务器进行处理，减少数据传输时间和中央服务器的计算压力。边缘计算在智能交通系统的多个方面都发挥了重要作用，例如交通流量预测、视频分割、交通信号控制和深度学习辅助处理。</li>
<li><strong>雾计算</strong>是云计算的一种新范式，它将计算需求调度到更靠近数据源的不同分布式计算中心。它还旨在促进智能交通系统的发展，例如，改进交通数据分析和检测，控制道路上的交通信号灯。</li>
</ul>
</li>
</ul>
</li>
<li>然而，目前主流的云计算框架仍未很好地解决智能交通系统中的两大挑战，缺乏实时处理和智能路边设备利用不足。<ul>
<li>第一个挑战是缺乏对交通大数据的<strong>实时处理能力</strong>。<ul>
<li>无论是边缘计算还是雾计算，数据源都需要将生成的数据传输到数据中心，这使得数据中心的处理压力更加强烈，<strong>数据传输时间</strong>不容忽视。</li>
<li>然而，由于交通是一个瞬息万变的场景，高时延处理方法无法灵活地对交通数据进行分析和决策。</li>
<li>因此，现代智能交通处理系统考虑如何为大数据提供足够的短距离算力，以降低传输时延，提高灵敏度。</li>
</ul>
</li>
<li>第二个挑战是<strong>各种可用</strong>的路边智能设备<strong>利用不足</strong>。<ul>
<li>随着路边设备功能的提升，许多设备不再局限于数据感知和传输，还可以进行数据分析和决策。例如，<ul>
<li>基于FPGA的<strong>智能相机</strong>用于实时视频分析和神经计算。</li>
<li>未来的<strong>智能汽车</strong>可以使用深度学习模型执行车辆检测算法。</li>
</ul>
</li>
<li>现有的智能系统很少关注它们加速工作负载执行的潜力。</li>
</ul>
</li>
</ul>
</li>
<li>我们观察到，分散计算（一种新兴的云计算范式）非常适合现代交通系统的要求。它通过缓解数据源和云服务器之间的数据传输来提供实时响应，并通过探索智能设备的计算能力来充分利用智能设备。<ul>
<li>幸运的是，我们发现<strong>分散计算</strong>是云计算的新概念，可以解决智能交通系统在诉诸云计算时面临的挑战。</li>
<li>分散计算是云计算的一种新范式，它<strong>将所有具有计算能力的网络节点组合成一个有机体</strong>。分散计算的核心是<strong>“一劳永逸，一劳永逸”</strong>，集群中的每个设备都可以是服务客户或提供商。</li>
<li>分散计算可以从两个方面解决当前智能交通系统的挑战。<ul>
<li>它首先解决了<strong>通信瓶颈</strong>，因为所有计算设备在地理上都是封闭的，从而减轻了数据源和远程云服务器之间繁琐的数据传输。</li>
<li>此外，分散计算可以提高路上<strong>异构设备的资源利用率</strong>。通过利用闲置的路边资源，分散计算可以节省成本，提高任务执行效率。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>因此，我们设计了RIDIC，一种具有分散计算的实时智能交通系统，以推动智能交通系统的前沿。RIDIC遵循分散计算的设计理念。<ul>
<li>通过充分利用路边设备的算力，RIDIC形成<strong>局部分散的计算集群</strong>，提升智能交通系统的整体效率。</li>
<li>RIDIC 为智能设备加入集群提供了三个阶段：Actor 注册、资源应用和任务执行。<ul>
<li>智能设备首先向地理位置封闭的主设备发送<strong>注册</strong>请求，主设备通过检测心跳确认其可用性。</li>
<li>如果任务需要额外的计算能力来帮助完成任务，则主节点会从虚拟化设备池中<strong>选择可用设备</strong>，并将连接信息返回给请求。</li>
<li>最后，在执行阶段，根据不同的任务需求，<strong>将任务分割并分发</strong>到具有不同计算能力的不同可用异构设备执行。</li>
</ul>
</li>
</ul>
</li>
<li>我们的贡献如下：<ul>
<li>1）我们分析了现有的智能交通系统构建方法，并<strong>确定了两个挑战</strong>——缺乏实时响应和路边智能设备利用不足，而主流云计算技术无法很好地解决这些问题。</li>
<li>2）我们介绍了RIDIC，这是一种具有分散计算的智能交通系统，可提高交通场景下的工作负载执行效率。据我们所知，RIDIC是<strong>第一个通过分散计算优化的运输系统</strong>。</li>
<li>3）我们在道路车辆检测和交通信号识别两个真实道路场景中对RIDIC进行了评估，证明了RIDIC在提高系统吞吐量和减少完成延迟方面的有效性。RIDIC可以显著减少单元任务的执行时间，减少对计算资源的设备要求。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们在两个经典的路边场景上进行了实验——道路车辆检测和交通信号识别。<ul>
<li>道路车辆检测结果表明，RIDIC通过利用边缘设备构建分散计算集群，可以实现更快的计算速度，这意味着<strong>更好的实时性能</strong>。</li>
<li>交通信号识别结果表明，RIDIC可以通过将任务分散到边缘设备来降低对设备计算性能的需求，从而<strong>最大限度地利用设备的计算资源</strong>。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>交通场景和一般大数据场景有什么区别？如果考虑移动性，会有什么额外挑战？</li>
<li>分散计算和“边缘计算”、“雾计算”有什么区别？是广义上相同，狭义上有细分差异？</li>
<li>如果所定位的现有研究两大挑战都被“分散计算”解决了，那应该如何定位本文的创新点？以前没有细致地设计且没有实现真实系统？执行了的实验非常丰富，确定了现状不足？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10225426">[1] Z. Cai, Z. Chen, Z. Liu, Q. Xie, R. Ma and H. Guan, “RIDIC: Real-Time Intelligent Transportation System With Dispersed Computing,” in IEEE Transactions on Intelligent Transportation Systems, vol. 25, no. 1, pp. 1013-1022, Jan. 2024, doi: 10.1109/TITS.2023.3303877.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>边缘计算</category>
      </categories>
      <tags>
        <tag>边缘计算</tag>
        <tag>人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记54-前沿-硬件辅助AI训练框架</title>
    <url>/2024/07/19/literature/literatureNotes54/</url>
    <content><![CDATA[<h1 id="x1f4d6-《GUARDIAN-A-Hardware-Assisted-Distributed-Framework-to-Enhance-Deep-Learning-Security》"><a href="#x1f4d6-《GUARDIAN-A-Hardware-Assisted-Distributed-Framework-to-Enhance-Deep-Learning-Security》" class="headerlink" title="📖《GUARDIAN: A Hardware-Assisted Distributed Framework to Enhance Deep Learning Security》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《GUARDIAN: A Hardware-Assisted Distributed Framework to Enhance Deep Learning Security》</h1><p>2024 年发表于 CCF-C 类期刊  IEEE Transactions on Computational Social Systems。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>人工智能（AI）的无处不在，使其在计算机视觉、自然语言处理、医学图像分析等各个领域得到了广泛的研究和应用。<ul>
<li>在过去的几十年里，以机器学习为代表的人工智能（AI）研究如火如荼地进行，对各行各业产生了深远的影响。在计算机视觉领域，它广泛应用于图像分类、图像合成、目标检测和跟踪。在自然语言处理中，机器学习可以在情感分析、文本合成和机器翻译中发挥作用。此外，这些主要领域的进展也促进了机器学习在其他领域的部署和应用。例如，将无监督学习应用于辅助治疗的医学图像分类，将分布式机器学习应用于智能交通系统处理多媒体计算任务。因此，人工智能的蓬勃发展极大地方便了我们的生活，为我们的日常活动提供了便利和好处。</li>
</ul>
</li>
<li>然而，可靠的（responsible）人工智能面临着严峻的挑战，最突出的问题是传统开发范式带来的机器学习安全性，包括<strong>有价值的训练数据的泄漏</strong>和<strong>机器学习模型知识产权</strong>。<ul>
<li>首先，<strong>用户的数据</strong>隐私面临威胁，因为传统的机器学习模式需要收集大量的训练数据和预处理，然后才能通过迭代训练来优化模型权重。<ul>
<li>然而，这种模式假设数据提供者不关心他们的隐私问题，这在现实生活中往往不是这样。有些数据通常具有商业价值；例如，财务数据通常包含信息，例如商业公司的商业模式和发展战略。其他的可能受到伦理和道德限制，例如包含患者私人信息的医学图像，其披露会引起公众的广泛质疑。</li>
</ul>
</li>
<li>其次，<strong>机器学习模型通常具有知识产权的价值</strong>，因此模型持有者应对模型结构和权重数据保密。<ul>
<li>因此，机器学习从业者必须仔细检查他们的私有数据和模型权重，然后才能将应用程序用于安全保证的广泛使用。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>现有的解决方案采用新的算法设计（如联邦学习）或密码学（如同态加密）来防止可能出现的安全漏洞。<ul>
<li>在机器学习过程中，已经提出了保护用户隐私数据和模型权重的工作。从算法的角度来看，这些方法通常会改进机器学习模式。<ul>
<li>联邦学习是一种典型的方法，它允许分布式训练的参与者在不共享数据的情况下共同训练和优化全局模型，打破了私有数据的孤岛问题。<ul>
<li>然而，联邦学习<strong>面临着许多安全问题</strong>，例如成员攻击和拜占庭攻击，这些问题需要特定的算法来解决。</li>
</ul>
</li>
<li>同态加密是一种可以保护数据和模型安全性的加密方案。它允许对密文进行加法和乘法运算的结果与解密后的明文结果相同。<ul>
<li>虽然同态加密可以提供更高的安全保障，但加密和解密步骤需要<strong>大量的计算能力</strong>。它还<strong>不支持</strong>深度学习中的<strong>标准非线性计算</strong>，例如 ReLU 和其他激活函数。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>我们观察到，硬件辅助的可信执行环境 （TEE） 可以进一步提高机器学习的可靠性。英特尔软件卫士扩展 （SGX） 是一种流行的、受信任的执行硬件，它使用户的程序能够在不受信任的执行环境（如恶意操作系统）中运行，但可确保数据的机密性和完整性。<ul>
<li>近年来，<strong>基于硬件辅助方法</strong>的安全计算逐渐引起了研究人员和工程师的广泛关注。</li>
<li>可信执行环境 （TEE） 为用户提供可信计算空间，即使在不受信任的操作系统和恶意外部环境中也是如此。</li>
<li>英特尔软件防护扩展（SGX）的 TEE 由特定的英特尔硬件保证。英特尔 SGX 中应用的代码和数据分为 TEE（飞地 enclave）和具有特定硬件保护的不受信任的执行环境。机器学习用户可以将用户的私有数据或模型权重上传到飞地进行存储或计算，以确保机器学习全生命周期数据的安全性和完整性。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>因此，我们提出了 GUARDIAN，这是一个分布式机器学习训练环境，它通过硬件保护机制优先考虑安全性和可靠性，可<strong>在训练过程中保护数据安全</strong>。<ul>
<li>GUARDIAN的工作流程可以概括为三个主要步骤。<ul>
<li>首先，机器学习从业者使用传统的训练技术<strong>开发模型结构并初始化模型权重</strong>。</li>
<li>其次，为了确保对用户模型和代码的影响最小，研究人员引入了Gramine作为SGX LibOS，以简化开发过程。因此，建立Gramine所需的<strong>必要配置文件</strong>以<strong>支持TEE中的分布式训练过程</strong>至关重要。</li>
<li>最后，鉴于英特尔 SGX 的 enclave 大小有限以及 TEE 中相关的执行性能下降，GUARDIAN 采用了<strong>数据并行性来加快模型训练速度</strong>。</li>
</ul>
</li>
</ul>
</li>
<li>与<strong>基于算法</strong>的安全机器学习技术相比，GUARDIAN具有显著的特点。<ul>
<li>首先，与需要算法优化的联邦学习或涉及加密和解密数据或模型的基于同态加密的算法不同，GUARDIAN 的<strong>安全机制依赖于特定的硬件</strong>。它不需要对用户的代码或模型进行任何修改，因此非常方便。</li>
<li>其次，通过细致的实验，研究了基于硬件保护的机器学习训练在实际部署中的问题。该检查表明，尽管 SGX 内部模型训练涉及更长的作业完成时间 （JCT），但数据并行性可以加快该过程。</li>
<li>此外，我们观察到，虽然异步通信减少了训练时间，但它可能导致模型准确性下降。因此，GUARDIAN的独特属性为机器学习训练提供了安全可靠的解决方案。</li>
</ul>
</li>
<li>我们的贡献如下：<ul>
<li>1）我们<strong>设计了</strong> GUARDIAN，这是一个基于硬件辅助机器学习训练的安全计算框架。GUARDIAN在不修改代码或模型的基础上提供原生安全支持，以保护用户数据和模型不泄露并造成经济损失。</li>
<li>2）我们通过大量的实验，<strong>全面分析了</strong>新交所的机器学习训练性能。我们的分析包括SGX应用执行时间的延长、SGX参数对任务完成时间的影响，以及通信模式对机器学习训练任务的影响。</li>
<li>3）我们提供了 GUARDIAN 的<a class="link" href="https://github.com/ZinuoCai/GUARDIAN.git">代码<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>，该代码为 TEE 中分布式机器学习训练的后续优化提供了基础。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>通过我们广泛的实验验证了 GUARDIAN 功能的有效性，突出了其在实际部署中的功效。我们的研究结果表明，引入安全保证会导致性能下降，这在不久的将来提供了一个可行的优化方向。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>第二个安全问题“模型的知识产权”问题如何解决的？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10093889">[1] Z. Cai, B. Ren, R. Ma, H. Guan, M. Tian and Y. Wang, “GUARDIAN: A Hardware-Assisted Distributed Framework to Enhance Deep Learning Security,” in IEEE Transactions on Computational Social Systems, vol. 10, no. 6, pp. 3012-3020, Dec. 2023, doi: 10.1109/TCSS.2023.3262289.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>AI</category>
      </categories>
      <tags>
        <tag>人工智能训练</tag>
        <tag>可信计算</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记51-前沿-主动式动态集成服务管理</title>
    <url>/2024/07/11/literature/literatureNotes51/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Proactive-Elastic-Scheduling-for-Serverless-Ensemble-Inference-Services》"><a href="#x1f4d6-《Proactive-Elastic-Scheduling-for-Serverless-Ensemble-Inference-Services》" class="headerlink" title="📖《Proactive Elastic Scheduling for Serverless Ensemble Inference Services》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Proactive Elastic Scheduling for Serverless Ensemble Inference Services》</h1><p>2024 年发表于 CCF-B 类会议 ICWS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>人工智能推理服务采用了集成（ensemble）架构，其先进的性能得到了广泛认可和使用。<ul>
<li>当前，机器学习和人工智能的迭代和发展为解决各行各业的复杂问题创造了新的可能性，从而推动了各行各业的创新。</li>
<li>推理服务是指部署在服务器或云环境中的机器学习模型，这些模型接收来自客户端的实时请求，并对接收到的数据进行预测或推理。</li>
<li>集成学习作为先进的人工智能技术之一，已广泛应用于在线推理服务。它<strong>综合了多个基础学习器的结果</strong>，从而得到最终结果，具有减少偏差、方差和过拟合风险的效果。采用集成架构的推理服务已广泛应用于图像分类、自然语言处理、医学成像、时间序列预测等领域。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>传统集成推理服务主要采用平台即服务（PaaS）的模式创建和管理，具有<strong>静态的集成服务架构</strong>和<strong>僵化被动的持久资源分配</strong>。这就使得<strong>高度异构</strong>的推理请求依赖于基础学习器的固定组合和人工同构资源管理，导致<strong>精度不足</strong>、<strong>资源浪费</strong>和<strong>管理成本高昂</strong>。</li>
<li>以 “功能即服务”（FaaS）为代表的无服务器计算可以实现对开发者透明的按需分配资源，适用于集成推理服务。<ul>
<li>因此，为了实现开发人员从资源管理的挑战中解脱出来，无服务器计算中最常用的服务交付模式–FaaS 成为越来越受欢迎的服务方式。无服务器技术具有弹性扩展、按需供应和即用即付定价模式等特点，为优化服务质量和成本效率奠定了基础。</li>
</ul>
</li>
<li>然而，目前的集成推理服务仍存在以下不足。<ul>
<li>1）<strong>集成推理服务的静态架构</strong>：推理服务的请求<strong>工作量极不稳定</strong>，大多数集成推理服务都是基于固定或依赖精度的基础学习器组合构建的，忽略了<strong>模型精度和开销</strong>的波动性和异构分布，难以适应工作量的波动性和异构性。</li>
<li>2）<strong>被动、僵化的基础学习器资源分配</strong>：无服务器功能采用按需分配资源的方式，现有的大多数工作都是<strong>被动</strong>地为基础学习器创建容器，并根据请求到达情况进行僵化的资源分配，导致基础学习器的<strong>准备时间和请求排队时间较长</strong>，不同基础学习器的<strong>运行时间不均衡</strong>，服务性能不足，资源浪费较多。</li>
<li>3）<strong>人工运维管理效率低</strong>：由于集成推理服务的复杂性和特殊性，目前的人工智能服务框架和无服务器平台不支持集成推理服务的自动运维，往往需要<strong>开发者参与模型选择和资源配置</strong>，导致运维效率低、管理成本高。</li>
</ul>
</li>
<li></li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>因此，我们为集成推理服务提出了一种无服务器主动弹性调度解决方案PESEI。<ul>
<li>1）提出了一种具有联合<strong>模型精度和开销</strong>感知的两级分层动态集成服务框架，该框架描述了精度和开销分布的特征，并创建了两级选择器，通过维护动态队列自动选择模型，实现动态集成架构，以适应工作负载的波动性和异质性。</li>
<li>2）提出了一种<strong>动态感知工作负载模式</strong>的基础学习器主动弹性资源分配算法，该算法基于长短时记忆模型（LSTM），考虑了多步超前请求工作负载的多种变化特征，按需主动分配弹性空间资源，并对基础学习器进行预热，缩短服务准备时间。</li>
<li>3）设计并开发了无服务器集成推理服务<strong>系统</strong>，该系统遵循管理-分析-计划-执行（MAPE）循环，实现了集成推理服务生命周期的自主运维。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>在公共数据集上进行的真实集群实验证明了PESEI的有效性和鲁棒性，尤其是验证了 PESEI 在推理服务精度、运行性能和成本效益方面的优势。，为构建无服务器集成推理服务提供了新的解决方案。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>今后，我们将考虑更多<strong>异常情况下</strong>的资源分配问题。<ul>
<li>组织 CPU 和内存资源方面的差异可能会导致主动模型资源分配行为的不同。</li>
<li>Kubernetes 会自动管理CPU时间片，以在CPU资源需求较高的情况下维持系统运行；但在内存资源需求较高的情况下，超出内存资源限制则可能引发内存不足（OOM）事件，从而可能导致系统崩溃。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>现状核心不足是什么？</li>
</ol>
<ul>
<li>a. 推理服务的精度和开销异构且存在波动性，现有研究没有考虑这些区别，仅静态选择。（波动性是为什么？因为服务器资源争用？）</li>
<li>b. 请求到来时才被动调整资源。（那现有的主动式方案有什么问题？）</li>
<li>c. AI方面尚不支持自动运维。</li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a href="">[1] Proactive Elastic Scheduling for Serverless Ensemble Inference Services</a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>人工智能服务管理</tag>
        <tag>服务选择</tag>
        <tag>资源分配</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记55-经典-噪声保护数据集的评估平台</title>
    <url>/2024/07/21/literature/literatureNotes55/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Themis-A-Fair-Evaluation-Platform-for-Computer-Vision-Competitions》"><a href="#x1f4d6-《Themis-A-Fair-Evaluation-Platform-for-Computer-Vision-Competitions》" class="headerlink" title="📖《Themis: A Fair Evaluation Platform for Computer Vision Competitions》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Themis: A Fair Evaluation Platform for Computer Vision Competitions》</h1><p>2021 年发表于 CCF-A 类会议 IJCAI。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>当参赛者有意针对测试数据集微调其模型以提高成绩时，计算机视觉竞赛在维护公平性方面就变得越来越棘手。<ul>
<li>机器学习在学术界和工业界的迅速发展催生了众多在线竞赛，尤其是在计算机视觉领域。大型竞赛激励着研究人员不断提高机器学习算法的性能。许多关键算法都是在竞赛中首次提出的，如 AlexNet、GoogleNet，以及在 ImageNet 大规模视觉识别挑战赛（ILSVRC）中出现的 ResNet。丰厚的奖金吸引着全球人才为特定问题设计机器学习模型，追逐冠军。</li>
<li>然而，一些不诚实的参赛者为了在排行榜上获得更高的测试准确率，故意用手工标注的测试集对自己的模型进行微调，这违反了竞赛道德，破坏了健康的竞赛生态系统。因此，竞赛平台必须在保证公平的前提下对参赛者的模型进行评估。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>为了减少这种不公平现象，比赛组织者会限制参赛者模型的训练和评估过程。然而，这种限制会给组织者带来大量的计算开销，并给参赛者带来潜在的知识产权泄露。<ul>
<li>如图1所示，我们将计算机视觉竞赛的主流平台分为三类：平台 A、平台 B 和平台 C。<ul>
<li>在平台 A 中，竞赛主办方<strong>发布测试数据和标签</strong>，无需进一步维护。这既减轻了组织者和参赛者的负担，又发布了测试标签，使参赛者可以利用测试集对其模型进行微调。平台 A 在机器学习社区而非竞赛中更为普遍，例如 MNIST 的手写数字识别任务。</li>
<li>在平台 B 中，组织者只<strong>发布测试数据</strong>，并<strong>对测试标签保密</strong>，以避免上述情况。参与者需要向平台提交他们的预测结果以供评估。然而，B 平台很难防止人为标记测试数据，从而对诚实的参与者造成潜在的不公平。Kaggle 是属于 B 平台的最著名的机器学习竞赛平台。类似的视觉竞赛平台还有 ILSVRC、PASCAL VOC、MOT Challenge、DAVIS Challenge on Video Object Segmentation等。</li>
<li>在平台 C 中，主办方既<strong>不发布测试数据</strong>，也<strong>不发布测试标签</strong>。参赛者需要上传机器学习模型或源代码进行评估。因此，平台 C 可以成功禁止人工标记，但由于模型评估环境的<strong>维护和配置成本较高</strong>，平台 C 只适用于参赛人数有限的小规模比赛，如 CodaLab、视觉物体跟踪（VOT）挑战赛。此外，参赛者在上传模型时通常不愿放弃自己的<strong>知识产权</strong>。<br><a class="link" href="https://figures.semanticscholar.org/7f48482fad372ab671e159162d0db0a843b5b7db/2-Figure1-1.png">图1<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>因此，我们提出了 THEMIS，这是一个与组织者和参赛者共同训练噪声生成器的框架，它既能防止参赛者用测试集微调模型，又不收集参赛者的模型，既结合了这三个平台的优点，又避免了它们的缺点。</p>
<ul>
<li>与平台 B 不同的是，THEMIS 通过向参赛者<strong>发布有噪声的测试数据</strong>来防止参赛者手工标注测试集。噪声由一系列独立的高斯分布产生，其参数由组织者和参与者共同训练。</li>
<li>此外，THEMIS 比 C 平台<strong>更具可扩展性和可信度</strong>，因为组织者无需维护模型评估环境，参与者也可以对其模型保密。通过比较参与者对噪声测试数据的预测和真值测试标签（Ground Truth），THEMIS 可以估算出参与者模型的性能排名。</li>
</ul>
</li>
<li><p>具体来说，通过精心设计的噪声发生器，THEMIS 可以添加噪声来扰乱测试集，而不会扭曲参赛者模型的性能排名。</p>
</li>
<li><p>我们的主要贡献如下： </p>
<ul>
<li>1）为了促进计算机视觉竞赛的公平性，我们提出了一个新的评估平台 THEMIS，以避免参赛者在测试集上对其模型进行微调。</li>
<li>2）我们设计了一种噪声发生器来保护测试集，从理论上推导出其参数约束，并通过大量实验证明了其确保公平性的可行性。</li>
<li>3）我们在UTKFace、CIFAR-10和CIFAR-100等公共数据集上进行的实验证明，THEMIS可以保护测试集不受人类视觉识别的影响，并抵御不诚实的参与者，从而保证竞赛的公平性。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们利用广泛的真实世界模型和数据集评估了 THEMIS 的有效性。我们的实验结果表明，THEMIS 通过排除对测试集的人工标注并保持参赛者模型的性能排名，有效地实现了竞争的公平性。<ul>
<li>我们评估了 THEMIS 在包括 LeNet、ResNet 和 VGG 等流行模型以及包括 UTKFace、CIFAR-10 和 CIFAR-100 等公共数据集上的有效性。</li>
<li>我们的大量实验证明，THEMIS 通过用随机噪声干扰测试数据，有效地保证了比赛的公平性，并精确地保留了参赛者模型在预测有噪声测试数据时的性能排名，与它们在没有添加噪声的普通测试数据上的性能相比，THEMIS 的性能排名是非常准确的。</li>
</ul>
</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>在今后的研究中，我们计划将 THEMIS 扩展到支持自然语言处理等领域。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>有公开的实验数据说明各个方法的排名情况吗？是以何种方式在保障隐私的前提下公开的？还是说只是公开了最经典的几种方法的排名情况？可以进一步看看文章实验部分。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.ijcai.org/proceedings/2021/83">[1] Zinuo Cai, Jianyong Yuan, Yang Hua, Tao Song, Hao Wang, Zhengui Xue, Ningxin Hu, Jonathan Ding, Ruhui Ma, Mohammad Reza Haghighat and Haibing Guan, “Themis: A Fair Evaluation Platform for Computer Vision Competitions,” Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence. Pages 599-605. https://doi.org/10.24963/ijcai.2021/83<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>AI</category>
      </categories>
      <tags>
        <tag>评估平台</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记56-前沿-量子云计算模拟器</title>
    <url>/2024/07/21/literature/literatureNotes56/</url>
    <content><![CDATA[<h1 id="x1f4d6-《iQuantum-A-toolkit-for-modeling-and-simulation-of-quantum-computing-environments》"><a href="#x1f4d6-《iQuantum-A-toolkit-for-modeling-and-simulation-of-quantum-computing-environments》" class="headerlink" title="📖《iQuantum: A toolkit for modeling and simulation of quantum computing environments》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《iQuantum: A toolkit for modeling and simulation of quantum computing environments》</h1><p>Rajkumar Buyya 教授团队 2024 年发表于 CCF-B 类期刊 Software: Practice and Experience。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>量子计算资源主要通过云服务访问，未来有可能转向边缘网络。这种模式以及全球对量子计算日益增长的兴趣，扩大了对高效、适应性强的资源管理策略和量子系统服务模式的需求。<ul>
<li>量子计算为解决难以计算的问题带来了巨大的希望，给药物发现、金融、优化和机器学习等各个领域带来了革命性的变化。</li>
<li>基于云的量子计算和量子计算即服务（QCaaS）模式的出现，使人们无需对量子硬件进行大量前期投资即可访问量子计算资源，从而在量子软件和算法方面取得了巨大进步。</li>
<li>此外，预计未来量子硬件普及后，量子计算资源将扩展到边缘网络，从而出现量子云-边缘连续体的混合模式，其主要组成部分如图 1 所示。<ul>
<li>预计<strong>未来的量子计算模式</strong>将包含位于不同层（包括云层和雾层/边缘层）的异构量子和经典计算实体。</li>
<li><strong>基于云的资源和基于边缘的资源</strong>之间的<strong>主要区别</strong>包括计算能力、移动性以及与数据源或用户的地理距离。每一层都包括不同的计算资源和中间组件，如用于资源管理和协调的网关和代理。如果边缘计算资源不足以执行接收到的任务，这些任务可以迁移或卸载到具有更强大计算能力的上层云。</li>
<li>需要强调的是，这是量子计算未来扩展的愿景，而由于当前量子硬件在数量、质量和成本上的限制，大多数可用的量子资源只能通过云访问。<br><a class="link" href="https://onlinelibrary.wiley.com/cms/asset/a4487f76-5b4b-4c98-aef7-d662e1f9e4c8/spe3331-fig-0001-m.jpg">图1<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>随着对量子计算服务的需求持续快速增长，不可避免地需要高效的系统设计和资源管理策略，以最大限度地发挥可用量子资源的优势。然而，量子资源在数量、质量、可用性和成本方面的诸多限制给<strong>在实际环境中开展研究</strong>带来了巨大挑战。在实际环境中设计和评估系统与资源协调策略存在若干挑战：<ul>
<li>首先，尽管 IBM Quantum 等供应商向公众提供免费使用几台量子计算机的机会，但这些设备规模较小，只有几个量子比特。</li>
<li>此外，完成一项基于云的量子任务可能需要几秒到几小时的时间，这是因为有限资源的需要在全球大量用户之间公平共享。</li>
<li>另一方面，商业量子计算服务的定价模式仍然昂贵。这是因为目前可用的量子硬件存在局限性和运营成本。例如，IBM 量子 “随用随付 “计划对每秒量子执行收费高达 1.6 美元（截至 2023 年 8 月）。</li>
<li>此外，值得注意的是，量子硬件仍处于噪声中量子（NISQ）时代，这意味着量子芯片内部量子比特的质量和数量都受到限制。</li>
<li>这些挑战阻碍了资源管理策略的大规模评估和实验验证。因此，拥有一个能够模拟混合量子计算环境的仿真框架来帮助设计和评估资源协调策略至关重要。</li>
</ul>
</li>
<li>在过去十年中，CloudSim等<strong>模拟工具包</strong>在云环境建模和支持资源管理研究方面大受欢迎。此外，针对混合云-边缘和雾/边缘环境也提出了一些模拟器，包括 EdgeCloudSim、FogNetSim、iFogSim、EdgeSimPy等。<ul>
<li>然而，据我们所知，现有的云-边缘模拟器都<strong>不支持量子计算系统和工作负载建模</strong>。</li>
</ul>
</li>
<li>同时，现有的<strong>量子模拟器</strong>主要集中于模拟量子计算机的量子物理操作，并没有为<strong>量子云计算环境</strong>建模提供全面支持。由于这些量子模拟器使用经典资源来模拟实际的量子执行，因此很快就会达到经典硬件的限制，通常最多只能支持几十到几百个量子比特。</li>
<li>总结而言，<strong>量子计算环境建模和仿真框架的缺乏</strong>给量子系统设计和资源管理研究带来了巨大挑战，阻碍了研究人员有效测试混合量子计算系统的系统设计或任务调度算法。此外，由于没有标准的模拟器，复制实验结果或比较不同算法或应用的性能也变得更加复杂。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了应对这些挑战，我们提出了 iQuantum，这是一个<strong>多功能、轻量级</strong>的仿真框架，旨在模拟量子计算环境，促进量子软件和系统研究，重点是资源管理和协调。<ul>
<li>我们工具包的主要方法是利用量子系统资源简化环境并建立模型，其关键指标包括量子比特数、量子体积、量子处理器速度、本机门集和量子比特拓扑结构。</li>
<li>同时，我们提取量子电路的特征，将其建模为环境中的工作负载实体。</li>
<li>我们利用最新版 CloudSim 的核心引擎和经典组件来扩展和适应量子计算环境，从云层扩展到具有各种潜在用例的边缘层。</li>
</ul>
</li>
<li>我们早期的研究介绍了创建 iQuantum 的初步想法和概念验证设计，主要侧重于基于云的量子环境。在本文中，我们全面扩展了 iQuantum 的架构设计、系统模型和实现，并进行了广泛的实证评估，以证明 iQuantum 在云-边缘连续体量子计算环境建模和仿真方面的有效性。我们的扩展研究的主要贡献如下：<ul>
<li>1.我们利用现有量子计算机和量子任务执行的关键指标和特征，提出了<strong>量子计算环境的综合系统模型</strong>。此外，我们还针对混合量子资源管理和协调的不同用例提出了各种模型和仿真逻辑。这些模型可作为混合量子计算系统设计和资源管理中原型设计和问题提出的理论参考。</li>
<li>2.我们基于 CloudSim 的离散事件仿真方法<strong>设计了 iQuantum 的架构</strong>，并<strong>广泛扩展了 iQuantum 的整个实现</strong>，以提高灵活性并支持所有建议的资源管理用例，包括任务调度、后端选择、混合任务协调以及边缘和云层之间的任务卸载。</li>
<li>3.我们使用<strong>值得信赖的数据集</strong>，包括量子系统的IBM Quantum校准数据和工作负载的MQT Bench数据集，在不同场景下对iQuantum进行了<strong>验证和评估</strong>。我们的研究结果表明，iQuantum 是一种多功能、高效的工具，在支持与各种资源管理问题相关的政策开发和评估方面具有巨大潜力。</li>
<li>4.我们讨论了 iQuantum 仿真器开发过程中的经验教训，这些经验教训可为今后开发和扩展量子计算环境建模与仿真框架带来宝贵的启示。</li>
</ul>
</li>
<li>我们的工具包可为量子环境建模和仿真的发展铺平道路，使研究人员能够在模拟的量子计算环境中对系统设计和策略进行原型设计、设计和评估，从而无需以高昂的成本获取实用的量子资源。此外，它还能加强量子软件和系统的研究与实验，实现结果比较和实验复制，从而根据量子计算的最新进展开展更稳健、更有影响力的研究。此外，作为一个开源工具包，iQuantum 旨在增强量子软件生态系统中的其他工具并与之合作，特别是在量子环境建模和仿真领域。随着量子硬件和软件的快速成熟，这一领域对于量子资源管理政策的进步必然是至关重要的。</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>通过使用大规模量子工作负载数据集进行严格的经验验证和评估，我们证明了我们的工具包在各种用例中的灵活性和适用性。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>我们的工作致力于为量子计算建模和仿真做出实质性贡献，为未来资源管理策略的创建和量子计算的广泛应用提供支持。</li>
<li>我们在 iQuantum 方面的未来工作包括确保我们能够适应量子硬件和软件设计方面的新进展和新标准。<ul>
<li>我们的目标是支持超过1000个量子比特的大规模量子芯片建模，并扩展我们的建模以分析各种量子错误率的影响。</li>
<li>我们还在考虑扩展 iQuantum 的功能，以模拟各种量子硬件和量子网络的特性。</li>
<li>我们还将考虑对即将出现的技术（如电路切割 circuit-cutting）进行建模，以便在未来将任务分配给多个量子资源。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>量子的模拟是如何开展的？说现有量子模拟器会很快达到硬件限制，那么iQuantum如何解决这些问题？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://onlinelibrary.wiley.com/doi/full/10.1002/spe.3331">[1] Nguyen HT, Usman M, Buyya R. iQuantum: A toolkit for modeling and simulation of quantum computing environments. Softw: Pract Exper. 2024; 54(6): 1141-1171. doi: 10.1002/spe.3331<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>模拟器</category>
      </categories>
      <tags>
        <tag>量子计算</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记57-前沿-大规模负载预测</title>
    <url>/2024/08/26/literature/literatureNotes57/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Less-Large-scale-Workload-Forecasting-Model-Based-on-Multiple-Sequence-Compression》"><a href="#x1f4d6-《Less-Large-scale-Workload-Forecasting-Model-Based-on-Multiple-Sequence-Compression》" class="headerlink" title="📖《Less: Large-scale Workload Forecasting Model Based on Multiple Sequence Compression》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Less: Large-scale Workload Forecasting Model Based on Multiple Sequence Compression》</h1><p>2024 年发表于 CCF-B 类会议 ICWS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>随着应用迁移到云端成为应用部署的主流方式，应用运行时管理对大规模工作负载预测技术提出了巨大需求。<ul>
<li>随着云原生成为现代网络应用的一个重要设计范式，大多数应用都采用微服务架构和容器化技术。<ul>
<li><strong>微服务</strong>架构旨在通过将复杂的应用程序分解为具有单一功能的服务来降低应用程序的耦合度。</li>
<li><strong>容器</strong>是一种内核级虚拟化技术，具有更高的性能和效率。</li>
</ul>
</li>
<li>因此，整个应用程序与多个容器合作交互以满足用户请求，这导致当前云平台上的容器数以千计，给云服务提供商带来了大规模应用程序管理的挑战。</li>
</ul>
</li>
<li>云服务提供商在谷歌云、阿里云、亚马逊 AWS 等云平台上部署应用和服务时，希望尽可能避免云服务出现违反服务水平协议（SLA）、成本效率低下等严重后果。通过<strong>工作负载预测</strong>技术，云服务提供商可以预测未来一段时间内的工作负载变化，从而提前执行扩展、迁移和调度等资源管理操作，以高性价比确保服务质量。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>现有的大规模工作负载方法通常根据原始数据生成的<strong>所有训练样本构建训练集</strong>，从而生成预测模型。然而，由于微服务应用的不同容器实例之间存在相似行为，通过这种方式进行训练和建模会产生<strong>大量冗余样本</strong>，从而产生巨大的冗余训练开销。<ul>
<li>1）在工作负载预测方面，大多数方法关注<strong>每个单一容器</strong>，并提出覆盖单一容器的单一模型进行预测，以准确描述每个单一容器序列的特征。<ul>
<li>然而，这类方法应用于大规模场景时，需要<strong>存储大量模型</strong>，占用过多存储资源，同时增加了<strong>管理的复杂性</strong>；</li>
<li>同时，它们忽略了分布式应用的工作负载相似性关系，导致工作负载<strong>预测精度不足</strong>。</li>
</ul>
</li>
<li>2）为此，有人针对大规模场景提出了<strong>覆盖多个容器的单一模型</strong>，即考虑容器之间的工作负载相似性，利用聚类等技术对容器进行分组，然后为每组容器分别构建一个模型。<ul>
<li>虽然模型数量大大减少，但每组容器仍需构建一个预测模型，因此<strong>只能部分解决模型过多</strong>的问题。</li>
</ul>
</li>
<li>3）注意到上述两种方法的不足，出现了<strong>覆盖所有容器的单一模型方法</strong>。该方法使用长短期记忆（LSTM）、卷积神经网络（CNN）等深度学习模型，以所有集装箱序列为输入，分析工作量变化的时空相关性，从而在确保准确性的同时减少模型数量。<ul>
<li>然而，完全依靠 CNN 和 LSTM 等模型来挖掘所有容器工作负载序列的空间<strong>相关性是隐含的</strong>，无法解读。</li>
<li>它也缺乏对容器工作负载<strong>共性和个体变化特征</strong>对预测模型准确性差异影响的分析，因此只能获得<strong>次优结果</strong>。</li>
<li>此外，与大规模容器<strong>相关的大量</strong>工作负载序列增加了此类方法的复杂性，导致模型<strong>存储开销、训练开销和推理开销增加</strong>。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>为此，我们提出了基于多序列压缩的大规模工作负载预测模型 Less 模型。</p>
<ul>
<li>首先，我们根据工作负载序列之间的基于形状的距离（SBD）对<strong>相似的容器进行分组并对齐序列</strong>。</li>
<li>其次，在每个预测周期内，对每组容器使用基于密度的有噪声应用空间聚类（DBSCAN）算法实现<strong>容器聚类</strong>，并以此确定容器工作负载的共性和个性特征，从而指导组内的工作负载序列压缩。</li>
<li>之后，我们设计了考虑共性特征、个性特征和序列数量的<strong>拟合函数</strong>，并通过鲸鱼优化算法（WOA）求解出<strong>最优压缩序列</strong>，从而有效减少冗余训练工作负载序列的数量。</li>
<li>最后，我们使用双向门控循环单元（BiGRU）模型来<strong>分析各组的压缩工作量序列</strong>，从而在确保准确性的同时有效降低了训练开销。</li>
</ul>
</li>
<li><p>具体来说，本文的主要贡献如下：</p>
<ul>
<li>1）提出了一种以<strong>多序列压缩</strong>为核心思想的单模型覆盖多容器的大规模工作量预测模型，通过<strong>挖掘</strong>容器工作负载<strong>共性特征和个性特征</strong>，在<strong>保证工作量预测精度</strong>的同时，最大限度地<strong>压缩冗余训练序列数量</strong>以降低训练开销，实现了精度和开销的双重优化。</li>
<li>2）基于 SBD 距离，对相似集装箱进行<strong>分组</strong>，然后提出多集装箱<strong>共性和个性特征识别</strong>算法，识别每个预测周期内每个组内的共性特征和个性特征，准确<strong>刻画集装箱工作负载的短期特征</strong>。</li>
<li>3）提出了一种<strong>基于 WOA 的大规模工作负载序列压缩算法</strong>，该算法最大限度地保留了共性特征，平衡了个性特征，同时借助拟合函数考虑了序列相似度的稳定性和压缩序列的数量，从而获得最优的压缩序列。</li>
</ul>
</li>
<li><p>【Abstract】因此，本文提出了基于多序列压缩的大规模工作负载预测模型 Less。</p>
<ul>
<li>首先，基于相似容器的分组结果，提出一种容器<strong>工作负载特征识别算法</strong>，以确定每个预测时段内容器工作负载的共性和个性特征，从而指导各组内工作负载序列的压缩；</li>
<li>其次，设计了兼顾共性特征、个性特征和序列数量的拟合函数，并通过鲸鱼优化算法（WOA）求解最优压缩序列，有效减少了冗余训练工作量序列的数量，然后基于压缩后的序列建立并训练双向门控循环单元（BiGRU）模型，在保证精度的同时有效降低了模型复杂度和开销。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>最后，我们基于公开数据集验证了 Less 在准确性和开销方面的综合优势，并通过消融实验验证了模型各子部分的有效性。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>未来，我们将进一步探索所提出的 Less 如何有效<strong>指导大规模容器应用的资源分配</strong>，从而实现应用运行时的主动优化。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>步骤1、2的目的都是分组和聚类？如果是的话，重复执行两次的意义在于？是说从长期分一次类，短期再细粒度分类？还是前一次重点在于分组（可解释），后一次重点在于特征捕捉（不可解释的黑盒，融于端到端模型）？<ol>
<li>使用SBD的算法重点在于分组；DBSCAN算法的重点在于确定容器工作负载的共性和个性特征。</li>
</ol>
</li>
<li>在Abstract和Intro中共提到三种逻辑，模型步骤（Intro）、创新点（Intro）、创新点（Abstract），也许保持一致会更好？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a href="">[1] Less: Large-scale Workload Forecasting Model Based on Multiple Sequence Compression</a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>大规模</tag>
        <tag>负载预测</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记59-前沿-共享带宽包异常流量定位</title>
    <url>/2024/09/14/literature/literatureNotes59/</url>
    <content><![CDATA[<h1 id="x1f4d6-《CouldPin-Fast-Effient-and-Effective-Root-Cause-Localization-for-Shared-Bandwidth-Package-Traffic-Anomalies-in-Public-Cloud-Networks》"><a href="#x1f4d6-《CouldPin-Fast-Effient-and-Effective-Root-Cause-Localization-for-Shared-Bandwidth-Package-Traffic-Anomalies-in-Public-Cloud-Networks》" class="headerlink" title="📖《CouldPin-Fast: Effient and Effective Root Cause Localization for Shared Bandwidth Package Traffic Anomalies in Public Cloud Networks》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《CouldPin-Fast: Effient and Effective Root Cause Localization for Shared Bandwidth Package Traffic Anomalies in Public Cloud Networks》</h1><p>2024 年发表于 CCF-A 类期刊 TSC。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>随着云服务的日益普及，许多公共云租户选择共享带宽包（sBwp）服务进行入站/出站通信。sBwp 服务允许租户为多个虚拟机（VM）购买共享带宽，而不是单独购买，这是一种既方便又经济的流量管理模式。<ul>
<li>公共云提供商向大规模用户提供云计算、存储和网络等各种服务。根据最新统计数据，2022 年全球云计算市场规模为 5,458 亿美元，预计 2027 年将达到 12,409 亿美元。随着用户和服务数量的不断增加，公共云的运营和维护面临着更多挑战。应对这些挑战的方法之一是通过<strong>资源共享</strong>来实现轻松管理和降低成本。例如，多个虚拟机（VM）可以共享一台物理机，多个服务或网络功能可以共享一个网络设备。为云用户提供的另一种常见资源共享服务是<strong>共享带宽包（sBwp）服务</strong>。<ul>
<li>sBwp 是一种<strong>用户友好型</strong>流量管理服务。具体来说，拥有大量虚拟机的用户可以选择使用 sBwp 服务为所有虚拟机购买总出口带宽，而不是为每个虚拟机单独购买带宽。</li>
<li>这项服务对用户有几个好处。<ul>
<li>首先是经济成本低。用户可以使用共享带宽，避免在特定虚拟机闲置时浪费带宽资源。</li>
<li>其次是便于应用服务管理。随着微服务技术的发展，现在很多应用服务都采用分布式微服务架构。sBwp 服务允许用户直接为应用服务所需的所有虚拟机购买出口带宽。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li><p>然而，sBwp 服务为运营商识别异常 sBwp 流量的根本原因提出了新的挑战，尤其是在拥有数百万用户的大规模、全球分布式公共云中。</p>
<ul>
<li>然而，sBwp 服务给公共云的运行和维护带来了新的问题。其中最关键的问题之一是定位流量异常的根本原因。<ul>
<li>具体来说，当<strong>用户在 sBwp 流量中发现异常</strong>时，他们希望在 sBwp 中找到与异常相关的<strong>一组特定虚拟机</strong>。由于大多数用户缺乏云操作技能，他们希望云提供商提供的诊断工具能帮助他们找到根本原因。</li>
<li>如下图1所示，我们展示了真实云网络环境中的一个具体异常示例。<ul>
<li>右上角的时间序列表示 sBwp 的<strong>流量时间序列</strong>，阴影部分表示<strong>异常时间间隔</strong>。这是一个持续 40 分钟的持续尖峰异常，经常出现在云网络中。</li>
<li>下面的三个时间序列代表使用 sBwp 服务的<strong>三个虚拟机的流量时间序列</strong>。可以看出，VM1 出现异常时与 sBwp 类似。不过，VM2 并没有出现明显变化，而 VM3 的流量则很少。因此，我们希望算法<strong>将 VM1 识别为异常原因</strong>，而将 VM2 和 VM3 排除在外。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>在公共云中开发本地化系统面临着几个挑战，包括动态可扩展性、超大规模数据的有效获取以及复杂的应用场景。</p>
<ul>
<li><strong>挑战❶动态性</strong>： sBwp 服务的大规模使用和云网络的动态可扩展性使得虚拟机和网络设备的<strong>流量指标经常变化</strong>。因此，用于识别流量异常根本原因的算法不需要为每个 sBwp 实例训练模型或保持历史状态。换句话说，该算法应能在“冷启动”模式下执行，而无需任何先验知识。</li>
<li><strong>挑战❷效率</strong>： sBwp 和虚拟机的历史流量数据通常<strong>存储在专用存储集群或云存储</strong>中，可通过 SQL 等外部查询功能进行访问。然而，这些内置查询功能往往不足以进行准确的根本原因分析。要设计一种全面的算法，我们需要通过网络从本地调取原始数据进行处理和排序。由于 sBwp 服务的<strong>大规模使用</strong>，从存储集群传输所有原始数据会造成不可接受的延迟。因此，算法应尽量减少需要检索的数据量，以实现高效率。</li>
<li><strong>挑战❸有效性</strong>： 用户经常在云网络中部署各种类型的应用程序，如游戏、直播平台和网站，这可能会导致<strong>各种流量异常</strong>。这些异常可能包括时间维度上的持续和瞬时现象、振幅维度上的尖峰和低谷以及频率维度上的高抖动。一些单维度分析方法可能在识别某一类异常时很有效，但在识别其他异常时却表现很差。因此，算法应能适应不同的异常类型。</li>
</ul>
</li>
<li><p>许多文献都致力于找出各种问题的根源。但是，这些方法通常是针对<strong>特定应用</strong>设计的，需要为每个服务训练一个单独的模型，因此在大型云网络中并不实用。</p>
</li>
<li><p>据我们所知，我们的研究是首次调查共享带宽流量异常的根本原因，并讨论在真实公共云网络环境中的部署经验。</p>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/949982becd87dd39688af56154e9a434c539267b/2-Figure1-1.png" alt="图1-sBwp异常示例"><figcaption>图1-sBwp异常示例</figcaption></figure></p>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了应对这些挑战，我们提出了一种名为 CloudPin-Fast 的两阶段定位方法。<ul>
<li>首先，CloudPin-Fast 采用冷启动模式来满足动态需求。</li>
<li>其次，CloudPin-Fast 实现了预过滤，以减少超大规模数据的传输和处理。</li>
<li>最后，CloudPin-Fast 在第二阶段使用了基于多维统计融合的异常定位算法，以覆盖复杂场景。</li>
<li>方法的基本思路是在<strong>第一阶段</strong>通过<strong>粗筛选</strong>降低数据采集的规模，以满足效率要求（挑战❷），并在<strong>第二阶段</strong>（挑战❸）进一步<strong>实施综合算法</strong>以生成精确的结果。此外，CloudPin-Fast <strong>基于统计学习模型</strong>，因此可以实现冷启动，以应对动态性挑战（挑战❶）。</li>
</ul>
</li>
<li>总之，本文有以下贡献：<ul>
<li>据我们所知，我们首次从实际生产系统出发，对公共云网络中异常 sBwp 服务流量的根源定位进行了详细分析。以前的文章大多基于离线分析，没有考虑实际部署中的一些问题。我们提出的两阶段分析方法旨在处理实际环境的复杂性。</li>
<li>我们提出了一种从预测偏差、异常程度和形状相似性等多个维度综合分析定位根本原因的方法，然后使用一种综合排名算法来整合这三个维度的结果。多维度方法避免了单维度方法的弊端，从而可以更准确地定位根本原因；对于每个维度的算法，我们都选择了表现最好的统计方法来实现冷启动。</li>
<li>我们在四个真实数据集上进行了全面的实验，以证明我们提出的算法 CloudPin-Fast 的效率和有效性。此外，CloudPin-Fast 已在一家<strong>大型公有云供应商</strong>上部署了一年多，我们分享了实际部署中的一些经验教训。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>在四个生产数据集上的评估结果表明了其卓越的效率和有效性。我们还分享了 CloudPin-Fast 在一家世界知名的公有云供应商中部署一年多的经验教训。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>我们将分享在部署 CloudPin-Fast 过程中获得的一些经验。<ul>
<li>首先，我们发现 CloudPin-Fast 不仅可用于 sBwp 的根源分析，还可用于任何需要<strong>在共享资源中定位异常根源的场景</strong>，甚至可用于定位区域出口流量异常的根源虚拟机，这可能需要从数百万虚拟机中找到根源。我们在部署中考虑到了这类应用，从而扩大了 CloudPin-Fast 的潜在用途。</li>
<li>其次，<strong>可解释性</strong>对于根本原因分析至关重要。用户往往缺乏掌握复杂统计输出的专业知识，因此需要能够提供简单易懂解释的算法。CloudPin-Fast 在设计时就考虑到了这一点，它使用特定的统计量来清楚地呈现偏差和异常。它提供用户友好的见解，例如将较高的虚拟机预测偏差与可能的根本原因联系起来。这种清晰的解释建立了用户信任，简化了参数调整，提高了算法的整体可用性。</li>
<li>第三，在真实世界环境中部署高效算法系统既复杂又苛刻。虽然许多研究都侧重于离线数据集评估，但如第 IV-B2 节所述，由于数据管理、大数据框架和并行处理需求等因素，<strong>实际生产环境带来了额外的挑战</strong>。此外，流量数据必须支持各种服务，包括计费和监控，这会限制数据检索速度。为解决这些问题，CloudPin-Fast 采用了初始粗筛选阶段，以尽量减少数据查询并提高系统速度。此外，我们还利用跨虚拟机的同构处理和多节点并行计算来进一步提高实际效率。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>暂无</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10494853">[1] S. Zhang et al., “CouldPin-Fast: Effient and Effective Root Cause Localization for Shared Bandwidth Package Traffic Anomalies in Public Cloud Networks,” in IEEE Transactions on Services Computing, vol. 17, no. 3, pp. 850-864, May-June 2024, doi: 10.1109/TSC.2024.3384093.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>网络</category>
      </categories>
      <tags>
        <tag>虚拟机</tag>
        <tag>共享带宽包</tag>
        <tag>异常定位</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记6-前沿-Serverless综述</title>
    <url>/2023/05/29/literature/literatureNotes6/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Serverless-Computing-State-of-the-Art-Challenges-and-Opportunities》"><a href="#x1f4d6-《Serverless-Computing-State-of-the-Art-Challenges-and-Opportunities》" class="headerlink" title="📖《Serverless Computing: State-of-the-Art, Challenges and Opportunities》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Serverless Computing: State-of-the-Art, Challenges and Opportunities》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>无服务器计算因其轻量级和管理简单性而越来越受欢迎。它通过将计算单元的粒度降低到功能级别来实现这些优点。<ul>
<li>无服务器计算作为云计算的一种新的执行模型，由于其轻量级和管理简单性，近年来得到了极大的普及。在无服务器计算中，开发人员只需要用高级语言（如Java、Python）编写云函数，设置几个简单的参数，并将这些函数上传到无服务器平台。然后，他们可以使用返回的 API 或 HTTP 请求来执行其明确定义的计算任务。与服务器计算模型相反，使用无服务器的开发人员不需要关心基础设施资源的管理，因为平台代表他们屏蔽了这些细节。</li>
<li>通过自动管理和轻量级功能，无服务器计算不仅可以帮助开发人员专注于应用程序的核心逻辑，还可以通过更精细的计费策略使他们受益，该策略可以在运行时以毫秒为单位计算，这可以大大降低开发人员的成本。此外，它还有助于无服务器提供商将闲置资源量减少到几乎为零，以提高资源利用率，从而允许使用固定数量的资源为更多客户提供服务。</li>
</ul>
</li>
<li>总结而言，无服务器允许用户直接关注功能本身，而将其他繁琐的管理和调度问题留给平台提供商，平台提供商负责在高性能调度和低资源成本之间取得平衡。</li>
<li>作为一种新的计算范式之一，无服务器计算在应用程序特征和运行时环境方面与服务器计算有很大不同。因此，现有技术将面临巨大挑战，需要进行调整以适应无服务器需求。例如，<ul>
<li>无服务器对网络延迟更敏感，需要更细粒度的调度策略，但无服务器中的网络通信相当复杂，传统架构中调度的粒度也相对较大。因此，现有的方法无法充分满足这些要求。</li>
</ul>
</li>
<li>最紧迫的任务是确定我们在当前的无服务器研究中面临的固有问题，以及哪些潜在的方法可能有效解决这些问题。<ul>
<li>据我们所知，无服务器计算中的一些挑战已经得到了充分的研究，而其他挑战在很大程度上仍然是开放的。因此，我们需要区分无服务器计算中不同问题的侧重点，并更多地关注那些没有很好地解决的问题。此外，还存在某些领域，例如所谓的无服务器边缘计算，尽管前景广阔，但尚未很好地涉足，因为边缘计算通常对低通信延迟有更高的要求，而无服务器支持的容错能力往往是不够的。因此，它们值得进一步探索和研究。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-本文工作"><a href="#x1f6e9-本文工作" class="headerlink" title="🛩本文工作"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>本文工作</h2><ul>
<li>文重点关注无服务器计算的底层基础设施，以找出挑战和机遇的共存。</li>
<li>为此，我们分析了现有的挑战和一些可以应用于进一步研究的实用方法，并就这些问题是否值得研究发表意见。<ul>
<li>在本文中，我们对无服务器计算进行了全面调查，特别关注其基础结构特征。从而确定一些现有的挑战，并分析相关的尖端解决方案。</li>
<li>有了这些结果，我们进一步调查了一些典型的开源框架，并研究它们如何应对已识别的挑战。</li>
</ul>
</li>
<li>然后，我们总结了一些在未来研究中可能很有希望但尚未被广泛注意到的方向。<ul>
<li>鉴于无服务器计算的巨大优势，预计其部署将主导未来的云平台。因此，我们也设想了一些有前途的研究机会，这些机会需要在未来进一步探索。我们希望本文的工作能够激发那些从事相关领域的研究人员和从业者欣赏无服务器计算，从而踏足这个有前途的领域，并为其发展做出巨大贡献。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><!-- 1.  -->

<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9756233">[1] Y. Li, Y. Lin, Y. Wang, K. Ye and C. Xu, “Serverless Computing: State-of-the-Art, Challenges and Opportunities,” in IEEE Transactions on Services Computing, vol. 16, no. 2, pp. 1522-1539, 1 March-April 2023, doi: 10.1109/TSC.2022.3166553.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>待精读</tag>
        <tag>Serverless</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记60-前沿-跨地域成本感知调度</title>
    <url>/2024/09/17/literature/literatureNotes60/</url>
    <content><![CDATA[<h1 id="x1f4d6-《A-Global-Cost-Aware-Container-Scheduling-Strategy-in-Cloud-Data-Centers》"><a href="#x1f4d6-《A-Global-Cost-Aware-Container-Scheduling-Strategy-in-Cloud-Data-Centers》" class="headerlink" title="📖《A Global Cost-Aware Container Scheduling Strategy in Cloud Data Centers》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《A Global Cost-Aware Container Scheduling Strategy in Cloud Data Centers》</h1><p>2022 年发表于 CCF-A 类期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>在数据中心运行的大型互联网应用通常是作为一组容器实例化的。<ul>
<li>在数据中心（DC）的建设和运营成本中，超过60%是耗电量。随着 5G、边缘计算、区块链等新技术的发展，2020 年至 2021 年期间，中国数据中心的总用电量也将超过 2000 亿度电，并在接下来的几年中快速增长，到 2023 年将超过 2500 亿度电。预计2011年至2035年之间全球对直流电的电力需求将增加超过66%。<ul>
<li><strong>传统的数据中心</strong>通常会将云资源打包成不同类型的虚拟机 （VM） 并提供给用户。这些数据中心存在功耗高、资源利用率低等问题。因此，云服务提供商迫切需要推动传统数据中心向具有更高计算能力和能效的新型数据中心演进。</li>
<li>近年来，<strong>容器云平台</strong>作为 VM 的轻量级替代品，因其启动速度快、资源利用率高、弹性扩展等优点而大受欢迎。容器简化了构建、部署和运行应用程序的过程。借助容器，应用程序可以共享操作系统，并且凭借其轻量级属性，可以在数据中心部署数百万个容器。现代云平台必须同时处理大量并发容器请求。一些流行的开源容器编排工具，包括 Google Kubernetes、Docker Swarm 和 Apache Mesos，正在为容器的自动化部署和配置提供基本服务。对 Google 集群跟踪的分析表明，调度器在高峰时段每秒需要做出数百次放置决策。这无疑对容器调度器提出了更高的要求。</li>
</ul>
</li>
</ul>
</li>
<li>将容器分配给亲和机器可以降低通信和运输成本，而将其分配给反亲和机器则可能影响容器的正常运行。<ul>
<li>容器技术的兴起也推动了大型 Internet 应用程序的抽象化，其中大型 Internet 应用程序的多个实例通常需要部署在集群中的多个不同服务器上。这要求应用程序在部署时可以轻松访问所需的计算、存储和网络资源，并且应用程序不能在不合格的服务器上部署其容器实例。因此，某些云服务通常允许用户为应用程序指定关联性/反关联性要求，以便他们可以根据其计算机的特性为应用程序选择合适的主机集。<ul>
<li>具体来说，亲和性是指由于性能或合规性，应用程序需要部署在具有特定内核版本的机器上或特定的资源池中，例如，只有具有高 IOPS 磁盘的主机才能用于 IO 密集型应用程序。</li>
<li>反亲和性意味着无法在某些不具备应用程序所需软件和硬件条件的计算机上安装应用程序。例如，出于立法原因或为了确保某些服务靠近最终用户，可能不允许在特定区域内和外托管。</li>
</ul>
</li>
</ul>
</li>
<li>综上所述，为了提高数据中心和应用的运行效率并节省电力成本，我们面临着以下挑战：<ul>
<li>1）当集群状态稳定时，调度算法的一项重要任务是能够<strong>最大化相同数量的机器的价值</strong>，或者用更少的机器支持当前的应用程序规模。</li>
<li>2）合理的调度算法可以在一定程度上<strong>缓解数据中心的电力负担</strong>。如何为要部署的所有容器选择更节能的机器是一个值得考虑的问题。</li>
<li>3）由于应用程序的容器实例与不同服务器之间存在<strong>亲和/反亲和关系</strong>，调度器面临着拥有足够机器资源但无法使用它们的挑战。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>现有的集装箱调度方法无法满足以上要求。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了降低数据中心的运维成本，本文重点研究了异构服务器集群中的容器实例分配问题，并提出了一种全局成本感知调度算法（GCCS）来解决这个问题。其目的是从全局角度最大限度地降低集群的总功耗，同时尽量满足应用程序的亲和/反亲和要求。<ul>
<li>在这项工作中，我们提出了一种全球成本感知的集装箱调度方法 （GCCS）。<ul>
<li>受<strong>进化种群动力学思想</strong>的启发，我们将状态变量表示为应用程序在每台机器上放置的容器数量与该应用程序的容器总数。</li>
<li>我们模拟<strong>不同应用程序之间的策略交互</strong>，同时考虑到应用程序的资源需求和计算机的容量限制。</li>
<li>此外，我们还支持<strong>指定应用程序和计算机之间的亲和性/反亲和性关系</strong>，以适应它们各自的性能。</li>
<li>目标是最大限度地降低集群的总成本，并平衡服务器集群的总功耗与应用程序的整体关联性满意度。</li>
</ul>
</li>
</ul>
</li>
<li>本文的主要贡献如下：<ul>
<li>1）基于进化种群动力学的思想，研究了应用程序选择的每台服务器的容器数量，计算了聚类的总成本，提出了整数线性规划 （ILP） 问题，得到了迭代解。然后，提出了一种启发式残差搜索算法 （RSA） 将容器分布的数量修复为整数次优可行解。因此，最终的次优放置方案是间接获得的。</li>
<li>2）贝叶斯优化器用于为所提出的算法提供亲和成本系数的自动选择。经过多次的开发和探索，贝叶斯优化器最终为我们的实验推荐了一个权衡功效优化比和亲和力满足比的最优成本系数。</li>
<li>3）所有步骤都总结在论文中提出的容器调度算法 GCCS 中。GCCS 的性能是通过大量模拟来评估的。与现有算法相比，GCCS 可以显著降低集群的总功耗，并在不同的集群环境和应用程序请求下保持较高的亲和性满足率。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>最后，实验结果表明，GCCS 可以显著降低集群的总功耗，同时保持较高的亲和满足率。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>我们计划扩展资源分配的维度，以实现多个资源的容器分配。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>创新性在于考虑了亲和性/反亲和性，但对此似乎没有提出什么特别的解决方案？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9645367">[1] S. Long, W. Wen, Z. Li, K. Li, R. Yu and J. Zhu, “A Global Cost-Aware Container Scheduling Strategy in Cloud Data Centers,” in IEEE Transactions on Parallel and Distributed Systems, vol. 33, no. 11, pp. 2752-2766, 1 Nov. 2022, doi: 10.1109/TPDS.2021.3133868.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>跨地域</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记61-前沿-复杂拓扑并行配置调整</title>
    <url>/2024/09/19/literature/literatureNotes61/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Astrea-Auto-Serverless-Analytics-towards-Cost-Efficiency-and-QoS-Awareness》"><a href="#x1f4d6-《Astrea-Auto-Serverless-Analytics-towards-Cost-Efficiency-and-QoS-Awareness》" class="headerlink" title="📖《Astrea: Auto-Serverless Analytics towards Cost-Efficiency and QoS-Awareness》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Astrea: Auto-Serverless Analytics towards Cost-Efficiency and QoS-Awareness》</h1><p>2022 年发表于 CCF-A 类期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>无服务器计算能够通过一键上传和轻量级执行来简化代码部署，已成为一种前景广阔的范式，越来越受欢迎。<ul>
<li>无服务器计算因其轻量级运行时、易于管理、高弹性和精细计费等引人注目的特性而广受欢迎。借助无服务器架构，在云计算中实现功能即服务 （FaaS），开发人员可以只专注于逻辑，无需配置环境、管理虚拟机 （VM） 集群和为 VM 实例付费，即使它们处于空闲状态。Amazon Lambda、Google Cloud Functions 和 Microsoft Azure Functions 等云提供商已经部署了这种有利的计算模式，并广泛用于实时视频编码、物联网应用程序、交互式数据分析等应用。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>在将数据密集型分析应用程序（例如 MapReduce、Spark 作业）适应无服务器平台时，出现了许多挑战，其中一个特别的挑战是：无服务器分析 遇到<strong>跨不同阶段协调计算和在大型配置空间中预置资源的困难</strong>。</li>
<li>1）如何有效地处理大量中间数据，与持久性输入和输出数据相比，也称为临时数据，这样的中间数据需要在不同阶段的无状态函数之间共享。<ul>
<li>例如，与 MapReduce shuffle 阶段中传统的 VM 到 VM 或服务器到服务器的中间数据传输不同，无服务器平台中的函数到函数网络不支持批量数据传输，这与无服务器计算的原始设计理念一致。因此，映射器函数需要将中间数据输出到外部存储中，例如对象存储 S3 或分布式缓存 Redis，以便稍后作为 reducer 函数的输入获取。上述短暂数据共享带来的成本和延迟在利用无服务器分析时引发了严重的应用程序性能和成本效率问题。</li>
</ul>
</li>
<li>现有的工作已经为无服务器分析提出了许多临时数据存储解决方案。例如，<ul>
<li>Pocket 被设计和实现为无服务器作业共享的分布式存储系统，它将数据放置在多个存储层上，以提供高吞吐量和低延迟的服务。</li>
<li>Locus 是一个针对无服务器环境定制的数据分析框架，它利用快速和慢速存储的混合，在无服务器 MapReduce 作业中编排中间数据的随机排序。</li>
</ul>
</li>
<li>2）尽管进行了这些研究工作，但对于<strong>大型配置空间</strong>之间无服务器分析的协调和资源预置，包括<strong>每个函数的内存大小</strong>、<strong>每个计算阶段的并行度</strong>等，还没有通用的指导。<strong>云用户很容易以次优方式部署其无服务器分析</strong>，冒着违反其服务质量 （QoS） 目标的风险（例如， 在延迟阈值内响应）或产生额外的计费成本，而这些成本本可以通过更好的配置来避免。<ul>
<li>从本质上讲，用户仍然面临用于大数据分析的无服务器预置的关键挑战（如第 2.3 节所示）：给定较大的配置空间和不同类型的用户需求（面向延迟或预算驱动），用户如何在不考虑底层复杂性（临时数据管理和资源配置）的情况下利用无服务器计算的突出特性， 同时在性能或成本方面实现最大收益？更具体地说，如何在有限的预算下实现最佳的工作绩效，以及如何在不违反 QoS 目标的情况下最大限度地降低成本？为了应对这一挑战，我们认为需要构建一个通用框架，在数据分析开发人员和 FaaS 云提供商之间，以明智地处理作业部署并隐藏潜在复杂性。一个全面的解决方案有望根据用户灵活指定的要求，以自主方式对无服务器分析作业进行最佳配置和编排。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>简单来说，本文介绍了我们的 Astrea ，它以自主方式配置和编排无服务器分析作业，同时考虑灵活指定的用户要求。 <ul>
<li>Astrea 依赖于性能和成本的建模，该模型表征了多维因素（例如，函数内存大小、每个阶段的并行度）之间错综复杂的相互作用。</li>
<li>我们根据用户对性能增强或成本的特定要求制定优化问题，并开发一套基于图论的算法来获得最优的作业执行。</li>
</ul>
</li>
<li>具体来说，我们设计了一个名为 Astrea 的通用框架，它可以自动配置和编排用于数据分析和机器学习作业的 lambda 函数，以在性能和成本之间进行权衡。<ul>
<li>首先，Astrea 根据用户特定的目标，在提交工作时为工作的成本和工作完成时间推导出数学模型。模型中表征的配置包括作业工作流中的阶段数、每个阶段的并行度（即每个阶段中的 lambda 函数数）以及 lambda 函数的类型（即请求的 lambda 的内存大小），这些配置与为作业调用的所有函数的编排相结合。</li>
<li>其次，在模型的基础上，Astrea 根据图论获得最优作业执行计划。具体来说，我们分别为完成时间和货币成本构建了两个有向无环图 （DAG） 模型，以制定两个优化问题：（1） 给定预算约束，制定配置和作业执行优化，以最小化作业完成时间为目标，（2） 在服务质量 （QoS） 要求下，制定配置和作业执行优化，以最小化货币成本为目标。</li>
<li>第三，在提交分析作业后，Astrea 通过解决我们针对特定目标制定的优化问题来计算资源分配和任务分配的最佳配置。鉴于当今无服务器平台上每个作业的最大并发数和每个函数的最大临时存储的限制，大型数据分析作业可能没有任何可行的直接部署解决方案（如第 4.3 节所示）。因此，我们设计了 Astrea 的扩展版本，通过明智的多轮执行来适应大型作业。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们部署 Astrea 在 AWS Lambda 平台中，并根据不同规模的代表性基准（包括大数据分析和机器学习工作负载）进行实际实验。<ul>
<li>广泛的结果表明 Astrea 可以与各种预置和部署基线相比，实现无服务器数据分析的最佳执行决策。</li>
<li>例如，与三个预置基准相比， Astrea 在给定的预算限制下，设法将作业完成时间减少 21% 到 69%，同时在不违反性能要求的情况下节省 20% 到 84% 的成本。</li>
</ul>
</li>
<li>最后，我们在 AWS Lambda 上实施和部署了 Astrea，并通过对不同规模的大数据分析和机器学习的各种工作负载进行实际实验来评估其性能，包括字数（1 GB、10 GB 和 20 GB）、排序（100 GB）、对 Uservisits 数据集（25.4 GB 和 126.8 GB）和排名数据集（6.38 GB）的各种查询， K 最近邻分类 （10 GB） 和 K-means 聚类 （10 GB）。我们将 Astrea 与 AWS 上的以下预置和部署解决方案进行了比较：i） AWS Lambda 上的三个预置基准，ii） 分别在 Amazon EC2 和 SageMaker 上的 Apache Spark，以及 iii） Amazon Elastic MapReduce （EMR）。</li>
<li>广泛的实验结果表明，Astrea 可以优化受预算约束的工作绩效（即最小化完成时间），并在不违反性能要求的情况下最大限度地降低货币成本。与三个基线相比，Astrea 在具有三种不同输入大小的 Wordcount 基准测试中实现了约 42% 到 69% 的性能提升，排序性能提高了 21%，Query over Uservisits 数据集的性能提高了 57%，对于其他查询工作负载，性能提高了至少 29%。在货币成本方面，Wordcount 最多可减少 80%，Sort 最多可减少 21%，Query over Uservisits 数据集最多可减少 42%，其他查询最多可减少 84%。与 EC2 上的 Spark 相比，Astrea 可节省至少 92% 的成本，同时实现类似或高达 2 倍的工作性能。与用于机器学习作业的 Spark on SageMaker 相比，Astrea 可以降低成本高达 97%，同时完成作业的速度至少提高 36%。与基于 VM 的商业 MapReduce 平台 EMR 相比，Astrea 的完成速度提高了 77%，并节省了 65% 的 Wordcount 和 Sort 工作负载成本。我们的 Astrea 扩展版本还被证明可以通过多轮有效地部署大型作业，与 EC2 上的 Apache Spark 相比，可以降低成本并提高性能。正如所证明的那样，Astrea 根据灵活的要求成功地在工作完成时间和金钱成本之间进行了权衡，超越了现有次优或不完整的解决方案。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>我们计划探索采用更好的<strong>中间数据传输策略</strong>和为大规模数据分析作业利用最佳任务级编排的方向，如 5.6 节所述。<ul>
<li>例如，可以设计一个更好的调度程序，以<strong>流水线方式</strong>调用不同阶段的函数，以加快工作流。</li>
</ul>
</li>
<li>在更普遍的背景下，无服务器计算被认为是云计算的下一阶段，将彻底改变云编程。有状态无服务器的未来方向，例如<strong>改进和发明共享日志记录的日志记录机制和容错工具</strong>，以轻松识别无服务器应用程序中的错误。</li>
<li>另一方面，随着物联网 （IoT）、区块链和人工智能对云的变革性影响，它仍然开放地发挥无服务器计算的潜力，以支持<strong>更广泛的云应用程序</strong>。<ul>
<li>更具体地说，在 IoT 的范式中，研究挑战包括将无服务器函数放置在何处（跨边缘、雾和云层）、如何卸载和分派函数、如何缓解<strong>冷启动</strong>以减少任务关键型应用程序的延迟等。</li>
</ul>
</li>
<li>最后但并非最不重要的一点是，与“天空计算”的概念保持一致并<strong>避免供应商锁定</strong>， 开发无服务器产品的跨提供商聚合解决方案可能是一个有趣的方向。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>避免供应商锁定问题的难点是什么？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9767624">[1] J. Jarachanthan, L. Chen, F. Xu and B. Li, “Astrea: Auto-Serverless Analytics Towards Cost-Efficiency and QoS-Awareness,” in IEEE Transactions on Parallel and Distributed Systems, vol. 33, no. 12, pp. 3833-3849, 1 Dec. 2022, doi: 10.1109/TPDS.2022.3172069.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>serverless</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记62-前沿-雾计算下仿真支持的动态编排</title>
    <url>/2024/09/23/literature/literatureNotes62/</url>
    <content><![CDATA[<h1 id="x1f4d6-《COSCO-Container-Orchestration-Using-Co-Simulation-and-Gradient-Based-Optimization-for-Fog-Computing-Environments》"><a href="#x1f4d6-《COSCO-Container-Orchestration-Using-Co-Simulation-and-Gradient-Based-Optimization-for-Fog-Computing-Environments》" class="headerlink" title="📖《COSCO: Container Orchestration Using Co-Simulation and Gradient Based Optimization for Fog Computing Environments》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《COSCO: Container Orchestration Using Co-Simulation and Gradient Based Optimization for Fog Computing Environments》</h1><p>2022 年发表于 CCF-A 类期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>雾计算是分布式系统中的一种新兴模式，它包括物联网（IoT）层（地理分布式传感器和执行器）和云层（远程云平台）之间的所有中间设备。它可以通过将计算、网络和存储服务置于更接近终端用户的位置来减少延迟，从而带来诸多好处。</li>
<li>然而，雾环境在与现实世界的应用集成时会带来一些挑战。由于现代工作负载应用的高度不稳定性，以及用户对低能耗和响应时间的敏感要求，在大规模雾平台中对任务进行智能安排和管理具有挑战性。<ul>
<li>例如，许多应用，尤其是医疗保健、机器人和智能城市领域的应用，都<strong>要求超低响应时间</strong>，特别是对服务水平目标（SLO）敏感的应用。</li>
<li>其他涉及能量回收边缘设备和可再生资源的应用则需要在执行任务时实现<strong>最高能效</strong>。</li>
<li>现代应用工作负载<strong>高度动态</strong>，主机资源能力不稳定，这使得实现低响应时间和低能耗的挑战变得更加复杂。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>为了缓解这一问题，容器协调平台应运而生.</li>
<li>现有技术要么使用启发式方法快速做出调度决策，要么使用人工智能驱动的方法（如强化学习和进化方法）来适应动态场景。前者往往无法在高度动态的环境中快速适应，而后者的运行时间则慢得足以对响应时间产生负面影响。<ul>
<li>为了提供快速、节能的解决方案，之前的许多工作都侧重于开发智能策略，以调度雾主机上的计算任务。<ul>
<li>1）这些方法主要采用<strong>启发式技术</strong>。<ul>
<li>优点：这些方法的<strong>调度时间短</strong>，在一般情况下效果良好；</li>
<li>缺点：但由于存在稳态或静态假设，在<strong>具有动态工作负载的非稳态异构环境中性能较差</strong>。</li>
</ul>
</li>
<li>2）为了解决这个问题，之前的一些方法采用了<strong>基于进化方法和强化学习</strong>的更智能、更自适应的方案。<ul>
<li>优点：这些方法<strong>能适应不断变化的场景</strong>，为动态优化提供了广阔的前景。</li>
<li>缺点：然而，由于这些方法的<strong>建模准确性差</strong>、<strong>可扩展性低</strong>，因此也无法有效管理多变的雾环境。</li>
</ul>
</li>
<li>3）为了对雾环境进行精确和可扩展的建模，许多研究都使用了<strong>基于深度学习的局部搜索或神经网络学习模型</strong>，<ul>
<li>优点：这些模型<strong>可以逼近目标函数</strong>，如能耗或响应时间。由于这些神经网络近似优化问题的目标函数，因此通常被称为 “神经近似器”。具体来说，由于遗传算法（GA）和策略梯度学习等优化方法的通用性，许多最新技术主要使用这些方法来优化 QoS 参数。</li>
<li>缺点：然而，由于采用非定向搜索方案，像遗传算法这样的无梯度方法收敛到最优状态的<strong>速度很慢</strong>。此外，策略梯度学习<strong>需要时间来适应环境的突然变化</strong>，而且同样存在调度开销大的问题。这种高调度时间限制了可能改善延迟的程度，进而限制了对 SLO 的违反。这不适用于主机和工作负载特性可能会突然发生不稳定变化的高波动环境。</li>
</ul>
</li>
</ul>
</li>
<li>因此，需要一种不仅能快速适应多变环境，而且调度开销低的方法，以有效处理现代工作负载需求。<ul>
<li>4）要解决这个问题，一个自然的选择是使用<strong>定向方案</strong>，如 A* 搜索或基于梯度的优化策略。<ul>
<li>优点：尽管这类策略的<strong>收敛速度</strong>已被证明比无梯度方法<strong>快得多</strong>，</li>
<li>缺点：但由于现实世界问题中的搜索空间高度非线性，可能导致这类方法陷入<strong>局部最优</strong>，因此之前的研究并没有使用这类策略。</li>
</ul>
</li>
<li>5）此外，之前的研究也没有利用<strong>最近的进步</strong>，比如均方根传播、动量梯度下降和退火梯度下降，这些都有助于<strong>防止局部最优问题</strong>。</li>
</ul>
</li>
</ul>
</li>
<li>有鉴于此，我们相信，通过利用<strong>神经网络的优势</strong>来精确逼近 QoS 参数，我们可以将<strong>基于梯度的算法</strong>与<strong>减少此类方法陷入局部最优的可能性的先进技术</strong>结合起来应用。<ul>
<li>先前的工作还证明，神经近似器能够利用反向传播精确模拟目标函数相对于输入的梯度，从而使我们能够在基于梯度的方法中使用它们，实现快速收敛。</li>
<li>将这一系列方法结合在一起，就能提供快速高效的优化方法。我们特别提出了一种基于梯度的优化算法（GOBI），它可以计算神经网络相对于输入的梯度，从而利用先进的基于梯度的优化策略优化 QoS 参数。我们通过实验证明，与最先进的方法相比，我们的方法为雾调度提供了更快、更可扩展的优化策略。</li>
</ul>
</li>
<li>然而，<strong>仅仅使用基于梯度的优化是不够的</strong>，因为数据驱动的神经模型有时会<strong>饱和</strong>。这时，向神经模型输入更多数据并不能提高性能。在这种情况下，很难进一步优化 QoS，需要更智能的方案。<ul>
<li>6）<strong>耦合仿真（也称协同仿真或共生仿真）和任务执行</strong>已被证明是在不久的将来快速获得 QoS 参数估计的一种可行方法。具体来说，耦合模拟允许我们<strong>在后台运行模拟器与调度算法</strong>，以促进决策制定。不过，之前的工作是利用它来辅助搜索方法，而不是<strong>生成更多数据来促进人工智能模型的决策制定</strong>。后者需要在调度程序和模拟器之间开发新的接口。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>我们开发了 COSCO： 耦合仿真与容器编排框架，以利用仿真结果获得更好的服务质量。COSCO 框架是首个允许在雾环境中对容器迁移决策进行单步或多步模拟的框架。它能让调度员在未来间隔结束时获得 QoS 参数的估计值，从而进行更好的预测，进而优化调度。容器迁移是指在不同的物理或虚拟主机之间移动应用程序，并在目标主机上恢复计算的过程。这样，我们就可以运行 GOBI 方法，模拟计划（使用预测的工作量模型），并将目标值提供给另一个神经近似器，后者可以更好地近似目标函数，从而提高性能。我们将这种新颖的优化循环称为 GOBI<em>（下图）。GOBI 和 GOBI</em> 之间的交互式动态训练有助于后者快速收敛并适应多变的环境。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/8557d9505a7e1b09dced5b019259004d56cc1b95/2-Figure1-1.png" alt="图1"><figcaption>图1</figcaption></figure></li>
<li>总之，本文的主要贡献是:<ul>
<li>1）我们提出了一个新颖的框架 COSCO，这是首个允许在雾环境中进行耦合模拟和容器协调的框架。</li>
<li>2）我们提出了一种基于梯度的反向传播优化方法（GOBI），用于快速、可扩展的调度，并证明它优于最先进的调度器。</li>
<li>3）我们还提出了一种扩展方法（GOBI*），利用 COSCO 运行 GOBI 决策的模拟结果，以较低的调度开销提供更好的预测和调度决策。</li>
<li>4）利用真实世界的基准数据在物理设置上对 GOBI 和 GOBI* 进行验证后发现，GOBI 的性能低于 GOBI<em>。不过，GOBI 更适合资源有限的雾代理，因为它的计算要求较低。另一方面，GOBI</em> 更适合具有关键 QoS 要求和功能强大的雾代理的设置。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>使用 GOBI 和 GOBI* 方法对真实世界的雾应用数据进行的实验表明，与最先进的算法相比，该方法在能耗、响应时间、服务水平目标和调度时间方面分别提高了 15%、40%、4% 和 82%。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>我们建议对 <strong>COSCO 框架</strong>进行扩展，以允许<strong>无服务器计算</strong>的工作流模型。扩展到无服务器将使我们能够<strong>执行细粒度的自动缩放</strong>，提高生产率并改善灵活性和物流。</li>
<li>对于<strong>反向传播方法</strong>，我们希望扩展我们的方法，以<strong>考虑层类型和激活</strong>，如递归、卷积或具有整流线性单元（ReLU）的残差。这是因为此类非可变函数正越来越多地用于逼近各种目标函数。更先进的层类型还能让我们模拟环境的时间和空间特征。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>本文解决的到底是迁移问题还是调度问题？</li>
<li>本文对现状的分类很清晰。但其中，梯度+神经网络的创新点的实际意义还不太了解？原本的神经网络不用定向梯度下降吗？</li>
<li>本文核心亮点是：定向搜索+避免局部最优+利用模拟生成更多数据供AI训练？</li>
<li>如果放到大规模场景下存在什么问题？智能方法调度效率太低？模拟效率太低？<ol>
<li>根据实验结果，仅50个主机情况下，调度就需要10s以上，现有其他算法更是慢到200s以上。</li>
</ol>
</li>
<li>大规模属性在于？动态变化的环境</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9448450">[1] S. Tuli, S. R. Poojara, S. N. Srirama, G. Casale and N. R. Jennings, “COSCO: Container Orchestration Using Co-Simulation and Gradient Based Optimization for Fog Computing Environments,” in IEEE Transactions on Parallel and Distributed Systems, vol. 33, no. 1, pp. 101-116, 1 Jan. 2022, doi: 10.1109/TPDS.2021.3087349.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>迁移</tag>
        <tag>雾计算</tag>
        <tag>定向搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记63-前沿-全局虚拟存储下虚机复用的工作流资源调度</title>
    <url>/2024/09/24/literature/literatureNotes63/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Cost-Efficient-Workflow-Scheduling-Algorithm-for-Applications-With-Deadline-Constraint-on-Heterogeneous-Clouds》"><a href="#x1f4d6-《Cost-Efficient-Workflow-Scheduling-Algorithm-for-Applications-With-Deadline-Constraint-on-Heterogeneous-Clouds》" class="headerlink" title="📖《Cost-Efficient Workflow Scheduling Algorithm for Applications With Deadline Constraint on Heterogeneous Clouds》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Cost-Efficient Workflow Scheduling Algorithm for Applications With Deadline Constraint on Heterogeneous Clouds》</h1><p>2022 年发表于 CCF-A 类期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li><p>近年来，越来越多的大规模数据处理和计算工作流应用在异构云上运行。</p>
<ul>
<li>如今，越来越多的<strong>大规模数据处理和计算应用</strong>，如数据挖掘、基因组测序和大数据分析，都是<strong>以工作流的形式</strong>进行组装和建模的，工作流由<strong>许多受优先级限制的相互依存的任务组成</strong>。这些应用通常在集群和网格等高性能计算平台上处理。</li>
<li>然而，这些平台不仅<strong>建设和维护成本高昂</strong>，而且<strong>不方便按需付费</strong>。因此，许多工作流应用，如 CyberShake、Epigenomics、LIGO、Montage 和 SIPHT，已经部署或逐步迁移到商业云。</li>
<li>云计算被定义为以 “即用即付 ”模式提供 IT 基础设施和应用服务。在这样一个平台上，有<strong>多种类型的异构虚拟机（VM）</strong>，它们具有不同的计算特性（内核、内存、存储和 I/O 带宽），可满足各种应用的相应需求。这种云<strong>按需服务模式</strong>为租用虚拟机类型提供了便利和灵活的计费方式，有利于云终端用户。成功的商业云系统包括 Amazon EC2、Google App Engine等。</li>
</ul>
</li>
<li><p>这类具有优先级限制任务的云应用通常都有截止日期限制，其调度是云提供商面临的一个基本问题。此外，基于云计费期的工作流执行成本最小化也是云面临的一个复杂而具有挑战性的问题。</p>
<ul>
<li>一般来说，云用户<strong>根据其应用程序的需求租用或发布虚拟机（VM）</strong>。商业云提供商根据提供的时间段（如分钟或小时）收费，价格基于其处理能力（如内核）、存储量和其他因素，这被称为<strong>按使用付费模式</strong>。<ul>
<li>在这种计费模式下，分配给<strong>大容量虚拟机</strong>类型的任务通常需要<strong>较短的执行时间</strong>和<strong>较高的费用</strong>。</li>
</ul>
</li>
<li>此外，<strong>任务执行成本</strong>不是根据其实际执行时间计算的，而是根据云用户<strong>租用的时间段</strong>计算的。</li>
<li>因此，对于云用户来说，任务或工作流租用成本最小化是一个关键问题，而不是优化工作流性能这一传统目标。解决这一问题的有效方法是将工作流的任务调度到异构云，同时考虑它们的租用期。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2></li>
<li><p>云工作流调度策略将受优先级限制的任务分配到虚拟机（VM）上，以获得<strong>最佳执行成本或最小调度长度（makespan）</strong>。由于工作流应用<strong>受到截止日期的限制</strong>，这个问题变得更加复杂。</p>
<ul>
<li>然而，工作流计划任务租用计费期的一部分可<strong>被同一应用的任务重复使用</strong>，而且<strong>不同的任务开始时间点会导致不同的租用计费期</strong>。例如，假设用户的任务实际执行时间为 1.1 个计费周期，但却租用了 2 个计费周期。剩余的 0.9 个计费周期可被同一用户的另一个只需 0.75 个计费周期的任务重复使用，用户可节省一个计费周期的费用。</li>
<li>因此，分配和租用适当的计费时段以节省执行成本是可取的。</li>
</ul>
</li>
<li><p>此外，许多工作流应用程序都是<strong>数据密集型</strong>的，其数据文件大小从 2 GB（SIPHT）到超过 200 TB（CyberShake）不等。大多数云系统都有一个<strong>全局虚拟存储系统</strong>，如亚马逊 S3。因此，<strong>工作流任务和 I/O 之间的数据通信</strong>也是全局虚拟存储系统面临的一个挑战。</p>
</li>
<li><p>此外，云用户通常希望他们的应用能在截止日期前完成，这也是各种云应用中普遍考虑的重要问题。</p>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>在本研究中，受工作流任务数据 I/O、截止日期限制调度和共享云计费期等挑战的启发，我们重点研究了有效调度截止日期限制的云工作流任务以实现最优财务成本和系统性能的问题。</p>
<ul>
<li>为实现这一目标，我们首先根据具有全局存储系统的云，将工作流应用建模为 I/O 数据感知有向无环图（DDAG）。</li>
<li>然后，我们以最小执行财务成本为目标，用数学方法阐述了这个有截止日期限制的工作流调度问题。我们还从多维多选包问题中推导出该问题的时间复杂度为 NP-hard。</li>
<li>第三，我们提出了一种启发式低成本任务调度策略，称为 CETSS，它包括工作流 DDAG 模型构建、任务子截止日期初始化、贪婪工作流调度算法和任务调整方法。贪婪工作流调度算法主要包括动态任务租用计费期共享方法和非计划任务子期限放松技术。</li>
</ul>
</li>
<li><p>我们的创新点总结如下：</p>
<ul>
<li>1）首先，我们考虑了云系统的文件数据 I/O（具有全局虚拟存储系统），并将经典工作流应用 DAG 扩展为 I/O 数据感知有向无环图（DDAG）模型。</li>
<li>2）其次，我们从数学上阐述了具有成本效益、截止日期和优先级限制的工作流任务调度问题。通过对多维多选包问题的推导，证明了该问题的 NP-硬时间复杂性。</li>
<li>3）第三，我们利用扩展的 SKOPE 代码骨架框架分析并构建了工作流应用 DDAG 模型。我们还引入了云异构因子来实现标准虚拟机，用于初始化每个任务的子死线。</li>
<li>4）第四，我们提出了一种启发式低成本高效任务调度策略（CETSS），它由云应用 DDAG 模型、任务子截止日期初始化、贪婪工作流调度算法和任务调整方法四部分组成。贪婪调度算法主要包括动态任务租用计费期共享方法和非计划任务子期限放松技术。</li>
<li>5）第五，我们在随机生成和实际应用中进行了大量仿真实验。实验结果清楚地表明，就工作流执行的总财务成本而言，我们提出的工作流调度策略（CETSS）优于现有的可共享计费期感知算法 LHCM 和不可共享计费期感知算法 PCP。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们在一些合成随机生成的应用和实际应用（如表观基因组学、CyberShake 和 LIGO）上进行了严格的仿真。实验结果清楚地表明，我们提出的启发式 CETSS 优于现有算法，能有效节省工作流的总执行成本。特别是，CETSS 非常适合大型工作流应用。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>实验结果也证明，我们提出的算法 CETSS 非常适合大规模工作流应用。主要原因有两个：<ul>
<li>1）一是 CETSS 有更多机会与其他任务共享租用计费时段。</li>
<li>2）另一个原因是，我们的动态子截止日期计算策略为将任务调度到更便宜的资源提供了宽松的条件。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>所定义的“大规模”有多大？依据是什么？</li>
<li>具体效率能达到多少？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9647942">[1] X. Tang et al., “Cost-Efficient Workflow Scheduling Algorithm for Applications With Deadline Constraint on Heterogeneous Clouds,” in IEEE Transactions on Parallel and Distributed Systems, vol. 33, no. 9, pp. 2079-2092, 1 Sept. 2022, doi: 10.1109/TPDS.2021.3134247.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>资源调度</tag>
        <tag>全局存储</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记64-前沿-边缘联邦集群框架</title>
    <url>/2024/09/26/literature/literatureNotes64/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Oakestra-A-Lightweight-Hierarchical-Orchestration-Framework-for-Edge-Computing》"><a href="#x1f4d6-《Oakestra-A-Lightweight-Hierarchical-Orchestration-Framework-for-Edge-Computing》" class="headerlink" title="📖《Oakestra: A Lightweight Hierarchical Orchestration Framework for Edge Computing》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Oakestra: A Lightweight Hierarchical Orchestration Framework for Edge Computing》</h1><p>2023 年发表于 CCF-A 类会议 ATC。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li><p>边缘计算旨在通过利用部署在离用户更近的多样化、动态和可能受限环境中的资源，实现对延迟有严格要求的应用。</p>
<ul>
<li>边缘计算诞生近十年来，已在行业和研究领域找到了广泛的用例，尤其是在支持 AR/VR、实时视频分析等延迟关键型服务方面。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2></li>
<li><p>尽管人们对边缘技术兴趣浓厚，但迄今为止，现实世界中的边缘技术演示却<strong>屈指可数</strong>。原因是多方面的，在技术方面可能包括以下几点。</p>
<ul>
<li>1）首先，<strong>边缘资源的能力和异构性远低于数据中心</strong>–通常具有较小的外形尺寸和专用硬件，例如英特尔 NUC、Coral AI 板、Jetson Xavier、Raspberry Pis 等。许多此类设备都设计为部署在用户附近，利用带宽有限、延迟较高的不可靠（无线）网络作为主要通信媒介。此外，边缘的优势只有在需要大量投资和规划的计算资源密集可用时才能显现出来。</li>
<li>2）其次，<strong>大多数流行的协调框架</strong>，如 Kubernetes、K3s、KubeFed等，都是解决方案的分支，其<strong>设计初衷就是为了在受管理的数据中心网络中良好运行</strong>。<ul>
<li>这些框架对底层基础设施（尤其是网络）的<strong>一致性可靠性和可达性做出了强有力的假设</strong>，<strong>而在资源更为分散的边缘，这种假设并不一定成立</strong>。<ul>
<li>例如，最近对 Kubernetes 运行的调查发现，它<strong>依赖于通过 etcd 在数据存储中保持强大的一致性</strong>，加上其<strong>有限的可扩展性</strong>，导致在边缘环境中出现严重的可用性和效率问题。</li>
</ul>
</li>
<li>此外，此类框架的<strong>核心组件包含许多重量级操作</strong>，限制了它们在受限硬件上的使用。</li>
<li>此外，几乎所有现有解决方案目前都无法支持边缘<strong>在硬件、网络和资源可用性方面的异构性</strong>。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>更具体地说：</p>
<ul>
<li>现有的先进编排框架（如 Kubernetes）在边缘计算中表现不佳，因为它们是为可靠、低延迟、高带宽的云环境而设计的。<ul>
<li><strong>地位：</strong>Kubernetes 已成为<strong>生产中最流行的编排系统</strong>，在最近的一项调查中，59% 的受访者都使用了该系统，许多人将其视为边缘计算的主要解决方案。</li>
<li><strong>机制：</strong>它将应用程序（节点）的执行运行时与全局集群决策（控制平面）分离开来。其最小的可部署计算单元是 Pod，这是一组容器化服务。节点嵌入 Pod 的执行运行时，以及平台的网络和监控组件。控制平面为开发人员和外部工具提供 API，监控和同步节点，并对集群事件（如部署、扩展和故障）做出反应。</li>
<li><strong>问题：</strong><ul>
<li>1）Kubernetes 专为数据中心环境设计，它<strong>假定节点是由可靠的低延迟网络互连</strong>的高端托管资源。该平台通过名为 <strong>etcd 的分布式键值存储</strong>，在复制控制平面设置中保证<strong>集群状态和资源的强一致性</strong>。<ul>
<li>最近的研究发现，在移植到<strong>异构和多样化的边缘基础设施</strong>时，<strong>etcd 的强一致性要求</strong>是其主要限制因素。在资源有限的情况下，这对可扩展性有明显的影响，会<strong>拖慢整个基础设施的运行速度</strong>。</li>
</ul>
</li>
<li>2）如现有文献所示，即使在 Kubernetes Federation 中，<strong>网络分区和多集群</strong>仍然至关重要。特别是，<strong>分布式地理区域缺乏合作和对剩余基础设施的感知</strong>。因此，集群间通信需要额外的工具，如 Submariner，它需要<strong>全局状态传输同步</strong>，阻碍了可扩展性。</li>
<li>3）Kubernetes的轻量级发行版，如KubeEdge、K3s和Microk8s，要么继承了kubernetes的强假设，要么是为了在小规模集群上有更好的表现，正如我们后来的评估所示。一般来说，虽然扩展 Kubernetes 或重新架构其组件是一个可行的选择，但我们认为，<strong>重新设计众多核心组件的工作量会很大</strong>，而且还要<strong>重新制定其一些基本假设</strong>。<ul>
<li>因此，Oakestra 采用了一种不同的方法，从头开始构建时就考虑到了边缘需求，它为当前的 Kubernetes 开发人员提供了一个熟悉的环境，同时还提供了灵活性，以利用接近客户和地理分布式多所有者基础设施部署的优势。Oakestra 的目标不是取代 Kubernetes 的功能集，而是填补在 Kubernetes 不适用的情况下发现的空白。我们<strong>正在探索如何整合基于 Kubernetes 的云集群</strong>。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>在文献中，我们还可以找到其他一些探索有效边缘协调的系统。<ul>
<li>第一类：从任务调度的角度来看，我们可能会涉及到不同的分层调度器方法，这些方法在云-边缘连续体上分配任务。不过，这些解决方案的重点是<strong>服务调度</strong>，而在我们的工作中，我们必须将调度问题<strong>整合到提供服务和资源管理</strong>的综合协调框架中。<ul>
<li>CloudPath设想通过多层路径计算，将无状态功能部署到更靠近客户端的地方；</li>
<li>HeteroEdge或SpanEdge专门针对流媒体应用；</li>
<li>FogLamp侧重于数据管理；</li>
<li>而VirtualEdge只考虑蜂窝网络中的边缘服务器。</li>
</ul>
</li>
<li>第二类：与我们的工作最接近的是 OneEdge，因为它提供了一个混合的双层控制平面，用于管理地理分布式边缘基础设施。不过，我们认为 Oakestra 是 OneEdge 的<strong>超集</strong>，因为前者是一个<strong>通用的模块化框架</strong>，允许开发人员将地理（和其他）管理约束表达为调度器插件。我们通过与 OneEdge 类似的 LDP 调度器插件（第 3.2 节）展示了 Oakestra 的这种<strong>可扩展性</strong>，该插件可对地理和延迟约束进行优化。因此，整合仍是一种可能性，我们将在未来的工作中加以考虑。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>在这项工作中，我们提出了一个灵活的分层协调框架–Oakestra，它克服了上述诸多挑战。</p>
<ul>
<li>a. 从概念上讲，Oakestra <strong>允许广大地理区域内的多个运营商向联合基础设施贡献资源</strong>，从而减少了在边缘实现密集计算结构的投资。</li>
<li>b. 此外，Oakestra 的实现是轻量级和可扩展的，使其能够有效管理受限和异构的边缘基础设施。</li>
</ul>
</li>
<li><p>我们提出的 Oakestra 是一个用于边缘计算的分层、轻量级、灵活且可扩展的协调框架。通过新颖的<strong>联合三层资源管理</strong>、<strong>委托任务调度和语义叠加网络</strong>，Oakestra 可以灵活地<strong>整合多个基础设施提供商</strong>，并支持边缘<strong>动态变化的应用</strong>。</p>
</li>
<li><p>具体来说，我们的贡献包括：</p>
<ul>
<li>1）我们将<strong>边缘基础设施整合到一个逻辑三层层次结构</strong>中。<ul>
<li>由一个<strong>根协调器</strong>管理多个资源集群，每个集群由一个<strong>集群协调器</strong>控制，从而实现基础设施联合。<strong>集群协调器</strong>行使本地细粒度控制，但只向根节点发送集群使用情况的<strong>汇总统计数据</strong>（第3节）。</li>
<li>在设计上，Oakestra 隐藏了每个集群的内部基础架构细节，<strong>允许许多提供商参与而不暴露内部配置</strong>。应用提供商可通过在根节点指定高级限制（硬件、延迟、地理位置）在边缘部署服务。Oakestra 采用委托调度机制，只在根节点做出粗粒度的集群选择，将细粒度的资源调度留给集群，从而将任务分配分离开来。</li>
</ul>
</li>
<li>2）我们设计了一种新颖的<strong>语义覆盖网络</strong>，它能透明地<strong>实现面向边缘的负载平衡策略</strong>（例如，连接到最近的实例），可直接使用具有语义能力的IPv4地址和主机名进行寻址（第3、4节）。这支持了云原生应用的可移植性，确保了应用开发人员优化边缘服务间交互的灵活性。该覆盖还允许 Oakestra <strong>根据基础设施的变化（如迁移、故障等）动态调整通信端点</strong>，确保不间断的服务交互。</li>
<li>3）Oakestra的<strong>轻量级模块化</strong>实现与大多数流行的云技术兼容，允许开发人员<strong>扩展内部组件</strong>，例如调度程序，而无需太多<strong>开发开销</strong>（第5节）。Oakestra 是一个开源项目 (<a class="link" href="https://www.oakestra.io/)%EF%BC%8C%E5%85%B6%E6%89%80%E6%9C%89%E7%BB%84%E4%BB%B6%E5%9D%87%E5%8F%AF%E4%BB%8E">https://www.oakestra.io/)，其所有组件均可从<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> <a class="link" href="https://github.com/oakestra">https://github.com/oakestra<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 获取。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/2024-ATC-Bartolomeo-Oakestra.png?raw=true" alt="图1"><figcaption>图1</figcaption></figure></p>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们对照最先进的技术进行了全面评估，结果表明 Oakestra 具有显著优势，它通过减少管理开销将资源使用量降低了约十倍，并通过在受限硬件上轻量级运行将应用性能提高了 10%。<ul>
<li>我们在高性能计算和边缘基础设施中进行的广泛评估证明了Oakestra的能力，因为它的性能始终（且显著）优于流行的生产框架（如Kubernetes及其衍生产品）。我们的结果显示，CPU 开销降低了 10 倍，服务部署时间缩短了 60%，应用性能提高了 10%。在重负载情况下，与最接近的竞争对手K3s相比，Oakestra的资源利用率降低了≈20%。</li>
</ul>
</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>1）我们计划为 Oakestra 添加几项功能扩展。例如，我们计划通过<strong>分布式领导者选举</strong>，在<strong>故障切换时动态分配集群协调者</strong>角色。</li>
<li>2）我们还打算利用<strong>最新的边缘研究</strong>解决方案扩展 Oakestra 的<strong>调度和网络功能</strong>，如截止日期感知调度、多级隧道等。</li>
<li>3）为了提供更好的 QoS 保证，我们还打算支持和比较<strong>更新颖的应用运行时</strong>，如 unikernels、demikernels 或 Akka。</li>
<li>4）最后，我们还试图探索<strong>将 Kubernetes 部署纳入 Oakestra 集群</strong>的可能性，以实现现有云部署的集成。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>边缘的特点是什么？<ol>
<li>无法保证强一致性</li>
</ol>
</li>
<li>为什么不基于k3s开发？理论上k3s也做了很多轻量化优化<ol>
<li>K8S及其衍生品都基于etcd的强一致性假设，若修改则需要进行大量重构，因此选择</li>
</ol>
</li>
<li>边缘的不稳定性是如何解决的？</li>
<li>解决异构性的难点是什么？只要设计一个抽象框架就行？</li>
<li>原语义覆盖网络的缺点是什么？作为创新点有点突兀？</li>
<li>组件轻量化的方法是什么？</li>
<li>一大亮点是多运营商联合（Sky Computing），难点在于？</li>
<li>为啥能发A？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.usenix.org/conference/atc23/presentation/bartolomeo">[1] Bartolomeo G, Yosofie M, Bäurle S, et al. Oakestra: A lightweight hierarchical orchestration framework for edge computing[C]//2023 USENIX Annual Technical Conference (USENIX ATC 23). 2023: 215-231.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>多云</tag>
        <tag>边缘</tag>
        <tag>联邦</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记65-前沿-真实与仿真混合的边缘DML测试平台</title>
    <url>/2024/09/27/literature/literatureNotes65/</url>
    <content><![CDATA[<h1 id="x1f4d6-《EdgeTB-A-Hybrid-Testbed-for-Distributed-Machine-Learning-at-the-Edge-With-High-Fidelity》"><a href="#x1f4d6-《EdgeTB-A-Hybrid-Testbed-for-Distributed-Machine-Learning-at-the-Edge-With-High-Fidelity》" class="headerlink" title="📖《EdgeTB: A Hybrid Testbed for Distributed Machine Learning at the Edge With High Fidelity》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《EdgeTB: A Hybrid Testbed for Distributed Machine Learning at the Edge With High Fidelity》</h1><p>2022 年发表于 CCF-A 类期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li><strong>边缘分布式机器学习（DML）</strong>已成为在数据源附近提供低延迟智能的重要课题。<ul>
<li>1）边缘计算给【<strong>传统应用</strong>】带来了改进。<ul>
<li>近年来，移动设备和物联网<strong>设备的数量</strong>及其产生的<strong>数据量**</strong>大幅增加<strong>。将这些数据</strong>传输到云并进行处理**给网络和云带来了巨大压力。</li>
<li>特别是在流媒体直播等对<strong>延迟敏感</strong>的场景中，需要传输和处理大量视频数据。高延迟会严重降低<strong>用户体验</strong>。</li>
<li>为解决这一问题，雾计算（也称为边缘计算）正在兴起。它将大量计算设备分布到网络边缘，使计算和存储资源更接近终端用户。因此，边缘计算大大减少了终端用户<strong>访问网络服务的延迟</strong>，从而改善了用户体验。</li>
</ul>
</li>
<li>2）除了关注边缘计算给<strong>传统应用</strong>带来的改进，研究人员还对【在边缘部署 <strong>DML</strong> 】感兴趣。<ul>
<li>在传统的<strong>集中式机器学习</strong>中，用户需要将数据上传到云端。云中许多<strong>强大且互联的计算设备</strong>会根据这些数据高效地训练机器学习模型。</li>
<li>然而，随着人们<strong>隐私保护意识</strong>的提高，他们不愿意分享自己的敏感数据。因此，在<strong>边缘部署 DML</strong>（如 Federated Learning、Gossip Learning 和 E-Tree Learning），既能充分<strong>利用数据价值</strong>，又能<strong>保护用户数据隐私</strong>，已成为一种流行的方法。<ul>
<li>在联邦学习中，用户设备始终持有数据，同时负责训练任务。用户只需上传机器学习模型，边缘基础设施就会聚合这些模型，加快训练任务的完成。</li>
<li>这与传统的集中式机器学习有很大不同，因为<strong>用户设备的性能有限</strong>，而且<strong>用户设备与边缘基础设施之间的网络不稳定、速度慢</strong>。</li>
<li>因此，边缘计算场景中使用的 DML 的开发和测试应充分考虑计算和网络资源的限制。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>在此基础上，应用程序在部署前应进行全面测试，以尽可能发现潜在问题。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，DML 的开发和测试都缺乏足够的支持。要实现快速开发，就需要能抽象出 DML 一般功能的可重用库。<ul>
<li>研究界通常使用<strong>测试平台（tested）</strong>来提供测试环境。<ul>
<li>测试平台主要有三种类型，即物理测试平台、模拟测试平台和仿真测试平台。为避免歧义，我们使用 “计算设备 ”来指现实世界中的物理硬件（如个人电脑、笔记本电脑和智能手机），使用 “节点”（物理、虚拟、模拟和仿真）来指测试环境中的实体。</li>
</ul>
</li>
<li>1）<strong>高保真的理想测试方法</strong>是使用由相互连接的计算设备组成的<strong>物理测试平台 physical testbed</strong>。<ul>
<li><strong>简介：</strong>在物理测试台中，每台计算设备都直接充当测试环境中的<strong>物理节点</strong>。此外，计算设备通过网络（如以太网、WiFi 和蓝牙）进行连接。因此，物理测试平台可为应用提供高计算和网络保真度的测试环境。</li>
<li><strong>案例：</strong>文献中提出了一些<strong>雾计算物理测试平台的架构或原型</strong>。研究人员还可以使用一些<strong>无线传感器网络（WSN）物理测试平台</strong>来验证其基于物联网的应用。</li>
<li><strong>缺点：</strong>不过，物理测试平台往往<strong>规模较小，部署和维护成本较高</strong>。此外，计算设备之间的<strong>网络拓扑结构是固定</strong>的，因此很难提供与边缘计算场景类似的<strong>动态网络环境</strong>。</li>
</ul>
</li>
<li>2）为了降低成本和提高网络灵活性，研究人员可以使用<strong>模拟测试平台 simulated testbed（模拟器 simulator）</strong>。<ul>
<li><strong>简介：</strong>模拟器对计算设备和网络进行抽象建模，从而在程序（如 Java 程序和 Python 程序）中提供测试环境。</li>
<li><strong>案例：</strong>没有一种模拟器能满足所有类型测试环境的要求，因此研究人员针对不同的研究课题提出了各种模拟器。<ul>
<li>CloudSim 是著名的云计算模拟器。</li>
<li>在它的基础上，研究人员实现了许多雾模拟器，包括 iFogSim、MyiFogSim 和 edgeCloudSim。</li>
<li>有些模拟器并非基于 CloudSim，如 YAFS 和 FogNetSim++。</li>
</ul>
</li>
<li><strong>缺点：</strong>由于<strong>缺乏计算和网络保真度</strong>，模拟器只适合粗略地尝试新想法。研究人员仍需进行更可靠的验证。<ul>
<li>测试环境中的模拟节点只是程序中的实例。因此，模拟器<strong>并没有连接模拟节点</strong>，而只是使用算法来模拟延迟和丢包等网络链接属性。</li>
<li>此外，由于模拟器本身是一个程序，研究人员<strong>无法部署应用程序</strong>对其进行测试。他们只能根据模拟器的抽象模型重新实现应用程序的主要工作流程。</li>
</ul>
</li>
</ul>
</li>
<li>3）<strong>模拟测试平台 emulated testbed（仿真器 emulator）</strong>通过使用虚拟化技术（如虚拟机（VM）技术和容器化技术），在物理测试平台和模拟测试平台之间实现了<strong>良好的平衡</strong>。<ul>
<li><strong>简介：</strong>它在单个计算设备中创建了多个计算空间和网络空间相互隔离的仿真节点。因此，仿真节点可以运行应用程序并通过网络相互通信。</li>
<li><strong>案例：</strong><ul>
<li>EmuFog 使用容器化技术在单个计算设备上创建多个仿真节点，而 EmuEdge 则使用虚拟机技术来实现这一目标。</li>
<li>部分研究将多个计算设备同时用作容器仿真器，以支持更大的规模。</li>
</ul>
</li>
<li><strong>缺点：</strong>在这些作品中，所有计算设备都被用作仿真器，以形成纯仿真测试平台，而不考虑<strong>计算设备计算和存储资源的差异</strong>。然而，只有拥有足够计算和存储资源的计算设备才适合作为仿真器，而低性能的计算设备则不适合。因此，尽管仿真器的计算和网络保真度高于模拟器，<strong>但仿真器与物理试验台之间仍有很大差距</strong>。</li>
</ul>
</li>
</ul>
</li>
<li>总结而言，现有的物理测试平台通常规模较小，缺乏网络灵活性，而模拟器和仿真器等虚拟测试平台则缺乏保真度。</li>
<li>另外，在 DML 的研究中，对测试的支持不够，对开发的支持也很缺乏。<ul>
<li>一方面，DML 是<strong>需要执行才能得到结果（如模型精度和模型收敛时间）</strong>的应用程序，因此不能部署应用程序的模拟器不适合测试 DML。此外，现有的物理测试平台和仿真器都是<strong>面向 DMLs 以外的特定研究领域</strong>，或者是<strong>通用平台</strong>，没有为 DMLs 开发提供专门支持。</li>
<li>另一方面，DMLs 应用程序中用于解决各种研究问题的<strong>许多部件都是可重复使用的</strong>。例如，在 Federated Learning 中，有关神经网络模型和客户选择的研究可以使用相同的模型训练、聚合和传输功能模块。然而，目前还没有对这些通用功能模块进行抽象和封装。因此，研究人员只能依靠更原生的机器学习库（如 TensorFlow）来开<strong>发 DML 中的所有功能模块</strong>。这大大增加了开发 DML 的难度，也不利于同行之间验证 DML 和实验。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>本文提出的 EdgeTB 是一种新型混合测试平台，用于研究边缘计算场景中的 DML。利用 EdgeTB，研究人员可以快速开发 DML，并在高保真、大规模和网络灵活的测试环境中进行测试。<ul>
<li>1）EdgeTB能重要的是，</li>
<li>1）在 EdgeTB 中，提供大量<strong>仿真节点</strong>来生成大规模、网络灵活的测试环境，同时<strong>结合物理节点</strong>来保证保真度。EdgeTB <strong>统一管理物理节点和仿真节点</strong>，并通过动态配置支持节点间的任意网络拓扑结构。<ul>
<li><strong>计算设备</strong>可以充当<strong>物理节点或仿真器</strong>，根据计算设备的性能或研究人员的要求提供仿真节点。<ul>
<li>a. 一方面，<strong>物理节点</strong>的存在提高了 EdgeTB 的<strong>计算和网络保真度</strong>，使其接近物理测试平台。</li>
<li>b. 另一方面，与物理测试平台相比，<strong>仿真器</strong>的采用使 EdgeTB 更容易生成<strong>大规模、网络灵活</strong>的测试环境。</li>
<li>c. 此外，为了提高<strong>可扩展性</strong>，EdgeTB 采用了<strong>控制器-工作器架构</strong>，并提供了<strong>统一管理</strong>物理节点和仿真节点的工具。</li>
<li>d. 重要的是，EdgeTB 允许用户动态配置节点间的网络拓扑，以便在运行测试时生成非固定的边缘网络。</li>
</ul>
</li>
<li>我们对现有的边缘计算测试平台进行了定性比较。EdgeTB 位于<strong>物理试验台</strong>和<strong>仿真试验台</strong>之间。由于 EdgeTB 并不强制要求将哪些设备用作仿真器或物理节点，因此用户可以决定在测试保真度、网络灵活性和成本之间取得更好的平衡。当所有计算设备都用作物理节点时，EdgeTB 将向物理测试平台靠拢。当所有计算设备都用作仿真器时，EdgeTB 将向仿真测试平台靠拢。</li>
</ul>
</li>
<li>2）我们提出了<strong>面向角色的开发方法</strong>，以支持 DML 的快速开发。<ul>
<li>为了支持 DML 的快速开发，我们提出了面向角色的开发方法，其中角色是一种<strong>编程抽象</strong>，可从各种 DML 中提取模型训练和模型聚合等<strong>通用功能模块</strong>。EdgeTB 封装了可重复使用的库，以支持面向角色的开发。用户可以使用这些库快速开发 DML，并用自定义功能模块替换与其研究课题相关的默认功能模块。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/e607c957bbf497e3cf966eaad704f26f572cdedc/500px/4-Figure2-1.png" alt="图"><figcaption>图</figcaption></figure></p>
<ul>
<li>我们的贡献总结如下：<ul>
<li>1）我们设计并实现了 EdgeTB，这是一个混合测试平台，可提供大量仿真节点来生成大规模、网络灵活的测试环境，同时结合物理节点来保证保真度。这是首个跨仿真器和物理边缘计算设备构建的混合边缘计算测试平台。</li>
<li>2）我们提出了面向角色的开发方法，并封装了可重复使用的库，以支持 DML 的快速开发。这是第一个用于开发任意 DML（如联邦学习、Gossip学习和E-Tree学习）的通用库。</li>
<li>3）我们进行了大量的案例研究和实验，证明研究人员可以使用 EdgeTB 开发 DML 并对其进行高保真测试。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>通过案例研究和实验，我们证明了 EdgeTB 为高效开发和测试各种结构的 DML 提供了便利，并具有高保真度和可扩展性。</li>
<li>EdgeTB 组件是用 Python (v3.6) 实现的，约有 3000 行代码，可在 <a class="link" href="https://github.com/Lin-1997/Edge-TB">https://github.com/Lin-1997/Edge-TB<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 上获取。</li>
</ul>
<h2 id="⛳️未来机会-开放性问题"><a href="#⛳️未来机会-开放性问题" class="headerlink" title="⛳️未来机会/开放性问题"></a>⛳️未来机会/开放性问题</h2><ul>
<li>1）仅 CPU 仿真。<ul>
<li>EdgeTB 中的仿真节点<strong>只使用 CPU 资源</strong>，因为<strong>目前对 GPU 资源隔离的支持还不够</strong>。</li>
<li>通过 CPU 资源隔离，EdgeTB 可以将不同仿真节点的工作负载调度到不同的物理 CPU 线程上，从而使仿真节点独占 CPU 资源（相对而言）。</li>
<li>假设仿真节点使用 GPU 资源。在这种情况下，它们需要等待 GPU 驱动程序的调度，以争夺 GPU 资源的使用权。这与现实世界中每台设备都有自己的硬件资源这一事实背道而驰。</li>
</ul>
</li>
<li>2）数据并行和模型并行架构。<ul>
<li>本文提到的架构是数据并行架构（DPA）。在 DPA 中，每个节点都会维护一份本地模型副本，并在其数据上进行训练，同时定期与其他节点同步模型。基本角色 “聚合器”（Aggregator）和 “训练器”（Trainer）适用于实现 DPA。</li>
<li>不过，另一种称为模型并行架构（MPA）的架构会对 DNN 进行分区，并为每个节点分配子层集。DNN 的中间输出（前向传播）和相应梯度（后向传播）在节点之间传输。因此，聚合器和训练器不适合实施 MPA。</li>
<li>在未来的工作中，我们将探索适合实施 MPA 的角色。</li>
</ul>
</li>
<li>3）仿真节点部署。<ul>
<li>目前，用户需要安排仿真节点的部署。然而，不同物理设备上的仿真节点可能会<strong>使用超出网络接口卡（NIC）能力的带宽</strong>。</li>
<li>在未来的工作中，我们将开发在同一物理设备上部署大带宽需求仿真节点的算法。这样，它们之间的网络通信就不会通过网卡。</li>
</ul>
</li>
<li>4）为什么不是 Kubernetes。<ul>
<li>Kubernetes <strong>不支持使用计算设备作为物理节点</strong>（底层物理机和容器分层，不能作为同一层资源使用），而我们需要物理节点来增强测试的真实性。</li>
<li>由于 Kubernetes 用于生产级容器编排，其<strong>网络模型侧重于服务发现和负载平衡</strong>。然而，这使得<strong>定制仿真节点之间的链接属性</strong>具有挑战性。</li>
<li>在未来的工作中，我们将整合现代 SDN 软件（如 Open vSwitch）来丰富 EdgeTB 的网络模型，这也与 Kubernetes 的<strong>网络模型相冲突</strong>。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>核心逻辑：边缘分布式机器学习（DML）应用广泛 -&gt; 需要测试 -&gt; 现有的物理测试平台通常规模较小，缺乏网络灵活性，而模拟器和仿真器等虚拟测试平台则缺乏保真度 -+- 针对DML的测试、开发支持更不够，无法使用现有testbed没有特定于 DML特点的测试（例如设定节点间任意网络拓扑功能）和开发（例如模块复用功能） -&gt; 结合真实与仿真testbed优点，支持 DML所需动态复杂网络拓扑需求，支持模块复用的开发功能。</li>
<li>面向 DML 的测试具有什么特点？为什么通用平台不能拿来用？<ol>
<li>网络拓扑复杂，通用平台不注重该问题。（文章总结得更偏向边缘资源的特点，和 DML 应用似乎没啥关系）</li>
</ol>
</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9693130">[1] L. Yang, F. Wen, J. Cao and Z. Wang, “EdgeTB: A Hybrid Testbed for Distributed Machine Learning at the Edge With High Fidelity,” in IEEE Transactions on Parallel and Distributed Systems, vol. 33, no. 10, pp. 2540-2553, 1 Oct. 2022, doi: 10.1109/TPDS.2022.3144994.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>边缘计算</tag>
        <tag>分布式机器学习</tag>
        <tag>测试平台</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记66-前沿-大规模超算自动镜像/配置分发部署</title>
    <url>/2024/10/08/literature/literatureNotes66/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Efficient-and-Automated-Deployment-Architecture-for-OpenStack-in-TianHe-SuperComputing-Environment》"><a href="#x1f4d6-《Efficient-and-Automated-Deployment-Architecture-for-OpenStack-in-TianHe-SuperComputing-Environment》" class="headerlink" title="📖《Efficient and Automated Deployment Architecture for OpenStack in TianHe SuperComputing Environment》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Efficient and Automated Deployment Architecture for OpenStack in TianHe SuperComputing Environment》</h1><p>2022 年发表于 CCF-A 类期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>近年来，随着全球金融危机和公共安全事件（如 COVID-19）的大规模爆发，高性能计算被广泛应用于风险预测、疫苗研发等领域。<ul>
<li>随着信息社会的快速发展，对信息处理能力的更高要求使得高性能计算成为科学研究不可或缺的工具。例如，地震波的频率范围可达 10Hz 左右。因此，三维地震波传播和破裂动力学模拟依赖于高性能计算。</li>
<li>此外，高性能计算也越来越多地渗透到一些传统行业，如石油行业，在提高生产效率、降低生产成本方面取得了巨大成效。</li>
<li>在突发金融危机和公共安全事件（如 COVID-19 的大规模爆发）中，高性能计算也发挥了重要作用。海量计算能力为疫情监测和病毒溯源分析提供了支持。</li>
</ul>
</li>
<li>在高性能计算基础设施应对计算需求瞬间爆炸的场景中，如何通过快速构建计算集群来提供大规模灵活的计算能力分配和调整是一个关键问题。<ul>
<li>无论是应对 COVID-19 等突发事件的瞬时计算需求，还是科学计算，<strong>大规模基础设施计算能力的快速分配和灵活调整</strong>都是高性能计算应用领域的关键问题。为用户提供独立管理计算资源的灵活服务策略，为用户提供可动态扩展的计算资源，并相应调整计算能力配置，已成为部署高性能计算环境的重要课题。</li>
<li>高性能计算云作为一种基于云计算的高性能计算资源管理与服务模式，可以解决上述用户服务问题。云计算作为一种技术手段，通过虚拟化技术对底层资源进行整合。它为用户提供了<strong>可动态扩展</strong>的高性能计算资源，尤其适用于一些<strong>需要高峰值计算</strong>性能的科学计算。此外，它还为不同规模的异构应用提供服务，以获得更高的吞吐量，提高计算资源的利用率。因此，高性能云可以满足高性能计算对资源<strong>按需访问和高效执行</strong>的要求。</li>
<li>同时，利用高性能计算云的<strong>巨大计算能力</strong>，可以灵活完成大规模数据分析任务，如基因组数据分析、自然语言处理和图像处理深度学习。高性能计算云还能进行数据密集型计算，满足分布式异构处理对低延迟和高吞吐量的要求。此外，它还能为医疗和金融企业的 IT 架构提供基础设施即服务（IaaS）。总之，要快速构建一个能提供灵活计算能力的高性能计算云中心，它是不可或缺的。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>OpenStack是一种<strong>云操作系统</strong>，可管理整个数据中心的大型计算、存储和网络资源池。它通过一个仪表板进行操作，让管理员能够控制，同时授权用户通过网络界面提供资源。<ul>
<li>然而，现有的 OpenStack 集群部署解决方案难以适应，<strong>无法满足大规模部署场景</strong>的实现。此外，<strong>繁琐且容易出错的部署过程</strong>通常会受到<strong>各种组件</strong>的影响。<ul>
<li>图 1 是 OpenStack 项目的变化趋势。我们可以观察到，OpenStack 的<strong>组件正在逐步复杂化</strong>。2010 年发布的 OpenStack 奥斯汀版本只有两个组件，即 nova 和 swift。目前，最新的 OpenStack 版本 Wallaby 于 2021 年 4 月发布。虽然它提升了安全性能，加强了开源基础设施在云原生领域的应用，但其<strong>核心组件数量高达 29 个</strong>。利用 OpenStack 构建计算中心，可以在大规模高性能计算基础设施上灵活分配计算资源，是满足用户需求的盈利方式。因此，构建适合大规模环境的高效 OpenStack 部署解决方案迫在眉睫。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/bc802a01cf02542f87c875a27cd7cb3732d0238c/2-Figure1-1.png" alt="图1"><figcaption>图1</figcaption></figure></li>
</ul>
</li>
</ul>
</li>
<li>现有的大规模部署解决方案都是基于传统的部署方法，采用组件源代码逐步部署或第三方插件部署的方式。这些操作会带来的主要问题归纳如下。<ul>
<li>1）<strong>完成度低。</strong>随着部署规模的扩大，组件被逐个部署到各个指定节点。由于组件之间存在错综复杂的依赖关系，部署的复杂性和难度都会大大增加，部署过程中极易出错。</li>
<li>2）<strong>效率低。</strong>OpenStack 组件通常为 2- 3G，数据量相当大。在大规模集群容器化部署过程中，需要将所需组件的容器镜像从存储库拉到本地节点。受限于节点带宽性能，网络瓶颈就会出现，导致网络带宽拥塞。整个集群部署过程中的网络延迟非常大，极大地影响了部署效率。</li>
<li>在<strong>数百个节点上</strong>部署大规模 OpenStack 云计算集群是一项艰巨的任务。它涉及大量软件的安装和组件间依赖关系的处理。更复杂的是在异构集群服务器硬件、操作系统和网络中设置许多配置参数。因此，以往的解决方案通常局限于小型数据中心和小规模集群。</li>
</ul>
</li>
<li>总结而言，面临的巨大挑战是<strong>如何减少过长的镜像分发时间</strong>和<strong>避免配置缺陷</strong>。</li>
<li>尽管文献中对大规模计算的资源管理和平台优化进行了广泛研究，但对于在竞争激烈的高性能计算市场中<strong>如何高效、自动地部署大规模计算集群</strong>却鲜有分析研究。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>本文设计了一种在大规模环境中高效、通用的部署架构，以克服上述难题。<ul>
<li>1）我们设计了一种基于 OpenStack 云平台的<strong>智能分布式注册表部署（IDRD）架构</strong>，该架构利用多个注册表的容器化部署自动放置<strong>分布式镜像存储库</strong>。IDRD 架构基于 Kolla-Ansible 的集成部署，通过脚本自动安装组件，<strong>降低了部署复杂度</strong>，<strong>提高了部署成功率</strong>。</li>
<li>2）我们提出了一种<strong>节点负载优先算法</strong>，以解决 IDRD 架构中<strong>多个注册表位置</strong>的问题。将注册表放在合适的位置，可以减少集群节点拉取镜像时的网络拥塞，提高集群部署效率。在此基础上，我们设计了一种基于需求密度的集群算法，可以<strong>优化 IDRD 的全局性能</strong>，改善大规模集群的负载均衡。</li>
<li>3）我们在天河超算环境中部署了不同集群规模的 IDRD，并评估了网络负载性能、安装效率和成功率。广泛的实验结果表明，所提出的 IDRD 架构可以缓解网络拥塞。它可以提供大规模计算集群的部署，并在降低操作难度的同时显著提高部署效率。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>大量实验结果表明，IDRD 能有效减少 30% - 50% 的组件图像分发时间，显著提高大规模集群部署的效率。</li>
</ul>
<h2 id="⛳️未来机会-开放性问题"><a href="#⛳️未来机会-开放性问题" class="headerlink" title="⛳️未来机会/开放性问题"></a>⛳️未来机会/开放性问题</h2><ul>
<li>在未来的工作中，我们将进一步考虑在部署过程中实现镜像压缩，以减少网络拥塞。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>超算具体用于什么地方？<ol>
<li>地震波等力学模拟：高频率震动，海量信息</li>
<li>疫情监测、病毒溯源：涉及大量人、物，海量复杂信息</li>
<li>石油领域：不懂</li>
</ol>
</li>
<li>云的特点和优点是什么？<ol>
<li>特点：基于虚拟化的统一管理</li>
<li>优点：灵活+海量</li>
</ol>
</li>
<li>OpenStack连数百个节点都无法支持？</li>
<li>核心逻辑：超算需要对大规模资源快速分配和灵活调整 -&gt; 云能满足这一特点 -&gt; 现有OpenStack工具的流程和组件过于复杂，不适合大规模 -+- 现有其他工具面向大量复杂组件的依赖关系、软件安装、配置参数分发时存在时间长、易出错两大问题 -&gt; 智能分布式注册表架构（分布式镜像分发） -+- 节点负载优先算法（确定每个镜像服务器最优位置）</li>
<li>本质是一个镜像/配置分发问题的解决方案，但文中没有考虑数据一致性问题带来的代价。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9610176">[1] B. Jiang, Z. Tang, X. Xiao, J. Yao, R. Cao and K. Li, “Efficient and Automated Deployment Architecture for OpenStack in TianHe SuperComputing Environment,” in IEEE Transactions on Parallel and Distributed Systems, vol. 33, no. 8, pp. 1811-1824, 1 Aug. 2022, doi: 10.1109/TPDS.2021.3127128.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>超算</tag>
        <tag>配置分发</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记67-前沿-大规模跨地域任务云边协作调度</title>
    <url>/2024/10/09/literature/literatureNotes67/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Efficient-Flow-Based-Scheduling-for-Geo-Distributed-Simulation-Tasks-in-Collaborative-Edge-and-Cloud-Environments》"><a href="#x1f4d6-《Efficient-Flow-Based-Scheduling-for-Geo-Distributed-Simulation-Tasks-in-Collaborative-Edge-and-Cloud-Environments》" class="headerlink" title="📖《Efficient Flow-Based Scheduling for Geo-Distributed Simulation Tasks in Collaborative Edge and Cloud Environments》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Efficient Flow-Based Scheduling for Geo-Distributed Simulation Tasks in Collaborative Edge and Cloud Environments》</h1><p>2022 年国防科大团队发表于 CCF-A 类期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li><strong>实验</strong>是科学的基础。当实验不能或不应该在真实系统中进行时，可以利用动态模型来完成特定目的的实验，这就是<strong>模拟</strong>。<ul>
<li>例如，飞机模拟器可以以更低的成本加快飞行员的培训，利用流行病模拟可以获得正确的公共卫生政策。</li>
</ul>
</li>
<li>为了缓解因实体数量和高精密模型不断增加而导致的大规模模拟成本增加的问题，一些从业者选择<strong>在云环境中部署模拟应用程序</strong>。边缘计算是云计算的良好补充，可用于部署<strong>大规模地理分布式模拟应用</strong>，这些应用对不同模拟组件（本文中也称为任务）和用户之间的通信延迟非常敏感。<ul>
<li>与提交给集群的<strong>普通任务</strong>不同，<strong>模拟应用程序</strong>通常是<strong>紧密耦合</strong>的，各组件之间通过发送许多小消息<strong>频繁通信</strong>，以进行数据交换或维持模拟事件的正确随机顺序。<ul>
<li>对于分析模拟而言，<strong>大部分数据交换</strong>发生在<strong>模拟组件之间</strong>，消息捆绑等技术可以有效缓解云平台在传输小消息方面的限制。</li>
<li>然而，在训练模拟等<strong>大规模地理分布模拟</strong>中，组件除了与其他模拟组件通信外，还需要<strong>与用户频繁地实时交换数据</strong>。将所有组件和模型部署在远程云数据中心很容易增加用户之间的通信延迟，造成数据中心的带宽瓶颈。<ul>
<li>例如，佩戴许多动作传感器的用户需要上传大量数据，以更新虚拟模拟环境中相应数字模型的状态。</li>
</ul>
</li>
</ul>
</li>
<li>边缘计算是缓解这一问题的一个不错选择，它将计算资源置于用户附近，受到了工业界和学术界的广泛关注。<ul>
<li>虽然与远程云数据中心相比，边缘计算节点更接近用户，<strong>但其计算资源也不充足</strong>。事实上，当模拟组件部署在云端或边缘时，会出现<strong>性能权衡问题</strong>。对于一个给定的组件，如果它与相应用户之间的交换数据量较大，而与其他组件的通信频率相对较低，那么它最好部署在靠近相应用户的近边缘节点。否则，应将其部署在云数据中心。</li>
</ul>
</li>
</ul>
</li>
<li>我们主要关注<strong>云边协作环境</strong>中模拟组件的高效调度，以便在考虑<strong>主机容量限制</strong>的情况下最大限度地<strong>降低总体通信成本</strong>。此外，计算节点（云数据中心和边缘）之间的<strong>网络拓扑结构</strong>、用户和任务之间的<strong>交换数据量</strong>以及任务之间的<strong>通信强度</strong>都在考虑之列。<ul>
<li>由于模拟中的任务通常是紧密耦合的，因此应该对它们进行联合调度，这实际上是一个 NP-complete（NP-complete）多维组合优化问题。</li>
<li>考虑到<strong>大规模</strong>地理分布模拟应用中的任务数量可能非常大，所选的调度策略应具有良好的<strong>扩展性</strong>。</li>
<li>此外，由于资源状态（可用性和容量）的<strong>动态变化</strong>以及模拟任务的动态加入和退出，<strong>尽快</strong>获得所有任务的部署决策非常重要，要求调度算法具有较低的<strong>决策延迟</strong>。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/4f9badc4c300001bc9bb8cccb9f90e3c9d7a673b/4-Figure1-1.png" alt="图1"><figcaption>图1</figcaption></figure></p>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>有关这一问题的方法大致可分为三类，即元启发式算法、启发式算法和精确算法。<ul>
<li>1）<strong>元启发式算法</strong>主要针对通用问题设计，通常受自然现象启发，如遗传算法（GA）和粒子群优化（PSO）。<ul>
<li>优点：这些算法可以为许多具有复杂约束条件的优化问题<strong>获得近似最优解</strong>。</li>
<li>缺点：然而，当问题空间较大时，这些算法会<strong>耗费大量时间</strong>，而且即使所有参数保持不变，<strong>结果也不是确定的</strong>。</li>
</ul>
</li>
<li>2）<strong>启发式算法</strong>是一组约束条件，旨在为特定问题找到好的解决方案。启发式算法是一类近似算法，倾向于按照某些预定义的规则（如主导资源公平性或最短作业优先）依次部署任务。<ul>
<li>优点：事实上，这些算法可以看作是算法运行时间与生成解决方案质量之间的权衡，其假设是，当<strong>每个任务都以最优方式安排</strong>时，最终的部署决定是可以接受的。</li>
<li>缺点：然而，这些算法<strong>很难模拟任务之间复杂的相互作用</strong>。而且，这些启发式算法很容易<strong>陷入局部最优状态</strong>。</li>
</ul>
</li>
<li>3）<strong>精确算法</strong>试图通过复杂的分析和计算找到理论上的最优解。特别是，一些学者将任务调度问题建模为整数线性问题（ILP），并利用现成的求解器（如 CPLEX）来获得最优解。<ul>
<li>优点：基于现成求解器，<strong>算法求解非常方便</strong>。</li>
<li>缺点：但这些算法<strong>所耗费的时间可能并不合理</strong>，尤其是在任务和主机数量非常大的情况下。主要原因可能是 ILP 的典型算法（如分支与边界法或切割面法）都是指数算法。</li>
</ul>
</li>
</ul>
</li>
<li>遗憾的是，现有的现代集群调度器大多基于队列（启发式算法），任务是按顺序调度的，因此缺乏联合处理紧密耦合任务的能力。</li>
<li>其他基于批处理的调度算法（元启发式算法、精确算法）通常也很耗时。</li>
<li>流网络是描述这一问题的一个很有前途的工具，它将任务调度问题表述为图上的最小成本最大流（MCMF）优化，在这种情况下，每个顶点代表一个任务节点或计算节点，从任务节点到计算节点的路径表示一个可能的布局决策。<ul>
<li>缺点：然而，现有的基于流量的调度器<strong>很少模拟任务或用户之间的交互</strong>，而且<strong>只考虑一维资源</strong>。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>根据上述观察结果，我们设计了用于分布式模拟的新型基于流量的调度器 Pond。</p>
<ul>
<li>1）任务与其对应用户或其他任务之间的数据传输成本被模拟为每个弧的成本。</li>
<li>2）此外，通过放宽一些约束条件，这个 NP 难的组合优化问题<strong>被简化为 MCMF 问题</strong>，这是一个 P 问题，并且已经开发出一些<strong>多项式时间算法</strong>。</li>
<li>3）需要注意的是，网络流优化理论只支持<strong>一维流向量</strong>。由于本文同时考虑了 CPU 和内存资源，因此必须在 Pond 中做一些额外的工作。</li>
</ul>
</li>
<li><p>总结而言，本文介绍的 Pond 是一种新型基于流的调度器，它能感知任务与用户以及异构多维资源之间的交互。</p>
<ul>
<li>首先，我们提出了边缘和云协作环境中大规模地理分布模拟的任务调度问题，分析了分布式模拟任务的特点，并通过将任务和用户之间的通信开销映射到网络中弧线的成本，将调度问题表述为流量网络上的最小成本最大流量（MCMF）问题。</li>
<li>考虑到现有基于流量的调度器在处理多维资源时存在的固有缺陷，我们提出了一种<strong>基于主导资源概念的方法</strong>来处理具有<strong>多维资源需求</strong>的异构任务。</li>
<li>我们设计了一些<strong>针对具体问题的启发式方法</strong>来消除不可行的放置决策。由流量碎片和容量违规引起的失败任务可通过在资源树中贪婪搜索来重新安排。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/4f9badc4c300001bc9bb8cccb9f90e3c9d7a673b/6-Figure3-1.png" alt="示意图"><figcaption>示意图</figcaption></figure></p>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>基于阿里巴巴生产轨迹和一些随机合成参数进行了广泛的模拟实验。结果表明，与一些基线方法相比，Pond 可以在相当低的部署延迟内显著降低每个任务的平均通信成本。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>结果表明，当负载不是很高时，Pond_Domi 在部署质量和延迟方面表现良好。但是，在高负载情况下，Pond_Domi 的资源效率并不令人满意，这可以看作是性能和资源效率之间的权衡。在未来的工作中，我们将设计一些额外的机制来缓解上述缺点。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>核心逻辑：传统模拟应用可以部署在云上，但大规模跨地域模拟需要与用户频繁交互，不适合在云上 -&gt; 适合使用云边协作，根据任务特点决定在云还是在边 -&gt; 问题是NP难的，算法应当能够处理动态变化的环境并快速求解 -&gt; 现有算法大多没考虑模拟任务和用户之间的交互、动态变化的环境，或效率不够高 -&gt; 提出Pond解决三大难点：刻画复杂交互、动态变化环境；将NP难问题转化为P问题，提高效率；提出算法，解决传统算法无法应对的多维资源、重调度问题。</li>
<li>和边缘的关系不大？和跨地域数据中心的关系更大？边缘的特点体现在哪里？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9726854">[1] Z. Miao, P. Yong, Z. Jiancheng and Y. Quanjun, “Efficient Flow-Based Scheduling for Geo-Distributed Simulation Tasks in Collaborative Edge and Cloud Environments,” in IEEE Transactions on Parallel and Distributed Systems, vol. 33, no. 12, pp. 3442-3459, 1 Dec. 2022, doi: 10.1109/TPDS.2022.3155713.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>跨地域</tag>
        <tag>云边协作</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记68-前沿-实时渲染无缝迁移</title>
    <url>/2024/10/11/literature/literatureNotes68/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Seamless-Cross-Edge-Service-Migration-for-Real-Time-Rendering-Applications》"><a href="#x1f4d6-《Seamless-Cross-Edge-Service-Migration-for-Real-Time-Rendering-Applications》" class="headerlink" title="📖《Seamless Cross-Edge Service Migration for Real-Time Rendering Applications》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Seamless Cross-Edge Service Migration for Real-Time Rendering Applications》</h1><p>2024 年发表于 CCF-A 类期刊 TMC。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>实时渲染应用的无缝跨边缘迁移具有挑战性。实时渲染应用具有很强的交互性，要求停机时间低于15ms，以实现不易察觉的迁移。<ul>
<li>云游戏、云虚拟现实、云增强现实等实时渲染应用在 5G 时代蓬勃发展。它们有望成为现实世界与数字孪生世界之间的桥梁。<ul>
<li>然而，受限于可穿戴显示设备<strong>较弱的计算能力</strong>，实时渲染应用必须连接到<strong>功能强大但价格昂贵</strong>的<strong>本地主机</strong>。这使得它既不轻便，大多数人也负担不起。</li>
<li>将渲染模块移动到<strong>云端</strong>并将渲染图像流式传输到用户设备（UE）似乎是一种成本友好的方案，但 UE 与云端之间的<strong>长距离</strong>会带来额外的<strong>高延迟</strong>，从而导致不愉快的<strong>用户体验</strong>。</li>
<li>为了解决这个问题，有人提出了<strong>边缘渲染</strong>。这种设计可在网络边缘提供<strong>低延迟</strong>渲染服务，并将 UE 从计算密集型渲染操作中解放出来。因此，用户可以在瘦客户端上以<strong>可接受的价格</strong>享受实时渲染应用。</li>
</ul>
</li>
<li>然而，实时渲染应用依赖于<strong>实时流协议</strong>，如实时流协议（RTSP）和实时消息协议（RTMP）来向 UE 传输高分辨率视频流。<strong>低延迟要求</strong>限制了提供边缘渲染的边缘云的覆盖范围。<ul>
<li>此外，为了<strong>防止缓冲区带来的额外延迟</strong>，一些专为实时渲染应用设计的流媒体系统甚至采用了在 UE 端<strong>不缓冲视频帧</strong>的设计。</li>
<li>上述设计使边缘渲染容易受到<strong>用户移动</strong>带来的延迟增加的影响。如果用户移出连接边缘云的覆盖区域，服务质量（QOS）就会因延迟增加而下降。</li>
<li>为了解决这个问题，有人提出了 Follow me cloud，它利用<strong>边缘云之间的服务迁移</strong>，将服务实例动态地迁移到更邻近、延迟更低的边缘云上。<ul>
<li>然而，服务迁移是一项成本高昂的操作。它涉及<strong>大量数据传输</strong>，并<strong>带来服务停机时间</strong>。停机时间是指服务迁移过程中服务冻结和不可用的一段时间。在停机期间，用户会有晕机、屏幕冻结和黑边等不愉快的体验。</li>
<li>因此，<strong>将停机时间缩短到 15 毫秒以内</strong>是防止不愉快体验并使服务迁移不易察觉的基本前提<a href="#refer-anchor-2"><sup>[2]</sup></a>。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/bc98b14c2271f37ce5570e614c26fff357934c42/3-Figure1-1.png" alt="图1"><figcaption>图1</figcaption></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>现有的基于虚拟机迁移和容器迁移的方法都存在<strong>脏页重传</strong>引起的重复<strong>内存数据</strong>拷贝和<strong>共享存储故障</strong>引起的大量<strong>磁盘数据</strong>拷贝所带来的令人不快的<strong>停机时间</strong>。<ul>
<li>进行服务迁移的主流方法是<strong>虚拟机（VM）实时迁移</strong>和<strong>容器实时迁移</strong>。<ul>
<li>1）<strong>虚拟机实时迁移</strong>是云数据中心广泛使用的成熟技术。然而，虚拟机实时迁移会<strong>迁移整个操作系统</strong>，因此会带来过多<strong>不必要的数据转移</strong>。</li>
<li>2）为了使迁移更加<strong>轻量级</strong>，<strong>容器实时迁移</strong>成为移动边缘计算的热门研究课题。借助用户空间检查点/恢复（Checkpoint/Restore In Userspace，CRIU），容器实时迁移实现了<strong>进程级迁移</strong>。在容器实时迁移过程中，<strong>只传输相关文件和内存状态</strong>，因此比虚拟机实时迁移更轻便。</li>
</ul>
</li>
<li>然而，虚拟机迁移和容器迁移并不是<strong>保证</strong>跨边缘场景中<strong>实时</strong>渲染应用服务连续性的理想方法。<ul>
<li>a. 首先，它们的<strong>停机时间是不可接受的</strong>。<ul>
<li>虽然已经采取了大量方法来减少停机时间，如预复制、后复制和分层结构，但它们的停机时间从几十毫秒到几秒不等。这些方法的性能都达不到 15 毫秒的标准。</li>
<li>此外，我们的测量结果表明，如果在迁移过程中进行<strong>高频内存写入操作</strong>，虚拟机迁移和容器迁移的<strong>停机时间会急剧增加</strong>。这一特性使它们无法迁移计算密集型实时渲染应用。</li>
</ul>
</li>
<li>b. 此外，虚拟机迁移和容器迁移还存在其他<strong>固有缺陷</strong>。<ul>
<li>虚拟机实时迁移主要依赖云内场景中提供的<strong>共享存储</strong>，如 Ceph 和 NFS，以防止大量文件系统转移，但由于<strong>广域网（WAN）环境</strong>带来的<strong>运行时性能下降</strong>，这种方法并不适用。</li>
<li>由于容器实时迁移依赖的 CRIU <strong>不支持图形应用程序的检查点</strong>，因此容器实时迁移无法用于实时渲染应用程序。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>我们的见解是：</p>
<ul>
<li>直接从<strong>源边缘云</strong>复制<strong>所有状态数据</strong>成本太高。相反，实时渲染应用的复杂状态可以从边缘和云之间<strong>交换的逻辑数据流中恢复</strong>。<ul>
<li>例如，移动游戏客户端可以在断开连接后恢复游戏并赶上其他玩家的进度。</li>
</ul>
</li>
<li>因此，我们使用云辅助<strong>孪生渲染（dual rendering）</strong>来代替直接点对点跨边缘<strong>状态复制</strong>来实现状态同步。它利用逻辑流中的状态信息，在目的边缘云上创建一个孪生应用实例，并与原始实例同步。</li>
<li>这样的设计绕过了内存复制过程中脏页重传带来的性能瓶颈，使进一步减少停机时间成为可能。</li>
</ul>
</li>
<li><p>然而，要实现这种架构，必须克服以下两个关键挑战：</p>
<ul>
<li><ol>
<li>如何在<strong>限制停机时间的前提下</strong>实现<strong>应用会话</strong>和 <strong>5G用户面会话</strong>的同步切换。</li>
</ol>
<ul>
<li>上述两个切换过程<strong>都应</strong>及时完成，以避免带来额外的停机时间。</li>
<li>然而，这两个系统都<strong>有各自的控制器</strong>，这就增加了会话快速协调切换的难度。</li>
</ul>
</li>
<li><ol start="2">
<li>如何在会话切换过程中<strong>保持 UE 屏幕的连续性</strong>，以保证迁移过程不被察觉。</li>
</ol>
<ul>
<li>我们将迁移过程<strong>简化</strong>为从源边缘视频流到目的边缘视频流的切换。</li>
<li>由于源边缘和目的边缘<strong>分别渲染图像</strong>，从两端到达UE的帧不可能完全一致。因此，即使停机时间可以压缩得足够短，用户仍可能会遭受令人不快的视觉突变，即<strong>帧闪烁</strong>。有了这种闪烁，迁移仍然是可感知的。</li>
</ul>
</li>
</ul>
</li>
<li><p>应对挑战的方法是：</p>
<ul>
<li>1）为了应对第一个挑战，我们提出了一种<strong>以UE为中心的会话管理机制</strong>。<ul>
<li>在<strong>预迁移阶段</strong>，迁移准备工作<strong>分别</strong>由计算控制器和 5G 核心网主导。<ul>
<li>在<strong>计算状态迁移</strong>方面，两个边缘云在云逻辑服务器的协助下同步计算状态。</li>
<li>在<strong>通信网络</strong>方面，将建立从基站到目的地边缘云的新协议数据单元（PDU）会话，并与之前的 PDU 会话并行工作。</li>
<li>由于采用了孪生渲染机制，在预迁移阶段结束时，UE 会<strong>同时接收来自两个边缘云的渲染流</strong>。</li>
</ul>
</li>
<li>在此基础上，计算和网络会话的物理切换变成了 UE 中的<strong>一次性软切换</strong>。</li>
<li><strong>迁移阶段</strong>简化为 UE 侧的流会话切换，通过交换 UE 流选择器中的配置来实现。</li>
</ul>
</li>
<li>2）为了应对第二个挑战，我们引入了一种<strong>平滑切换机制</strong>，包括结构相似性（SSIM）门限、帧滑动和异步一帧缓冲。<ul>
<li>2.1）<strong>SSIM阈值</strong>决定<strong>何时触发流切换</strong>。只有当来自两个边缘的视频帧流足够相似时，才允许进行流切换。</li>
<li>2.2）<strong>帧滑动</strong>使 UE 端能够在触发切换后呈现两个视频流帧的加权平均值，从而使两个视频流之间的过渡更加平滑。</li>
<li>2.3）<strong>异步一帧缓冲机制</strong>定义了 UE 中流媒体客户端线程和流媒体选择器线程之间的数据交换模式，可确保差异显著的帧及时刷新。</li>
</ul>
</li>
</ul>
</li>
<li><p>在本文中，我们提出了云辅助服务迁移（CSM），利用云边缘协作实现实时渲染应用的无缝服务迁移。CSM 从三个方面改善了服务迁移的用户体验：</p>
<ul>
<li>1）首先，它引入了孪生渲染机制，绕过了点对点数据复制，压缩了停机冻结阶段。</li>
<li>2）第二，提出了以用户设备为中心的会话切换机制，通过很好地协调应用会话切换和 5G 用户平面会话切换来节省时间。</li>
<li>3）第三，利用平滑切换机制防止会话切换期间出现令人不悦的帧闪烁。</li>
</ul>
</li>
<li><p>概括而言，主要贡献如下。</p>
<ul>
<li>1）我们证明了脏页重传引起的重复内存数据拷贝导致的大量数据传输是虚拟机实时迁移和容器实时迁移的性能瓶颈（第二节）。</li>
<li>2）然后，我们提出了基于云边缘协作的 CSM 方法，该方法专为实时渲染应用而设计（第三节-A 和 第三节-B）。CSM 以云辅助孪生渲染取代了点对点状态复制，从而压缩了冻结阶段。据我们所知，这项工作首次不仅考虑了计算状态转移，还考虑了 5G 用户平面 PDU 会话切换以减少服务停机时间。</li>
<li>3）我们开发了以 UE 为中心的会话管理和平滑切换机制（第三节-C）。前者负责协调应用会话和 5G 用户平面会话的同步切换。后者使视频流从源边缘到目的边缘的转换不易察觉，并保证用户体验。</li>
<li>4）我们在包含全栈 5G 核心网用户平面的 5G 核心网测试平台上实现了所提出的架构（第四节）。我们对边缘渲染模式进行了实验（第五节）。实验结果表明，我们的方法可以进一步将平均停机时间减少到 14 毫秒以下，这足以实现不易察觉的无缝迁移。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们在边缘渲染多人游戏中实现了 CSM，并将其部署在带有全栈用户平面协议栈的 5G 测试平台上。</li>
<li>评估结果表明，CSM可以将停机时间减少到&lt;14ms，而且服务迁移过程是用户无法察觉的。</li>
</ul>
<h2 id="⛳️Discussion（未来机会）"><a href="#⛳️Discussion（未来机会）" class="headerlink" title="⛳️Discussion（未来机会）"></a>⛳️Discussion（未来机会）</h2><ul>
<li>与虚拟机和容器一起工作： CSM 与虚拟机和容器并不冲突。它只是为迁移提供了一种替代方法。虚拟机和容器的应用分发和部署功能可以保留。除了停机时间方面的性能提升，CSM 还可以被视为虚拟机和容器的补充。首先，它支持共享实例部署。虚拟机和容器只能迁移只服务于一个用户的独占实例。如果迁移共享实例，实例的其他用户也会受到影响。由于 CSM 是应用级的，因此它可以迁移一个用户的状态，而不会影响共享同一实例的其他用户。其次，它弥补了容器无法迁移图形用户界面应用程序的缺陷，使容器可用于部署实时渲染应用程序。这种组合充分利用了容器在应用部署中灵活轻便的特点和 CSM 的高迁移性能。</li>
<li>适用的应用程序类型： CSM 假定有一个包含全局状态信息的逻辑服务器。这种部署架构通常用于多用户应用程序，从本质上分离了全局逻辑模块和渲染模块，非常适合 CSM。然而，并非所有应用程序都符合这一假设。有些应用程序会将部分状态信息放在客户端，以减少信息交换，如用户视角。另一个例外是单用户应用程序，它根本没有中央逻辑服务器。为使 CSM 适用于上述例外情况，应对应用程序进行修改。对于客户端有部分状态的应用，源边缘云可以在迁移过程中临时将本地状态发送到全局逻辑服务器，以实现完整的状态同步。这种临时状态共享已在评估中使用的修改版 Minetest 中实现。用户的视角状态会首先发送到逻辑服务器，然后同步到辅助会话，以保证视图一致。对于单用户应用程序，渲染模型和逻辑模型可以解耦，使其与多用户应用程序相似。因此，在多用户应用中，逻辑模型可以发挥类似于云逻辑服务器的作用。此外，还应为跨服务器状态同步提供网络接口。</li>
<li>对应用程序进行必要的修改（侵入式）： 由于 CSM 是一种应用层面的方法，因此应修改应用程序，使 CSM 适用。好消息是，应用程序的核心逻辑不会受到影响。开发人员只需应用会话 III-C2 中提到的会话管理机制，即可支持协同会话。这将允许一个用户账户在迁移过程中在不同地点同时登录，并启用孪生渲染过程。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>孪生渲染具体指什么？有什么缺点？<ol>
<li>在做完迁移决策后，不从源主机复制内存，而是从云上获取逻辑操作，根据逻辑操作知道接下来需要渲染什么样的内容。</li>
<li>是否会导致切换时间短但预热时间长？如果这样的话，则要求有提前很多的预测、否则需要对很多个可能的主机都提前预热。</li>
<li>接2，在用户高速移动的场景下本方法会很难支持（但好像所有技术都无法支持，是整个场景的一大痛点）。</li>
</ol>
</li>
<li>如何判断移动性？<ol>
<li>本文不做讨论，仅处理已确定移动性和迁移目标后的操作。如果联合考虑是否会存在问题？例如在决策迁移目标时就应该考虑到哪个机器更适合迁移（例如已有部分状态信息）。</li>
</ol>
</li>
<li>若资源是跨域的，没有完整权限，该怎么协作？</li>
<li>云边协同体现在什么地方？</li>
<li>本文实现强实时的代价是什么？能否优化？<ol>
<li>资源浪费。</li>
</ol>
</li>
<li>本文方法是侵入式的，如果想使用非侵入式方式该怎么办（站在云供应商的角度）</li>
<li>核心逻辑：渲染任务有强实时要求 -&gt; 边缘计算能够满足强实时需求，但覆盖范围有限导致必须使用迁移技术(Follow me cloud) -&gt; 传统迁移方式先拷贝状态再更新脏数据，存在无法避免的较高停机时间（大于15ms），使用户体验差 -&gt; 本方法从源主机拷贝状态，而是通过上层下发的控制逻辑直接实时渲染最终结果，避免脏数据。</li>
<li>论文写的太清晰了！值得学习！</li>
<li> 论文的insight是很重要的一部分，如果论文设计了case study体现insight，将会对读者产生巨大价值。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10314778">[1] Y. Li et al., “Seamless Cross-Edge Service Migration for Real-Time Rendering Applications,” in IEEE Transactions on Mobile Computing, vol. 23, no. 6, pp. 7084-7098, June 2024, doi: 10.1109/TMC.2023.3331773.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.huawei.com/minisite/pdf/ilab/cloud_vr_network_solution_white_paper_en.pdf">[2] “Cloud VR solution white paper”, Hua Wei iLab Tech. Rep, 2018, [online] Available: https://www.huawei.com/minisite/pdf/ilab/cloud_vr_network_solution_white_paper_en.pdf.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>迁移</tag>
        <tag>云边协同</tag>
        <tag>强实时</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记69-前沿-基于干扰感知预测的深度学习调度系统</title>
    <url>/2024/10/12/literature/literatureNotes69/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Horus-Interference-Aware-and-Prediction-Based-Scheduling-in-Deep-Learning-Systems》"><a href="#x1f4d6-《Horus-Interference-Aware-and-Prediction-Based-Scheduling-in-Deep-Learning-Systems》" class="headerlink" title="📖《Horus: Interference-Aware and Prediction-Based Scheduling in Deep Learning Systems》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Horus: Interference-Aware and Prediction-Based Scheduling in Deep Learning Systems》</h1><p>2022年 英国兰卡斯特大学（Lancaster）团队 发表于 CCF-A 类期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>为了加速深度学习（DL）模型的训练，配备了 GPU 等硬件加速器的机器集群被用来缩短执行时间。<ul>
<li>深度学习（DL）是一种日益重要的机器学习类型，将对许多领域产生影响。</li>
<li>深度学习架构的创新和数据量的增长导致从业人员的需求增加，从而建立了配备图形处理器（GPU）等计算机加速器的机器集群。这些由小型和大型分布式系统组成的 DL 系统可实现大量计算吞吐量并缩短模型训练总时间。</li>
</ul>
</li>
<li>需要最先进的资源管理器来<strong>提高 GPU 利用率</strong>并最大限度地<strong>提高吞吐量</strong>。<ul>
<li>云提供商通过<strong>调配资源</strong>来部署和执行 DL 工作负载（封装为 DL 作业），作为其服务模式的一部分。</li>
<li>此类数据链路系统的一个重要目标是能够<strong>以资源高效的方式满足服务水平协议（SLA）和服务质量（QoS）标准</strong>。由于 <strong>GPU 利用率不足</strong>，确保此类 SLA 和 QoS 保证的努力面临挑战。<ul>
<li>这是由于 Kubernetes 和 YARN 等现有资源管理器<strong>禁止明确使用 GPU 共享</strong>（即只允许将单个 DL 作业分配给每个 GPU）。</li>
<li>这种利用不足会降低性能、资源效率和服务可用性，导致排队时间延长，需要额外的 GPU 设备来满足需求。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>虽然在同一 GPU 上共定位 DL 作业已被证明是有效的，但这会产生干扰，导致速度减慢。<ul>
<li>1）<strong>共同定位 DL 作业</strong>（co-locate DL jobs，即在同一 GPU 上执行）的能力已被确定为解决利用率不足问题的一种手段。<ul>
<li><strong>特点：</strong>这种共同定位的有效性基于对 DL 工作负载 GPU <strong>利用模式</strong>的充分了解。</li>
<li><strong>优势：</strong>对于提供商而言，这有助于做出高质量的 DL 系统调度和共址决策，从而减少 GPU 资源利用不足的情况。</li>
<li><strong>挑战：</strong>了解并利用 DL <strong>工作负载的利用率</strong>来改进共同定位对于设计资源节约型 DL 系统至关重要。</li>
<li><strong>缺点：</strong>虽然共同定位可以提高 GPU 利用率，但也会产生<strong>性能干扰</strong>（我们称之为干扰），导致不同共同定位组合的 DL 作业平均减慢 18%。</li>
</ul>
</li>
<li>2）然而，用于<strong>描述 DL 工作负载的 GPU 利用率的现有方法</strong>利用的是执行过程中的<strong>在线剖析</strong>。<ul>
<li><strong>特点：</strong>在线剖析需要在<strong>独立</strong>的 GPU（或<strong>专用</strong>机器）上执行每个独特的 DL 作业，以确保准确的指标收集。</li>
<li><strong>缺点：</strong>由于需要<strong>预留 GPU 设备</strong>，这种在线剖析导致服务可用性和资源效率降低：鉴于<strong>不同模型架构和配置的数量不断增加</strong>，这个问题日益严重。</li>
</ul>
</li>
<li>3）虽然现在已有<strong>允许共定位的 DL 资源管理器</strong>。<ul>
<li><strong>缺点：</strong>但人们较少关注在放置决策过程中积极解决共享同一 GPU 的 DL 作业之间的<strong>干扰</strong>问题。不良的 DL 作业放置会导致更高的作业间隔（makespan）、更长的作业完成时间（JCT）、作业驱逐以及 GPU 内存不足（OOM）错误导致的作业失败。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>在本文中，我们介绍了 Horus：一种<strong>基于预测</strong>的 DL 系统<strong>干扰感知</strong>资源管理器。<ul>
<li>与现有方法不同的是：<ul>
<li>当前的方法是预留独立 GPU 以执行在线剖析，并直接测量每个已提交作业的 GPU 利用率。</li>
<li>Horus 会根据<strong>未见过的 DL 作业</strong>的模型特征主动预测其 GPU 利用率，我们的调度器会利用这些特征来确定合适的 DL 作业共定位组合，以最大限度地减少干扰。<ul>
<li>可根据 DL 模型的计算图特征，主动预测异构 DL 作业的 GPU 利用率，从而无需在线剖析和隔离预留 GPU。通过在异构 GPU 硬件上进行微基准测试和作业共同定位组合，我们将 GPU 利用率确定为一个通用代理指标，以确定良好的定位决策。</li>
<li>我们的方法<strong>避免了对内核模式进行剖析</strong>，<strong>避免了对底层 DL 框架的修改</strong>，也<strong>不需要在调度程序运行时对需要隔离 GPU 的作业执行情况进行广泛的在线剖析</strong>–所有这些都既昂贵又耗时。</li>
</ul>
</li>
</ul>
</li>
<li>我们提供了三项具体的研究成果：<ul>
<li>1）<strong>描述因共用位置而产生的 DL 工作负载干扰</strong>。我们对异构 GPU 硬件架构中超过 600 种独特的共定位 DL 作业组合的干扰特征进行了分析。研究结果表明，DL 作业共定位干扰会导致高达 2.4 倍-3.4 倍的速度减慢，与分布式训练的网络局部性不相上下。</li>
<li>2）<strong>针对 DL 工作负载的 GPU 利用率分析和预测引擎</strong>。通过一系列基准测试，我们分析并确定了 DL 模型的关键特征及其与 GPU 利用率的关系。这些特征包括每秒浮点运算次数（FLOPs）、输入数据大小和 DL 计算图结构（如卷积层数）。我们提出的预测引擎可实现亚秒级的 DL 作业 GPU 利用率预测，而无需进行在线剖析。</li>
<li>3）干扰感知 DL 资源管理器。利用我们的预测引擎，我们提出了一种可感知干扰的资源管理器，该资源管理器支持共同定位并最大限度地减少 GPU 过度承诺。我们的方法提供了两种可供选择的调度算法，它们优先考虑最小化作业时间跨度或提高公平性，以避免作业饥荒–降低作业等待时间的中位数，但代价是作业时间跨度和利用率的边际下降。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/8b67d9535efd60194d37f6c76b67d53bd8015be5/5-Figure5-1.png" alt="架构"><figcaption>架构</figcaption></figure></p>
<ul>
<li>我们在先前工作的基础上进行了扩展：<ul>
<li>1）将 DL 工作负载<strong>特征研究的范围从 81 个模型扩大到 292 个模型</strong>；</li>
<li>2）<strong>捕获了更多 GPU 架构和 600 多个共定位配置文件</strong>用于分析和建模，提高了 GPU 预测模型的准确性；</li>
<li>3）并通过对生产集群进行跟踪驱动模拟，对 Horus 进行了大规模评估。</li>
<li>4）Horus 框架也进行了重新设计，纳入了一种改进的<strong>公平排队调度算法</strong>，以最大限度地降低成本目标。</li>
<li>5）最后，<strong>评估</strong>还使用了一组<strong>额外</strong>的工作负载组合和一种额外的共同定位<strong>算法进行比较</strong>。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>资源管理器被集成到 Kubernetes 中并部署在一个 DL 集群中，并通过对生产型 DL 集群的跟踪驱动模拟进行了大规模评估。<ul>
<li>结果表明，与现有方法相比，我们的方法使 GPU 集群的利用率提高了 32-61.5%，时间跨度降低了 23.7-30.7%，在缩短作业等待时间方面比其他 DL 资源管理器高出 68.3%。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>预测的难点在哪里？是以前人都没考虑？如果只是这样的话，难度如何体现？本方法巧妙的点在什么地方？</li>
<li>干扰的本质原因是什么？论文没有显式提炼出insight。</li>
<li>引言说K8S不支持GPU共享，但实验中又说基于K8S</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9428512">[1] G. Yeung, D. Borowiec, R. Yang, A. Friday, R. Harper and P. Garraghan, “Horus: Interference-Aware and Prediction-Based Scheduling in Deep Learning Systems,” in IEEE Transactions on Parallel and Distributed Systems, vol. 33, no. 1, pp. 88-100, 1 Jan. 2022, doi: 10.1109/TPDS.2021.3079202.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>预测</tag>
        <tag>机器学习</tag>
        <tag>干扰</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记7-前沿-基于图的工作流卸载</title>
    <url>/2023/05/30/literature/literatureNotes7/</url>
    <content><![CDATA[<h1 id="x1f4d6-《A-Novel-Graph-Based-Computation-Offloading-Strategy-for-Workflow-Applications-in-Mobile-Edge-Computing》"><a href="#x1f4d6-《A-Novel-Graph-Based-Computation-Offloading-Strategy-for-Workflow-Applications-in-Mobile-Edge-Computing》" class="headerlink" title="📖《A Novel Graph-Based Computation Offloading Strategy for Workflow Applications in Mobile Edge Computing》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《A Novel Graph-Based Computation Offloading Strategy for Workflow Applications in Mobile Edge Computing》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>移动边缘计算（MEC）正被越来越多研究者关注。<ul>
<li>随着各种智能终端设备计算能力的不断提高，越来越多的智能应用部署在智能物流等移动终端设备上。同时，终端设备提交的大量计算请求可以卸载到云数据中心。但是，带宽有限的公共网络会导致明显的延迟，这对于许多延迟敏感的应用程序来说是不可接受的。如今，移动边缘计算（MEC）已被广泛用于提供从网络边缘到终端设备的计算资源，以减少响应延迟。终端设备上的计算任务可以卸载到边缘服务器，通过低成本和高带宽传输（如5G和WIFI网络）执行。计算卸载通过减少终端设备的响应延迟和能耗，在有效提高基于 MEC 的应用的服务质量 （QoS） 方面发挥着关键作用。</li>
</ul>
</li>
<li>随着移动边缘计算 （MEC） 的快速发展，对在边缘运行复杂应用程序的需求不断增加。这些复杂的应用程序可以表示为显式指定任务依赖项的工作流。<ul>
<li>例如，在基于UAV（无人机）的智能交付系统中，有许多复杂的应用，例如动态路线规划，障碍物检测和面部识别。</li>
<li>本文重点介绍以数据为中心的科学工作流。具体来说，表示为每个任务的输入数据或是否执行的任务依赖关系取决于前一个任务的执行结果。</li>
</ul>
</li>
<li>为了实现更好的服务质量（QoS），计算卸载在MEC环境中被广泛使用。<ul>
<li>例如，无人机受到其计算能力和电池寿命的限制，无法执行上述计算密集型任务。在MEC环境中，通过计算卸载技术可以有效降低无人机的能耗和任务响应时间。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，许多现有的计算卸载策略只关注独立的计算任务，而忽略了任务依赖关系。</li>
<li>一般来说，所有实际应用都可以用线性（即顺序）和非线性（即并行、选择性和迭代）结构工作流的混合来表示。它需要计算卸载策略应该能够同时处理线性和非线性结构。<ul>
<li>贪婪类型的策略已被广泛用于在短时间内获得可行的解决方案，但它们无法产生最佳的卸载决策。</li>
<li>为了提高决策的质量，许多研究采用粒子群优化（PSO）和遗传算法（GA）等搜索算法，通过迭代过程搜索最佳卸载决策，这可能会产生大量的时间开销。<ul>
<li>这些基于搜索算法的算法通常很耗时，因此不适合MEC中许多对时延敏感的复杂应用。</li>
</ul>
</li>
<li>目前，大多数计算卸载策略要么简单但不够好，要么太耗时而不适合对时滞敏感的复杂应用。</li>
</ul>
</li>
<li>因此，在我们最近的工作中提出了一种高效的基于图的策略，但它只能处理具有线性（即顺序）结构的简单工作流应用程序。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>该文针对MEC中的工作流应用提出了一种基于图分区技术的计算卸载策略。<ul>
<li>考虑了复杂任务依赖关系对计算卸载决策的影响，并在给定的期限约束下有效地优化了终端设备的能耗。<ul>
<li>请注意，本文不考虑边缘服务器的能耗。这是因为边缘服务器通常连接到电网，因此它们的能耗不被视为MEC环境中的限制因素。</li>
</ul>
</li>
<li>具体来说，<ul>
<li>这种策略可以处理具有非线性（即并行、选择性和迭代）结构的复杂工作流应用程序。</li>
<li>同时，利用基于图的划分技术，可以找到截止时间约束下终端设备能耗最低的卸载决策方案。</li>
</ul>
</li>
</ul>
</li>
<li>本文的贡献总结如下：<ol>
<li>该文针对基于MEC的复杂应用提出了一种新颖的非线性工作流程模型。该模型基于 WDG（工作流依赖关系图），它既考虑了复杂的任务依赖关系，又考虑了降低终端设备能耗的目标。</li>
<li>我们提出了一种基于WDG的新型基于图的计算卸载策略，名为Graph4Edge-非线性，该策略可以在给定的期限内以最小的终端设备能耗找到最佳的计算卸载决策。它的性能明显优于流行的基于搜索算法的策略。</li>
<li>介绍了真实世界无人机交付系统的案例研究，以及在基于MEC的工作流程应用的FogWorkflowSim平台上的广泛仿真实验。实验结果表明，所提策略的有效性，以及优于其他代表性策略的整体性能，特别是在策略运行时间方面。</li>
</ol>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们已经全面评估了我们在FogWorkflowSim平台上针对复杂工作流程应用程序的策略。大量数值结果表明，与PSO和GA相比，所提策略可有效降低终端设备能耗7.81%和9.51%。同时，策略运行时间分别为PSO和GA的1%和0.2%。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>具体使用了什么图划分算法？</li>
</ol>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9788058">[1] X. Li, T. Chen, D. Yuan, J. Xu and X. Liu, “A Novel Graph-Based Computation Offloading Strategy for Workflow Applications in Mobile Edge Computing,” in IEEE Transactions on Services Computing, vol. 16, no. 2, pp. 845-857, 1 March-April 2023, doi: 10.1109/TSC.2022.3180067.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>图论</tag>
        <tag>云计算</tag>
        <tag>调度</tag>
        <tag>边缘计算</tag>
        <tag>工作流</tag>
        <tag>卸载</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记70-前沿-跨多层级管理域容器迁移</title>
    <url>/2024/10/14/literature/literatureNotes70/</url>
    <content><![CDATA[<h1 id="x1f4d6-《UMS-Live-Migration-of-Containerized-Services-across-Autonomous-Computing-Systems》"><a href="#x1f4d6-《UMS-Live-Migration-of-Containerized-Services-across-Autonomous-Computing-Systems》" class="headerlink" title="📖《UMS: Live Migration of Containerized Services across Autonomous Computing Systems》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《UMS: Live Migration of Containerized Services across Autonomous Computing Systems》</h1><p>2023 年 拉斐特路易斯安那大学（Louisiana）团队 发表于 CCF-C 类会议 GLOBECOM（短论文）。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>部署在边缘和云等各种计算系统中的容器化服务需要实时迁移支持，以实现用户移动性、弹性和负载平衡。<ul>
<li>基于智能物联网的系统中的应用，如辅助技术和自动驾驶汽车中的应用，往往需要<strong>低延迟限制</strong>才能实现其目标。这就是<strong>边缘计算</strong>出现的原因，它可以绕过网络瓶颈，将计算带到用户（数据）附近，从而满足延迟限制。</li>
<li>然而，边缘计算固有的资源短缺和缺乏弹性的问题，催生了一种新的分布式计算范式，这种范式基于<strong>连续的层级运行</strong>，可包括边缘、雾和云系统。为了克服边缘弹性不足的问题，在<strong>从边缘到云的连续统一体</strong>中进行实时服务搬迁（即服务迁移）的能力至关重要。</li>
<li>此外，实现服务迁移还有助于克服现代分布式系统长期面临的其他挑战，如<strong>用户移动性</strong>、<strong>供应商锁定</strong>、<strong>能效</strong>、<strong>负载平衡</strong>和<strong>实现多云</strong>等。<ul>
<li>1）作为一个<strong>示例用例</strong>，可以考虑：<ul>
<li>将一副智能眼镜与边缘-云连续体一起使用，通过识别障碍物和检测接近物体的实时服务为盲人和视障人士提供环境感知。在我们希望创造的未来假设场景中，<ul>
<li>一位盲人<strong>走进</strong>一家咖啡店，店里的人正在利用资源有限的内部边缘服务器玩一款<strong>在线游戏</strong>。为了为盲人的辅助服务获取资源，必须将游戏服务迁移到云端，同时<strong>不对游戏玩家造成任何重大影响</strong>。</li>
<li>当残疾人<strong>离开时</strong>，就会发生反向迁移。打个比方，这就像在公共交通系统中为残疾人保留优先座位一样。</li>
</ul>
</li>
</ul>
</li>
<li>2）实时服务迁移的另一个动机用例是通过跨多云（即从一个云提供商迁移到另一个云提供商）无缝迁移服务来<strong>避免供应商锁定</strong>。</li>
</ul>
</li>
<li>由于 DevOps 和 CI/CD 等现代软件工程方法主要利用容器和容器编排器（如 Kubernetes）进行服务部署，因此实现服务迁移的关键在于实现<strong>容器化服务</strong>在计算系统间的实时迁移。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/cb80a50066fa8444390f2ef689e9d00c29d94051/2-Figure1-1.png" alt="图1"><figcaption>图1</figcaption></figure></p>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>为了实现这种无处不在的高效服务迁移，实时迁移解决方案需要处理用户对底层计算系统<strong>拥有不同权限级别（完全控制、有限控制或无控制）</strong>的情况。支持这些级别的实时迁移是互操作性的基石，并能在各种形式的分布式系统中释放出多种用例。<ul>
<li>有人可能会说，要迁移容器化服务，我们只需要<strong>对服务容器进行检查点、转移和还原</strong>。的确，在高层次上，这是一个有效的论点，容器可以在源端透明地进行检查点，然后传输到目的地。<ul>
<li>但问题是，容器恢复后，目的地编排器<strong>无法识别和采用容器</strong>，也就无法提供任何管理设施（如扩展）。</li>
</ul>
</li>
<li>目前解决这一问题的方法是对底层计算系统的平台<strong>进行侵入式更改</strong>。<ul>
<li>虽然侵入式方法通常效率较高，因为它们带来的<strong>迁移开销较低（轻量级）</strong>，</li>
<li>但不同的计算系统通常是<strong>自主控制</strong>的，系统管理员<strong>无权</strong>同时修改源系统和目标系统。</li>
<li>此外，这些系统有可能采用<strong>不同的编排器</strong>（如 Kubernetes 和 Mesos），而现有的作品只在<strong>同类编排器</strong>之间执行迁移，这就限制了迁移的可用性，并产生了<strong>供应商锁定</strong>的影响。</li>
</ul>
</li>
<li>据我们所知，目前还没有人尝试过基于容器级迁移方法<strong>在编排器级别进行迁移</strong>，没有一种实时服务迁移解决方案能做到两全其美：<ul>
<li>(i) 在自治系统和异构编排器之间无处不在地运行；</li>
<li>(ii) 保持迁移效率。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了实现这种无处不在的高效服务迁移，我们在本文中开发了无处不在的迁移解决方案（Ubiquitous Migration Solution，UMS），它可根据用户对底层计算系统的不同授权级别提供迁移服务：<ul>
<li>(A) <strong>完全控制</strong>：允许在源系统和目标系统的平台级别上进行更改；</li>
<li>(B) <strong>有限控制</strong>：只允许更改两个系统中的服务映像；</li>
<li>(C) <strong>无控制</strong>：不允许对底层系统进行任何更改。</li>
</ul>
</li>
<li>UMS 作为一个总括解决方案，涵盖了与上述权限级别相对应的以下三种迁移方法：<ul>
<li>(A) <strong>编排器级</strong>迁移方法，要求对源系统和目标系统进行完全控制，以便对其编排器进行更改；<ul>
<li>需要：将源系统和目标系统的<strong>编排器配置为完全兼容</strong>。更具体地说，应将编排器配置为调用底<strong>层容器运行时</strong>使用的<strong>相同检查点/恢复和同步模块</strong>。虽然这种方法具有侵入性，但它能使容器在无需任何修改的情况下高效迁移。</li>
<li>我们：<ul>
<li>1）为实现无共享存储的容器化服务迁移，开发了一个新的<strong>同步模块</strong>，用于接收迁移请求中的目标地址，并将<strong>检查点文件传输</strong>到该地址。</li>
<li>2）为减少迁移开销，我们将同步模块设置为与容器检查点和文件传输步骤重叠，即<strong>文件传输步骤无需等待检查点步骤完成即可开始</strong>。这是通过监控文件系统中的写入事件并将更改的内容复制到检查点文件来实现的。</li>
</ul>
</li>
</ul>
</li>
<li>(B) <strong>服务级</strong>迁移方法，只要求对服务容器映像进行有限的控制更改；<ul>
<li>需要：在没有编排器配合的情况下在服务级运行，必须在容器中嵌入检查点/还原和同步模块。因此，只需在目的地的另一个容器中对服务内存足迹进行检查点和还原，而无需迁移整个容器。<ul>
<li>不过，我们注意到，这种方法要求开发人员在源系统和目标系统中都构建一个<strong>可迁移的容器映像</strong>。此外，这种方法还需要<strong>开发人员参与实时迁移</strong>的细节。</li>
</ul>
</li>
<li>我们：<ul>
<li>采用了现有的服务级迁移解决方案，即 FastFreeze 容器，并对其进行了扩展，以便与编排器协同工作。</li>
</ul>
</li>
</ul>
</li>
<li>(C) <strong>容器级</strong>迁移方法，不要求对底层系统或服务进行任何控制。<ul>
<li>需要：<ul>
<li>1）一种非侵入式方法，以自给自足的方式执行实时迁移。</li>
<li>2）然而，仅凭这种能力并不能解决服务迁移问题，因为在迁移时，目标编排器<strong>无法识别并逃避管理迁移的服务容器</strong>。</li>
</ul>
</li>
<li>我们：<ul>
<li>1）利用容器运行时独立于编排器执行容器检查点/恢复的能力。</li>
<li>2）将可迁移容器<strong>嵌套在外层容器中</strong>。一方面，外层容器与目的地编排器保持绑定，另一方面，外层容器作为嵌套容器托管迁移服务。</li>
<li>如下图第3部分所示，外层容器包括容器运行时（如 Docker 引擎）、检查点/恢复模块（如 CRIU）和同步模块。<ul>
<li>源代码中的这种安排使外层容器能够将其嵌套容器迁移为目的地中对等外层容器的嵌套容器，而无需任何编排者的参与。</li>
<li>值得注意的是，嵌套容器只是一个普通容器，没有任何具体调整，由外部容器进行管理（例如，在资源使用跟踪方面）。</li>
<li>为了实现容器嵌套的想法，我们采用了 Docker 中的 Docker，这是一个 Docker 引擎，并将其部署在外层容器内。</li>
<li>为了在不跨系统共享存储的情况下同步检查点文件，我们采用了与编排器级方法相同的方法。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>支持多种迁移方法给 UMS 带来了挑战，即:<ul>
<li>(A) 如何<strong>透明地检测底层容器的结构</strong>，并采用适当的迁移方法。</li>
<li>(B) 此外，为了支持异构编排器，UMS 必须能够<strong>编排</strong>源系统和目标系统之间的<strong>迁移</strong>，而<strong>不论其底层平台</strong>如何。</li>
<li>(C) 除此之外，UMS 还必须为迁移<strong>选择合适的容器</strong>。</li>
</ul>
</li>
<li>为了处理所有这些复杂问题，我们将 UMS 设计成一个多层次的系统，使其能够从迁移编排挑战和核心迁移过程中抽象出决策方面的问题。<ul>
<li>UMS 不会干扰编排器处理容器的方式，并能在编排器不参与的情况下编排迁移。</li>
<li>此外，UMS 与编排器无关，即可以插入任何底层编排器平台。</li>
<li>UMS 配备了新颖的方法，可以在编排器、容器和服务层面编排和执行实时迁移。</li>
</ul>
</li>
<li>总之，本文做出了以下贡献：<ul>
<li><ul>
<li>开发<a class="link" href="https://github.com/hpcclab/NIMS">UMS框架<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>，该框架可在具有潜在异构编排器的自主计算系统中实现容器化服务的无缝、轻量级实时迁移。</li>
</ul>
</li>
<li><ul>
<li>开发在编排器、容器和服务层面运行的容器实时迁移方法。</li>
</ul>
</li>
<li><ul>
<li>证明在异构编排器（Kubernetes、Mesos、K3S 和 Minishift）之间以及微软 Azure 和谷歌云之间实时迁移容器化服务的可行性。我们还分析了不同迁移方法的开销。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/cb80a50066fa8444390f2ef689e9d00c29d94051/4-Figure3-1.png" alt="图2"><figcaption>图2</figcaption></figure></p>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>实验结果表明，对于单进程容器，采用服务级方法；对于内存占用较小（&lt; 128 MiB）的多进程容器，采用容器级迁移方法，迁移开销和服务停机时间最低。为了证明 UMS 在实现互操作性和多云场景方面的潜力，我们测试了 UMS 在异构编排器之间以及 Microsoft Azure 和 Google Cloud 之间执行实时服务迁移的能力。</li>
<li>结果表明，UMS 可以在任意两个计算系统之间执行低开销的服务迁移。我们得出的结论是，尽管服务级方法是最轻量级的，但对于权限不足的多进程容器，其性能会下降。我们还演示了 UMS 在异构编排器之间执行容器迁移的用例，以实现多云的理念。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>本文只设计了“已知迁移源与目标后的”迁移系统，没有自动决策模块，也没有设计决策所需的信息获取模块。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>案例中为什么能够“不对游戏玩家造成任何重大影响”？按理解游戏类型的应用一旦迁移到云则会产生较大的用户体验影响。是否有其他更合适的案例？</li>
<li>核心逻辑：云边协同场景中，为了应对用户移动性、供应商锁定等问题，需要实时迁移 -&gt; 容器是现有主流基础设施，因此本文考虑容器 -&gt; 调度器对不同集群所拥有的管理权限不同、不同集群底层管理平台不同，因此需要有适应于“完全控制”、“有限控制”、“无控制”三种情况的迁移方法 -&gt; 带来三大难点：检测权限、异构管理平台兼容、迁移目标选择</li>
<li>具体咋做的迁移？在摘要中没有提及方法或核心思想</li>
<li>没有完全控制权限的前提下需要使用哪些信息？是否有取舍？</li>
<li>“编排器级”、“服务级”、“容器级”分别代表什么含义？</li>
<li>FastFreeze是用来干啥的？如何运转？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a href="">[1] 论文引用</a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>迁移</tag>
        <tag>跨管理域</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记71-前沿-多进化算法结合</title>
    <url>/2024/10/16/literature/literatureNotes71/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Multi-Swarm-Co-Evolution-Based-Hybrid-Intelligent-Optimization-for-Bi-Objective-Multi-Workflow-Scheduling-in-the-Cloud》"><a href="#x1f4d6-《Multi-Swarm-Co-Evolution-Based-Hybrid-Intelligent-Optimization-for-Bi-Objective-Multi-Workflow-Scheduling-in-the-Cloud》" class="headerlink" title="📖《Multi-Swarm Co-Evolution Based Hybrid Intelligent Optimization for Bi-Objective Multi-Workflow Scheduling in the Cloud》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Multi-Swarm Co-Evolution Based Hybrid Intelligent Optimization for Bi-Objective Multi-Workflow Scheduling in the Cloud》</h1><p>2022 年 北理工大学团队 发表于 CCF-A 类期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>许多科学应用都可以很好地模拟为大规模工作流。<strong>云计算</strong>已成为托管和执行这些<strong>工作流</strong>的合适平台。<ul>
<li>科学应用通常以工作流的形式呈现。<ul>
<li>它们通常规模庞大，包含<strong>数百或数千个关系复杂的任务</strong>，这就进一步要求具有强大计算和存储能力的庞大基础设施来处理这些应用。</li>
</ul>
</li>
<li>如今，云计算因其弹性和异构性而成为一种前景广阔的分布式计算图。<ul>
<li>在云计算中，用户可以按需动态请求服务，而无需自行购买和维护本地物理机器。因此，越来越多的科学工作流正在过渡到或已经转移到云平台上执行。</li>
</ul>
</li>
</ul>
</li>
<li>近年来，<strong>工作流调度</strong>备受关注。<ul>
<li>云计算中的工作流调度是将工作流中的每个任务分配给合适的资源，以满足某些性能标准。云服务提供商（CSP）可以以不同的价格为不同能力的用户提供各种几乎无限的虚拟化资源。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/a3d44c4b9c5e4c84509ac96f670c5f973395d019/3-Figure1-1.png" alt="图1"><figcaption>图1</figcaption></figure></li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，由于云服务提供商必须为<strong>具有不同 QoS 需求</strong>的<strong>多个用户</strong>提供服务，因此对具有不同 QoS 需求的多个应用进行调度极具挑战性。<ul>
<li>通常情况下，租用<strong>更多资源或更昂贵的资源</strong>会缩短<strong>执行时间</strong>，但会增加<strong>成本</strong>。因此，由于云计算中的按使用付费模式，工作流调度的时间和成本都备受关注，这样的调度问题可以被模拟为<strong>多目标优化问题（MOP）</strong>。</li>
<li>在现实调度情况下，会有<strong>越来越多</strong>的云用户在一段时间内向云提交各种工作流，这对数据中心的响应能力提出了更高的要求。因此，云数据中心必须以<strong>批量/并行模式处理多个</strong>工作流，以满足多个用户的 QoS 要求。</li>
<li>因此，很难找到一种合适的多工作流调度算法，以优化所有工作流的执行时间和成本，同时确保每个用户所需的 QoS 要求。</li>
</ul>
</li>
<li>受人类智慧、社会或生物实体自然现象的启发，<strong>依赖于随机搜索技术的智能优化</strong>是一种广泛应用于处理MOP的方法。<ul>
<li>它往往具有突出的全局优化能力和较强的通用性，适合迭代进化。<ul>
<li>近年来，粒子群优化（Particle Swarm Optimization，PSO）、遗传算法（Genetic Algorithm，GA）、模拟退火（Simulated Annealing，SA）等在解决云计算工作流调度问题中发挥了主导作用。<ul>
<li>PSO 具有强大的社会学习机制，<strong>收敛速度快</strong>，而且<strong>易于实现</strong>，只需调整很少的参数。然而，PSO 在演化过程中很容易<strong>陷入局部最优</strong>状态，因此缺乏局部搜索技术。</li>
<li>SA 能够通过概率降低解的质量来<strong>解决陷入局部最优</strong>的问题，但它<strong>缺乏快速收敛能力</strong>。</li>
<li>GA 在<strong>多样性</strong>保持方面表现良好，但<strong>收敛速度较慢</strong>，找到全局最优的<strong>时间</strong>也比其他算法<strong>长</strong>。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了克服上述缺点并充分发挥它们的优势，本研究提出了一种基于多群协同进化的混合智能优化（MCHO）算法，用于多工作流调度，在满足每个工作流的截止日期约束的同时，最大限度地减少总工作时间和成本。<ul>
<li>1）首先，我们设计了一种<strong>基于MPMO框架的多蜂群协同进化机制</strong>，采用<strong>三个蜂群</strong>来充分搜索各种精英解决方案，其中<strong>第一蜂群</strong>和<strong>第二蜂群</strong>分别专注于<strong>工期和成本的优化</strong>，而新引入的<strong>第三蜂群</strong>则<strong>兼顾</strong>两个目标，使三个蜂群集中搜索不同的非优势解，增加了精英个体的多样性。</li>
<li>2）其次，为了提高全局搜索和收敛性能，我们在PSO粒子群优化器的<strong>更新过程</strong>中<strong>嵌入了局部和全局指导信息</strong>，引入全局档案和局部档案中的精英个体，分别对粒子进行全局和局部引导；并开发了一种<strong>群合作技术</strong>，进一步提高了其收敛性和全局搜索能力。</li>
<li>3）第三，我们提出了一种基于遗传算法的<strong>精英增强策略</strong>，即对每个蜂群局部档案中的<strong>优势个体进行遗传操作</strong>，以利用更多的精英个体，扩大找到更多解的可能性，从而提高解的质量；并应用模拟退火的 <strong>Metropolis Acceptance 规则更新每个蜂群的局部指导解</strong>，通过概率接受局部档案中的劣质个体来更新局部指导解，以防止蜂群在早期阶段陷入局部最优，从而帮助 MCHO 摆脱局部最优状态。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>大量实验结果表明，MCHO 的分布式非优势解优于最先进的调度算法。<ul>
<li>MCHO 的性能通过与 NSGA-II、ECMSMOO 和 MOACS 这三种同类算法的比较得到了验证。</li>
<li>最终结果表明，MCHO 在解决方案的数量和优势方面都优于同行。它获得的 PFs 明显优于 NSGA-II 和 ECMSMOO。虽然 MOACS 与 MCHO 在小规模数据集上的表现相似，但我们的方法所得到的解决方案在 MOACS 为大规模数据集找到的解决方案中占据了多数优势。因此，MCHO 可以有效地解决双目标多工作流调度问题。</li>
</ul>
</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>作为未来的工作，我们计划：<ul>
<li>1）处理更复杂的问题场景，如具有<strong>各种资源供应模式</strong>的混合云；</li>
<li>2）开发我们的算法，以应对<strong>考虑能耗的三目标优化</strong>问题；</li>
<li>3）研究如何将<strong>基于关键路径的启发式算法产生的初始解</strong>添加到我们的算法中；</li>
<li>4）在包含<strong>更多类型、更大规模</strong>科学工作流的数据集上评估我们的算法；</li>
<li>5）在优化多目标工作流调度时<strong>应用基于支配关系或分解的方法</strong>；</li>
<li>6）研究其他更有效的<strong>局部搜索方案</strong>，以提高 MCHO 的性能。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>根据摘要，需求是多用户异构QoS工作流，看起来没有很特别的挑战。挑战具体是什么？如何更好地定位需求提出挑战？<ol>
<li>同时存在大量用户的大量异构复杂工作流请求，同时优化困难。（感觉听起来没有很难，没体现出定量或定性的特点）</li>
<li>现有元启发式算法有陷入局部最优或求解效率低的问题，因此需要兼顾二者。（怎么样算高？怎么样算低？元启发式算法整体都很慢，如何判断是否满足需求？）</li>
</ol>
</li>
<li>没说清楚挑战的结果就是，看起来仅仅把不同方案杂揉在一起，没感觉到很难、很新、很亮。也没有针对大规模复杂工作流的特点设计独特机制。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9585437">[1] H. Li, D. Wang, M. Zhou, Y. Fan and Y. Xia, “Multi-Swarm Co-Evolution Based Hybrid Intelligent Optimization for Bi-Objective Multi-Workflow Scheduling in the Cloud,” in IEEE Transactions on Parallel and Distributed Systems, vol. 33, no. 9, pp. 2183-2197, 1 Sept. 2022, doi: 10.1109/TPDS.2021.3122428.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>进化算法</tag>
        <tag>元启发式算法</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记72-前沿-动态概率建模指导的复杂工作流调度</title>
    <url>/2024/10/17/literature/literatureNotes72/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Taming-System-Dynamics-on-Resource-Optimization-for-Data-Processing-Workflows-A-Probabilistic-Approach》"><a href="#x1f4d6-《Taming-System-Dynamics-on-Resource-Optimization-for-Data-Processing-Workflows-A-Probabilistic-Approach》" class="headerlink" title="📖《Taming System Dynamics on Resource Optimization for Data Processing Workflows: A Probabilistic Approach》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Taming System Dynamics on Resource Optimization for Data Processing Workflows: A Probabilistic Approach》</h1><p>2022 年 深圳大学团队 发表于 CCF-A 类期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>在许多数据密集型应用中，工作流通常被用作组织数据处理任务的重要模型，而资源调配则是提高工作流性能的一个重要且具有挑战性的问题。<ul>
<li>在许多<strong>数据密集型应用</strong>中，数据处理工作通常被建模为<strong>工作流</strong>，工作流是根据数据和计算依赖关系连接起来的任务集。<ul>
<li>例如，Montage 工作流是一个与天文学相关的大数据应用，它处理的天空马赛克数据规模高达数百 GB。</li>
<li>Facebook、雅虎和谷歌等大公司经常基于 MapReduce工作流，对 PB 级数据执行临时查询和定期批处理作业。</li>
<li>这些数据密集型工作流通常在大型系统（如用于科学应用的高性能计算机和用于工业应用的公共/私有云）中执行，而<strong>资源配置</strong>决定了执行工作流任务的资源规模和类型，是工作流性能的重要优化因素。</li>
</ul>
</li>
</ul>
</li>
<li>最近，人们观察到云和大规模集群中的系统变化，如 I/O 和网络性能的变化以及故障事件的变化，会极大地影响工作流的性能。<ul>
<li>在许多大型系统中，<strong>变化</strong>已成为常态而非例外。造成变化的原因既有<strong>硬件方面</strong>的，也有<strong>软件方面</strong>的。例如，<ul>
<li>在超级计算机架构中，<strong>芯片的功率和温度变化</strong>可导致处理器之间的性能差异高达 16%。</li>
<li>在云环境中，由于多个用户之间的<strong>资源共享</strong>，网络和 I/O 性能也会出现显著变化。</li>
<li><strong>作业故障</strong>已被证明是多种多样的，不同系统（如高性能计算、集群和云）遵循不同的概率分布。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，由于工作流结构复杂，资源调配一直是数据处理工作流的一个难题，现有工作已对此进行了广泛研究。</li>
<li>但传统的资源调配方法会<strong>忽略</strong>大型系统中的这些<strong>变化</strong>，导致资源调配结果不理想。</li>
<li>为什么要<strong>考虑变化</strong>？<ul>
<li>云提供商通常会提供各种类型的实例（即虚拟机），供用户选择最合适的资源来执行工作流任务。大多数现有的资源调配方法都<strong>假设</strong>每个任务在给定类型的虚拟机上的<strong>执行时间是静态的</strong>。<ul>
<li>1）然而，这一假设在云中并不成立，已有研究发现<strong>云的动态变化</strong>（如 I/O 和网络性能的变化）会导致<strong>大规模数据处理工作流的性能发生重大变化</strong>。传统的资源调配方法会忽略这些差异值，从而导致<strong>次优</strong>的资源调配结果。</li>
<li>2）我们分析了工作流的几个常见资源调配问题，发现性能优化目标通常与 I/O 和网络性能的云动态<strong>非线性相关</strong>。因此，传统的<strong>静态优化</strong>（例如，将平均或预期性能作为优化输入）可能会导致次优甚至不可行的解决方案。例如，要利用检查点优化工作流性能，我们必须考虑<strong>系统故障动态</strong>（更多详情见第 6 节）。</li>
</ul>
</li>
<li>利用谷歌云的生产跟踪和亚马逊 EC2 的性能跟踪，我们发现在超过 60% 的时间里，动态感知方法比静态方法能获得更好的性能优化结果。</li>
</ul>
</li>
<li>为什么<strong>采用概率方法</strong>？<ul>
<li>现有研究提出了各种方法，如动态调度和随机建模等，以解决<strong>考虑云动态的资源调配问题</strong>。</li>
<li>然而，这些方法要么依赖于运行时<strong>精确的云性能估计</strong>（如动态调度），要么涉及<strong>复杂的建模和分析</strong>，因此<strong>难以推广</strong>（如随机方法）。</li>
</ul>
</li>
</ul>
<h2 id="🤺挑战"><a href="#🤺挑战" class="headerlink" title="🤺挑战"></a>🤺挑战</h2><ul>
<li>我们研究了一种将云动态纳入工作流资源优化的系统而有效的方法。我们建议<strong>将云动态建模为随机变量</strong>，并将其<strong>概率分布</strong>作为优化输入来制定资源调配问题。<ul>
<li>优点：这种设计有两大优势：<ul>
<li>1）首先，它实现了许多具有系统随机性的问题所需的<strong>概率分析</strong>，例如在系统随机故障的情况下为工作流设计容错调度技术。</li>
<li>2）其次，它可以推导出<strong>概率边界</strong>，以保证应用程序的最坏情况性能，而现有的静态方法只能保证平均性能。</li>
</ul>
</li>
<li>挑战：<ul>
<li>1）在云动态的概率表征下，传统的静态资源调配方法无法直接使用。主要的挑战在于，将概率分布作为资源调配问题的优化输入可能会导致<strong>高昂的计算开销</strong>，这是由于<strong>昂贵</strong>的分布计算和数据处理工作流的<strong>复杂结构</strong>造成的。</li>
<li>2）其他领域也有一些提高概率方法效率的优化技术，如概率数据库中的高效查询评估和硬件设计中的高效概率分析。然而，这些技术都<strong>没有考虑工作流结构</strong>和<strong>资源配置问题的特殊性</strong>，而这些特殊性有助于更有效地降低工作流概率资源配置的开销。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>本文以<strong>云计算中的工作流资源配置问题</strong>为例进行讨论，旨在提出一种<strong>将系统变化纳入工作流性能优化问题的通用解决方案</strong>。虽然讨论的重点是云，但我们猜想，这些观察结果可以为共享集群等其他系统提供启示（见第 7 节）。</li>
<li>在本文中，我们提供了一种考虑系统变化的工作流性能优化通用解决方案 Prob。<ul>
<li>具体来说，我们将系统动态建模为随时间变化的随机变量，并将其概率分布作为优化输入。尽管这种解决方案很有效，但计算开销很大。</li>
<li>因此，我们提出了三种剪枝技术，以简化工作流结构并减少概率评估开销。这些技术是根据工作流结构和资源配置问题的特点设计的。<ul>
<li>1）首先，我们发现计算工作流的<strong>有效期</strong>是许多工作流资源配置问题中的常见操作。因此，我们提出了预处理剪枝方法，以减少这一重要计算的开销，从而降低概率优化的开销。</li>
<li>2）其次，我们利用现有的<strong>工作流转换技术</strong>提出了针对工作流的优化方案，以减少评估一个实例配置解决方案的开销。</li>
<li>3）第三，我们提出了一种<strong>部分解决方案评估方法</strong>，并采用现有的剪枝技术，以减少比较多个解决方案的开销。</li>
</ul>
</li>
<li>我们在运行时库中实现了我们的技术，使用户能够将高效的概率优化纳入现有的资源调配方法。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/6718de1a347458ade4c3a9c4a281af0c25d09c79/8-Figure5-1.png" alt="系统实现图"><figcaption>系统实现图</figcaption></figure></li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>实验表明，与最先进的静态解决方案相比，概率解决方案最多可将性能提高 65%，而我们的剪枝技术可大大降低概率方法的开销。<ul>
<li>我们开发了一个运行时库，其中包含 Prob 的所有剪枝技术。用户可以使用 Prob API 实现其现有的资源调配方法，将概率优化纳入其中，从而提高现有方法的有效性和效率。</li>
<li>我们将<strong>预算受限调度</strong>和<strong>容错问题</strong>作为工作流资源优化问题的两个例子。我们利用两个<strong>真实云平台上</strong>的实际工作流和模拟，将 Prob 与最先进的静态算法进行了比较。实验结果证明了我们的概率方法的有效性和效率。<ul>
<li>具体来说，在预算受限的调度问题上，Prob 比静态算法提高了工作流性能的 2-65%，在容错问题上提高了 5-30%。Prob 的剪枝技术显著降低了我们的概率方法的开销（例如，与蒙特卡罗（MC）方法相比，速度提高了 567 倍）。因此，对于一个拥有 10,000 多个任务的蒙太奇工作流程来说，完成优化只需不到一秒钟的时间。</li>
</ul>
</li>
</ul>
</li>
<li>目标与非目标 Prob 的主要目标，也是本文的重点，是为现有的资源调配方法<strong>提出一个高效的接口</strong>，以便轻松纳入概率优化，而不是提出一种新的资源调配技术。<ul>
<li>为了展示 Prob 的通用性，我们使用工作流中两个常见的资源调配问题作为用例，并讨论 Prob 如何提高这两个用例的现有解决方案的有效性。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>基于概率的方法具体如何实现？是否会很依赖于人工建模？</li>
<li>如何定义“考虑变化”？预测本质上是否也是一种考虑概率变化的手段？</li>
<li>结合工作流结构和资源配置特殊性的概率建模是什么样的？是否能够凝练出一句话insight？</li>
<li>看起来最适应的场景是随机故障场景下的容错问题？如果不是随机概率场景，考虑概率可能反而会起到反作用？</li>
<li>核心逻辑：大型系统中存在大量软件与硬件导致的变化 -&gt; 现有研究无法感知动态变化，导致做出次优解 -&gt; 采用概率的方法无需准确预测，适用随机变化场景、并能够从理论上推导出最差边界，因此具有更高的适用性，但需要解决两大挑战：1.直接在传统静态资源配置方法基础上输入概率分布，会导致高昂的计算开销；2.在其他领域提高概率优化方法的手段没有考虑工作流和资源配置问题的特点，会导致较差的适用性 -&gt; 在传统方法的基础上，将系统动态建模为随时间变化的随机变量，并提出三大效率优化方案。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9462122">[1] A. C. Zhou, W. Xue, Y. Xiao, B. He, S. Ibrahim and R. Cheng, “Taming System Dynamics on Resource Optimization for Data Processing Workflows: A Probabilistic Approach,” in IEEE Transactions on Parallel and Distributed Systems, vol. 33, no. 1, pp. 231-248, 1 Jan. 2022, doi: 10.1109/TPDS.2021.3091400.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>工作流</tag>
        <tag>概率</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记73-经典-大规模网络函数请求可重用部署与流量调度</title>
    <url>/2024/10/18/literature/literatureNotes73/</url>
    <content><![CDATA[<h1 id="x1f4d6-《A-Scalable-Stateful-Approach-for-Virtual-Security-Functions-Orchestration》"><a href="#x1f4d6-《A-Scalable-Stateful-Approach-for-Virtual-Security-Functions-Orchestration》" class="headerlink" title="📖《A Scalable Stateful Approach for Virtual Security Functions Orchestration》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《A Scalable Stateful Approach for Virtual Security Functions Orchestration》</h1><p>2021 年 Shahid Beheshti University(SBU，前身为伊朗国立大学)团队 发表于 CCF-A 类期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>网络函数虚拟化（NFV）是一种通过<strong>虚拟化</strong>技术促进<strong>网络服务动态供应</strong>的模式。在这一场景中，网络服务可以通过具有虚拟化能力的硬件上的软件模块来实现，即虚拟网络函数（VNF）。</li>
<li>另一方面，软件定义网络（SDN）是对 NFV 的补充，可在虚拟函数之间提供<strong>动态流量工程和动态管理设施</strong>。这是通过转发功能的完全可编程性实现的。</li>
<li>入侵检测系统 (IDS)、防火墙 (FW)、深度包检测 (DPI)、流量监控、负载平衡器 (LB) 等软件中间件被广泛用于云中，以检测和反击攻击。它们<strong>根据云用户应用需求动态部署/销毁</strong>。<ul>
<li>例如，假设云用户有一个基于云的分布式应用，突然它的性能下降了。<ul>
<li>此时，可在云的不同位置部署多个 IDS 作为协同检测策略，以查看是否发生了分布式拒绝服务攻击。</li>
<li>作为缓解方案，我们可以部署一个负载平衡器来克隆分布式应用的某些组件，或者在云的边界部署几个 FW 来过滤某些流量。</li>
<li>一段时间后，如果流量正常，我们可以销毁所有创建的中间件、IDS、LB 和 FW。</li>
</ul>
</li>
</ul>
</li>
<li>请注意，在本文中，我们重点关注的是<strong>东西向流量</strong>，以确保<strong>不同应用的通信安全</strong>，并<strong>动态放置所需的中间件</strong>，如图所示。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/4d0fe231d7e28d57bccb812a2a08152b43b5f712/2-Figure1-1.png" alt="图"><figcaption>图</figcaption></figure></li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>以往的研究提出了不同的<strong>服务链实施</strong>方法。它们的目标是提高中间件的性能，满足云提供商和用户的期望。为了满足这些期望，需要考虑<strong>延迟因素</strong>（即通过低成本路径的流量）和<strong>最佳节点处理位置因素</strong>。<ul>
<li><strong>服务链</strong>由一系列中间件组成，流量必须<strong>按特定顺序</strong>通过中间件。一般来说，两个虚拟机之间的流量需要部署服务链，以管理用户请求、提高性能或增强安全性。<ul>
<li>由于云数据中心承载着<strong>成千上万</strong>的用户和应用程序，因此创建或删除服务链的<strong>实时性</strong>要求很高。因此，必须改善这些中间件的<strong>性能</strong>，提高<strong>服务质量</strong>。</li>
</ul>
</li>
<li>近年来，许多人都在努力<strong>优化中间件的放置</strong>，以满足策略执行（如服务链中的内联服务顺序）的要求。<ul>
<li>优化放置的<strong>两个主要目标</strong>是最大限度地减少<strong>流量端到端延迟</strong>和网络交换机上的处理成本。<ul>
<li><strong>端到端延迟</strong>是通过路径上所有链路的延迟总和。链路延迟可根据以下四个基本因素建模：<ul>
<li>i) 当前可用带宽；</li>
<li>ii) 已消耗带宽；</li>
<li>iii) 通过链路的流量转向数量；</li>
<li>iv) 每个转向流量的发送速率。</li>
</ul>
</li>
<li>此外，在网络中选择部署中间件的<strong>最佳节点处理位置</strong>还要考虑：<ul>
<li>i) 节点的可用空间（vCPU 和 vMem）；</li>
<li>ii) 资源消耗；</li>
<li>iii) 当前活动的中间件；</li>
<li>iv) 每个中间件的输入流量速率。</li>
</ul>
</li>
<li>我们认为，根据上述参数<strong>制定节点和边的成本</strong>需要独立的研究，超出了本文的范围。</li>
</ul>
</li>
<li>只考虑其中一个目标并不会导致另一个目标的实现。因此，需要同时考虑这两个目标。同时实现这<strong>两个目标</strong>会使中间件的最佳放置变成一个 NP 难问题。因此，当问题规模较大时，在合理的时间内获得最优解是不可行的。</li>
</ul>
</li>
</ul>
</li>
<li>之前的研究中没有考虑的另一个重要问题是<strong>接收到新请求时的有状态优化放置</strong>。由于资源限制以及客户的经济成本，不可能为所有请求创建功能。因此，不仅可以在新流量之间集成相同的网络功能，还可以在新的按需网络功能和现有功能之间进行检查。<ul>
<li>将类似函数结合起来会有很多好处。例如，我们可以降低安装成本或资源消耗，如 CPU 和内存或共享存储空间。</li>
<li>因此，非常重要的一点是，我们可以将安全函数拆分成几块，它们之间有相似的任务，这样我们就可以利用作业搭配的优势。</li>
<li>这可能会引起不同客户的担忧，但对于每个客户来说，都可以轻松应用拼凑策略。作业搭配操作既可以在新请求之间进行，也可以在新请求的安全函数和当前活动函数之间进行。</li>
<li>我们将我们的解决方案称为有状态配置，以区别于之前的工作。</li>
<li>一般来说，中间件放置问题本身就是一个 NP 难问题，尤其是最近的大多数研究成果都无法在大型网络中扩展。因此，对常见的放置问题采用有状态的方法，也会使当前的数据中心更难实时解决这个问题。有几种启发式方法被用来克服可扩展性问题。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>我们的最佳中间件放置方法同时考虑了这两个目标，即<strong>选择高效的交换机</strong>来部署中间件（服务部署），同时通过<strong>端到端延迟最小的链路</strong>来路由流量（流量调度）。除了之前的工作，我们还考虑了另一个目标，即在考虑可用的已部署中间件的情况下优化布局。为了实现这一目标，我们在请求的安全函数和当前函数之间执行了作业搭配操作。</li>
<li>我们提出的方法不仅可以减少创建对客户而言具有成本效益的网络功能，而且由于将以前的网络功能（与按需网络功能整合）迁移到优化新请求上，总体而言，它将随着时间的推移优化整个网络成本。我们将该问题表述为 0-1 编程问题。本文的结果基于一个胖树数据中心。为了证明我们的有状态解决方案在大型网络中的可扩展性，我们使用了网络分区和拓扑分区启发式方法。</li>
<li>总的来说，本文的主要贡献如下：<ul>
<li>1）与该领域的前人不同，我们的优化布局目标主要基于以下五个方面：<ul>
<li>i) 尽量减少端到端延迟；</li>
<li>ii) 尽量减少交换机处理成本；</li>
<li>iii) 通过将流量的安全函数配置在同一交换机上，尽量减少流量对网络的影响。这样，我们只需为网络中的每个流量支付一项成本（信息解析和所需的预处理），</li>
<li>iv) 尽量减少新请求中同类型安全函数的数量和相关成本。具体做法是在同一交换机上集成同一类型的功能，</li>
<li>v) 考虑到现有功能，降低创建新请求安全函数的成本。这可以通过检查当前部署的函数的当前容量并优化请求流量到该区域的路由，或将当前函数迁移到另一个最佳区域来实现。</li>
</ul>
</li>
<li>2）据我们所知，我们是第一个将服务链安置的有状态方法表述为 0-1 编程问题的人。尽可能防止创建新的请求安全函数。具体做法是检查整合同类安全函数的可能性。</li>
<li>3）安置问题的适用性对于大型网络来说非常重要。因此，我们采用了一些启发式方法（即限制旧函数迁移区域、限制新函数创建区域），我们的方法可以扩展到拥有 54K 个节点和 1.5M 条边的网络。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们的模拟结果表明，我们能够将我们的放置模型扩展到拥有 54K 个节点和 150 万条边的网络。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>未来，我们希望分析我们的模型，以最大限度地提高虚拟内容分发网络（CDN）中虚拟流媒体服务的体验质量。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>逻辑怪怪的，比较难懂。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9316976">[1] N. Moradi, A. Shameli-Sendi and A. Khajouei, “A Scalable Stateful Approach for Virtual Security Functions Orchestration,” in IEEE Transactions on Parallel and Distributed Systems, vol. 32, no. 6, pp. 1383-1394, 1 June 2021, doi: 10.1109/TPDS.2021.3049804.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>部署</tag>
        <tag>流量调度</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记74-经典-大规模调度冲突预防</title>
    <url>/2024/11/05/literature/literatureNotes74/</url>
    <content><![CDATA[<h1 id="x1f4d6-《A-Conflict-Prevention-Scheduling-Strategy-for-Shared-State-Scheduling-in-Large-Scale-Cluster》"><a href="#x1f4d6-《A-Conflict-Prevention-Scheduling-Strategy-for-Shared-State-Scheduling-in-Large-Scale-Cluster》" class="headerlink" title="📖《A Conflict Prevention Scheduling Strategy for Shared-State Scheduling in Large Scale Cluster》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《A Conflict Prevention Scheduling Strategy for Shared-State Scheduling in Large Scale Cluster》</h1><p>2016 年 云南大学团队 发表于会议 ICCCS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>随着大数据的增长，如今云计算集群的规模正在迅速扩大，以运行复杂的数据并行计算作业。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>在单体调度架构（如 Hadoop Fair Scheduler）中，提交给集群管理系统的所有作业<strong>只有一个调度器</strong>。<ul>
<li>然而，随着集群规模的扩大和更复杂的应用需求，单体调度器的高效调度成为<strong>可扩展性的瓶颈</strong>。</li>
</ul>
</li>
<li>因此，许多调度架构，如 Mesos、YARN、Omega、Sparrow、Apollo和 Borg、Tarcil，都提出了许多方法来克服这一挑战。谷歌目前的集群管理系统 Borg 采用了 Omega 的方法，该方法基于<strong>将整个集群状态共享给并行调度器</strong>以做出调度决策的概念，实现了高效灵活的调度。<ul>
<li>在共享状态调度架构中，至少有两个并行调度器负责寻找合适的机器来放置作业任务。这些并行调度器的调度算法需要考虑很多因素，如任务的约束条件、用户指定的偏好等。</li>
<li>由于调度员可以灵活选择调度策略，因此<strong>没有一种策略将缓解冲突作为调度目标</strong>。</li>
<li>然而，在这种架构中，由于调度决策是由并行调度员同时做出的，因此<strong>冲突是影响调度效率的主要因素</strong>。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>在本文中，我们为调度器提出了一种新的特定调度策略，以尽量避免并行调度器之间的冲突。本文的贡献如下：<ul>
<li><ol>
<li>我们为大型集群中的共享状态调度提出了一种新颖的<strong>冲突预防调度策略</strong>。据我们所知，这是第一项探索在共享状态调度架构中使用调度策略来减少调度器之间冲突的工作。</li>
</ol>
</li>
<li><ol start="2">
<li>防止冲突的调度策略有点类似于“二选一”负载均衡技术和 “多选一”方法。我们的策略<strong>不是通过探测机器</strong>来获取集群机器的负载信息，而是<strong>使用类似于单元状态的放置阵列</strong>来记录并发调度事务信息，以帮助调度员做出决策。</li>
</ol>
</li>
<li><ol start="3">
<li>我们重写了 Omega 的模拟器，并在模拟器中实现了提出的冲突预防调度策略。通过一系列实验来评估该方法的有效性。</li>
</ol>
</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们在 Omega 的模拟器中实施了这种新的策略，即冲突预防调度策略，结果发现它可以减少并行调度器之间的冲突，提高调度器的效率，尤其是显著提高了调度器放置长决策时间作业的效率。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>我们今后的工作可以把重点放在这些方面：<ul>
<li>1）即使我们提出了防止冲突的新调度策略，共享状态调度系统中的冲突依然存在。我们认为冲突与资源的使用密切相关，很难完全消除。在防止冲突的调度策略中，我们只是基于避免冲突来选择机器，而<strong>没有考虑其他调度目标</strong>，如尽量减少放弃任务的数量、选择已经有任务包副本的机器等。我们未来的工作将探索如何将我们的调度策略与Borg的评分机制结合起来。</li>
<li>2）此外，在本文中，我们只是重点提出了一个想法，但在实际调度系统中，如何给 m 和 d 赋值还需要进一步研究。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>多个调度器并行调度时，如何维护一致性的“放置阵列”？</li>
<li>本质上采用了Sparrow的多绑定策略，一次性做出多个决策，然后从中一一尝试。<ol>
<li>传统方法是失败后再重调度，而本方法是提前重调度。其中的取舍有待考量。</li>
</ol>
</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://link.springer.com/chapter/10.1007/978-3-319-48671-0_22">[1] He, L., Qiang, Z., Liu, L., Zhou, W., Yao, S. (2016). A Conflict Prevention Scheduling Strategy for Shared-State Scheduling in Large Scale Cluster. In: Sun, X., Liu, A., Chao, HC., Bertino, E. (eds) Cloud Computing and Security. ICCCS 2016. Lecture Notes in Computer Science(), vol 10039. Springer, Cham. https://doi.org/10.1007/978-3-319-48671-0_22<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>大规模</tag>
        <tag>状态共享</tag>
        <tag>冲突预防</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记75-经典-大规模调度冲突检测</title>
    <url>/2024/11/05/literature/literatureNotes75/</url>
    <content><![CDATA[<h1 id="x1f4d6-《An-extended-fine-grained-conflict-detection-method-for-shared-state-scheduling-in-large-scale-cluster》"><a href="#x1f4d6-《An-extended-fine-grained-conflict-detection-method-for-shared-state-scheduling-in-large-scale-cluster》" class="headerlink" title="📖《An extended fine-grained conflict detection method for shared-state scheduling in large scale cluster》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《An extended fine-grained conflict detection method for shared-state scheduling in large scale cluster》</h1><p>2016 年 云南大学团队 发表于会议 ICIIP。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>作为共享状态调度架构的重要组成部分，乐观并发控制算法（OCC）在数据库领域的研究由来已久。<ul>
<li>如今，许多企业都需要集群管理系统来管理集群上运行的数据并行应用程序。 因此，近年来提出了许多集群管理系统。由于集群规模的不断扩大和更复杂的应用需求，<strong>单片式调度器</strong>遇到了可扩展性瓶颈。于是，<strong>分布式调度架构</strong>被用来解决这一问题。Mesos、Sparrow和Omega是分布式调度架构的三种典型实现。</li>
<li>作为第一个在调度架构中引入<strong>乐观并发控制（OCC）</strong>的架构，<strong>Omega</strong> 是一种可扩展且灵活的调度架构，它基于将整个集群状态共享给分布式调度器的理念。一些成功者也使用了与 Omega 相同的概念，如 Apollo 和 Tarcil。这些架构被称为共享状态调度。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>作为共享状态调度架构的重要组成部分，乐观并发控制算法（OCC）已被数据库界研究了很长时间，但很少有研究旨在使其更适合共享状态调度环境。<ul>
<li>迄今为止，研究人员<strong>主要</strong>关注于<strong>提出新的调度架构和调度算法</strong>。</li>
<li>此外，<strong>很少</strong>有人关注对共享状态调度中采用的 <strong>OCC 进行扩展</strong>。然而，在这些架构中，OCC <strong>是影响调度器吞吐量的主要因素</strong>。对于共享状态调度来说，为了实现更好的效率和鲁棒性，在这一领域进行一些研究是非常必要的。 <ul>
<li>作为共享状态调度的典型实现，Omega 给出了集群调度系统中事务的定义。然后采用<strong>粗粒度冲突检测</strong>和<strong>细粒度冲突检测</strong>两种OCC方法来控制调度事务的并发提交。</li>
</ul>
</li>
</ul>
</li>
<li>在具体应用中，如<strong>图1</strong>所示，当集群的闲置资源足以满足到达作业时，与粗粒度冲突检测相比，<strong>细粒度冲突检测</strong>表现良好，<strong>冲突率降低了2-3倍</strong>，但当集群的闲置资源有限且竞争激烈时，两种OCC都会<strong>忽略检测大量有害冲突</strong>。<ul>
<li>在本文中，我们将<strong>有害冲突</strong>定义为任务的资源需求<strong>未被验证为冲突</strong>，但可能让其请求的<strong>机器超额承载</strong>。<ul>
<li>调度器通过使用这些 OCC 无法意识到这些冲突，并将这些任务分派到没有足够资源的处理机上。</li>
<li>在谷歌的集群管理系统 Borg 中，当任务请求的机器没有足够的可用资源来处理新任务时，它会抢占（杀死）优先级较低的任务，或拒绝该任务并将其排入待处理队列。然后可能会出现<strong>抢占级联</strong>。</li>
</ul>
</li>
<li>然而，<strong>提高几个百分点的利用率</strong>就能<strong>节省数百万美元</strong>。在研究人员和开发人员的努力下，集群的利用率与日俱增。</li>
<li>因此，大量有害冲突将是一个不容忽视的问题。</li>
</ul>
</li>
<li>另一方面，虽然有一些<strong>处理有害冲突</strong>的机制，但与在验证阶段检测和处理有害冲突的成本相比，在任务派发后处理冲突的成本更高。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/2016-ICIIP-he.png?raw=true" alt="图1"><figcaption>图1</figcaption></figure></li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>本文提出了一种适用于共享状态调度架构的扩展细粒度冲突检测方法。该方法扩展了原有细粒度冲突检测方法的验证标准，使其能够在高并发调度事务下检测复杂的并发冲突。<ul>
<li>我们的解决方案倾向于在任务派发前通过 OCC 减少有害冲突。因此，我们提出了一种<strong>扩展的细粒度冲突检测</strong>方法来实现这一目标。<ul>
<li>首先，这种检测方法<strong>扩展了</strong>细粒度冲突检测方法的<strong>验证条件</strong>。</li>
<li>其次，为了实现扩展的验证条件，除了单元状态外，我们还使用了另一个<strong>全局对象（称为活动索赔数组）</strong>来帮助检测有害冲突。</li>
</ul>
</li>
<li>最后，我们重写了欧米茄的公共模拟器，并在该模拟器中实现了我们的 OCC。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们使用 Google 的跟踪数据进行了一系列实验。实验结果表明，在高负载情况下，与原来的细粒度冲突检测方法相比，我们的方法减少了 60% 的有害冲突数量，而且只导致调度器性能下降到可以忽略不计的程度。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li><h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2></li>
</ul>
<ol>
<li>本文的假设是基于Omega而非Fuxi2.0，因此假设状态同步是实时的，不存在影子资源等问题。要解决的问题为：多个调度器同时拿着完整的资源状态，同时做出决策，此时可能出现的冲突需要被消解。</li>
<li>冲突检测是调度器层面还是状态管理器层面？<ol>
<li>状态管理器层面。</li>
</ol>
</li>
<li>场景是什么？请求申请了多少资源量就会用多少资源量？还是会超用？<ol>
<li>请求申请了多少资源量就会用多少资源量。</li>
</ol>
</li>
<li>细粒度和粗粒度冲突检测的区别是什么？<ol>
<li>粗粒度冲突检测：当验证一个请求时，如果其请求的<strong>机器序列号已被其他并发调度事务占用</strong>，则该请求为冲突请求。<ol>
<li>该条件可形式化为${C}<em>{i}.ms!={M}</em>{share}.ms<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 1000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mo"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">。</text></g></g></g></g></svg></mjx-container>C_{i}<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="20.362ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 9000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">是</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">需</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">要</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">验</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">证</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">请</text></g><g data-mml-node="mi" transform="translate(7000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">求</text></g><g data-mml-node="mi" transform="translate(8000,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g></g></g></svg></mjx-container>C_{i}.ms<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 1000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">是</text></g></g></g></svg></mjx-container>C_i<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="36.199ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 16000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">希</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">望</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">将</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">任</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">务</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">分</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">配</text></g><g data-mml-node="mi" transform="translate(7000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">到</text></g><g data-mml-node="mi" transform="translate(8000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(9000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">机</text></g><g data-mml-node="mi" transform="translate(10000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">器</text></g><g data-mml-node="mi" transform="translate(11000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(12000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">序</text></g><g data-mml-node="mi" transform="translate(13000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">列</text></g><g data-mml-node="mi" transform="translate(14000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">号</text></g><g data-mml-node="mi" transform="translate(15000,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g></g></g></svg></mjx-container>C_{i}.ms<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="24.887ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 11000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">从</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">本</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">地</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">状</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">态</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">信</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">息</text></g><g data-mml-node="mi" transform="translate(7000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">中</text></g><g data-mml-node="mi" transform="translate(8000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">获</text></g><g data-mml-node="mi" transform="translate(9000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">取</text></g><g data-mml-node="mi" transform="translate(10000,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g></g></g></svg></mjx-container>{M}_{share}.ms$是当前共享状态信息中同一台机器的序列号。</li>
<li>仅判断是否有多个请求被调度到同一台机器，即使这台机器上资源量充足、足以服务多个请求，也被视为冲突并触发重调度。</li>
</ol>
</li>
<li>细粒度冲突检测：不受机器序列号是否发生变化的影响，它检索共享单元的状态，只在验证时刻判断<strong>可用资源是否能容纳任务</strong>。<ol>
<li>其验证条件可形式化为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="10.195ex" height="1.952ex" role="img" focusable="false" viewBox="0 -705 4506.2 862.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,-150) scale(0.707)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g><g data-mml-node="mo" transform="translate(1185.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="msub" transform="translate(2241.6,0)"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mi" transform="translate(748,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(3283.6,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="msub" transform="translate(3728.2,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>。变量<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="5.123ex" height="1.952ex" role="img" focusable="false" viewBox="0 -705 2264.6 862.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mi" transform="translate(748,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1042,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="msub" transform="translate(1486.6,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>是请求<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.357ex" height="1.952ex" role="img" focusable="false" viewBox="0 -705 1042 862.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mi" transform="translate(748,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>请求的资源，变量<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.355ex;" xmlns="http://www.w3.org/2000/svg" width="2.054ex" height="1.355ex" role="img" focusable="false" viewBox="0 -442 908.1 599.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,-150) scale(0.707)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g></g></g></svg></mjx-container>是机器中当前可用的资源。</li>
<li>如果可用资源小于该请求要求所请求的资源，则该请求被检测为冲突。</li>
</ol>
</li>
</ol>
</li>
<li>细粒度冲突检测有什么问题？<ol>
<li>意识不到有害冲突。原因是：我们发现粗粒度冲突检测和细粒度冲突检测方法都无法检测到一些有害的冲突。<ol>
<li>以细粒度冲突检测为例，如果 <strong>调度程序X</strong> 想把需要0.5个CPU内核的 <strong>任务T1</strong> 放在 <strong>E机器</strong> 上，而 <strong>调度程序Y</strong> 想把需要1.0个CPU内核的 <strong>任务T2</strong> 放在 <strong>E机器</strong> 上。<strong>机器E</strong> 有 1.2 个备用 CPU 内核。如果在 <strong>调度程序X</strong> 和<strong>调度程序Y</strong> 的验证阶段没有<strong>更改全局机器信息</strong>（？意思是同时发生？），那么这两个请求都被验证为 “非”。那么这两个请求都会被验证为无冲突，并进入提交阶段。但只有一个任务能成功部署到 <strong>E机器</strong>上，但两个调度器都会进入提交阶段。然后两个任务都被分派到<strong>机器E</strong>。延迟提交的要求可能会冲突，但尚未被这些 OCC 验证为冲突。</li>
<li>这种行为会影响一个调度程序为其任务寻找另一个更合适的机器（即<strong>重调度</strong>）。更严重的是，这种<strong>过度承诺</strong>行为可能会导致<strong>机器故障和单元状态信息错误</strong>。因此，稳健的 OCC 应尽可能减少这些被忽视的冲突。</li>
</ol>
</li>
</ol>
</li>
<li>更细粒度的冲突理论上会花费更大的开销、或会过于保守导致资源浪费，这两方面的代价是否被刻画？如果已被刻画且能够豁免代价，方法是什么？<ol>
<li>方法：为了扩展细粒度冲突检测方法的验证条件，我们引入了一个类似于单元状态的持久对象来记录活动请求，并用它来帮助检测冲突。它是一个机器编号长度的数组，记录了每台机器的活动并发请求。我们会在事务提交验证时添加新的活动请求，并在验证操作完成后删除过时的请求。有了活动索赔信息，我们方法的验证条件就会发生变化。</li>
<li>我的评价：本质上就是加了个锁，使得不会存在并发检测冲突。</li>
</ol>
</li>
<li>“有害冲突”的比例大概在多少？优化的必要性有多大？<ol>
<li>所定位的“有害冲突”问题听起来并不严重，因此仅设计了很简单的方法就能解决问题。</li>
</ol>
</li>
<li>核心逻辑：单体式调度有性能瓶颈，分布式调度能提高效率-&gt;分布式调度中状态共享是一种被广泛使用的架构-&gt;状态共享中OOC是影响吞吐量的主要因素，现有研究很少关注OOC优化-&gt;现有OOC方式无法意识到“有害冲突”，即使细粒度冲突比粗粒度冲突冲突率低很多，但还是有很多“有害冲突”-&gt;粗粒度冲突检测导致频繁重调度，细粒度冲突检测导致冲突不被发现，进而导致任务失败、甚至导致级联抢占问题，影响集群利用率。</li>
<li> 冲突是怎么影响利用率的？是重调度浪费时间？还是已运行任务会被杀死？</li>
<li>什么情况下会出现级联抢占？导致的代价有多大？在什么场景下特别需要优化？</li>
<li>现实场景中优化目标会是什么？什么情况下会出现多个优化目标相互冲突并且导致严重后果？是否有可能作为一个新研究方向？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/abs/10.1145/3028842.3028871">[1] Libo He, Shaowen Yao, and Wei Zhou. 2016. An extended fine-grained conflict detection method for shared-state scheduling in large scale cluster. In Proceedings of the 1st International Conference on Intelligent Information Processing (ICIIP ‘16). Association for Computing Machinery, New York, NY, USA, Article 29, 1–7. https://doi.org/10.1145/3028842.3028871<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>大规模</tag>
        <tag>状态共享</tag>
        <tag>冲突检测</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记76-前沿-面向视频分析的状态细分实时迁移</title>
    <url>/2024/11/07/literature/literatureNotes76/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Live-Migration-of-Video-Analytics-Applications-in-Edge-Computing》"><a href="#x1f4d6-《Live-Migration-of-Video-Analytics-Applications-in-Edge-Computing》" class="headerlink" title="📖《Live Migration of Video Analytics Applications in Edge Computing》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Live Migration of Video Analytics Applications in Edge Computing》</h1><p>2023 年 清华大学王继龙、王会老师团队 发表于 CCF-A 类期刊 TMC。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>为了有效调度资源或保持移动客户应用的连续性，边缘平台通常需要对其上的应用进行自适应迁移。<ul>
<li><strong>公共边缘平台越来越受欢迎</strong>，如 AWS Local Zones 和 Azure private MEC。通过使计算和存储更接近终端客户，与云平台相比，它们可以为边缘应用提供更低的延迟和更好的服务质量（QoS）。</li>
<li>边缘平台的<strong>杀手级应用是实时视频分析（VA）应用</strong>，这吸引了许多研究人员努力优化其性能。特别是，边缘平台需要<strong>自适应地改变边缘应用的位置</strong>，以应对用户的移动性或提高资源效率。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>许多研究都集中在<strong>何时何地迁移应用的调度决策</strong>问题上。<ul>
<li>但是，如何<strong>实现</strong>这些工作所做的迁移决策呢？换句话说，边缘平台需要一种<strong>解决方案</strong>来<strong>迁移</strong>其上的虚拟局域网应用，同时又不会明显降低应用的<strong>性能</strong>。</li>
<li>在边缘平台上迁移虚拟局域网应用实质上就是<strong>迁移容器</strong>，因为边缘平台通常使用容器技术为应用服务，这是因为容器技术简单、开销低。当边缘平台决定迁移容器化应用时，它需要转移<strong>被迁移应用容器的内存状态</strong>。</li>
</ul>
</li>
<li>许多研究人员对<strong>云内应用程序内存状态的迁移</strong>进行了研究，提出的解决方案按其基本思路可分为三类，即：<ul>
<li>1）检查点/恢复</li>
<li>2）预复制</li>
<li>3）后复制。</li>
</ul>
</li>
<li>然而，我们的测量结果表明，现有的迁移解决方案无法解决边缘计算中视频分析应用程序的迁移问题，因为<strong>视频分析应用程序的内存状态</strong>与<strong>其他应用程序的内存状态</strong>具有不同的特点。<ul>
<li>1）典型 VA 应用程序的<strong>内存状态非常大</strong>，这使得 Checkpoint/Restore <strong>效率低下</strong>。</li>
<li>2）典型 VA 应用程序运行期间内存状态的<strong>脏页率非常大</strong>，这使得预复制方法不可行。</li>
<li>3）后复制方法需要<strong>更长的时间才能完成迁移</strong>，而且无法保证<strong>迁移过程中的应用性能</strong>，这对于边缘 VA 应用程序来说是不可接受的，因为这些应用程序通常<strong>对延迟要求很高</strong>。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>我们对视频分析应用程序的内存状态进行了细分分析，并提出用三种不同的技术（即预热、同步和重放）分别处理三类状态，以尽量减少迁移对应用程序性能的负面影响。</p>
<ul>
<li>幸运的是，通过对虚拟机构应用的内存状态进行细分分析，我们发现<strong>并非所有内存状态都值得从源头转移到目的地</strong>，这就是状态<strong>同步</strong>的一种思路。<ul>
<li>1）需要传输的内存状态只有那些<strong>持久的、经常修改的状态</strong>（称为关键状态），如对象的特征点和虚拟机构应用程序特定组件生成的结果。</li>
<li>2）相比之下，<strong>持久和未修改的状态</strong>（称为永久状态），如模型参数和运行时库，可以通过在目的地加载和初始化应用程序映像来提前恢复，这就是<strong>预热</strong>的概念。</li>
<li>3）<strong>不稳定和频繁修改的状态</strong>（称为短暂状态），如 CNN 模型输出的中间特征，可以通过在目的地<strong>重新分析同一帧</strong>来重新创建，这就是<strong>重放</strong>的概念。</li>
<li>我们的测量结果还表明，<strong>永久状态和短暂状态</strong>主导着 VA 应用程序<strong>内存状态的大小</strong>。<strong>关键状态的大小较小</strong>，传输它们比传输所有内存状态更容易、更高效。</li>
</ul>
</li>
</ul>
</li>
<li><p>基于这一想法，我们实现了一个原型系统，其中设计了两个新组件，即状态存储和边车sidecar，以最小的应用代码修改实现近乎透明的实时迁移。</p>
<ul>
<li>我们尝试为边缘平台开发迁移解决方案。然而，在实现这些想法的过程中存在<strong>两个问题</strong>。<ul>
<li>1）首先，边缘平台应与现有应用程序兼容，而无需复杂的移植工作，但边缘平台缺乏使用上述想法进行迁移所必需的一些关键信息，这可能会导致<strong>大量应用程序代码的修改</strong>。<ul>
<li>具体来说，边缘平台<strong>无法实时获取关键状态的内存页</strong>，也不知道应该重放哪些帧来获取应用程序的短暂状态。</li>
</ul>
</li>
<li>2）其次，迁移过程应该对应用程序（即边缘平台的客户）透明。<ul>
<li>换句话说，在边缘平台上无缝迁移应用应该是为边缘应用提供的一项服务，而且最好<strong>不会给应用带来任何开销</strong>。</li>
</ul>
</li>
</ul>
</li>
<li>我们设计了<strong>两个组件</strong>来解决上述实施问题，并以最小的应用代码修改实现近乎透明的迁移。<ul>
<li>1）我们<strong>要求应用程序主动</strong>向边缘平台<strong>报告其关键状态</strong>，这些状态将保存在新组件的<strong>状态存储</strong>中。<ul>
<li>状态存储的设计是分布式的，每个边缘服务器都有一个本地状态存储，用于保存本服务器上应用程序的关键状态。这样就避免了频繁的跨服务器数据传输，有利于提高应用性能。</li>
<li>全局状态存储仅用于同步从源到目标的关键状态。</li>
</ul>
</li>
<li>2）另一个新组件 <strong>sidecar</strong> 的设计目的是提高迁移的透明度。<ul>
<li>有了它，应用程序只需在代码中<strong>适当插入两个简单的 HTTP GET/PUT 操作</strong>，就能请求/报告关键状态，而无需关心迁移解决方案的任何实现细节，从而以最小的应用程序代码修改实现应用程序迁移。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>总而言之，我们的工作有三个贡献。</p>
<ul>
<li>1）首先，我们<strong>分析了 VA 应用程序的内存状态</strong>，<strong>揭示了</strong>现有的云计算场景迁移方法无法解决边缘平台中 VA 应用程序迁移问题的原因。</li>
<li>2）其次，通过对内存状态的细分分析，我们提出了分别<strong>处理三类状态</strong>并<strong>利用三种不同技术</strong>（即预热、同步和重放）进行迁移的建议。</li>
<li>3）第三，在此基础上，我们使用<strong>精心设计的应用程序接口（API），以及边车sidecar和分层状态存储</strong>的新颖组合，以最小的应用代码修改实现视频分析应用近乎透明的状态迁移。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>评估实验表明，我们的系统可以实现无缝的 VA 应用程序迁移，应用程序中断时间不超过 405 毫秒，并且不会以大量资源换取迁移性能的提高。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>我们将讨论迁移方案的局限性和未来的研究方向。<ul>
<li>1）在我们的系统中，我们<strong>假设模型在 VA 应用程序的整个生命周期内不会被修改</strong>，但也有一些工作假设应用程序使用的模型在应用程序运行期间并不总是不变的。<ul>
<li>例如，有些工作建议根据服务器负载在<strong>轻量级和重量级模型之间切换</strong>。在这些工作中，虚拟机构应用可能会间隔切换所使用的模型。</li>
<li>我们把切换模型的时间间隔称为时间窗口。从本质上讲，DL 模型可以在应用程序的整个生命周期内进行修改，但<strong>在时间窗口内不会改变</strong>。我们的系统可以在时间窗口内响应应用程序迁移命令，在这些作品的应用场景中迁移 VA 应用程序。</li>
</ul>
</li>
<li>2）在本文中，我们以两种典型的虚拟机构应用程序为例，<strong>指导开发人员如何修改应用程序</strong>。开发人员只需根据自己的经验确定应用程序特定组件代码中的关键状态即可。特定应用组件通常比较简单，因此开发人员很容易识别其关键状态。然而，复杂的特定应用组件仍然很少。为了确保带有复杂特定应用组件的迁移应用程序的可靠性，开发人员需要反复修改代码和相应的单元测试，以确定状态的完整性，这就<strong>增加了开发人员的负担</strong>。<ul>
<li>理想情况下，我们应该提供一种工具来<strong>自动识别 VA 应用程序代码中的关键状态</strong>。理论上，我们可以使用静态分析来识别所有潜在的关键状态，然后使用动态分析尽可能缩小范围并消除冗余数据。详细设计将在我们今后的工作中探讨。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>最近看的几篇迁移方面的文章都不是攻击通用迁移方案（上一篇实时渲染、这一篇视频分析），而是结合某种特定应用的特点进行优化。还有什么重点应用具有特点？</li>
<li>论文写得非常清晰，很易懂，值得学习</li>
<li>核心逻辑：边缘环境中需要不断迁移以调整到最合适的应用状态-&gt;现有大部分研究关注迁移决策，少部分关注迁移执行、但由于VA应用的大内存状态、高脏页率、高延迟要求导致现有方法都不适用-&gt;细分发现VA应用的内存状态可被分为关键状态、永久状态、短暂状态三类，可以分别针对特点利用不同的方式迁移-&gt;进一步本文设计了对应的利用算法并实现了对应的系统。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10049158">[1] C. Rong, J. H. Wang, J. Wang, Y. Zhou and J. Zhang, “Live Migration of Video Analytics Applications in Edge Computing,” in IEEE Transactions on Mobile Computing, vol. 23, no. 3, pp. 2078-2092, March 2024, doi: 10.1109/TMC.2023.3246539.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>迁移</tag>
        <tag>边缘</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记77-前沿-灵活的跨云天空计算</title>
    <url>/2025/01/07/literature/literatureNotes77/</url>
    <content><![CDATA[<h1 id="x1f4d6-《SkyPilot-An-Intercloud-Broker-for-Sky-Computing》"><a href="#x1f4d6-《SkyPilot-An-Intercloud-Broker-for-Sky-Computing》" class="headerlink" title="📖《SkyPilot: An Intercloud Broker for Sky Computing》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《SkyPilot: An Intercloud Broker for Sky Computing》</h1><p>2023 年 UC Berkeley大学团队 发表于 CCF-A 类会议 NSDI。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>为了遵守越来越多的有关数据放置和处理的<strong>政府法规</strong>，并保护自己<strong>免受重大云中断</strong>的影响，许多用户希望能够在<strong>云之间</strong>轻松迁<strong>移工作负载</strong>。<ul>
<li>现代信息基础设施围绕三个组成部分构建。这些生态系统显然有许多表面上的差异，但也许它们<strong>最根本的差异</strong>在于每个生态系统中<strong>提供者之间的兼容性程度</strong>。<ul>
<li>(1)<strong>互联网</strong>提供端到端的网络连接，</li>
<li>(2)<strong>蜂窝电话</strong>通过功能日益强大的手机提供几乎无处不在的用户访问，</li>
<li>(3)<strong>云计算</strong>使所有人都可以使用可扩展的计算。</li>
<li>(1)<strong>互联网</strong>和(2)<strong>蜂窝基础设施</strong>的设计目标是<strong>普遍可达</strong>。<ul>
<li>这需要统一和全面的<strong>行业标准</strong>以及广泛采用的<strong>互连协议</strong>（用于互联网对等互连和蜂窝漫游），从而形成竞争提供商的<strong>全球连接联盟</strong>。</li>
</ul>
</li>
<li>(3)<strong>云生态系统</strong>有着截然不同的起源，它是作为<strong>专用本地计算集群的替代品</strong>而出现的，而不是充当互连的通信基础设施。<ul>
<li>因此，云提供商一开始就<strong>强调</strong>它们的<strong>差异</strong>而不是相似之处；尽管云都基于相同的基本概念单元（例如虚拟机、容器和现在的 FaaS），但它们最初在编排界面上存在很大差异。随着时间的推移，这些编排接口变得越来越相似，但一些云继续通过众多<strong>专有服务接口</strong>（例如存储或键值存储）来<strong>区分</strong>自己。</li>
<li>此外，云通常对数据离开收取比数据输入更高的费用，从而导致 <strong>“数据引力”</strong> （即，由于传输数据的费用而难以将工作转移到另一个云）。</li>
<li><strong>专有服务接口（有限的接口兼容性）</strong>和<strong>数据引力</strong>的结合导致了严重的客户锁定：对于在一个云上建立计算工作负载的公司来说，很难将其转移到另一个云上。</li>
</ul>
</li>
</ul>
</li>
<li>然而，随着云计算已成为我们计算基础设施的重要组成部分，企业越来越担心<strong>在云之间迁移工作负载</strong>的难度。希望在工作负载分配方面获得更多自由有两个令人信服的理由。<ul>
<li>a）首先，没有企业希望其基础设施的任何<strong>关键部分与单一提供商绑定</strong>，因为这种锁定会降低其<strong>谈判筹码</strong>，也使企业容易受到提供商大规模<strong>中断的影响</strong>。</li>
<li>b）其次，现在有关于<strong>数据和操作主权的严格规定</strong>，规定了数据可以存储在哪里以及计算作业可以在哪里运行。并非所有云提供商在所有国家/地区都设有数据中心，因此无法在云提供商之间迁移工作可能会成为满足这些新法规的痛苦障碍。</li>
<li>这两个原因并不是“可有可无”的理论问题。最近发生的大规模云中断以及越来越多的政府法规正在迅速使这种解决方案成为大规模云用户的“必备”。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>我们首先回顾与迁移工作负载能力相关的两个概念——标准和多云，然后讨论兼容性方面的最新进展。</li>
</ul>
<h3 id="（1）为什么不直接采用标准？"><a href="#（1）为什么不直接采用标准？" class="headerlink" title="（1）为什么不直接采用标准？"></a>（1）为什么不直接采用标准？</h3><ul>
<li>人们可能会问的第一个问题是，如果无缝迁移是目标，为什么不采用一套<strong>统一且全面的云标准</strong>，就像互联网和蜂窝网络所做的那样？<ul>
<li>事实上，十年前，IEEE 提出了一套针对云提供商之间的可移植性、互操作性和联合的 Intercloud 标准，涉及 Intercloud 服务目录和 Intercloud 联合层。对于这种<strong>统一和全面的云标准</strong>，此提案和其他提案存在<strong>两个基本问题</strong>。</li>
<li>a）首先，<strong>主导云</strong>（即拥有较大市场份额的云）<strong>没有动力采用</strong>此类标准；这会降低他们的竞争优势，并使客户更容易将其业务转移到其他云。</li>
<li>b）其次，除了 Kubernetes 等<strong>底层编排接口</strong>之外，用户还使用 PyTorch 或 TensorFlow 等<strong>高层服务接口</strong>与多个级别的云进行交互。如果目标是实现工作负载无缝迁移，那么所有这些接口都需要标准化。要求每个云标准化每个接口既不现实（如第一个反对意见中所述）也不明智（因为这些更高级别的接口随着时间的推移已经发生了显着变化，标准化它们将极大地阻碍创新）。</li>
</ul>
</li>
</ul>
<h3 id="（2）为什么现有多云技术还不够？"><a href="#（2）为什么现有多云技术还不够？" class="headerlink" title="（2）为什么现有多云技术还不够？"></a>（2）为什么现有多云技术还不够？</h3><ul>
<li><strong>a）灵活性差</strong>：<strong>多云</strong>现已成为行业流行语，有报告表明大多数企业已经或即将拥有<strong>多云部署</strong>；这似乎意味着我们无缝工作负载迁移的目标已经实现。然而，多云一词的常见使用<strong>仅要求</strong>企业在两个或多个云上<strong>运行工作负载</strong>（例如，财务团队在 Amazon 上运行后端功能，而分析团队在 Google 上运行 ML 作业），而不是说他们可以轻松地在在云之间<strong>移动这些工作负载</strong>。从我们采访过的业内每个人看来，很明显，在云之间移动许多工作负载<strong>仍然很困难</strong>。</li>
<li><strong>b）独占性强：</strong>例外的是最近在多个云上运行的第三方产品（例如 Trifacta、Confluence、Snowflake、Databricks 等），用户确实可以相对轻松地在云之间<strong>迁移仅使用这些服务的工作负载</strong>（Google 提供的 BigQuery 提供类似的跨云支持）。但是，这些都是<strong>针对特定工作负载</strong>的，并不为工作负载迁移提供一般支持。</li>
<li><strong>c）自动性差：</strong>此外，还有多种支持多云的编程或管理框架。 JClouds 和 Libcloud 提供了对许多提供商的计算、存储和其他服务的可移植抽象。然而，用户<strong>仍然手动进行放置</strong>，而自动放置是SkyComputing的一个关键功能。</li>
<li><strong>d）管理层级过低：</strong>在管理方面，Terraform 在不同的云上配置和管理资源，但需要使用特定于提供商的 API，并且也不处理工作安排。 Kubernetes 编排容器化工作负载，并且可以跨多个云运行（例如 Anthos）。这些框架虽然非常有价值，但专注于<strong>在云提供的较低级别基础设施</strong>接口中提供更多兼容性（请参阅第 2.3 节），因此与 SkyComputing 很好地<strong>互补</strong>，但并不能消除对 SkyComputing 的需求。</li>
</ul>
<h3 id="（3）接口兼容性的趋势"><a href="#（3）接口兼容性的趋势" class="headerlink" title="（3）接口兼容性的趋势"></a>（3）接口兼容性的趋势</h3><ul>
<li>如前所述，云计算的用户调用各种各样的计算和管理<strong>接口</strong>。其中许多是开源系统，已成为软件堆栈不同层的事实上的标准，包括：<ul>
<li>操作系统（Linux）、</li>
<li>集群资源管理器（Kubernetes、Apache Mesos）、</li>
<li>应用程序打包（Docker）、</li>
<li>数据库（MySQL、Postgres）、</li>
<li>大数据执行引擎（Apache Spark、Apache Hadoop）、</li>
<li>流引擎（Apache Flink、Apache Spark、Apache Kafka）、</li>
<li>分布式查询引擎和数据库（Cassandra、MongoDB、Presto、SparkSQL、Redis）、</li>
<li>机器学习库（PyTorch、TensorFlow、MXNet、MLflow、Horovod、Ray RLlib）</li>
<li>以及通用分布式框架（Ray、 Erlang、Akka）。</li>
</ul>
</li>
<li>此外，<strong>AWS **的一些接口越来越多地在</strong>其他云**上得到支持：<ul>
<li>Azure 和 Google 为其 Blob 存储提供类似 S3 的 API，以便客户更轻松地从 AWS 迁移到自己的云。</li>
<li>同样，用于管理机器映像和专用网络的 API 也在融合。</li>
</ul>
</li>
<li>这说明<strong>有限的接口兼容性</strong>正在成为趋势，其中：<ul>
<li>尽管部分API有兼容性，但这种兼容性<strong>仅适用于单个接口</strong>；</li>
<li>并且这些接口通常不受所有云支持，而是<strong>受有限个云支持</strong>。</li>
</ul>
</li>
<li>根据我们在生态系统中看到的情况，我们的论点是，这些具有<strong>有限兼容性</strong>（即在多个云上支持）的接口的<strong>数量</strong>和<strong>使用量</strong>正在增加，这主要是由于开源的努力。</li>
<li>我们的方法基于这样的信念：这一趋势将持续下去，并且利用这一趋势远比追求统一和全面的标准更可取。<ul>
<li>套用林肯的一句话，我们知道所有接口都被某些云支持，并且某些接口可能被所有云支持，但我们不能也不应该要求所有接口都被所有云支持。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>在本文中，我们建议<strong>不要通过强加统一和全面的标准</strong>来实现这一目标，而是<strong>通过云间代理</strong>创建细粒度的双边市场。这些代理将允许用户不只是将云生态系统视为单个且基本上不兼容的云的集合，而且视为更加集成的计算天空。我们描述了名为 SkyPilot 的云间代理的设计和实现，评估其优势并报告其实际使用情况。</li>
<li>我们首先描述什么是天空计算，并阐明为什么我们认为它不仅是渐进性的，而且是颠覆性的。</li>
</ul>
<h3 id="什么是天空计算？"><a href="#什么是天空计算？" class="headerlink" title="什么是天空计算？"></a>什么是天空计算？</h3><ul>
<li><strong>天空计算</strong>这个概念首次在<a href="#refer-anchor-2">[2]</a>中引入，但在这里得到了显着扩展和更深入的探讨。<strong>天空计算</strong>是指用户不直接与云交互，而是将其作业提交给我们所谓的云间经纪人，后者负责处理放置并监督其作业的执行。</li>
<li>在这种有限的接口兼容性不断增加的情况下，我们如何利用它来缓解工作负载迁移?有两个关键的组成部分。<ul>
<li>（1）首先，为了<strong>降低数据引力</strong>，云可以进入对等的自由数据对等；也就是说，两个云可以同意让用户在不收取费用的情况下将数据从一个云移动到另一个云。<ul>
<li>随着高速连接(许多云有100Gbps的连接到各种互连点,它们可以与其他云对等)的盛行，我们认为这种自由对等很容易得到支持，其它所能实现的收益增加超过所产生的成本。</li>
<li>人们可能担心这种传输引起的延迟，但如果由此产生的计算时间在数据大小(或具有合理的高常数的线性)上是超线性的。<strong>（？）</strong></li>
</ul>
</li>
<li>（2）第二个组件，也是我们在本文其余部分重点关注的组件，就是我们所说的<strong>云间代理</strong>。<ul>
<li>在本文中，我们描述了我们的 intercloud 代理，它是专门为计算<strong>批处理作业</strong>而设计的。虽然批处理作业（例如 ML、科学作业、数据分析）仅代表当今多样化云用例的一小部分，但它们的计算需求正在快速增长，并且导致了最近专用硬件的激增。因此，我们从一个为批处理作业设计的代理开始，作为一种易于处理但常见且快速增长的工作负载。我们预计<strong>代理的未来版本将解决更广泛的工作负载</strong>，并提供更广泛的功能，但这不是我们的重点。</li>
<li>此外，我们预计最终将有一个开放的云间经纪商市场，其经纪服务收取少量费用；其中一些代理将是通用的，而其他代理则更适合特定的工作负载，就像我们的一样。</li>
</ul>
</li>
</ul>
</li>
<li>云间代理将<strong>计算请求</strong>作为输入，该<strong>计算请求</strong>被指定为**有向无环图 (DAG)**。<ul>
<li>这是由工作流系统提供的，该系统现在已成为编排复杂批处理应用程序的事实上的标准。</li>
<li>其中<strong>节点</strong>是粗粒度<strong>计算</strong>（例如数据处理、训练）。由于缺乏更好的术语，我们将这些<strong>计算</strong>称为<strong>“任务”</strong>。该请求还包括<strong>用户对价格和性能的偏好</strong>。</li>
</ul>
</li>
<li>然后，云间代理负责跨云<strong>放置这些任务</strong>。<ul>
<li>与每个云运行应用程序实例的现有多云应用程序不同，云间代理可以<strong>跨多个云</strong>运行单个应用程序实例。<ul>
<li>例如，图 1 显示了包含三个任务的机器学习 (ML) 管道：数据处理、训练和服务。用户可能希望在安全处理数据的同时最小化总成本。云间代理可能决定在 Azure <a class="link" href="https://learn.microsoft.com/zh-cn/azure/confidential-computing/overview">机密计算<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>上运行数据处理以匿名化数据，从而保护数据机密性，在 GCP（Google Cloud Platform） 上进行训练以利用 <a class="link" href="https://cloud.google.com/tpu?hl=zh-CN">TPU<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>，并在 AWS 上提供服务以利用 <a class="link" href="https://aws.amazon.com/cn/ai/machine-learning/inferentia/">Inferentia<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 加速器。</li>
</ul>
</li>
<li>划分应用程序的能力使得专用云的出现成为可能。例如，云提供商只需专注于单一任务（例如 ML 训练）并为该任务提供最佳性价比，就可以建立成功的业务；有关此问题的更详细讨论，请参阅正文附录§A.1部分。</li>
</ul>
</li>
<li>此外，即使应用程序在以下两种情况，云间代理也能提供优势： <ul>
<li>(i) <strong>完全在单个云上运行</strong>，通过自动选择最符合用户偏好的云并选择该云内的最佳区域和区域，</li>
<li>或 (ii) <strong>使用仅由单个云提供的服务</strong>，将任务放置在该云上，但仍然可以自由地使用其他云来执行其他任务。<ul>
<li>“服务”是指由一个或多个云提供的计算服务或托管服务，例如托管的 Apache Spark（例如，EMR、HDInsight）和托管的 Kubernetes（例如，EKS、GKE，或 AKS）。仅由单个云提供，将任务放置在该云上，但仍然可以自由地使用其他云来执行其他任务。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://blog.bxhu2004.com/sci/Networks/SkyPilot/image.png" alt="图1"><figcaption>图1</figcaption></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="为什么是颠覆性的？"><a href="#为什么是颠覆性的？" class="headerlink" title="为什么是颠覆性的？"></a>为什么是颠覆性的？</h3><p>我们将其视为云计算的变革，而不仅仅是工作负载迁移的战术机制，这有三个原因，每个原因都从不同的角度来看。</p>
<ul>
<li><strong>（1）用户的视角：</strong>使用云间代理时，用户不再与单个云交互，而是与更集成的计算“天空”交互。他们只需指定计算结果和标准，然后经纪人就会安排工作。这使得云的使用变得更加容易，并可能导致云的采用率增加。请注意，这样的界面隐藏了云之间和云内部的异构性。用户不再需要研究哪些云具有最优惠的价格，或提供特定的服务。这也适用于单个云，因为云中的不同区域可以提供不同的硬件选项和不同的价格。</li>
<li><strong>（2）竞争视角：</strong>请注意，通过充当用户和云之间的中介，云间代理正在创建一个细粒度的双边计算市场：用户指定他们的任务和要求，云提供其定价和性能的接口。工作安排不再主要由促进锁定的措施（例如专有接口和数据引力）驱动，而是越来越多地由每个云通过更快和/或更经济高效的实施来满足用户需求的能力驱动。这意味着，为了扩大市场，云可能会开始支持工作中常用的接口，从而推动市场提高兼容性。</li>
<li><strong>（3）生态系统视角：</strong>一旦建立了双边市场，云生态系统就可以从所有云都提供广泛的服务并尽力锁定客户的生态系统转变为许多云致力于成为其中一部分的生态系统。计算天空，他们可以专注于某些任务，因为如果他们最好地满足用户对这些特定任务的需求，云间代理将自动将计算定向给他们；正文附录（§A.1.2）中的经济分析使这种情况更加准确。</li>
</ul>
<p>这一愿景应该与现实相结合。</p>
<ul>
<li><strong>（1）首先</strong>，虽然我们预计一些云将通过专注于兼容接口和采用互惠的免费数据对等来拥抱天空计算的愿景，但我们预计其他云，特别是那些拥有主导市场地位的云，将继续将锁定作为一种市场策略。尽管如此，可行的替代云生态系统的存在将为创新和满足用户需求设定标准，因此所有用户都将受益。</li>
<li><strong>（2）其次</strong>，我们假设天空计算的创建将是一个漫长的过程，将缓慢开始并逐渐积聚动力。我们本文的目标是研究如何开始这种转变，而不是定义其最终形式。因此，我们从用于批处理作业的云间代理开始——一组小但重要的工作负载。</li>
<li><strong>（3）第三</strong>，鉴于我们专注于Sky的早期阶段，我们没有为最终必须解决的几个问题提供解决方案，例如如何解决跨多个云运行的应用程序发生的故障。</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>SkyPilot 是开源的，可从 <a class="link" href="https://github.com/skypilot-org/skypilot">https://github.com/skypilot-org/skypilot<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 获取。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>我们预计代理的未来版本将解决更广泛的工作负载，并提供更广泛的功能。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>本文的描述方式、故事线很有意思，不愧是数年磨一剑的产品。“数据引力”的描述很形象。</li>
<li>为什么互联网和移动蜂窝就能够接纳“统一标准”？是因为接纳后能够为自己带来更广阔的市场？为什么云计算就不可以？是因为大家产品本身的差异化不够明显，所以统一反而容易让别人抢占市场？还是说只是因为现在的供应商呈现几乎垄断的态势，所以在初期更难推进、在未来还是有可能的？并没有感受到在本质上云计算和另外两类（互联网和移动蜂窝）的区别。</li>
<li>解决“数据引力”的“对等的自由数据对等”在市面上如何支持？有什么产品能够支持？</li>
<li>跨云传输数据的时间开销能够忽视？没有足够的论据。根据现有共识，跨云传输会导致模型训练时间大大延长才对。</li>
<li>SkyPilot的输入是什么？能够获取多云的什么信息？<ul>
<li>通过“Catalog”组件维护，记录每个云中的可用实例和服务信息。具体包括详细位置、分配/关闭/访问API、按需VM/数据存储/数据出口/服务的长期价格（通常长期不发生变化）。</li>
<li>看起来一个假设是“云是无限的”，比较符合日常使用场景。但如果在云资源不足的情况下则不适用。</li>
</ul>
</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.usenix.org/conference/nsdi23/presentation/yang-zongheng">[1] Yang, Zongheng, et al. “{SkyPilot}: An intercloud broker for sky computing.” 20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23). 2023.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link" href="https://dl.acm.org/doi/abs/10.1145/3458336.3465301">[2] Ion Stoica and Scott Shenker. From cloud computing to sky computing. In Proceedings of the Workshop on Hot Topics in Operating Systems, HotOS ’21, page 26-32, New York, NY, USA, 2021. Association for Computing Machinery.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>多云</tag>
        <tag>非侵入</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记78-前沿-Meta跨地域ML训练MAST</title>
    <url>/2025/01/10/literature/literatureNotes78/</url>
    <content><![CDATA[<h1 id="x1f4d6-《MAST-Global-Scheduling-of-ML-Training-across-Geo-Distributed-Datacenters-at-Hyperscale》"><a href="#x1f4d6-《MAST-Global-Scheduling-of-ML-Training-across-Geo-Distributed-Datacenters-at-Hyperscale》" class="headerlink" title="📖《MAST: Global Scheduling of ML Training across Geo-Distributed Datacenters at Hyperscale》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《MAST: Global Scheduling of ML Training across Geo-Distributed Datacenters at Hyperscale》</h1><p>2024 年 Meta、The Ohio State University团队 发表于 CCF-A 类会议 OSDI。</p>
<blockquote>
<p>系列博客：</p>
<ol>
<li><a href="/2025/01/10/literature/literatureNotes78/" title="MAST-初步略读笔记">MAST-初步略读笔记</a></li>
<li><a href="/2025/06/24/literature/literatureNotesIntensive7/" title="MAST-相关工作发展脉络梳理">MAST-相关工作发展脉络梳理</a>
</li>
</ol>
</blockquote>
<h2 id="x1f3af-需求：供需不均衡"><a href="#x1f3af-需求：供需不均衡" class="headerlink" title="🎯需求：供需不均衡"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求：供需不均衡</h2><ul>
<li>任务：机器学习应用程序的成功导致机器学习训练成为增长最快的数据中心工作负载。</li>
<li>资源：公共云提供商在<strong>多个地理分布式数据中心区域</strong>运行 ML 训练工作负载，以确保足够的容量。</li>
<li>问题：在公有云中，用户必须手动选择数据中心区域来上传机器学习<strong>训练数据</strong>，并在同一区域启动机器学习训练<strong>工作负载</strong>，以确保<strong>数据和计算共置</strong>。不幸的是，个人用户的<strong>孤立决策</strong>可能会导致跨区域的工作负载需求和硬件供应之间的<strong>不匹配</strong>，从而损害云提供商的硬件利用率和盈利能力。<ul>
<li>例如，一个区域可能会耗尽其容量，积累一长串待处理的作业，而另一个区域则有剩余容量闲置。</li>
<li>Meta 的私有云曾经经历过这种负载不平衡的情况。它由<strong>数十个数据中心区域</strong>、<strong>数百万台机器</strong>和<strong>数万个 GPU 组成</strong>。与公共云类似，用户最初必须手动选择区域来存储训练数据和启动工作负载。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>虽然在单个集群中调度 ML 工作负载方面已经进行了大量研究，但几乎没有采取任何措施来解决工作负载需求和硬件供应之间的<strong>区域不匹配</strong>问题。</li>
<li>为了提供全局调度抽象，面临两大挑战：<ul>
<li><strong>1）数据-GPU 共置</strong>：如果没有仔细协调，GPU 和数据之间存在<strong>位置不匹配</strong>的风险。<ul>
<li>例如，一个区域可能拥有必要的训练数据，但耗尽了可用的 GPU，而另一区域可能拥有可用的 GPU，但缺乏所需的训练数据。由于训练数据量巨大，而跨区域网络带宽有限，按需<strong>跨区域数据迁移</strong>成本高昂且耗时。</li>
</ul>
</li>
<li><strong>2）可扩展性</strong>：MAST 不仅分配 GPU 机器进行训练，还分配 CPU 机器进行数据预处理。由于 CPU 机器可以根据需求在 ML 和非 ML 工作负载之间动态重新分配，因此从概念上讲，MAST 需要从分布在<strong>数十个区域</strong>的<strong>数百万台机器</strong>中找到运行 ML 工作负载的机器。此前尚未研究过如此规模的全球资源分配。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了解决 Meta 超大规模私有云中的这个问题，我们为所有机器学习训练工作负载提供了<strong>全局调度抽象</strong>，使用户免受区域复杂性的影响。用户只需将训练工作负载提交给我们名为 MAST（ML Application Scheduler on Twine 的缩写）的全局调度程序，并依靠它智能地将<strong>数据和训练工作负载</strong>放置到不同的区域。</li>
<li>我们描述了三个设计原则，使 MAST 能够在全球范围内安排复杂的 ML 训练工作负载：时间解耦、范围解耦和穷举搜索。 <ul>
<li><strong>1）时间解耦</strong>。我们将调度职责分为两条路径：实时作业调度的<strong>快速路径</strong>和在后台不断优化数据和机器分配的<strong>慢速路径</strong>。<ul>
<li><strong>慢速路径</strong>智能地跨区域<strong>复制</strong> ML 训练数据，使快速路径能够更轻松地将计算与数据并置。尽管时间安排宽松，但跨区域数据放置仍然非常具有挑战性。<ul>
<li>它需要持续优化数十亿个数据分区在数十个地理分布式区域的放置，考虑每个区域的容量限制以及来自 Spark 和 Presto 的数百万个日常 ML 训练作业和分析作业的<strong>数据访问模式</strong>。</li>
</ul>
</li>
<li>我们将数据放置建模为<strong>混合整数规划 (MIP) 问题</strong>，GPU 的稀缺性推动了我们解决方案中的新颖决策。<ul>
<li>由于 GPU 的成本和需求较高，我们的目标是<strong>最大化 GPU 利用率（Utilization）</strong>。<ul>
<li>在 MIP 问题中施加硬性约束，即每个区域的 GPU 需求必须低于 GPU 供应，就像之前针对 CPU 和存储的工作一样，通常会导致问题无法解决。</li>
<li>相反，MAST 允许 GPU <strong>超额订阅</strong>并根据需要<strong>抢占</strong>低优先级作业。</li>
<li>这种方法要求重新评估 MIP 问题中的目标函数和约束，不仅针对与 GPU 相关的术语，还针对 <strong>GPU 依赖的其他资源</strong>。我们分享通过生产经验改进 MIP 问题的多次迭代所获得的见解。</li>
</ul>
</li>
</ul>
</li>
<li>为了应对可扩展性挑战，如图 1 所示，MAST 采用三级调度层次结构：全局 ML 调度器 (GMS) 区域 ML 调度器 (RMS) 集群管理器 (CM)。</li>
<li>除了管理数据放置之外，慢速路径还通过限制对可用机器的搜索来帮助扩展 RMS。它动态地将机器预先分配给动态集群，允许 RMS 仅搜索 ML 动态集群内的机器并忽略非 ML 动态集群。</li>
</ul>
</li>
<li><strong>2）范围解耦</strong>。作业调度系统具有三个主要职责。传统系统在同一范围内（即集群内）处理所有这些职责。<ul>
<li>a）首先，它管理<strong>作业队列</strong>，当没有足够的资源来运行所有作业时，这需要对作业进行排队和优先级排序。</li>
<li>b）其次，它处理<strong>资源分配</strong>，这涉及通过将机器建模为箱子并将任务建模为对象来计算类似装箱的解决方案。</li>
<li>c）第三，它管理<strong>容器编排</strong>，执行装箱计划、运行容器并监控其运行状况。</li>
<li>我们的主要见解是，所有三个职责共享相同的范围不必要地限制了可扩展性，将作业队列管理和资源分配的潜在更大范围减少到容器编排的最小范围。请注意，容器编排由于其职责繁重，可扩展性最差，因此范围最小。</li>
<li>相比之下，如图1所示，我们的范围解耦原则允许三个职责在不同的范围内运行：<ul>
<li>（2.1）<strong>作业队列</strong>由 GMS 在全局范围内管理，覆盖所有区域的所有待处理作业；</li>
<li>（2.2）<strong>资源分配</strong>由 RMS 在区域范围内管理，考虑到区域 ML 动态集群中的所有机器； </li>
<li>（2.3）<strong>容器编排</strong>由 CM 在最小的动态集群范围内进行管理。</li>
<li>这种方法允许作业队列管理和资源分配在更大的范围内运行，以最大限度地减少搁浅的资源并优化作业安排。一个关键挑战是使 GMS 和 RMS 具有足够的可扩展性，以便在更大的范围内运行。</li>
</ul>
</li>
</ul>
</li>
<li><strong>3）穷举搜索</strong>。现有系统通常采用<strong>联邦方法进行横向扩展</strong>。当新作业到达时，联合管理器采用简单的启发式方法将作业分配给负载最少的集群，然后集群管理器管理所有后续操作，包括作业排队、资源分配和容器编排。<ul>
<li>然而，由于 ML 训练集群几乎总是得到充分利用，因此安排新作业通常需要做出复杂的决策来<strong>抢占</strong>现有的较低优先级作业。这种复杂性使得简单的联合方法效率较低。</li>
<li>我们的主要见解是，与短期分析作业不同，ML 训练作业通常在昂贵的 GPU 上运行很长时间。因此，与其仅搜索一个集群来仓促分配资源，不如对所有相关集群进行详尽的搜索以获得更高质量的布局。如图 1 所示，MAST 的多个 RMS 可以同时计算不同区域中一项作业的资源分配计划，并通过最终<strong>拍卖</strong>过程确定最佳计划。一个关键障碍是确保 RMS 的可扩展性。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/2024-OSDI-Choudhury-MAST.png" alt="图1：MAST 的概念架构。全局 ML 调度器（GMS）、区域 ML 调度器（RMS）和群集管理器（CM）分别处理不同范围内的不同调度职责：全局、区域和群集。"><figcaption>图1：MAST 的概念架构。全局 ML 调度器（GMS）、区域 ML 调度器（RMS）和群集管理器（CM）分别处理不同范围内的不同调度职责：全局、区域和群集。</figcaption></figure></p>
<ul>
<li>我们做出以下贡献。 <ul>
<li>• 1）我们提出全局调度抽象，使用户免受地理分布式数据中心复杂性的影响，并通过跨区域联合放置数据和训练工作负载来提高硬件利用率。 </li>
<li>• 2）我们提出了三个原则——时间解耦、范围解耦和穷举搜索——以可扩展的方式实现高质量的数据和计算布局。 </li>
<li>• 3）我们通过超大规模部署 MAST 展示了全局 ML 调度的有效性，并使用生产数据验证其设计。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>MAST 成功平衡了全球区域的负载。在 MAST 之前，对于高优先级工作负载，<strong>最过载区域的 GPU 供需比为 2.63</strong>。借助 MAST，该比率已降至 0.98，有效消除了过载。</li>
</ul>
<!-- ## ⛳️未来机会
*  -->

<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>场景规模：数十个Region、数百万机器、数万个GPU。</li>
<li>架构：三级调度层次结构</li>
<li>感知：不考虑</li>
<li>决策：快速负载调度（MIP）、慢速数据调度</li>
<li>对本文来说，为了解决数据和工作负载协同带来的影响，提出了“快速负载调度”和“慢速数据调度”两个维度，其中慢速数据调度需考虑数据访问模式，具体来说是什么样的？</li>
<li>“快速负载调度”使用的是最优化的整数线性规划求解，能够达到什么效率、能够称为“快速”吗？任务需要的响应时间在什么级别？</li>
<li>数据和工作负载跨区域是否绝对不可行？什么条件下可行、什么条件下不可行？</li>
<li>作业队列、资源分配、容器编排三件事之间的关系是什么？</li>
<li>作业队列、资源分配、容器编排的三个范围具体是如何执行的？全局管理同一作业队列是否会导致“作业队列收到用户请求的时延”过长？</li>
<li>多个 RMS 间存在“拍卖”形式的协作，具体是如何执行的？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.usenix.org/conference/osdi24/presentation/choudhury">[1] Choudhury, Arnab, et al. “MAST: Global scheduling of ML training across Geo-Distributed datacenters at hyperscale.” 18th USENIX Symposium on Operating Systems Design and Implementation (OSDI 24). 2024.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>大规模</tag>
        <tag>跨地域</tag>
        <tag>机器学习训练</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记79-前沿-存算分离集群、跨地域集群调度</title>
    <url>/2025/01/11/literature/literatureNotes79/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Adaptive-QoS-Aware-Microservice-Deployment-With-Excessive-Loads-via-Intra-and-Inter-Datacenter-Scheduling》"><a href="#x1f4d6-《Adaptive-QoS-Aware-Microservice-Deployment-With-Excessive-Loads-via-Intra-and-Inter-Datacenter-Scheduling》" class="headerlink" title="📖《Adaptive QoS-Aware Microservice Deployment With Excessive Loads via Intra- and Inter-Datacenter Scheduling》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Adaptive QoS-Aware Microservice Deployment With Excessive Loads via Intra- and Inter-Datacenter Scheduling》</h1><p>2024 年 上海交大团队 发表于 CCF-A 类期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>面向用户的应用程序经常会遇到过多的负载，并正在转向微服务架构。<ul>
<li>具有严格服务质量 (QoS) 要求的面向用户的应用程序部署在数据中心上，以获得高性能和可扩展性。</li>
</ul>
</li>
<li>为了充分利用异构资源，当前的数据中心采用了分散的存储和计算架构，其中存储和计算集群分别适合部署有状态和无状态微服务。<ul>
<li>虽然流行的互联网服务提供商和云提供商经常在<strong>不同的地理区域构建多个数据中心</strong>，但应用程序通常部署在<strong>靠近最终用户的数据中心</strong>上，以缩短响应延迟。</li>
<li>在数据中心内部，当前许多云提供商都采用了<strong>分散的存储和计算架构</strong>，其中存储集群具有更高的数据处理能力，而计算集群具有更好的计算性能。应用程序的<strong>IO密集型操作</strong>通常部署在存储集群上，而其他<strong>计算密集型操作</strong>通常部署在计算集群上。</li>
</ul>
</li>
<li>此外，当本地数据中心没有足够的资源来承载过多的负载时，合理的解决方案是将部分微服务迁移到远程数据中心。<ul>
<li>对于面向用户的应用程序，除了常规的<strong>昼夜负载模式</strong>（除高峰时段外负载较低）之外，偶尔可能会发生<strong>不可预测的极高用户查询负载</strong>。例如，在线<strong>购物节期间</strong>电子商务服务会出现过多查询，<strong>突发新闻发生时</strong>社交网络服务会出现过多查询。某一区域的数据中心的计算能力通常可能无法满足过多的查询负载，并且面向用户的应用程序通常会遇到严重的服务质量违规。</li>
<li>在托管数据中心<strong>添加更多服务器</strong>可以解决过多的服务负载。然而，这种方法对于偶尔出现的超负荷情况会显着<strong>增加运行成本</strong>。</li>
<li>另一个解决方案是利用<strong>远程数据中心</strong>来提供所需的计算能力。特别是，许多面向用户的应用程序已经从单体软件架构转向微服务架构。在微服务架构中开发，通过连接许多<strong>解耦的微服务</strong>来实现复杂的应用程序，这些微服务可以独立部署并通过网络相互交互。仅在远程数据中心部署必要的微服务<strong>会更加节省资源</strong>。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，在本地数据中心内<strong>决定适当的微服务部署并</strong>确定向远程数据中心的<strong>适当迁移决策</strong>并非易事，因为<strong>微服务表现出不同的特征</strong>，并且本地数据中心表现出<strong>不同的资源争用情况</strong>。<ul>
<li>微服务分为<strong>有状态</strong>（例如磁盘或内存数据库）和<strong>无状态</strong>（例如推荐业务）微服务，并且需要部署在本地数据中心分解架构下的存储或计算集群上。<ul>
<li>一方面，<strong>有状态微服务</strong>适合部署在<strong>存储集群</strong>上。<ul>
<li>磁盘数据库（如mongodb）需要固定在存储数据的存储集群上。</li>
<li>对于内存数据库（例如，redis），由于内存中的数据更新或卸载数据的请求，它们必须在运行时频繁地与磁盘数据库同步数据。因此，它们需要与磁盘数据库部署在同一集群上，以避免较高的数据通信开销。此外，由于在运行时<strong>更改内存数据库部署</strong>时可能会产生大量<strong>内存副本</strong>，因此需要修复它们的部署以避免损害应用程序的 QoS。因此，将内存数据库固定在存储集群上是有好处的。</li>
</ul>
</li>
<li>另一方面，<strong>无状态微服务</strong>可以部署在<strong>两个集群</strong>上，但更适合部署在<strong>计算集群</strong>上，因为它们大多数都是计算密集型的。部署在计算和存储集群上的微服务通过局域网（LAN）相互通信，会消耗<strong>相当大的网络带宽</strong>，甚至可能在负载过大时造成网络带宽瓶颈。通过在存储集群上部署一些无状态微服务，可以节省计算和存储集群之间的带宽使用。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5d2381c5237ac3e55b61b5bec65562c48884030a/2-Figure1-1.png" alt="图1"><figcaption>图1</figcaption></figure></li>
</ul>
</li>
</ul>
</li>
<li>图 1 显示了使用本地和远程数据中心来支持基于微服务的面向用户的应用程序的过度负载的示例。据观察，高效的数据中心内和数据中心间调度需要：<ul>
<li><strong>1）</strong> 最好地管理本地数据中心的有限资源，</li>
<li><strong>2）</strong> 在本地数据中心内的存储和计算集群之间正确部署微服务，</li>
<li><strong>3）</strong> 识别要迁移的适当微服务</li>
<li><strong>4）</strong> 最大限度地减少远程数据中心的资源使用。</li>
</ul>
</li>
<li>之前有一些关于管理微服务资源分配的工作，以确保具有每日负载模式的面向用户的应用程序的 QoS。然而，他们忽略了<strong>本地数据中心的分解存储和计算架构</strong>，并假设本地数据中心具有足够的计算资源用于面向用户的应用程序。而且，他们没有考虑<strong>数据中心之间的公共网络</strong>状况，只是简单地使用Kubernetes来放置微服务。</li>
<li>与传统数据中心内部的调度相比，在分解存储和计算架构下的数据中心内部以及跨数据中心的微服务调度需要解决<strong>三个新的挑战</strong>。<ul>
<li><strong>1）首先</strong>，当分配<strong>相同数量的资源</strong>（CPU 时间、内存等）或部署在不同集群上时，微服务会表现出<strong>不同的性能</strong>（延迟和吞吐量）。</li>
<li><strong>2）其次</strong>，分散的存储和计算架构导致<strong>大量的本地网络带宽消耗</strong>。结合微服务之间，尤其是有状态和无状态之间频繁的数据通信，一种方法是将部分微服务部署到存储集群中，同时满足其资源需求。</li>
<li><strong>3）第三</strong>，数据中心之间<strong>公网的带宽和延迟</strong>比数据中心内部的要差。数据中心之间的微服务放置很重要，因为通过公共网络进行的大量数据通信可能会损害服务的 QoS。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>因此，我们提出了 ELIS，这是一种数据中心内和数据中心间的调度系统，可确保微服务应用程序的服务质量 (QoS)，同时最大限度地减少网络带宽使用和计算资源使用。 </p>
</li>
<li><p>ELIS 由<strong>资源管理器</strong>、<strong>跨集群微服务部署器</strong>和<strong>基于奖励的微服务迁移器</strong>组成。</p>
<ul>
<li><strong>1）资源管理器</strong>： 为微服务分配近乎最优的资源，同时保证 QoS。<ul>
<li>对于要部署的微服务应用程序，微服务<strong>最初部署在本地数据中心</strong>。随着负载的变化，<strong>资源管理器</strong>根据微服务的性能状况确定微服务的资源调整顺序，并使用<strong>贝叶斯优化（BO）算法</strong>来最小化资源使用。</li>
</ul>
</li>
<li><strong>2）微服务部署器</strong>： 在本地数据中心的存储和计算集群之间部署微服务，在满足微服务资源需求的同时最大限度地减少网络带宽的使用。<ul>
<li><strong>微服务部署器</strong>通过集群算法调整存储集群和计算集群之间微服务的部署，在满足各个微服务的资源需求的同时，最小化本地网络带宽的使用。</li>
<li><strong>资源管理器</strong>和<strong>微服务部署器</strong>共同使本地数据中心支持最高负载。</li>
</ul>
</li>
<li><strong>3）微服务迁移器</strong>： 当本地资源无法承受过多负载时，会将部分微服务迁移到远程数据中心。<ul>
<li><strong>迁移器</strong>在保证QoS和吞吐量目标的同时，最大限度地减少公共网络带宽使用和远程资源使用。</li>
</ul>
</li>
</ul>
</li>
<li><p>主要贡献如下：</p>
<ul>
<li>1）对具有分解存储和计算架构的数据中心内以及跨数据中心的微服务部署进行<strong>全面分析</strong>。此分析有助于解决设计数据中心内和数据中心间微服务调度系统的挑战。</li>
<li>2）本地数据中心基于BO的<strong>资源管理策略设计</strong>。该策略从某些微服务中回收资源，并将其重新分配给容易导致 QoS 违规的微服务。它最大限度地提高了本地数据中心所支持的峰值负载。</li>
<li>3）设计一种在<strong>存储和计算集群之间部署微服务</strong>的方法。我们提出了基于集群的方法来确定微服务部署，以最大限度地减少本地数据中心的存储和计算集群之间的本地网络带宽使用。</li>
<li>4）设计一种<strong>搜索待迁移微服务</strong>的方法。我们确定了两个准则，通过它们可以确定要迁移的微服务，这些微服务在负载过大时可以最大程度地减少网络带宽使用和尾部延迟。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>实验结果表明，ELIS保证了面向用户的应用程序的QoS。同时，公网带宽占用、远程计算资源占用和本地网络带宽占用平均分别减少49.6%、48.5%和60.7%。</li>
</ul>
<!-- ## ⛳️未来机会
*  -->

<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>是很规范的写作方式，非常清晰。</li>
<li>三个挑战带来的难点不够突出，感觉只要简单考虑一下就能解决，没看到简单贪心算法无法解决的“矛盾点”。未来自己撰写挑战时也需要注意这个问题。</li>
<li>本文最大的特点可能是“引入集群内计算存储分离架构”，但说服力似乎有些待商榷，来源是 AWS的 EBS 产品、Azure 的 blob storage 产品和 Facebook 的博客:[P. Kestutis and J. Amisha, <a class="link" href="https://pic.huodongjia.com/ganhuodocs/2017--08-14/1502677821.82.pdf">“Facebook’s disaggregated storage and compute for map/reduce,”<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 2016.]</li>
<li>迁移过程中对请求的影响似乎没有考虑。</li>
<li>没有测试算法执行时间，实验中仅面向8台服务器执行了真实实验，“在多大规模下能达到多少效率”是一个问题。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10592806">[1] J. Shi, K. Fu, J. Wang, Q. Chen, D. Zeng and M. Guo, “Adaptive QoS-Aware Microservice Deployment With Excessive Loads via Intra- and Inter-Datacenter Scheduling,” in IEEE Transactions on Parallel and Distributed Systems, vol. 35, no. 9, pp. 1565-1582, Sept. 2024, doi: 10.1109/TPDS.2024.3425931.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>多云</tag>
        <tag>存算分离架构</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记26-经典-深度强化学习在大规模MEC网络中在线资源调度</title>
    <url>/2023/11/16/literature/literatureNotes26/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Stacked-Autoencoder-Based-Deep-Reinforcement-Learning-for-Online-Resource-Scheduling-in-Large-Scale-MEC-Networks》"><a href="#x1f4d6-《Stacked-Autoencoder-Based-Deep-Reinforcement-Learning-for-Online-Resource-Scheduling-in-Large-Scale-MEC-Networks》" class="headerlink" title="📖《Stacked Autoencoder-Based Deep Reinforcement Learning for Online Resource Scheduling in Large-Scale MEC Networks》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Stacked Autoencoder-Based Deep Reinforcement Learning for Online Resource Scheduling in Large-Scale MEC Networks》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>近年来，移动电话和物联网（IoT）设备等用户设备（UE）的数量正在迅速增长。同时，增强现实（AR）、虚拟现实（VR）、实时游戏、人脸识别、自然语言处理等资源密集型应用不断涌现。但是，上述有吸引力的应用程序通常需要大量的计算资源，并且对延迟敏感。由于UE的规模和资源有限，可能无法在规定的时间内完成上述任务或满足服务质量（QoS）要求。</li>
<li>移动边缘计算（MEC）旨在使UE能够将上述任务卸载到边缘服务器，并引起了学术界和工业界的广泛关注。应用 MEC 来协助 UE 有两个主要优势。<ul>
<li>首先，UE可以降低本地能耗，因为UE可以将计算密集型任务卸载到MEC。</li>
<li>其次，响应时间可以缩短，因为 MEC 通常比本地设备拥有更多的计算资源，因此可以比本地设备更快地完成任务，从而显着增加用户体验。</li>
</ul>
</li>
<li>但是，当我们拥有大量用户时，一个 MEC 可能不够强大，因此可以部署多个 MEC。<ul>
<li>那么，这里的关键问题是我们如何决定用户关联和资源分配，特别是在大规模环境中。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>已经提出了一些工作来<strong>优化基于MEC的延迟敏感服务</strong>，即VR应用程序。如：<ul>
<li>部分人员提出了低延迟 MEC 系统的安全卸载优化框架。</li>
<li>部分人员研究了具有缓存辅助低延迟系统的MEC。</li>
<li>此外，部分人员还研究了资源分配的延迟优化。</li>
<li>此外，部分人员提出了异构多层MEC系统的时延最优任务分配和资源分配方法。</li>
</ul>
</li>
<li>上述问题通常被认为是混合整数非线性规划（MINLP），因为卸载决策始终是整数变量，而资源分配是连续变量。提出了一些传统的方法来解决上述MINLP问题，如：<ul>
<li>动态规划、分支和边界方法和博弈论。<ul>
<li>然而，这些方法通常具有<strong>很高的计算复杂性</strong>，尤其是在大规模场景中。</li>
</ul>
</li>
<li>此外，还提出了一些启发式搜索和基于凸的松弛，<ul>
<li>但这些算法通常需要<strong>多次迭代</strong>才能收敛，因此可能不适合快速决策过程。</li>
</ul>
</li>
</ul>
</li>
<li>在具有多用户场景的多MEC系统中，时变无线信道在很大程度上影响了最优决策过程，这对于上述传统算法来说非常具有挑战性，因为一旦环境发生变化，这些传统解决方案通常<strong>需要重新运行算法</strong>。</li>
<li>幸运的是，基于机器学习（ML）的解决方案在通过应用自适应建模和智能学习来解决上述问题方面显示出巨大的潜力。一旦训练完成，通常可以很快获得解决方案，因为只需要少量的代数计算。最近，一些基于ML或深度学习（DL）的算法被提出并应用于MEC系统，如：<ul>
<li>深度神经网络（DNN）、长短期记忆（LSTM）、CNN、Q-学习、DQN 和 DDPG。<ul>
<li>然而，一方面，基于深度学习的模型（如DNN、LSTM和CNN）具有出色的预测和推理能力，但它们<strong>需要大量的标记训练数据</strong>。</li>
<li>另一方面，当 MEC 系统的规模扩大时，基于强化学习（RL）的模型（例如，Q-learning、DQN和DDPG）<strong>无法收敛</strong>，最终结果不稳定。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>在上述背景下，本文提出了一个综合框架，用于在部署了多个UE的大规模MEC系统中共同优化计算卸载和资源分配。</p>
<ul>
<li>我们的<strong>目标</strong>是获得一种<strong>在线调度算法</strong>，以<strong>最小化所有 UE 的加权任务延迟总和</strong>。</li>
<li>为此，我们提出了一个基于深度强化学习（DRL）的框架，该框架包含以下三个组件，即<strong>相关和正则化堆叠自编码器（2r-SAE）</strong>、<strong>自适应模拟退火方法（ASA）</strong>以及<strong>保留和优先体验回放（2p-ER）</strong>。<ul>
<li>1）首先，应用一种具有无监督学习的相关正则化堆叠自编码器（2r-SAE）对高维信道质量信息（CQI）数据进行数据压缩和表示，从而减小DRL的状态空间。</li>
<li>2）其次，我们提出了一种自适应模拟退火方法（ASA）作为DRL的动作搜索方法，其中自适应h-mutation 用于引导搜索方向，并提出自适应迭代以提高 DRL 过程中的搜索效率。</li>
<li>3）第三，引入保留优先体验回放（2p-ER），帮助DRL训练策略网络，找到最优的卸载策略。数值结果表明，与现有基准相比，所提算法在实现接近最优性能的同时，显著缩短了计算时间。</li>
</ul>
</li>
</ul>
</li>
<li><p>与现有作品相比，我们有以下贡献。</p>
<ul>
<li>1）首先，我们提出了一种具有无监督学习的2r-SAE，用于<strong>对高维信道质量数据进行数据压缩和表示</strong>。<ul>
<li>2r-SAE可以为DRL模型提供紧凑的数据表示，从而减少状态空间，提高DRL的学习效率。此外，我们将每个UE的相对误差项添加到损失函数的误差项中，可以同时考虑相对误差和绝对误差，减少特征提取过程中每个UE的信息损失。我们还在损失函数中添加了一个正则化项，以提高 SAE 的泛化性。此外，增量学习用于更新 SAE，以跟踪真实场景的变化。</li>
</ul>
</li>
<li>2）然后，我们提出了一种ASA方法作为启发式搜索方法，以<strong>找到DRL模型的最优动作</strong>，以生成具有相应状态的卸载决策。<ul>
<li>在ASA中，我们引入了两种自适应机制：<ul>
<li>一方面，后续解根据信道质量信息（CQI）自适应地变异。</li>
<li>另一方面，根据DRL的损耗减少，自适应地调整迭代次数。</li>
</ul>
</li>
<li>这两种机制可以在不影响系统性能的情况下，提高SA的效率，减少求解原始优化的时间。</li>
</ul>
</li>
<li>3）最后，提出了一种2p-ER方法<strong>在DRL框架中训练DNN</strong>。<ul>
<li>具体而言，我们使用保留策略来保护接近当前卸载策略的转换。</li>
<li>我们还采用优先策略来选择对损失函数的减少做出更大贡献的过渡。</li>
<li>这两种策略可以加速DRL的收敛，这对于大规模网络非常重要。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>数值结果表明，与现有基准相比，所提算法在实现接近最优性能的同时，显著缩短了计算时间。</li>
<li>结果表明，所提框架能够高精度地同时优化计算卸载和资源分配，使大规模MEC系统的实时资源调度成为可能。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>所提到的“大规模”具体有多大？</li>
<li>论文穿肠过，空气心中留🥲。如何能让论文内容真正内化成知识？通过对比总结将一批论文统一编码？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9070170">[1] F. Jiang, K. Wang, L. Dong, C. Pan and K. Yang, “Stacked Autoencoder-Based Deep Reinforcement Learning for Online Resource Scheduling in Large-Scale MEC Networks,” in IEEE Internet of Things Journal, vol. 7, no. 10, pp. 9278-9290, Oct. 2020, doi: 10.1109/JIOT.2020.2988457.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
        <tag>调度</tag>
        <tag>边缘计算</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记58-前沿-大模型抢占式调度</title>
    <url>/2024/09/10/literature/literatureNotes58/</url>
    <content><![CDATA[<h1 id="x1f4d6-《SpotServe-Serving-Generative-Large-Language-Models-on-Preemptible-Instances》"><a href="#x1f4d6-《SpotServe-Serving-Generative-Large-Language-Models-on-Preemptible-Instances》" class="headerlink" title="📖《SpotServe: Serving Generative Large Language Models on Preemptible Instances》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《SpotServe: Serving Generative Large Language Models on Preemptible Instances》</h1><p>2024 年发表于 CCF-A 类会议 ASPLOS，获 Distinguished Artifact Award 奖。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>生成式大型语言模型（LLM）<strong>对计算和内存的要求很高</strong>，因此以低廉的价格为其提供服务具有挑战性。<ul>
<li>生成式大型语言模型（LLM），如 ChatGPT 和 GPT-4，已在各种应用领域展示出创建自然语言文本的卓越能力，包括摘要、指令跟踪和问题解答。</li>
<li>然而，LLM <strong>对计算和内存的要求很高，</strong>因此要在现代硬件平台上高效地为它们提供服务具有挑战性。<ul>
<li>例如，GPT-3 包含 1750 亿个参数，需要<strong>超过 16 个英伟达 A100-40GB GPU</strong> 以单精度浮点方式存储模型参数，在 AWS 上为 GPT3 提供单个推理流水线服务的<strong>成本超过每小时 66 美元</strong>。随着 LLM 的规模逐渐增大，在普通云 GPU 实例上为其提供服务的成本会让大多数企业望而却步，尤其是那些预算有限的企业。</li>
</ul>
</li>
</ul>
</li>
<li>本论文旨在利用现代云上的可抢占式 GPU 实例来<strong>降低为 LLM 服务的货币成本</strong>，这些实例以比普通实例便宜得多的价格提供对空闲 GPU 资源的访问，但<strong>随时可能被云提供商抢占</strong>。在可抢占实例上服务 LLM 需要解决<strong>实例频繁被抢占</strong>所带来的挑战，以及迁移实例以处理这些抢占的必要性。<ul>
<li>现代云提供了各种<strong>可抢占的 GPU 实例</strong>（例如 AWS spot instances 和 Azure spot VM），这为服务 LLM 提供了一种更经济实惠的方法。这些实例在现代云的<strong>空余容量上运行</strong>，**价格比按需实例低90%**。</li>
<li>然而，与按需实例不同的是，当其他实例需要容量时，现货实例可能<strong>随时被抢占</strong>。当现货实例被抢占时，现代云会提供一个宽限期（例如 AWS 现货实例的宽限期为 30 秒），允许实例完成运行任务并优雅地停止。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>为了应对这一挑战，最近的研究引入了多种方法，通过将 LLM 分成多个子模型（每个子模型都部署在专用 GPU 上）来<strong>并行化</strong> LLM 推断。<ul>
<li>之前的研究已经推出了几种 DNN 服务系统，它们利用现货实例来降低 DNN 推断的货币成本。<ul>
<li>这些系统（如 MArk、Cocktail）大多以<strong>小型 DNN 模型为目标</strong>，这些模型可以安装在一个或多个 GPU 的现货实例上，并使用<strong>请求重路由或冗余计算处理抢占</strong>。</li>
<li>虽然这些方法可以有效地<strong>利用数据并行性</strong>为小型模型提供服务，但它们<strong>无法扩展到 LLM</strong>，而 LLM 的服务<strong>需要结合数据、张量模型和管道模型并行性</strong>。<ul>
<li>模型并行将最小推理粒度从单个 GPU 实例扩大到一组实例（即<strong>推理流水线</strong>），这就<strong>需要</strong>比重定向和冗余计算<strong>更有效的方法</strong>来处理抢占，因为抢占不再是独立的， <font color="red"> 每次抢占都会影响同一推理流水线中的所有其他实例 </font> 。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f93a-挑战"><a href="#x1f93a-挑战" class="headerlink" title="🤺挑战"></a><span class="emoji" alias="person_fencing" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f93a.png?v8">🤺</span>挑战</h2><ul>
<li>本文介绍了 SpotServe，这是首个在<strong>现货实例</strong>上提供 LLM 服务的分布式生成系统。SpotServe 通过<strong>结合数据、张量模型和流水线模型并行性</strong>，在多个现场 GPU 实例上并行 LLM 推断，并产生与使用<strong>按需实例</strong>提供 LLM 完全相同的结果。</li>
<li>在现货 GPU 实例上提供 LLM 服务需要应对三大挑战：**(1)动态重并行化LLM推断<strong>；</strong>(2)低成本迁移实例<strong>；</strong>(3)有效利用宽限期**。我们将详细阐述这些挑战以及 SpotServe 用来克服这些挑战的关键理念。<ul>
<li><strong>（1）挑战一：动态再并行化</strong>。要为 LLM 提供服务，就需要在多个 GPU 上并行处理模型参数和计算，同时使用操作器内（如数据和张量模型）和操作器间（如流水线模型）并行化策略。SpotServe 必须应对的第一个挑战是，由于实例抢占和收购，可用的 Spot 实例数量经常变化，这就需要<strong>动态调整并行化配置</strong>，以实现优化的 LLM 服务性能，我们将这一问题称为动态再并行化。<ul>
<li>解决方案：为应对这一挑战，SpotServe 的并行化控制器可根据现货实例可用性的变化，动态调整为 LLM 服务的并行化策略。SpotServe 同时考虑了并行化策略的推理延迟和服务吞吐量，并使用混合优化算法来平衡吞吐量和延迟之间的权衡。动态重新并行化 LLM 推理使 SpotServe 能够快速适应现货实例可用性和请求到达率的变化。</li>
</ul>
</li>
<li><strong>（2）挑战二：实例迁移</strong>。SpotServe 必须应对的第二个挑战是最大限度地降低为重新并行化而迁移 GPU 实例的成本。特别是在过渡到<strong>不同的并行化策略</strong>时，SpotServe 必须<strong>重新初始化所有现货实例</strong>，以纳入新的模型参数并建立新的通信组。之前在 Spot 实例上提供小型 DNN 模型的工作假定，<strong>重新初始化 Spot 实例的开销可以忽略不计</strong>。然而，我们发现这一假设对 LLM 并不成立，因为从头开始重启 LLM 服务会产生大量开销。例如，在 AWS 上，从持久存储中加载一个包含 1200 亿个参数的 GPT 模型需要 2 分钟以上的时间。<ul>
<li>解决方案：为了最大限度地降低重新并行化的迁移成本，SpotServe 伺机重用模型参数和中间结果，如推理请求的键/值缓存（见第 2 节），以避免实例之间不必要的通信。在 SpotServe 中，将可用的现货实例映射到并行化策略的设备网格的任务被形式化为一个双方图匹配问题，该问题利用 Kuhn-Munkres（KM）算法来确定最佳设备映射，从而最大限度地降低为重新并行化而迁移现货实例的成本。此外，为了决定迁移实例的顺序，SpotServe 的迁移规划器利用管道阶段的顺序执行顺序，将实例迁移与推理计算重叠。</li>
</ul>
</li>
<li>（3）<strong>挑战三：宽限期</strong>。利用现代云提供的宽限期会带来另一个挑战，因为 LLM 的推理时间可能会<strong>超过宽限期</strong>，从而<strong>导致请求未完成</strong>。在现有的现货实例服务系统中，这些未完成的请求通常会被转发到其他推理管道，这些请求的推理计算会<strong>从头开始</strong>。这种方法不能有效利用宽限期，并<strong>导致冗余计算</strong>。<ul>
<li>解决方案：为了利用宽限期，SpotServe 利用了 LLM 的自回归特性，并引入了有状态的推理恢复，这使得 SpotServe 中的推理引擎能够在令牌级而非之前工作中的请求级提交其进度。SpotServe 的推理引擎使用即时 (JIT) 安排来决定何时将已提交标记的键/值缓存迁移到其他可用实例，这些实例使用缓存结果来恢复推理。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>本文介绍了 SpotServe，它是第一个在可抢占实例上的分布式 LLM 服务系统。</li>
<li>SpotServe 中的几项关键技术实现了在廉价的可抢占实例上快速、可靠地提供生成式 LLM 服务。<ul>
<li>首先，SpotServe针对动态实例可用性和波动的工作量动态调整LLM并行化配置，同时平衡整体吞吐量、推理延迟和货币成本之间的权衡。</li>
<li>其次，为使动态并行化迁移实例的成本最小化，SpotServe 将迁移实例的任务表述为一个双方图匹配问题，并使用 KuhnMunkres 算法确定一个能使通信成本最小化的最佳迁移计划。</li>
<li>最后，为了利用现代云平台提供的宽限期，我们引入了有状态推理恢复，这是一种新的推理机制，能以更精细的粒度提交推理进度，并允许SpotServe在抢占时以低成本恢复推理。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>通过上述技术，SpotServe的性能明显优于现有方法。我们在真实轨迹和各种 LLM 上对 SpotServe 进行了评估，结果表明，与现有的 LLM 服务系统相比，SpotServe 可将 P99 尾部延迟降低 2.4 - 9.1 倍。此外，与按需实例相比，SpotServe 还能在保持接近的平均推理延迟的情况下，利用现货实例将 LLM 服务的货币成本最多降低 54%。代码开源于：<a class="link" href="https://github.com/Hsword/SpotServe%E3%80%82">https://github.com/Hsword/SpotServe。<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>方法有一定的局限性，因此有一些未来的研究方向：<ul>
<li>1）首先，SpotServe 的关键理念是<strong>主动处理</strong>实例可用性变化，这在很大程度上<strong>依赖于宽限期</strong>。虽然目前所有云提供商都提供了这一功能，但仍值得探索更有远见的解决方案来提高系统性能，例如与推理工作量<strong>预测</strong>或实例可用性<strong>预测</strong>相结合。</li>
<li>2）其次，我们的方法主要针对单一<strong>GPU实例类型</strong>。也有可能整合异构现货实例，甚至整合来自不同云的实例（如 SkyPilot ），以获得金钱上的优势。这些场景也为 SpotServe 中的上下文迁移带来了新的挑战。</li>
<li>3）最后，我们的方法目前将推理延迟最小化作为<strong>优化目标</strong>。正如我们在第 3.2 节中提到的，探索其他目标（如严格的 SLO、高吞吐量）以满足不同推理场景的需求仍然很有意义。</li>
<li>4）此外，并行化配置的探索空间还可以扩大，以支持未来新出现的<strong>大模型变体（如混合专家）</strong>。</li>
<li>5）虽然 SpotServe 专注于现货实例，但我们的技术可以很容易地推广到其他可抢占的资源，例如，资源调度器可以为紧急作业抢占资源，并产生切换开销。我们相信，我们的方法为可抢占实例的分布式推理提供了一个新范例，从 SpotServe 的设计中获得的启示可以激励沿着这个方向开展各种后续研究。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>最大的亮点在于发现问题并用于实际系统，那么一个算法的新颖性该如何体现？如果审稿人说“我看不出你的创新点”又该如何回答？</li>
<li>为什么场景定位在推理任务？如果放在训练任务场景下故事是否能说得通？如果不能，说不通的原因是什么？隐含的推理作业的特点是什么？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://arxiv.org/abs/2311.15566">[1] SpotServe: Serving Generative Large Language Models on Preemptible Instances, Xupeng Miao* , Chunan Shi*, Jiangfei Duan, Xiaoli Xi, Dahua Lin, Bin Cui, and Zhihao Jia. In Proceedings of the ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), April 2024.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>大模型</tag>
        <tag>推理</tag>
        <tag>抢占</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记8-前沿-CoLocateMe聚合部署VM</title>
    <url>/2023/05/31/literature/literatureNotes8/</url>
    <content><![CDATA[<h1 id="x1f4d6-《CoLocateMe-Aggregation-Based-Energy-Performance-and-Cost-Aware-VM-Placement-and-Consolidation-in-Heterogeneous-IaaS-Clouds》"><a href="#x1f4d6-《CoLocateMe-Aggregation-Based-Energy-Performance-and-Cost-Aware-VM-Placement-and-Consolidation-in-Heterogeneous-IaaS-Clouds》" class="headerlink" title="📖《CoLocateMe: Aggregation-Based, Energy, Performance and Cost Aware VM Placement and Consolidation in Heterogeneous IaaS Clouds》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《CoLocateMe: Aggregation-Based, Energy, Performance and Cost Aware VM Placement and Consolidation in Heterogeneous IaaS Clouds》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>云数据中心面临的主要挑战之一是有效地管理计算资源能源和性能。能源消耗会影响我们的环境，并占大笔能源费用，而性能会影响云经济。因此，云服务提供商正专注于设计能源、性能感知计算策略，这也是已投产的计算机集群的高运营成本导致的。可以通过两种不同的方式实现这一目标：<ul>
<li><p>（i）只分配适当的资源；</p>
</li>
<li><p>（ii）使用 VM 迁移和关闭空闲计算机将工作负载整合到更少的计算机上。</p>
<ul>
<li>一方面，虚拟机迁移功能带来了多种好处，例如改进的可管理性、提高利用率和节能。但是，另一方面，它会导致停机时间，从而降低工作负载的性能。迁移成本高昂，并且在动态云环境中，一小时内有数千个 VM 请求到达，即使它们可能不合适。因此，适当的虚拟机放置策略对于节省能源和为客户提供预期的工作负载性能级别至关重要。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2></li>
</ul>
</li>
<li>虚拟机放置策略可分为：<ul>
<li>（a）隔离；<ul>
<li>在基于隔离的策略中，提供程序在单独的集群（主机）中运行面向用户的工作负载、批处理工作负载和生产工作负载。因此，即使工作负载需求较低甚至没有需求，仍需要使其资源保持运行，这也可能导致资源搁浅（Stranded）。大量正在使用的主机会增加提供商的能源费用，并对我们的环境产生影响。</li>
</ul>
</li>
<li>（b）基于聚合。<ul>
<li>基于聚合的策略在同一主机上运行混合工作负载，这可能会降低工作负载性能，特别是如果它们争用类似的资源（共存虚拟机）。此外，工作负载性能也因不同的 CPU 架构而异——类似的工作负载在相同的 CPU 型号上运行可能大不相同。随后，较低的工作负载性能可能会增加基础设施能耗和用户货币成本。</li>
</ul>
</li>
<li>前一种方法广泛用于许多生产云，例如阿里巴巴集群，但谷歌的集群是一个明显的例外。也许，受到基于聚合的方法的好处的启发，阿里巴巴的集群资源现在也可以混合运行工作负载。然而，在能源效率和工作负载性能方面，仍然需要对这两种方法进行详细调查。<strong>供应商的需求促使我们研究哪种技术在能源、性能和成本效率方面优于另一种技术。此外，也促使我们考虑使用工作负载的哪些特征将它们聚合到类似的服务器上。</strong></li>
</ul>
</li>
<li>在许多生产云中，基于聚合的 VM 放置策略已被用于高效地配置数据中心资源能源和性能。但如果将具有类似工作负载的 VM 放置在同一台计算机上，则它们可能会受到争用的影响，尤其是在它们争用类似资源时。高级别的资源争用可能会降低 VM 的性能，因此可能会增加用户的成本和基础结构的能耗。此外，基于隔离的方法导致资源搁浅，因此经济性降低。</li>
<li>由此导致的工业界对分离工作负载的兴趣，为研究开辟了新的方向。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>在本文中，对于将虚拟机和工作负载放置在异构集群中的物理主机问题，我们将演示基于聚合和隔离的 VM 放置策略如何导致能效、工作负载性能和用户成本的变化。然后，我们提出了基于聚合的放置和迁移的各种方法，以便在性能和用户成本约束下将基础设施能耗降至最低。<ul>
<li>我们提出了基于运行时感知聚合的节能、性能、成本 （EPC） 高效虚拟机放置和整合策略，以便混合执行多个工作负载。由于聚合倾向于将具有相似特征的虚拟机共置到相似的主机上，因此我们将其称为“CoLocateMe”。</li>
</ul>
</li>
<li>本文的主要贡献是：<ul>
<li>提出了基于聚合的能源、性能和成本 （EPC） 感知虚拟机放置策略;</li>
<li>建议采用合并方法，将类似的工作负载放在相同的资源上;</li>
<li>在工作负载性能方面，我们对数据中心中的资源异构性进行建模;</li>
<li>我们评估基于聚合和隔离的虚拟机放置和迁移策略对基础架构能效、工作负载性能和用户成本的影响。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们通过一系列实验进行调查，使用 Microsoft Azure 和 Google 对一万两千多台主机和 100 万个虚拟机的工作负载跟踪，调查放置决策对能源、性能和成本的影响。我们广泛的模拟和实证评估表明，对于某些工作负载，基于聚合的分配和整合是∼9.61% 以上的能量和∼性能效率比基于隔离的策略高 20.0%。此外，各种聚合指标（如运行时和工作负载类型）在能耗和性能方面提供了变化，因此，用户的成本也各不相同。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>引言中提及“类似需求的工作负载会导致资源争用”，那为什么本文的贡献中有“将类似的工作负载放在相同的资源上”？</li>
<li>搁浅资源是什么意思？<blockquote>
<p>“搁浅资产”一词被用于描述因市场形势变化而失去其应有价值的投资或资产。<br>  造成搁浅的原因通常与法律法规出现重大变化以及频繁性突变、环境制约或致使资产成为不良或废弃资产的技术突破等因素有关。</p>
</blockquote>
</li>
</ol>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/9793695">[1] M. Zakarya, L. Gillam, K. Salah, O. Rana, S. Tirunagari and R. Buyya, “CoLocateMe: Aggregation-Based, Energy, Performance and Cost Aware VM Placement and Consolidation in Heterogeneous IaaS Clouds,” in IEEE Transactions on Services Computing, vol. 16, no. 2, pp. 1023-1038, 1 March-April 2023, doi: 10.1109/TSC.2022.3181375.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>部署</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记81-前沿-地理分布式边缘云微服务自动伸缩</title>
    <url>/2025/01/14/literature/literatureNotes81/</url>
    <content><![CDATA[<h1 id="x1f4d6-《GeoScale-Microservice-Autoscaling-With-Cost-Budget-in-Geo-Distributed-Edge-Clouds》"><a href="#x1f4d6-《GeoScale-Microservice-Autoscaling-With-Cost-Budget-in-Geo-Distributed-Edge-Clouds》" class="headerlink" title="📖《GeoScale: Microservice Autoscaling With Cost Budget in Geo-Distributed Edge Clouds》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《GeoScale: Microservice Autoscaling With Cost Budget in Geo-Distributed Edge Clouds》</h1><p>2024 年 南京大学团队 发表于 CCF-A 类期刊 TPDS。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>微服务是一种软件架构，其中整体式应用程序被<strong>分解</strong>为一组<strong>松散耦合</strong>的微服务。每个微服务都可以独立开发、测试、更新和维护，这大大提高了软件的可维护性，并加快了应用程序的开发。此外，微服务总是在<strong>轻量级</strong>容器化实例中运行，实例可以快速启动和终止，这提高了部署的便利性。由于上述优势，近年来，微服务已成为主流软件架构，并被阿里巴巴、亚马逊、谷歌和Netflix等互联网巨头广泛采用。</li>
<li>在位于网络边缘并靠近最终用户的<strong>地理分布式边缘云</strong>中部署微服务实例可以提供<strong>现场处理</strong>，从而提高服务质量（QoS）。<ul>
<li>为了进一步优化QoS，如今从业人员在地理分布的边缘云中部署微服务实例，这些云通常是构建在接入网络附近的微数据中心。边缘云是地理分布的，每个边缘云都可以接收来自其<strong>周围地理区域</strong>的用户请求。用户请求可以直接由附近的边缘云而不是远程云处理，这避免了耗时的<strong>回传</strong>，并减少了请求响应时间。因此，QoS可以大大改善。边缘云可以相互通信并协作以服务用户请求，从而形成边缘环境（简称边缘）。</li>
</ul>
</li>
<li>为了适应每个边缘云的时间变化的<strong>请求到达率</strong>，微服务实例的<strong>部署</strong>方案是<strong>动态调整</strong>的，这被称为微服务自动缩放。<ul>
<li>为了适应每个边缘云的时变请求到达率，微服务实例的部署方案被动态调整，这被称为微服务<strong>自动缩放</strong>。</li>
<li>如图1所示，一个由三个串行连接的微服务组成的应用程序在边缘部署。由于最终用户的移动性、加入和退出（例如，启动和停止使用应用程序），每个边缘云的请求率会随着时间的推移而变化。随着边缘云1附近的请求率增加，在边缘云1中启动更多实例，以提供足够的现场处理。此外，边缘云2和3中的几个实例被终止，以节省部署成本。在本文中，请求率被定义为每秒到达的请求数量（RPS）。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/56298c3857c7d44932796585855173c4d80872f2/1-Figure1-1.png" alt="图1"><figcaption>图1</figcaption></figure></p>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，关于边缘微服务自动缩放的现有研究要么<strong>只是优化QoS</strong>，而不考虑部署微服务<strong>实例的成本</strong>，要么只是专注于<strong>每个时间段的成本</strong>，因此总是严重违反长期预算约束。<ul>
<li>从应用程序服务提供商的角度来看，他们在云供应商管理的边缘云中部署基于微服务的应用程序，并为微服务实例占用的<strong>计算资源付费</strong>。</li>
<li>然而，关于边缘微服务自动缩放的现有研究没有考虑到部署成本的长期预算。他们要么只旨在优化QoS（例如，请求响应时间），而不考虑部署成本，要么只是专注于每个时间段的成本。因此，它们严重违反了长期成本预算，而长期成本预算在实际实践中通常受到限制。</li>
</ul>
</li>
<li>为了解决上述问题，我们面临着两个主要挑战。<ul>
<li><strong>1）首先</strong>，在每个时间段，我们只能观察近期的当前信息或预测信息。然而，这种<strong>短期信息</strong>不足以解决<strong>长期问题</strong>。</li>
<li><strong>2）其次</strong>，由于基于微服务的应用程序<strong>结构复杂</strong>，以及边缘环境中的<strong>请求分布</strong>在地理上<strong>不均匀</strong>，因此很难同时确定每个微服务的实例数量，以及这些实例的部署位置以优化QoS。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了解决这个问题，在本文中，我们研究了在长期成本预算约束下边缘环境中面向QoS的微服务自动缩放问题，并设计了一种名为GeoScale的新方法来解决这个问题，旨在优化<strong>长期</strong>成本预算约束下的平均请求响应时间。<ul>
<li>GeoScale首先利用Lyapunov优化框架将长期优化问题分解为一系列每个时间段的子问题，</li>
<li>然后应用基于符号几何编程（SGP）的算法，为每个NP-hard子问题获得接近最佳的解决方案。</li>
</ul>
</li>
<li>我们的主要贡献如下。<ul>
<li><strong>1）</strong>我们提出了基于微服务的应用程序和边缘环境的<strong>建模</strong>，在此基础上，我们制定了长期成本预算约束下边缘环境中面向QoS的微服务自动缩放问题。</li>
<li><strong>2）</strong>为了解决长期问题，我们提出了一种名为GeoScale的方法，该方法利用Lyapunov优化将问题分解为一系列<strong>单时间段</strong>子问题。GeoScale通过随着时间的推移解决子问题来确保成本预算。</li>
<li><strong>3）</strong>通过确定每个微服务的实例数量并放松整数变量，GeoScale将单时间段子问题转换为SGP问题，可以用接近最佳的解决方案解决。最后，设计了一种新的四舍五入算法来获得整数解。</li>
<li><strong>4）</strong>进行了广泛的跟踪驱动实验，以验证GeScale的优越性。实验结果表明，GeScale可以改善QoS，同时显著减轻对长期成本预算约束的违反。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>通过广泛的跟踪驱动实验，我们验证了GeoScale的优越性。实验结果表明，与现有策略和设计的基线相比，GeoScale可以通过将平均请求响应时间减少到87.8%来提高QoS，同时显著减轻对长期成本预算约束的违反。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>虽然在本文中，我们主要关注边缘的不同请求到达率，但在实践中，基于微服务的应用程序也在不断发展。<strong>微服务可以修改或删除</strong>，也可以<strong>添加新的微服务</strong>。GeoScale也能够适应此类应用程序更改，只需在相应时间段内更新微服务信息。</li>
<li>未来，我们将探索计算异构边缘云中的微服务自动缩放，其中同一微服务的实例在部署在各种边缘云中时具有不同的处理率。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>很经典的写作手法，很清晰，但创新性体现不足。如果只是利用Lyapunov优化，似乎就很简单？运筹学方法的亮点在什么地方？</li>
<li>图1中体现了用户的移动性，在具体处理时如何考虑？只预测移动性导致的请求量变化？</li>
<li>图画得很好看，值得借鉴。</li>
<li>国家级/世界级的地理分布式调度落地很难，但如果缩小成区域级边缘地理分布式数据中心下的调度，似乎就比较容易接受了。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10440209">[1] K. Cheng et al., “GeoScale: Microservice Autoscaling With Cost Budget in Geo-Distributed Edge Clouds,” in IEEE Transactions on Parallel and Distributed Systems, vol. 35, no. 4, pp. 646-662, April 2024, doi: 10.1109/TPDS.2024.3366533.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>伸缩</tag>
        <tag>地理分布</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记82-前沿-用RL进行VM重调度以整理碎片VMR2L</title>
    <url>/2025/04/28/literature/literatureNotes82/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Towards-VM-Rescheduling-Optimization-Through-Deep-Reinforcement-Learning》"><a href="#x1f4d6-《Towards-VM-Rescheduling-Optimization-Through-Deep-Reinforcement-Learning》" class="headerlink" title="📖《Towards VM Rescheduling Optimization Through Deep Reinforcement Learning》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Towards VM Rescheduling Optimization Through Deep Reinforcement Learning》</h1><p>2025 年 UC Merced大学、 UC Berkeley大学、字节跳动团队 发表于 CCF-A 类会议 EuroSys。</p>
<p>系列博客：</p>
<ol>
<li><a href="/2025/04/28/literature/literatureNotes82/" title="VMR2L-初步略读笔记">VMR2L-初步略读笔记</a></li>
<li><a href="/2025/05/11/literature/literatureNotesIntensive2/" title="VMR2L-整体逻辑精解笔记">VMR2L-整体逻辑精解笔记</a></li>
<li><a href="/2025/05/14/literature/literatureNotesIntensive3/" title="VMR2L-相关工作发展脉络梳理笔记">VMR2L-相关工作发展脉络梳理笔记</a>

</li>
</ol>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>现代行业规模的数据中心需要管理大量虚拟机（VM）。<ul>
<li>云服务提供商（Cloud Service Providers）允许最终用户（end-users）访问计算资源，例如CPU和内存。</li>
<li>他们采用<strong>资源虚拟化</strong>来最大化硬件利用率，将虚拟机（Virtual Machines，VMs）与请求的资源分配给最终用户。一个行业规模的数据中心通常组织成集群（Cluster），每个集群都有数百种物理机器（Physical Machines，PMs），每个PM可以托管多个独立运行的VM。</li>
</ul>
</li>
<li>由于VM的不断创建和释放，许多小型资源片段散布在物理机器（PMs）之间。<ul>
<li>但是，如果PM已经托管了多个VM，并且PM上的<strong>其余资源</strong>无法满足额外的VM请求，则不能使用剩余的资源称为碎片（fragments）。</li>
</ul>
</li>
<li>为了处理这些片段，数据中心定期将一些VM重新安排为替代PM，这种做法通常称为VM重新安排。<ul>
<li>为了有效地分配资源，中央服务器通过执行两个任务，<strong>调度</strong>和<strong>重调度</strong>来管理PMs上的所有VM请求，以实现不同的资源利用目标，例如最大程度地<strong>减少总体碎片率（Fragment Rate，FR）</strong>或最大程度地<strong>减少实现特定FR所需的迁移数量</strong>。<ul>
<li><strong>碎片率（Fragment Rate，FR）</strong>。FR量化了<strong>无法使用的CPU资源</strong>与<strong>所有PMS中可用的CPU资源的比率</strong>。具体而言，<ul>
<li>分子代表无法用于安排16核VM的总CPU资源（即，太小或太分散而无法容纳这种VM的CPU碎片）；</li>
<li>分母是所有PMs中可用的CPU资源。</li>
<li>该指标有助于评估系统如何利用其资源进行大型VM分配。</li>
</ul>
</li>
<li><strong>VM调度（VM Scheduling，VMS）</strong>。当一个新的虚拟机请求到达时，VMS 会从所有可用的 PM 中选择一个可以满足该请求的 PM。如果虚拟机调度不当，会直接影响最终用户。<ul>
<li>图 1 显示了 <strong>24 小时内每分钟虚拟机变化（虚拟机到达和退出）的分布情况</strong>，这是我们内部数据中心集群 30 天内的平均值。<ul>
<li>Y 轴表示每分钟内发生变化（到达和退出）的虚拟机数量。</li>
<li>要在所有时间为所有用户提供服务，VMS 算法（绿色数字 1）必须处理<strong>最大数量的虚拟机变更</strong>，如绿线所示，绿线代表全天持续的虚拟机调度过程。每秒高查询次数（QPS）要求 VMS 算法具有严格的延迟和稳定性，因此只有推理时间短的简单启发式方法才可行。<ul>
<li>在实践中，ByteDance 采用了 <strong>best-fit</strong>，即根据添加该虚拟机前后的 FR 减少量对满足当前虚拟机要求的所有 PM 进行排序，并选择减少量最大的 PM。</li>
<li>然而，这种启发式算法会导致许多碎片分散在 PM 中。再加上已完成虚拟机的不断退出，导致许多碎片分散在各个 PM 中。</li>
<li>这些问题必须通过<strong>虚拟机重调度</strong>来解决。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>VM重调度（VM Rescheduling，VMR）</strong>。重新调度对于优化资源使用至关重要，它将虚拟机从当前 PM 迁移到新的目标 PM。<ul>
<li><strong>时机：</strong>与需要全天运行的 VMS 不同，VMR 主要在<strong>非高峰时段</strong>的清晨执行，如图 1 中的红点所示，清晨的 VM 变动较少。这样就可以使用更先进的算法。在不太常见的情况下，如果观察到高 FR，有可能导致即将到来的虚拟机请求资源不足，也会执行 VMR。</li>
<li><strong>影响：</strong>此外，如果重新调度操作失败，虚拟机只需停留在原来的 PM 上，不会影响最终用户。VMR 可通过实时迁移高效执行，确保停机时间最短。由于大多数数据中心在管理虚拟机时都将计算与存储分离（即使用云磁盘），因此只需传输内存。具体来说，我们首先将虚拟机的内存状态从源 PM 复制到目标 PM，同时继续在源 PM 上运行。在此过程中，虚拟机内存的变化（称为 “脏页”）会被跟踪并逐步重新复制，直到剩余的变化很小为止。此时，虚拟机会短暂暂停，进行最终同步。由于现代数据中心使用高带宽网络进行内部文件传输，因此 <strong>VMR 过程产生的开销较低</strong>。</li>
<li><strong>对象-任务：</strong><ul>
<li>重调度主要应用于托管使用硬件虚拟化的虚拟机（VMs）的集群，类似于弹性计算云（EC2）环境。这些虚拟机提供强大的隔离性，并且启动成本高，因此适合运行<strong>长时间</strong>的工作负载，如开发机器。</li>
<li>对于CI/CD或CronJob等<strong>短期</strong>任务，重新调度是不必要的。它们通过Kubernetes在单独的集群中管理，Kubernetes通过操作系统级别的虚拟化提供快速启动。</li>
<li>小型虚拟机（例如，Proxy代理服务器或常规监控/测试。Proxy代理服务器在请求资源的客户端和提供该资源的服务器之间充当中间人。）使用碎片化资源创建简单，几乎不存在供应中断的风险。相反，许多直接面向消费者的高优先级任务需要中等和大型虚拟机。因此，我们的研究重点在于16核心FR，以满足字节跳动的运营需求，其中16核心是开发机器的默认虚拟机类型。</li>
</ul>
</li>
<li><strong>对象-资源：</strong><ul>
<li>为了系统稳定性，重新调度通常限制在同一个集群。一个集群通常涉及不超过几百个PM，因为<ul>
<li>i）它允许为不同的用户组分配专用资源，其中特定的配置可以更好地优化，</li>
<li>ii）每个集群可以独立监控和管理，允许一个集群升级而不影响其他集群。</li>
</ul>
</li>
<li>设置<strong>迁移数量限制（migration number limit，MNL）</strong>以控制迁移的虚拟机数量，通常选择为所有虚拟机的 2∼3%。</li>
</ul>
</li>
</ul>
</li>
<li><strong>VMR的益处</strong>。<ul>
<li><strong>有效：</strong>考虑图2中的FR。PM1剩余12个CPU，PM2剩余20个CPU，但只有PM2可以托管另一个16核心的虚拟机，剩余的12 + (20 - 16) = 16个CPU成为碎片。因此，FR为16/(12 + 20) = 50%。在图3中，VMR将VM1从PM1重新分配到PM2，每个PM上留下16个空闲CPU，这正好可以处理额外的16核心虚拟机。VMR后的FR变为0%。</li>
<li><strong>失效：</strong>请注意，虽然VMR算法正在计算解决方案，但VMS仍在处理新的虚拟机请求，并且完成的虚拟机也在被删除。虚拟机状态的动态性导致计算出的VMR解决方案不再是最优的，甚至可能不可行。虚拟机如果已退出或目标PM不再有足够的资源或未能满足其他服务约束，将不会被重新安排。<ul>
<li>因此，VMR也需要非常高效。在第2节中，我们将VMR表述为一个混合整数规划（MIP）问题，并进行实验以表明，与其他MIP应用不同，VMR<strong>推理时间必须低于五秒</strong>，以确保解决方案具有竞争力。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/888adfb5d44d5baaba8f6cbbc7b551595c8bcc80/2-Figure1-1.png" alt="图1"><figcaption>图1</figcaption></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>尽管随着数据中心的规模增长，VM重新安排的重要性越来越大，但问题仍在研究中。<ul>
<li>大多数现有的解决方案要么涉及加速MIP求解器，要么完全依靠启发式方法。但是，前者仍然无法满足严格的延迟要求，而后者则导致了次优的解决方案。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>我们首先表明，与大多数组合优化任务不同，由于此期间动态VM状态变化，VM重新安排算法的推理时间显着影响其性能。这会导致现有方法的扩展较差。</li>
<li>因此，我们开发了用于VM重调度的强化学习系统VMR2L，该系统结合了一组定制技术，例如适合各种约束和工作量条件的两阶段框架，该框架是一种特征提取模块，可捕获特定于重新安置，重新安置的关系信息，以使寻求评估的用户以及能够享受额外的用户，并确保使用额定范围，并准确地享受了准确的范围。<ul>
<li>RL非常适合，有两个原因。<ul>
<li>1）首先，尽管RL通常患有样本复杂性差，但VMR在确定性的环境中运行，这意味着，鉴于当前状态和动作，可以准确预测下一个状态。这使我们能够构建一个仅需要初始的VM-PM映射进行培训的模拟器，而无需与真实数据中心互动，该中心大大降低了所需的培训样本数量。</li>
<li>2）其次，深度RL的概括能力使代理商能够离线训练并直接在生产中直接应用学习政策而无需再培训。这对于满足VMR严格的延迟要求至关重要。</li>
</ul>
</li>
</ul>
</li>
<li>我们总结了本文的贡献如下：<ul>
<li>1）用于虚拟机重新安排的 RL。我们确定了重新安排问题在延迟要求和环境不确定性方面的独特特征，这促使我们将其表述为一个 RL 问题。</li>
<li>2）虚拟机重新安排的定制技术。我们设计了 <ul>
<li>i) 一个两阶段框架，可灵活适应不同的服务约束并解决探索难题；</li>
<li>ii) 一个特征提取模块，可扩展到大型数据中心，同时捕捉 VMR 特有的关系信息；</li>
<li>iii) 一个风险寻求评估管道，可利用 VMR 的确定性，在推理速度和解决方案质量之间进行更好的权衡。</li>
</ul>
</li>
<li>3）VMR2L 原型和广泛评估。我们收集了两个真实数据集，并证明 VMR2L 能够适应不同的目标、服务约束以及部署时的异常工作负载。我们的代码和数据集已发布。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们对来自行业规模数据中心的数据进行了广泛的实验。我们的结果表明，VMR2L可以实现与最佳解决方案相当的性能，但运行时间为几秒钟。 代码和数据集是开源的。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>跨地域场景下的资源整合该如何处理？</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>现在在多大规模下达到5s？如果更大规模情况下该如何处理？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3689031.3717476">[1] Xianzhong Ding, Yunkai Zhang, Binbin Chen, Donghao Ying, Tieying Zhang, Jianjun Chen, Lei Zhang, Alberto Cerpa, and Wan Du. 2025. Towards VM Rescheduling Optimization Through Deep Reinforcement Learning. In Proceedings of the Twentieth European Conference on Computer Systems (EuroSys ‘25). Association for Computing Machinery, New York, NY, USA, 686–701. https://doi.org/10.1145/3689031.3717476<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>迁移</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记80-前沿-混合云等待时间自动决策</title>
    <url>/2025/01/13/literature/literatureNotes80/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Starburst-A-Cost-aware-Scheduler-for-Hybrid-Cloud》"><a href="#x1f4d6-《Starburst-A-Cost-aware-Scheduler-for-Hybrid-Cloud》" class="headerlink" title="📖《Starburst: A Cost-aware Scheduler for Hybrid Cloud》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Starburst: A Cost-aware Scheduler for Hybrid Cloud》</h1><p>2024 年 UC Berkeley大学团队 发表于 CCF-A 类会议 ATC。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>为了有效地应对工作需求的爆发，组织<strong>采用混合云</strong>架构将批量工作负载从私有集群扩展到公共云。这需要将集群调度程序转换为支持公共云的版本，以在云成本和调度程序目标（例如作业完成时间（JCT））之间进行权衡。<ul>
<li>随着人工智能 (AI) 和数据分析工作负载需求的不断增长，企业构建了<strong>大型多租户私有集群</strong>（以下简称固定集群）以及高端 GPU 加速器。这些固定集群利用集群管理器根据定义的调度策略将资源分配给作业。在即将到来的<strong>截止日期或产品发布等事件</strong>期间，这些集群还会经常遇到作业量的<strong>大幅激增</strong>，从而导致长时间的排队延迟。</li>
<li>许多组织没有投资更多的本地硬件，而是采用<strong>混合云架构</strong>。这些架构利用云在峰值负载期间动态配置额外资源，提供更具成本效益的解决方案。</li>
</ul>
</li>
<li>然而，云对<strong>无限资源容量</strong>的幻想给支持云的调度程序带来了新的挑战。这些调度程序不仅必须<strong>在固定集群和云之间分配</strong>作业，而且还必须<strong>了解云成本</strong>。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，我们对生产级跟踪的分析表明，由于<strong>集群利用率低</strong>，现有的支持云的调度程序会导致<strong>低效的成本与 JCT 权衡</strong>。</li>
<li>当作业到达时集群已满时，调度程序会执行两种选择：等待（Wait）或立即将作业发送到云端（No-Wait）。<ul>
<li><strong>（1）No-Wait</strong>：具有云自动扩展功能的<strong>现有集群管理器</strong>选择后者——我们称之为“No-wait”的策略。这种方法<strong>消除了排队延迟</strong>并<strong>减少了平均作业完成时间 (JCT)**，但由于仅考虑当前时刻而不考虑未来时刻，使得</strong>集群利用率较低**，因此会带来较高的云成本。No-Wait 忽略等待选项，这会延迟集群上的作业执行，以避免配置昂贵的云资源。</li>
<li><strong>（2）Constant-Wait</strong>：如果我们选择等待（Wait），下一个问题是：要等多久？一种简单的策略，<strong>Constant-Wait</strong>，在将所有作业 j 发送到云之前分配恒定的等待时间 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="9.049ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 3999.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mo" transform="translate(716,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1105,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(1517,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2183.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(3239.6,0)"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g></g></g></svg></mjx-container>。在实践中，选择正确的 C 具有挑战性。<ul>
<li>较短的等待时间可以<strong>减少排队延迟</strong>，但会带来较高的云成本和较低的集群利用率,大型作业往往在等待一小段时间后仍不能获取资源，则容易被发送到云端。</li>
<li>相反，较长的等待时间<strong>可以降低成本</strong>，并且对于较长的作业来说是可以接受的，但较长的等待时间会阻塞并不公平地延迟较短作业的运行。</li>
</ul>
</li>
</ul>
</li>
<li>这些不同的问题凸显了支持云的调度程序需要进行权衡：平衡云成本与作业完成时间 (JCT)。<ul>
<li>如果集群已满，No-Wait 会立即调度作业，从而导致高昂的云成本。</li>
<li>如果没有云，作业可以无限期地排队（无云，C=∞），从而导致零云成本和高 JCT。</li>
<li>最后，Constant-Wait 根据不同的 C 值调整成本和 JCT。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>在本文中，我们探讨了何时在云上安排作业的问题，以降低云成本，同时避免长时间的排队延迟。</p>
</li>
<li><p>我们推出了 Starburst，这是一个最大化集群利用率以简化成本与 JCT 权衡的系统。 </p>
<ul>
<li>Starburst 的调度程序动态控制作业的等待时间以提高利用率 - 它为大型作业分配较长的等待时间以增加其在集群上运行的机会，为小型作业分配较短的等待时间以增加其在云上运行的机会。</li>
<li>为了提供可配置性，Starburst 为系统管理员提供了一个简单的等待预算框架，以调整他们在成本 JCT 曲线上的位置。</li>
<li>与传统的集群调度程序不同，Starburst 在私有集群和动态云集群上作为更高级别的资源管理器运行。</li>
<li>我们的主要见解是，与<strong>作业的计算成本成正比的等待可以更好地平衡成本和 JCT</strong>；大型昂贵作业可以更好地利用集群，等待足够长的时间才能在集群上运行，而较小的作业成本较低，等待时间较短，更有可能在云上运行。</li>
</ul>
</li>
<li><p><strong>（1）</strong>Starburst 引入了一种新颖的框架，可以<strong>根据作业的特征动态分配等待时间</strong>。我们提出了两种调度算法：Compute-Wait（<strong>假设了解作业运行时间</strong>）和 Star-Wait（<strong>不需要先验知识</strong>）。 </p>
<ul>
<li><strong>Compute-Wait</strong> 根据作业的总计算量（其预测运行时间和请求的资源的乘积）来分配作业的最大等待时间。</li>
<li>与 Compute-Wait 类似，<strong>Star-Wait</strong> 具有运行时和资源感知能力，但假设作业运行时的知识为零。为了将长时间运行的作业与短期作业分开，它会<strong>抢占</strong>从云端返回集群执行时间超过一小段时间的云运行作业。然后，被抢占的作业将根据其资源需求的比例分配等待时间。</li>
<li>更重要的是，为大型作业分配长时间等待会<strong>阻塞</strong>队列中更靠后的<strong>较小作业</strong>。为了减少阻塞，Starburst 积极地在队列中<strong>无序执行作业</strong>。该技术可以有效地调度小型作业，同时大型作业则等待足够的资源。<ul>
<li>无序调度（Out-of-order）改进了无云环境中的 JCT，但在 JCT 中产生了长尾。在混合云环境中，由于作业超时到云，我们在 Starburst 中没有观察到不公平的作业延迟。</li>
</ul>
</li>
<li>总的来说，Starburst 的策略将成本-JCT 曲线转向更帕累托有效的解决方案（图 2），使 Starburst 能够实现高达集群利用率为 99%，与最佳解决方案的误差不超过 5%。</li>
</ul>
</li>
<li><p><strong>（2）</strong>鉴于各组织的工作负载和预算限制各异，在 costJCT <strong>权衡</strong>方面不存在一刀切的立场。 Starburst 提供了一个简单的<strong>等待预算功能</strong>，为系统管理员提供了一个单一的<strong>旋钮</strong>来确定他们在成本-JCT 曲线上的位置。这被定义为管理员**愿意接受的平均作业运行时间增加的最大百分比 P%**。</p>
</li>
<li><p><strong>（3）</strong>与集群调度程序不同，Starburst 是一种通用的高级资源管理器，它通过私有集群和动态配置的云集群跨集群协调作业，并且对其用户是透明的，不需要对作业进行修改。</p>
</li>
<li><p>本文的主要贡献是： </p>
<ul>
<li>• 我们将云成本-JCT 权衡形式化为混合云环境中的调度问题。</li>
<li>• Starburst 根据作业的特征动态分配等待时间，以最大限度地提高集群利用率，更好地平衡成本和 JCT。 Starburst 可以利用作业运行时的知识，但也可以在没有先验知识的情况下进行操作。</li>
<li>• Starburst 的等待预算框架为系统管理员提供了一个旋钮来定义他们在成本-JCT 曲线上的位置。</li>
<li>• 我们的系统易于部署，并显示出显着的性价比改进。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们实现了一个高保真模拟器，用于在多个生产轨迹上测试 Starburst。</li>
<li>我们在 32 个 GPU 私有物理集群上的结果表明，与 No-Wait 相比，Starburst 降低了 80% 的成本，而 JCT 仅增加了 5.8%。对于大规模模拟，Starburst 可以将成本降低 54-91%，同时将 JCT 提高最多 5%。</li>
<li>最后，Starburst 对于数据传输开销、高度突发的工作负载以及较低级别的排队和装箱策略具有鲁棒性。</li>
</ul>
<!-- ## ⛳️未来机会
*  -->

<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>有点意思的文章，粗看问题觉得很简单，但看到解决方案又觉得挺好玩。一方面刻画了C值曲线，另一方面提出了“需要先验知识”和“不需要先验知识”的两种方案。</li>
<li>这类看起来很简单的文章该如何体现新？被ATC看中的原因是什么？是实用？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.usenix.org/conference/atc24/presentation/luo">[1] Luo, Michael, et al. “Starburst: A Cost-aware Scheduler for Hybrid Cloud.” 2024 USENIX Annual Technical Conference (USENIX ATC 24). 2024.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>混合云</tag>
        <tag>等待时间</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记83-前沿-Eva考虑干扰的任务共置成本优化</title>
    <url>/2025/05/19/literature/literatureNotes83/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Eva-Cost-Efficient-Cloud-Based-Cluster-Scheduling》"><a href="#x1f4d6-《Eva-Cost-Efficient-Cloud-Based-Cluster-Scheduling》" class="headerlink" title="📖《Eva: Cost-Efficient Cloud-Based Cluster Scheduling》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Eva: Cost-Efficient Cloud-Based Cluster Scheduling》</h1><p>2025 年 威斯康星大学麦迪逊分校（University of Wisconsin-Madison）团队 发表于 CCF-A 类会议 EuroSys。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><p>云计算提供了资源调配的灵活性，允许企业通过动态调整基于云的集群（从云中调配的实例集合）的规模和组成，以经济高效的方式托管批处理工作负载。</p>
<ul>
<li>云计算已被广泛采用，由于机器学习（ML）和大数据分析等新兴技术的兴起，对云计算的需求不断增加[12, 18]。<ul>
<li>具体来说，对于<strong>批量计算工作负载</strong>，云平台的灵活性和可扩展性为企业提供了一种解决方案，使其可以使用基于云的集群（即从云中调配的实例池），以具有成本效益的方式托管作业[8]。因此，研究机构和企业已将批处理工作负载从内部计算集群迁移到由数百或数千个云实例组成的云集群[17, 41, 53, 54]。</li>
</ul>
</li>
<li>为确保云计算集群的成本效益，必须采用<strong>有效的调度机制</strong>，将提交的任务映射到适当的实例上[1]。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><p>然而，由于任务和实例调度策略不理想、同地任务之间相互干扰以及实例调配开销等原因，现有的调度程序无法最大限度地降低总成本。<br>传统方案：虽然<strong>针对批处理工作负载</strong>的<strong>任务调度</strong>已在<strong>固定规模的集群</strong>设置中进行了广泛研究[19、23、28、36、37、43、45、47、62、63、67]，但<strong>基于云的集群</strong>的额外灵活性为调度问题带来了复杂性。</p>
<ul>
<li><strong>挑战一：无限云资源下，代替排队执行的按需分配决策</strong><ul>
<li>具体来说，资源的<strong>按需分配</strong>消除了作业因<strong>资源不足</strong>而在队列中等待的时间[6]，而这正是大多数固定规模集群调度器的主要关注点。</li>
</ul>
</li>
<li><strong>挑战二：吞吐量保证的异构实例成本优化决策</strong><ul>
<li>此外，基于云的集群可以利用云提供商提供的<strong>各种异构实例</strong>动态调整其组成，每种实例类型都有自己的成本。<ul>
<li>因此，这些因素将调度问题的目标从<strong>仅最小化作业完成时间（JCT）</strong>转变为在<strong>不影响作业吞吐量的情况下最小化总供应成本</strong>。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>云上方案：有鉴于此，先前的工作提出了云环境下的调度器[6, 26, 57, 71]。然而，这些调度器未能解决某些难题，而这些难题对于以具有成本效益的方式托管批处理作业至关重要（第 2.3 节）。</p>
<ul>
<li>前提：由于<strong>任务调度</strong>和<strong>实例供应</strong>从根本上是相关联的，因此应联合优化这两个方面，以确定最佳集群配置，其中包括组成集群的实例数量和类型以及任务到实例的分配。<ul>
<li>任务调度：应有效利用供应实例的可用资源，</li>
<li>而实例供应：选择应与任务的需求相匹配。</li>
</ul>
</li>
<li><strong>挑战三：考虑干扰下的互补任务共置</strong><ul>
<li>首先，集群中的批处理作业对资源的需求多种多样，且<strong>相关性较弱</strong>[19, 73]，这就提供了将<strong>多个任务共置到</strong>同一实例上的机会，以<strong>减少实例配置数量</strong>，从而<strong>降低总成本</strong>。</li>
<li>然而，共置任务之间的干扰会导致<strong>性能下降</strong>，不同任务之间的性能<strong>下降幅度</strong>可能很大。<ul>
<li>图 1 显示，**仅两个共置任务的性能降低幅度就可达 0-36%**。</li>
<li>因此，简单地将任务共置可能会导致作业持续时间大大延长，这反过来又会增加实例的正常运行时间，导致总体配置成本增加。</li>
</ul>
</li>
</ul>
</li>
<li><strong>挑战四：迁移时间开销导致资源浪费感知</strong><ul>
<li>此外，随着作业提交到系统或在系统中完成，<strong>最佳集群配置也会随时间发生变化</strong>。集群重新配置，即从一种集群配置切换到另一种集群配置，可以提高资源配置的成本效益。</li>
<li>但涉及<strong>任务迁移和实例启动</strong>，会带来几分钟数量级的延迟，如表 1 所示。在这些延迟期间，已配置的资源仍处于闲置状态，导致<strong>成本浪费</strong>。因此，调度程序必须考虑长期供应成本节约与短期迁移开销之间的权衡。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/8ee079a778816d327103a2d14873d4dc343cb272/3-Figure1-1.png" alt="图1：批处理任务在同一实例上共置时的性能。每个单元显示的是工作负载 1 与工作负载 2 同处一地时的归一化吞吐量。如表 7 所列，两个工作负载都获得了各自所需的资源，并被分配给同一实例上的不同 GPU 和 CPU。工作同时启动并运行 10 分钟。在此期间对每个作业的吞吐量进行测量，并将其除以该作业在未共置实例上的独立吞吐量进行归一化。"><figcaption>图1：批处理任务在同一实例上共置时的性能。每个单元显示的是工作负载 1 与工作负载 2 同处一地时的归一化吞吐量。如表 7 所列，两个工作负载都获得了各自所需的资源，并被分配给同一实例上的不同 GPU 和 CPU。工作同时启动并运行 10 分钟。在此期间对每个作业的吞吐量进行测量，并将其除以该作业在未共置实例上的独立吞吐量进行归一化。</figcaption></figure></p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/8ee079a778816d327103a2d14873d4dc343cb272/4-Table1-1.png" alt="表 1.重新配置延迟。与实例相关的延迟基于 AWS EC2 上 126 个实例的测量结果，而与作业相关的延迟则是根据表 7 所列 10 个工作负载中 120 个作业的抽样测量结果得出的。"><figcaption>表 1.重新配置延迟。与实例相关的延迟基于 AWS EC2 上 126 个实例的测量结果，而与作业相关的延迟则是根据表 7 所列 10 个工作负载中 120 个作业的抽样测量结果得出的。</figcaption></figure></p>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><p>为了应对这些挑战，我们提出了 Eva，这是一种基于云的集群调度器，可降低托管长期批处理作业的总成本。在 Eva 中，我们建议<strong>将任务打包到一组实例中</strong>，以提高利用率并降低成本。</p>
<p>创新一：Eva 利用经济学中的预订价格来推导出最佳实例配置集和任务到实例的分配。</p>
<ul>
<li>(1) 为了将任务调度和实例供应联系起来，Eva 的调度算法从一个有效的启发式中汲取了灵感，该启发式可用于解决可变大小的装箱问题（VSBPP），众所周知，该问题具有 <strong>NP 难度</strong>[13]。<ul>
<li>该启发式优先考虑较大的桶类型和球，以减少已使用的桶数量和每个垃圾桶内未使用的空间，从而降低总成本。</li>
<li>虽然启发式在单维环境中很有效，但由于存在<strong>多维资源</strong>（如 GPU、CPU、RAM），很难为实例类型和任务定义单一的 “大小”，因此将启发式<strong>推广到基于云的集群调度中会带来挑战</strong>。</li>
</ul>
</li>
<li>(2) 在 Eva 中，我们通过成本捕捉最小化资源分散的直觉，成本与所涉及的资源数量和类型成正比（第 4.2 节）。<ul>
<li>具体来说，任务按从高到低的预订价格[58]来考虑。<ul>
<li>预订价格是从经济学中借用的概念，代表<strong>买方愿意</strong>为商品或服务支付的最<strong>高价格</strong>，而实例类型则按从低到高的小时成本来考虑。</li>
<li>在调度上，执行任务的预订价格是指如果任务在独立实例上执行而不共用位置，则会产生的每小时成本。</li>
<li>这为评估任务分配到实例的成本效率提供了依据：分配到实例的一组任务的预订价格之和不应低于实例的实际每小时成本。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>创新二：Eva 还考虑到了共置任务时的性能下降，并在考虑改变集群配置时定量评估了短期迁移开销与长期供应节省之间的权衡。</p>
<ul>
<li>(1) 为了考虑主机托管干扰造成的性能下降，我们<strong>扩展了预订价格</strong>，以考虑<strong>任务的吞吐量</strong>（第 4.3 节）。<ul>
<li>任务的<strong>吞吐量归一化预订价格</strong>代表用户愿意支付的最高价格，以便在干扰情况下以一定的吞吐量水平托管任务。<ul>
<li>例如，如果一个任务可以托管在一个每小时花费 3 美元的实例类型上，并且在没有共置的情况下吞吐量达到 100%，那么当它的吞吐量由于与其他任务共置的干扰而下降到 80% 时，用户愿意支付每小时 3 美元 × 0.8 = 2.40 美元。</li>
<li>这样，即使存在多任务工作（同一工作中各任务的性能相互依赖），我们也可以根据性能对任务到实例的分配进行相同的成本效益评估（第 4.4 节）。</li>
</ul>
</li>
</ul>
</li>
<li>(2) 基于<strong>吞吐量归一化预订价格</strong>，我们设计了两种调度算法：完全重新配置（§4.2）和部分重新配置（§4.5）。这两种算法结合使用，可在线更新集群配置。<ul>
<li>a. <strong>“完全重新配置”</strong>考虑了当前系统中的所有任务，以确定能使配置成本最小的集群配置。</li>
<li>b. **”部分重新配置 “**保留了当前集群配置的大部分，只更新了任务和实例的子集，以尽量减少迁移开销。</li>
<li>在每一轮调度中，Eva 都会运行这两种算法来生成两个候选集群配置，并从中选择一个。<ul>
<li>直观地说，当节省的潜在配置成本能够证明迁移开销的合理性时，尤其是当节省的成本可观且持久时，完全重新配置是首选。</li>
</ul>
</li>
<li>我们提出了一种<strong>定量方法</strong>（第 4.5 节）来估算节省的配置成本和迁移开销之间的权衡，Eva 将其作为在两个候选集群配置中做出选择的标准。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><p>AWS EC2 上的实验和大规模跟踪仿真表明，与为每个任务分配单独实例相比，Eva 降低了 42% 的成本，而 JCT 仅增加了 15%。</p>
<ul>
<li>我们用 Python 实现了 Eva 和高保真模拟器。<ul>
<li>虽然目前的实现假定 AWS EC2 [55] 为云平台，但 Eva 的模块化设计（第 3 节）可确保轻松适应其他云提供商。</li>
<li>任务在云中作为容器执行，确保不受框架或任务环境的限制。</li>
<li>此外，Eva 还包含一个轻量级的迭代器应用程序接口（API），用于监控作业吞吐量，只需在用户端进行少量代码修改。</li>
</ul>
</li>
<li>我们在 AWS EC2 上对 Eva 进行了评估，跟踪了 ML 和科学计算中的各种批处理应用（表 7）。<ul>
<li>我们发现，Eva 将总成本降低了 25%，将平均资源分配提高了 1.2 倍。</li>
<li>此外，我们使用阿里巴巴生产跟踪[66]的 6200 多个作业进行的模拟显示，Eva 降低了 42% 的成本，即使在共置干扰和任务迁移延迟较高的不利情况下，也能持续实现显著的成本降低。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/8ee079a778816d327103a2d14873d4dc343cb272/11-Table7-1.png" alt="表 7.评估的工作负载和每个任务的资源需求。除 ResNet18 外，所有工作负载均为单任务工作。对于 CPU 需求，括号外的数字代表 P3 实例的需求，而括号内的数字（如有）代表 C7i 和 R7i 实例的需求。由于 C7i 和 R7i 实例的 CPU 频率较高，CPU 作业在这些实例上可以用较少的 CPU 达到相同的吞吐量。"><figcaption>表 7.评估的工作负载和每个任务的资源需求。除 ResNet18 外，所有工作负载均为单任务工作。对于 CPU 需求，括号外的数字代表 P3 实例的需求，而括号内的数字（如有）代表 C7i 和 R7i 实例的需求。由于 C7i 和 R7i 实例的 CPU 频率较高，CPU 作业在这些实例上可以用较少的 CPU 达到相同的吞吐量。</figcaption></figure></p>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>目前对共置干扰影响的分析刻画是黑盒的，且没有对共置预估方法合理性做理论分析。可以考虑利用基于白盒分析的方法预估，并全面地描述准确性。</li>
<li>目前共置干扰分析不考虑资源的影响，没有分析在不同资源下共置干扰是否会不同。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>“任务迁移和实例启动会带来几分钟级的延迟”和常识有所差别，理论上容器应该是秒级启动？且热迁移技术也能在秒级完成。<ol>
<li>本文的前提是AWS EC2，虚机确实有较长的启动时间，这是否意味着在容器场景下可以忽略该冷启动问题？另外，实时租用AWS EC2（并在虚机上以容器形式启动任务）这个操作直观上很不符合实际，长租虚拟机、或直接租容器更像是符合实际情况的方案。</li>
<li>像本文一样，如果希望有论据，则应该在实际场景下收集数据以论证。</li>
</ol>
</li>
<li>引入“经济学中的预订价格”有什么好处？</li>
<li>传统方法难道都没有考虑共置？对这部分现有研究分析很缺乏，这影响到了对本文创新性的评估。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3689031.3717483">[1] Tzu-Tao Chang and Shivaram Venkataraman. 2025. Eva: Cost-Efficient Cloud-Based Cluster Scheduling. In Twentieth European Conference on Computer Systems (EuroSys ’25), March 30–April 3, 2025, Rotterdam, Netherlands. ACM, New York, NY, USA, 18 pages. https: //doi.org/10.1145/3689031.3717483<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>任务干扰</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记84-前沿-大规模模拟器LGDCloudSim</title>
    <url>/2025/05/19/literature/literatureNotes84/</url>
    <content><![CDATA[<h1 id="x1f4d6-《LGDCloudSim-A-Resource-Management-Simulation-System-for-Large-Scale-Geographically-Distributed-Cloud-Data-Center-Scenarios》"><a href="#x1f4d6-《LGDCloudSim-A-Resource-Management-Simulation-System-for-Large-Scale-Geographically-Distributed-Cloud-Data-Center-Scenarios》" class="headerlink" title="📖《LGDCloudSim: A Resource Management Simulation System for Large-Scale Geographically Distributed Cloud Data Center Scenarios》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《LGDCloudSim: A Resource Management Simulation System for Large-Scale Geographically Distributed Cloud Data Center Scenarios》</h1><p>2024 年 同济大学团队 发表于 CCF-C 类会议 IEEE Cloud，获最佳学生论文奖。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><p>当前IaaS提供商已在全球范围内部署数据中心，资源持续增加。</p>
<ul>
<li>随着数字经济的发展，全球的laaS提供商如亚马逊、谷歌和微软已在世界各地部署数据中心以提高用户服务质量[1]。数据中心的规模和数量正在增加，总主机数量超过数千万[2]，[3]。</li>
</ul>
<p>同时，用户请求的并发性和请求类型多样性呈上升趋势。</p>
<ul>
<li>全球laaS提供商处理用户请求的并发性也在增加，达到每秒高达100k次[2]。为了更好地利用地理分布数据中心资源，对多个资源节点的用户请求通常需要网络约束。例如，具有网络延迟、带宽和用户访问延迟约束的亲和性请求[4]。</li>
</ul>
<h2 id="x1f6a7-现状——调度架构"><a href="#x1f6a7-现状——调度架构" class="headerlink" title="🚧现状——调度架构"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状——调度架构</h2><p>为了实现更好的资源分配，已提出了各种复杂的调度架构。</p>
<ul>
<li>为了更好地分配资源以满足用户请求，人们提出了许多调度架构（SAs，scheduling architectures），包括多个数据中心的数据中心间调度架构（inter-SA）和单个数据中心内的数据中心内调度架构（intra-SA）。<ul>
<li>前者包括集中式单级[5]、[6]、集中式双级[7]、[8]、分布式双级[9]和混合式双级[10] SA。</li>
<li>后者涉及单体[11]-[15]、两级[16]-[18]和共享状态[3]、[19]-[21] SA。</li>
</ul>
</li>
</ul>
<p>具体而言，对于inter-SA：</p>
<ul>
<li>为了更好地利用不同地理位置的数据中心资源，提出了许多inter-SAs，包括集中式一阶段[5]、[6]，集中式两阶段[7]、[8]，分布式两阶段[9]，以及混合式两阶段[10]SA，如图1所示。<ul>
<li>（1）在集中式一阶段SA中，集中式调度器位于所有数据中心的上层，调度器掌握所有主机资源状态的信息。它接收所有用户请求并直接将这些请求调度到相应的主机上。例如，CA-DP [5] 中使用的SA和[6]中的SA。</li>
<li>（2）在集中式两阶段SA中，调度过程分为两个阶段，如OODA [7] 和[8]中的SA。在第一阶段，上层的集中式调度器将请求分发到每个数据中心。在第二阶段，每个数据中心的调度器将请求调度到相应的主机上。</li>
<li>（3）在分布式两阶段SA中，没有上层的集中式调度器。用户请求被发送到最近的数据中心进行两阶段调度。首先，数据中心的调度器尝试在数据中心内部找到适合的主机来处理请求。如果未成功，则将请求调度到其他数据中心。一个代表是[9]中的SA。</li>
<li>（4）在混合式两阶段SA中，类似于集中式两阶段SA和分布式两阶段SA的混合。与集中式两阶段SA相比，上层的集中式调度器将请求分发到数据中心后，数据中心的调度器可以将请求调度到主机上，或者如果没有任何合适的主机，则将请求转发到其他数据中心。一个示例是[10]中提出的SA。</li>
</ul>
</li>
<li>inter-SA的目标是通过上层集中调度器或数据中心转发请求到最合适的数据中心。因此，模拟这些调度架构需要多种多样的主动请求转发能力。</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/6edaa5deda1c3b0320db845c0574788a41d70ded/2-Figure1-1.png" alt="图1. Inter-SAs"><figcaption>图1. Inter-SAs</figcaption></figure></p>
<p>对于intra-SA：</p>
<ul>
<li>随着单数据中心规模的增加，传统的单个集中式调度器的单体式SA [11]–[13] 已不再能满足调度需求。这导致了多调度器SA的提出，例如两级SA [16]–[18] 和共享状态SA [3]，[19]–[21]。这些intra-SA如图2所示。<ul>
<li>（1）单体式SA：Borg [11]、[12]、Maui [13] 和 Kubernetes [14]、[15] 等单体 SA 的特点是由一个集中式调度器负责所有请求的调度决策。它们的特点包括无调度冲突和高调度质量。然而，在大规模场景中，仅由一个调度器进行请求调度具有挑战性，因为调度速度通常慢于请求到达速度。</li>
<li>（2）两级式SA：以 YARN[16]、Mesos[17]和伏羲[18]为例，两级 SA 采用悲观并发控制。中央资源管理器将资源划分成小块，并将其分配给多个任务调度器，以便在块内进行独立调度。任务调度器执行请求调度，既不协作也不竞争。</li>
<li>（3）状态共享式SA：共享状态 SA 采用乐观并发控制，具有多个并行调度器。每个调度器都可以通过自由竞争将请求调度到数据中心的任何主机。这方面的例子包括 Fuxi 2.0 [3]、Omega [19]、Yaqd [20] 和 Apollo [21]。</li>
</ul>
</li>
<li>模拟这些内部SA的关键在于支持多调度器并行调度和调度冲突处理。</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/6edaa5deda1c3b0320db845c0574788a41d70ded/3-Figure2-1.png" alt="图2. Intra-SAs"><figcaption>图2. Intra-SAs</figcaption></figure></p>
<h2 id="x1f6a7-现状——模拟器"><a href="#x1f6a7-现状——模拟器" class="headerlink" title="🚧现状——模拟器"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状——模拟器</h2><p>然而，由于与实际实验相关的挑战，需要模拟系统来构建相关研究的环境。</p>
<ul>
<li>由于基础设施限制、成本高、实验时间长、可重复性差等原因，在大规模地理分布式云数据中心（LGDC，large-scale geographically distributed cloud data center）的实际场景中进行调度实验极具挑战性。因此，使用仿真系统进行研究更为合适[22]。</li>
<li>虽然存在一些云仿真系统，如 CloudSim [22] 和 IfogSim2 [23]，但它们在 LGDC 场景中的仿真能力仍然不足。<ul>
<li>(1) 在场景仿真方面，现有系统对全球分散的数据中心和用户之间的网络延迟和带宽描述不足。它们无法支持 LGDC 场景的部分状态同步需求[3]。它们也没有考虑复杂网络拓扑约束下的用户请求模拟。</li>
<li>(2) 在调度模拟方面，许多站点间服务需要主动转发用户请求，许多站点内服务需要多个调度器并行调度。然而，现有系统并不能充分支持这些功能。此外，这些系统通常假设调度时间可以忽略不计，而这在 LGDC 场景中是不切实际的。</li>
<li>(3) 在大规模仿真方面，现有系统无法支持数千万台主机和 100k/s 并发请求的仿真。它们缺乏针对大规模场景的特定优化。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><p>因此，我们设计了LGDCloudSim 以支持LGDC场景的资源分配模拟。本文的主要贡献如下。</p>
<ul>
<li>（1）我们充分考虑了大规模地理分布云数据中心场景的特点。我们建立了LGD场景模型并提供了一个软件架构来模拟它。<ul>
<li>关于场景模拟，使用谷歌网络数据集，LGDCloudSim可以模拟数据中心-数据中心（Dc-Dc）网络和数据中心-用户（De-User）网络。它支持与定制内容的数据中心状态周期性同步。它支持普通和亲和力请求。</li>
<li>关于调度模拟，它使数据中心之间能够进行主动请求转发，在数据中心内部进行多个调度器的并行调度，并跟踪调度时间。</li>
</ul>
</li>
<li>（2）为了支持大规模模拟，我们提出了状态管理优化和操作流程优化方法。我们提出了适用于大规模模拟的优化方法。这些方法包括状态管理和操作过程优化方法。它们减少了内存使用并加速了模拟。</li>
<li>（3）我们进行了实验以确认LGDCloudSim的可扩展性和有效性。</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><p>实验表明，LGDCloudSim可以模拟高达5 X 10^8个主机和10^7请求并发。它还支持多样化的调度架构和不同类型的请求。</p>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>考虑到能源在地理分布的云数据中心场景中被广泛考虑，我们计划在未来增强LGDCloudSim模块中的数据中心能源统计功能。</li>
<li>我们还打算在LGD场景中基于LGDCloudSim研究跨SAs和内SAs、亲和请求处理方法、高效调度算法和状态同步策略。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>intra-SA的分类其实有争议。<ol>
<li>一方面，YARN有争议，在部分文章中将其视为单体式集中调度架构、而其他部分文章中将其视为两级式调度架构；</li>
<li>另一方面，总类别有争议，还有部分本文未归类的调度架构可被称为“完全分布式SA”，如Sparrow。</li>
</ol>
</li>
<li>inter-SA的进一步总结：<ol>
<li>除了分布式两阶段SA外，其余架构都依赖于一个集中式调度器（所有任务都要先到达该调度器，再进行后续操作），因此在高效率要求的场景下该单点调度器将会成为瓶颈。</li>
<li>同时，目前总结的都是学界的相关架构，业界成熟的多集群管理工具有脱胎于华为的CNCF项目Karmada和脱胎于字节的KubeAdmiral，初步看来都是集中式两阶段SA。</li>
</ol>
</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://ieeexplore.ieee.org/document/10643915">[1] J. Liu, Y. Xu, B. Feng and Z. Ding, “LGDCloudSim: A Resource Management Simulation System for Large-Scale Geographically Distributed Cloud Data Center Scenarios,” 2024 IEEE 17th International Conference on Cloud Computing (CLOUD), Shenzhen, China, 2024, pp. 194-204, doi: 10.1109/CLOUD62652.2024.00031.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>模拟器</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记85-前沿-GPU碎片调度</title>
    <url>/2025/06/10/literature/literatureNotes85/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Beware-of-Fragmentation-Scheduling-GPU-Sharing-Workloads-with-Fragmentation-Gradient-Descent》"><a href="#x1f4d6-《Beware-of-Fragmentation-Scheduling-GPU-Sharing-Workloads-with-Fragmentation-Gradient-Descent》" class="headerlink" title="📖《Beware of Fragmentation: Scheduling GPU-Sharing Workloads with Fragmentation Gradient Descent》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Beware of Fragmentation: Scheduling GPU-Sharing Workloads with Fragmentation Gradient Descent》</h1><p>2023 年 香港科技大学、阿里巴巴团队 发表于 CCF-A 类会议 ATC。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><p>大型科技公司正在其服务器机群中堆积大量 GPU，以运行各种机器学习 (ML) 工作负载。然而，这些昂贵的设备往往利用率严重不足。</p>
<ul>
<li>图形处理器（GPU）被广泛部署在生产集群中，用于加速大量人工智能应用中的机器学习（ML）任务。与 CPU 和其他资源相比，GPU 的成本要高得多，但在生产集群中往往<strong>利用率不足</strong>，据报道，利用率仅在<strong>从 25% 到 50% 以下</strong>不等。</li>
<li>GPU 利用率低的主要原因是，大量 ML 任务（主要是推理）<strong>无法充分利用现代 GPU 的能力</strong>，而近年来 <strong>GPU 的性能已呈指数级增长</strong>。预计在可预见的未来，这一趋势还将继续。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><h3 id="历史解决方案1：GPU共享"><a href="#历史解决方案1：GPU共享" class="headerlink" title="历史解决方案1：GPU共享"></a>历史解决方案1：GPU共享</h3><p>为了解决这个问题，人们开发了 GPU 共享技术，以便在单个 GPU 上运行多个 ML 任务。</p>
<ul>
<li>通过虚拟化或英伟达公司 Ampere 架构支持的多实例 GPU（MIG）功能，使<strong>多个 ML 任务能够在单个 GPU 上安全运行</strong>，并保证隔离。</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/f59705b8f69a6d28ad171c541cf4886aa9f147ac/2-Figure1-1.png" alt="图 1：部分GPU（partial GPU，粒度小于1个，从而实现GPU共享）分配会导致碎片化，这可以通过打包来解决。"><figcaption>图 1：部分GPU（partial GPU，粒度小于1个，从而实现GPU共享）分配会导致碎片化，这可以通过打包来解决。</figcaption></figure></p>
<p>然而，我们对阿里巴巴生产跟踪的分析表明，在大型集群中，分配部分 GPU 可能会导致严重的 GPU 碎片化，导致数百个 GPU 无法分配。</p>
<ul>
<li>仅仅启用GPU共享并不一定能够提高利用率。在许多情况下，分配部分GPU会导致<strong>碎片化</strong>，从而阻止剩余的GPU资源被分配。</li>
<li><strong>图 1</strong> 在玩具示例（Toy Example）中说明了这个问题。<ul>
<li>考虑一个由<strong>两个节点A和B</strong>组成的集群，节点A具有⟨9个CPU，1个GPU⟩，节点B具有⟨6个CPU，1个GPU⟩。</li>
<li>有<strong>两个任务A和B</strong>分别在两个节点上运行，每个任务分别需要⟨6个CPU，0.75个GPU⟩和⟨2个CPU，0.25个GPU⟩。</li>
<li><strong>情况1</strong>：如果不启用GPU共享，即使这些任务无法充分利用整个GPU，它们也会被分配一个完整的GPU（图1，左）。</li>
<li><strong>情况2</strong>：通过使用GPU共享技术分配部分GPU可以解决这个问题（图1，中）。现在假设又有一个任务A的实例到达，尽管集群有足够的总GPU资源（0.25 + 0.75 = 1个GPU），但它仍然无法在任何一个节点上运行。</li>
</ul>
</li>
<li>我们在支持 GPU 共享的生产集群中广泛观察到了 GPU 碎片现象。<ul>
<li><strong>图 2</strong> 显示了从一个 1280 GPU 集群收集到的 7 天跟踪。<ul>
<li>平均而言，GPU allocations 分配总量占总容量的 77.6%（橙色虚线）。</li>
<li>这些 allocations 分配（很多是部分 GPU）分布在几乎所有 GPU 设备上（蓝色实线），</li>
<li>导致 21-42% 的 unallocated 未分配 GPU 资源成为当前工作负载无法利用的碎片（红色虚线）。</li>
</ul>
</li>
<li>一般来说，更高的 allocations 分配会导致更严重的碎片化。</li>
<li>根据我们的运行经验，尽管集群仍有<strong>足够的闲置 GPU</strong>，但有关<strong>调度失败的投诉</strong>通常会在高峰时段激增，这表明<strong>碎片化</strong>现象非常严重。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/f59705b8f69a6d28ad171c541cf4886aa9f147ac/3-Figure2-1.png" alt="图 2：一个大型GPU共享集群的7天追踪记录。GPU occupation 占用衡量的是未完全空闲的GPU设备数量；GPU allocation 分配衡量的是分配的GPU资源总量；GPU utilization 利用率指的是任务实际使用的GPU资源比例；GPU frag rate 碎片率是由于碎片化导致无法分配的GPU资源所占的百分比（定义在§3.2）。"><figcaption>图 2：一个大型GPU共享集群的7天追踪记录。GPU occupation 占用衡量的是未完全空闲的GPU设备数量；GPU allocation 分配衡量的是分配的GPU资源总量；GPU utilization 利用率指的是任务实际使用的GPU资源比例；GPU frag rate 碎片率是由于碎片化导致无法分配的GPU资源所占的百分比（定义在§3.2）。</figcaption></figure></p>
<h3 id="历史解决方案2：打包-packing"><a href="#历史解决方案2：打包-packing" class="headerlink" title="历史解决方案2：打包 packing"></a>历史解决方案2：打包 packing</h3><p>解决碎片问题的有效方法是进行打包。</p>
<ul>
<li>回到前面的例子，调度器可以将两个原始任务打包到节点 A，从而将整个节点 B 留给任务 A 的新实例（图 1，右）。</li>
<li>大量工作将工作负载调度表述为多维装箱问题（multi-dimensional bin packing problem），其中任务和节点分别被建模为球和箱，球和箱的大小取决于多个资源维度，目标是将球打包到最少的箱中。<ul>
<li>人们提出了许多启发式方法来调度集群工作负载，如最佳拟合、向量排列评分和 “GPU打包”。</li>
</ul>
</li>
</ul>
<p>但现有的资源打包算法无法解决这一问题，因此 GPU 共享要求在经典的 bin packing 之外采用新的调度方案。</p>
<ul>
<li>然而，我们的实验表明，这些启发式方法都不能很好地调度 GPU 共享工作负载（第 6 节）。</li>
<li>我们认为，<strong>根本原因</strong>在于，当一个节点拥有多个 GPU 时，该问题与经典的 bin packing 本质上是不同的。</li>
<li>考虑两种自然的 bin packing 方案。<ul>
<li>（1）第一种是将服务器的多个 GPU 建模为一个具有总容量的大型设备。这种方案将所有未分配的 GPU 集中在一起，<strong>单个 GPU 上的碎片</strong>变得无关紧要，而现实情况并非如此（笔者理解：GPU虚拟化还不够成熟，不像CPU虚拟化可以忽略单节点多个CPU间区别）。</li>
<li>（2）另外一种，我们也可以将服务器上的多个 GPU 视为不同的 “资源维度”。然而，与 CPU 和内存等其他资源不同的是，这些 <strong>GPU 并不是独立的</strong>，而是可以互换的，任务可以在任何一个 GPU 上运行，这就要求在经典的 bin packing 之外采用新的表述方式。</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><p>在本文中，我们为 GPU 共享工作负载开发了一种新颖的碎片感知调度方法。我们首先提出了一种新的碎片化测量方法，以统计量化不同来源造成的 GPU 碎片化程度。在这一指标的基础上，我们建议将 GPU 共享工作负载调度为碎片最陡峭的下降方向，我们称这种方法为碎片梯度下降（FGD）。直观地说，FGD 对任务进行打包，以尽量减少 GPU 碎片的增长，从而实现最大的 GPU 分配率。</p>
<ul>
<li>（1）我们的方法的核心是一个新的分析框架，它可以统计地量化集群中的 <strong>GPU 碎片化程度</strong>。<ul>
<li><strong>给定一个任务</strong>，我们识别出每个节点上不能用于运行该任务的 GPU（例如，缺乏足够的 GPU 或其他资源）。从该任务的角度来看，这些 GPU 都是<strong>碎片</strong>化的，因为它们的剩余资源都无法利用。</li>
<li>现在，我们来考虑<strong>目标工作负载</strong>，它由一组我们感兴趣的任务（如 ML 推理和训练）组成。我们将 <strong>GPU 碎片化程度量化</strong>为无法分配给从目标工作负载中随机抽取的任务的 GPU 的预期数量。直观地说，它衡量的是目标工作负载无法利用的 GPU 资源的预期数量。</li>
<li>我们可以将碎片分析进一步细分为不同的原因，如节点的 GPU 不足或搁浅，或工作负载与节点规格不匹配等。这种分析为操作员推理集群状态提供了更多见解（第 3 节）。</li>
</ul>
</li>
<li>（2）基于GPU碎片化分析，我们提出了一种简单而有效的<strong>启发式方法</strong>，将工作负载调度到<strong>碎片化最陡下降的方向</strong>，我们称之为碎片化梯度下降或FGD。<ul>
<li>对于提交的每个GPU任务，FGD会选择一个节点及其可用的GPU来运行该任务，以使由于这一决定导致的GPU碎片化增长最小化（§4）。</li>
<li>通过这样做，FGD可以最小化GPU碎片化，从而节省大量昂贵的资源用于更多的工作负载。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><p>我们在 Kubernetes 中实施了 FGD 作为一种新的调度程序，并在由 6200 多个 GPU 组成的模拟集群上使用生产跟踪评估了其性能。与现有的基于打包的调度程序相比，FGD 最多减少了 49% 的未分配 GPU，从而提高了 290 个 GPU 的利用率。</p>
<ul>
<li>我们在 Kubernetes 第5节）中<strong>实现了一种新的调度器FGD</strong>，并在包含超过1200个节点和6200个GPU的模拟集群上使用生产工作负载和合成工作负载跟踪对其性能进行了<strong>评估</strong>（第6节）。</li>
<li>FGD在各种设置中始终优于现有的基于打包的调度算法：它最多可减少49%未分配的GPU，使290个GPU能够在大型生产集群中得到利用。</li>
<li>我们的实现包括<a class="link" href="https://github.com/hkust-adsl/kubernetes-scheduler-simulator">调度器和模拟器<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>，以及<a class="link" href="https://github.com/alibaba/clusterdata">用于评估的跟踪数据<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>，均已开源软件形式提供。</li>
</ul>
<h2 id="⛳️讨论与未来机会"><a href="#⛳️讨论与未来机会" class="headerlink" title="⛳️讨论与未来机会"></a>⛳️讨论与未来机会</h2><p>（1）<strong>调度无关的碎片化度量</strong>。</p>
<ul>
<li>我们提出的碎片化度量量化了当前集群的碎片化程度，仅考虑即将到来的任务。这种狭窄的焦点确保了调度器独立性。</li>
<li>具体来说，如果我们考虑两个或多个即将到来的任务，每个节点在评估由第二个任务测量的碎片化时，需要确定第一个任务是否已经消耗了其资源。这一确定过程会涉及调度策略。</li>
<li>相比之下，我们的一步碎片化度量仅基于节点剩余资源是否能完全被下一个任务利用来确定节点是否碎片化，不依赖于调度器或其他节点。</li>
</ul>
<p>（2）<strong>与其他启发式方法相结合</strong>。</p>
<ul>
<li>在集群资源丰富且几乎没有碎片化观察到的早期阶段，调度器可能会由于受到单步碎片化度量的指导而表现不佳。然而，可以通过将碎片化指导的调度启发式方法与其他启发式方法结合使用来应对这一初始阶段。例如，如果未检测到碎片化的增加，调度器可以退回到最佳适应的方法。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>在大规模场景下，传统装箱方法是否能够有足够高的效率应付任务？本论文方法似乎效率能够达标、但是碎片能优化到什么程度，如果多调度器并行可能还会有更进一步的问题？需要实验进一步验证。</li>
<li>任务持续时间有多长？本文只关注当下的“碎片率最优方向”，长期看是否会因为任务在不同时间结束，导致碎片问题和预期不一致？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.usenix.org/conference/atc23/presentation/weng">[1] Weng, Qizhen, et al. “Beware of fragmentation: Scheduling {GPU-Sharing} workloads with fragmentation gradient descent.” 2023 USENIX Annual Technical Conference (USENIX ATC 23). 2023.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>资源碎片</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记86-前沿-DLRM的CPU-GPU分解调度</title>
    <url>/2025/08/13/literature/literatureNotes86/</url>
    <content><![CDATA[<h1 id="x1f4d6-《GPU-Disaggregated-Serving-for-Deep-Learning-Recommendation-Models-at-Scale》"><a href="#x1f4d6-《GPU-Disaggregated-Serving-for-Deep-Learning-Recommendation-Models-at-Scale》" class="headerlink" title="📖《GPU-Disaggregated Serving for Deep Learning Recommendation Models at Scale》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《GPU-Disaggregated Serving for Deep Learning Recommendation Models at Scale》</h1><p>2025 年 香港科技大学+阿里巴巴团队 发表于 CCF-A 类会议 NSDI。</p>
<p>作者之一<a class="link" href="https://www.zhihu.com/people/llllkkkk">刘侃<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>提到：实际工作在 n 年前就完成了，论文写作在 n-m 年前就完成了~<a href="#refer-anchor-1"><sup>[2,3]</sup></a>连这样的论文都花了这么久[/惊恐]</p>
<p>RTP（Real Time Prediction）<a href="#refer-anchor-1"><sup>[4]</sup></a>平台是阿里内部一个通用的在线预测平台，广泛支持淘天、本地生活、AIDC、菜鸟、大文娱等搜索和推荐业务场景的 DLRM（Deep Learning Recommendation Model）部署。自2022年起，RTP开始探索大规模GPU-Disaggregation技术的落地，运用RDMA高性能网络通信构建GPU-CPU全分离的分布式推理系统。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>在线推荐系统使用深度学习推荐模型（DLRMs）提供准确、个性化的推荐以提升用户体验。<ul>
<li>个性化推荐系统是许多面向用户、创造收入的网络服务的关键基础设施，如内容流媒体、电子商务、社交网络和网页搜索。这些系统使用深度学习推荐模型（DLRM）提供准确、个性化的推荐，以改善客户体验并增加用户参与度。</li>
<li>根据Meta的数据，DLRM服务消耗了当今AI云中大部分的推理资源，顶级推荐模型占用了<strong>超过79%的AI周期</strong>。</li>
</ul>
</li>
</ul>
<h3 id="DLRM特点"><a href="#DLRM特点" class="headerlink" title="DLRM特点"></a>DLRM特点</h3><p>鉴于现在 LLM 很火，作者之一刘侃用下面的表格对比了两者在线部署角度的差异，以便更好地理解问题。</p>
<blockquote>
<p>如果想了解更多 DLRM 的信息，可以参考原文或相关博客<a href="#refer-anchor-1"><sup>[2,3]</sup></a>，或原博客推荐的“典中典 W&amp;D<a href="#refer-anchor-1"><sup>[5]</sup></a>以及系统介绍<a href="#refer-anchor-1"><sup>[6]</sup></a>”。</p>
</blockquote>
<p>模型特点对比：<br>|-| DLRM | LLM |<br>|—|—|—|<br>|Feature Engineering|    ID 化、统计、笛卡尔积、查外表…太多了|    Tokenize，字符到 int 的 ID 转换|<br>|Feature Store|    100G-10T 量级，有行为序列、商品属性等|    额，如果是说 tokenizer 表的话，那就是 M 级别。|<br>|Embedding|    10G-1T 量级，大规模稀疏|    &lt;10G|<br>|Model|    DNN + Attention 等变种结合|    Transformer/Mamba，没了|</p>
<p>对应算力特点对比：</p>
<table>
<thead>
<tr>
<th>-</th>
<th>DLRM</th>
<th>LLM</th>
</tr>
</thead>
<tbody><tr>
<td>CPU</td>
<td>负载重，大量特征查表（如 KV）和计算。不同模型之间负载差距大，有 32c:1GPU 也有 128c:1GPU。</td>
<td>Tokenize 开销很小，剩下还有少量 Framework 和 KernelLaunch 开销。8c 算多的。</td>
</tr>
<tr>
<td>GPU</td>
<td>模型杂，方法多，实验也多；模型输入偏小，Kernel Launch 开销较大，算力利用有限。</td>
<td>社区很卷，都是标准算子，接近硬件算力极限。</td>
</tr>
</tbody></table>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，大规模高效提供DLRM服务具有挑战性。</li>
<li>DLRMs表现出独特的资源使用模式：它们需要<strong>大量的CPU核心和巨大的内存</strong>，但只有<strong>少量GPU</strong>。<ul>
<li>DLRM提供具有严格的延迟服务级别目标（SLO），通常每个请求在数十毫秒的规模。同时，DLRM提供需要处理需求的频繁波动。满足延迟SLO通常意味着为<strong>峰值</strong>负载提供资源，这可以显著高于平均水平。</li>
</ul>
</li>
<li>在多GPU服务器上运行它们会迅速耗尽服务器的CPU和内存资源，导致大量未分配的GPU闲置，无法被其他任务利用。<ul>
<li>图1说明了阿里巴巴DLRM服务在生产集群中的资源需求。我们观察到明显的日间模式，峰值与谷值之比超过6倍；在季节性促销活动中，峰值负载可以比常规峰值高1.3倍，这与之前的报告一致。在如此规模上为峰值负载提供资源会导致显著的低利用率，使其在经济上不可行。</li>
</ul>
</li>
<li>为了减少过度配置，更好的策略是为平均负载进行配置，并在负载高峰期间启用容量借贷。<ul>
<li>像阿里巴巴这样的大型公司拥有多个特定用途的基础设施：一些用于训练，其他用于推理。当DLRM服务处于高峰时段时，它可以暂时从训练集群借用GPU服务器，因为训练作业对延迟不敏感，可以容忍中断。</li>
<li>然而，服务器池操作之间存在不匹配。<ul>
<li>与需要大量GPU周期的训练任务不同，推荐模型表现出较低的计算强度，并且不依赖于GPU。相反，它们执行稀疏计算，如嵌入，这需要大量内存来存储嵌入表，以及许多CPU核心用于查找和池化操作。因此，在训练服务器上运行推荐模型会迅速耗尽服务器的CPU和内存资源，留下大量未分配的GPU闲置。</li>
</ul>
</li>
<li>在我们的集群中，典型的DLRM服务请求48个CPU和1个GPU，而训练服务器通常有〈96个CPU，8个GPU〉。部署两个DLRM推理实例将占用主机上的所有CPU，留下6个未分配的GPU无法被其他任务利用。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/2025-NSDI-Yang-GPU-Disaggregated.png?raw=true" alt="原文图1：DLRM服务的CPU需求表现出每日和季节性变化；GPU需求遵循相同趋势。从生产集群收集的跟踪数据，包括三个（带星号）电子商务促销活动。"><figcaption>原文图1：DLRM服务的CPU需求表现出每日和季节性变化；GPU需求遵循相同趋势。从生产集群收集的跟踪数据，包括三个（带星号）电子商务促销活动。</figcaption></figure></p>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>本文描述了Prism，一个生产级DLRM服务系统，通过<strong>资源解耦</strong>的方式消除GPU碎片化。<ul>
<li>Prism运行在共享基础设施上，其中一组CPU节点（CNs）通过高速RDMA网络与一组异构GPU节点（HNs）互连，形成两个可以独立扩展的资源池。<ul>
<li>每个CN拥有大量CPU核心和高内存，但没有GPU，而每个HN是一个典型的具有多个GPU但CPU和内存资源有限的训练服务器。</li>
<li>这种基础设施将具有固定配置的单体服务器集群分解为两个解耦的资源池，其中CNs提供丰富的CPU和内存资源，而HNs提供大量的GPU。这两个资源池可以独立扩展以匹配动态工作负载的变化需求。</li>
</ul>
</li>
<li>Prism自动将DLRMs划分为CPU密集型和GPU密集型子图，并在CNs和HNs上调度它们以实现解耦服务。<ul>
<li>给定一个DLRM，Prism自动将其计算图分为两个子图，一个包含CPU和内存密集型操作符，另一个GPU密集型。然后，系统将这两个子图调度到选定的CN和HN上进行解耦服务，并将结果返回给用户。</li>
</ul>
</li>
</ul>
</li>
<li>本文还描述了在生产规模下构建解耦的DLRM系统所面临的挑战、技术和经验教训。Prism采用各种技术来最小化由解耦引起的延迟开销，包括最优图划分、拓扑感知资源管理和SLO感知通信调度。<ul>
<li>首先，解耦需要对模型所有者透明。<ul>
<li>手动重构模型到解耦版本会增加精度下降的风险，并需要模型所有者额外的努力，因此是不理想的。</li>
</ul>
</li>
<li>其次，系统应扩展到数千台服务器以处理过度的负载峰值。<ul>
<li>鉴于流量激增，它应迅速将工作负载调度到大量服务器上，以在短时间内实现显著的总吞吐量。</li>
</ul>
</li>
<li>第三，系统应满足DLRM服务的严格延迟SLO，由于GPU解耦导致CN和HN之间存在非平凡的通信开销。</li>
</ul>
</li>
<li>Prism通过三个主要组件应对这些挑战：<ul>
<li>一个解耦优化的实时预测（RTP）框架，该框架在CN和HN之间最优地划分计算图（第4.1节），</li>
<li>一个拓扑感知的资源管理器，该管理器最小化服务器间和服务器内的通信开销（第4.2节），</li>
<li>以及SLO感知的通信调度，确保在目标延迟SLO内进行解耦服务（第4.3节）。</li>
</ul>
</li>
<li>总结而言，我们的主要贡献如下：<ul>
<li>• 我们在部署生产规模的弹性DLRM服务时，识别了资源配置的挑战，并激励了GPU解耦服务的需求。</li>
<li>• 我们设计和实现了Prism，通过解耦服务从CPU节点和异构GPU节点中收集资源，缓解了服务器配置与DLRM资源需求之间的不匹配，同时仍满足延迟SLOs。</li>
<li>• 我们在生产环境中评估了Prism，并证明它可以有效地减少资源碎片化，而不会损害服务性能，在促销活动期间实现高效的容量借贷。</li>
<li>我们将生产DLRM服务跟踪作为阿里巴巴集群跟踪计划的一部分发布<a href="#refer-anchor-1"><sup>[7]</sup></a>。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>评估表明，Prism在拥挤的GPU集群中有效地将CPU和GPU碎片化降低了53%和27%。在季节性促销活动中，它有效地实现了从训练集群的容量借贷，节省了超过90%的GPU（§5）。Prism已在生产集群中部署超过两年，现在运行在超过10k个GPU上。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>操作经验。生产集群经常采用在线和离线任务的混合部署以提高效率。但在我们的情况下，分类的DLRM服务引入了频繁的RDMA网络通信。<ul>
<li>我们观察到，即使获得RNIC，RDMA转移潜伏期也可以在强烈的资源争夺中增加十倍。根本原因是在容器覆盖网络下，RDMA和TCP都依赖于覆盖网络方案进行通信。混合工作负载的TCP流量会影响网卡底层的流表逻辑，从而影响RDMA流量。</li>
<li>我们当前的解决方法涉及监视节点资源利用率和在线服务延迟，并在指标变得异常时触发离线任务的驱逐。我们认为这是未来研究的一个开放问题。</li>
</ul>
</li>
</ul>
<!-- ## <span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">&#x1f9e0;</span>疑问 -->


<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.usenix.org/conference/nsdi25/presentation/yang">[1] Yang L, Wang Y, Yu Y, et al. {GPU-Disaggregated} Serving for Deep Learning Recommendation Models at Scale[C]//22nd USENIX Symposium on Networked Systems Design and Implementation (NSDI 25). 2025: 847-863.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://mp.weixin.qq.com/s/fk_x6pdu2BNdyIvnkfQRfA">[2] GPU，CPU，谁是谁的“伴侣”？—— 阿里 RTP 平台的异构资源解耦大冒险 - InfoQ<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://zhuanlan.zhihu.com/p/1892365414530516703">[3] 解读 NSDI25 GPU-Disaggregated Serving for Deep Learning Recommendation Models at Scal - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://developer.aliyun.com/article/674182">[4] 深度预测平台RTP介绍<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://arxiv.org/abs/1606.07792">[5] Wide &amp; Deep Learning for Recommender Systems<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://blog.csdn.net/tianshuai1111/article/details/136275123">[6] 【AI.OS】深入解读阿里开源系统全图化引擎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://github.com/alibaba/clusterdata/tree/master/cluster-trace-gpuv2025">[7] Github - alibaba/clusterdata/cluster-trace-gpuv2025<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>AI-Infra</tag>
        <tag>DLRM</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记87-经典-vLLM</title>
    <url>/2025/09/02/literature/literatureNotes87/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Efficient-Memory-Management-for-Large-Language-Model-Serving-with-PagedAttention》"><a href="#x1f4d6-《Efficient-Memory-Management-for-Large-Language-Model-Serving-with-PagedAttention》" class="headerlink" title="📖《Efficient Memory Management for Large Language Model Serving with PagedAttention》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Efficient Memory Management for Large Language Model Serving with PagedAttention》</h1><p>2023 年 UC Berkeley 大学、斯坦福大学、UC San Diego 大学团队 发表于 CCF-A 类会议 SOSP。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>高吞吐量服务大型语言模型（LLMs）需要同时批量处理足够多的请求。<ul>
<li>大型语言模型（LLMs）如 GPT 和 PaLM 的出现，使得编程助手和通用聊天机器人等新应用成为可能，这些应用正开始深刻影响我们的工作和日常生活。</li>
<li>许多云公司正在竞相提供这些作为托管服务。然而，运行这些应用非常昂贵，需要大量的硬件加速器，如GPU。根据最新的估计，处理LLM请求的成本可能比传统的关键词查询高10倍。</li>
<li>鉴于这些高昂的成本，提高LLM服务系统的吞吐量——从而降低每请求的成本——变得越来越重要。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05/1-Figure1-1.png" alt="图1：左侧：在NVIDIA A100上为具有130亿参数的LLM提供服务时的内存布局。参数（灰色）在整个服务过程中持续存在于GPU内存中。KV缓存内存（红色）根据服务请求进行（分配）和（释放）。一小部分内存（黄色）用于暂时的激活。右侧：vLLM平滑了现有系统中观察到的KV缓存内存的快速增长曲线，从而显著提高了服务吞吐量。"><figcaption>图1：左侧：在NVIDIA A100上为具有130亿参数的LLM提供服务时的内存布局。参数（灰色）在整个服务过程中持续存在于GPU内存中。KV缓存内存（红色）根据服务请求进行（分配）和（释放）。一小部分内存（黄色）用于暂时的激活。右侧：vLLM平滑了现有系统中观察到的KV缓存内存的快速增长曲线，从而显著提高了服务吞吐量。</figcaption></figure></p>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，现有系统存在困难，因为每个请求的关键值缓存（KV缓存）内存巨大，且动态增长和收缩。<ul>
<li>LLMs的核心是一个自回归Transformer模型。该模型根据输入（提示）和之前生成的输出token序列，逐个生成单词（token）。对于每个请求，这个过程会重复进行，直到模型输出终止token。这种顺序生成过程使得工作负载受<strong>内存限制</strong>，未能充分利用GPU的计算能力，限制了服务吞吐量。</li>
<li>通过将多个请求一起批处理，可以提高吞吐量。然而，为了批量处理许多请求，每个请求的内存空间应该得到有效管理。例如，<ul>
<li>图1（左）展示了在配备40GB RAM的NVIDIA A100 GPU上运行13B参数的LLM的内存分布。<ul>
<li>大约65%的内存分配给模型权重，在服务期间保持静态。</li>
<li>接近30%的内存用于存储请求的动态状态。对于Transformer，这些状态包括与注意力机制相关的键和值张量，通常称为KV缓存，它们代表从早期标记到生成新输出标记的上下文。</li>
<li>剩余的小部分内存用于其他数据，包括激活——在评估LLM时创建的短暂张量。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>当管理效率低下时，这种内存可能会因碎片化和冗余重复而造成显著浪费，限制批量大小。<ul>
<li>由于模型权重是恒定的，而激活只占用GPU内存的一小部分，因此KV缓存的内存管理方式对于确定最大批量大小至关重要。管理不当时，KV缓存内存可以显著限制批量大小，从而降低LLM的吞吐量，如图1（右）所示。</li>
<li>在这篇论文中，我们观察到现有的LLM服务系统在高效管理KV缓存内存方面存在不足。这主要是因为它们将请求的KV缓存<strong>存储在连续的内存空间中</strong>，因为大多数<strong>深度学习框架</strong>要求张量存储在连续的内存中。<ul>
<li>然而，与传统的深度学习工作负载中的张量不同，KV缓存具有独特的特性：随着时间的推移，随着模型生成新的tokens，它动态地增长和缩小，其生命周期和长度事先并不知道。这些特性使得现有系统的方法在两个方面都显著低效：<ul>
<li>首先，现有的系统存在<strong>内部和外部内存碎片化</strong>问题。<ul>
<li>为了在连续空间中存储请求的KV缓存，它们预先分配一个与请求最大长度连续的内存块（例如，2048个标记）。这可能导致严重的<strong>内部碎片化</strong>，因为请求的实际长度可能远短于其最大长度（例如，图11）。</li>
<li>此外，即使事先知道实际长度，预分配仍然效率低下：在整个请求生命周期中，整个块（chunk）被预留（reserved），其他较短的请求无法利用当前未使用的任何部分。</li>
<li>此外，<strong>外部内存碎片化</strong>也可能很大，因为预分配的大小对每个请求可能不同。</li>
<li>实际上，我们图2中的分析结果显示，在现有系统中，只有20.4% - 38.2%的KV缓存内存用于存储实际标记状态。</li>
</ul>
</li>
<li>其次，现有系统无法利用<strong>内存共享</strong>的机会。<ul>
<li>LLM服务通常使用先进的<strong>解码算法</strong>，如并行采样和束搜索（parallel sampling and beam search），每个请求生成多个输出。在这些场景中，请求（request）由多个序列（sequences）组成，这些序列可以部分共享它们的KV缓存。然而，由于序列的KV缓存存储在各自连续的空间中，现有系统中无法实现内存共享。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05/2-Figure2-1.png" alt="图2：第6.2节实验中不同LLM服务系统中内存浪费的平均百分比。"><figcaption>图2：第6.2节实验中不同LLM服务系统中内存浪费的平均百分比。</figcaption></figure></p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05/9-Figure11-1.png" alt="图11：输入和输出长度分布的（a）ShareGPT和（b）Alpaca数据集。"><figcaption>图11：输入和输出长度分布的（a）ShareGPT和（b）Alpaca数据集。</figcaption></figure></p>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li><p>为了解决这个问题，我们提出了PagedAttention，这是一种受操作系统中的解决内存碎片化和共享方案（经典虚拟内存和分页）启发的注意力算法。</p>
<ul>
<li>PagedAttention将请求的KV缓存划分为块（blocks），每个块可以包含一定数量的标记的注意力键K和值V。</li>
<li>在PagedAttention中，KV缓存的块不一定存储在连续的空间中。因此，我们可以像操作系统中的虚拟内存一样以更灵活的方式管理KV缓存：可以将块视为页面，将tokens视为字节（bytes），将请求（requests）视为进程（processes）。这种设计通过使用相对较小的块并在需要时分配它们来缓解内部碎片。</li>
<li>此外，它消除了外部碎片，因为所有块的大小都相同。</li>
<li>最后，它允许在块粒度上实现内存共享，跨越与同一请求相关联的不同序列（sequences），甚至跨越不同的请求。</li>
</ul>
</li>
<li><p>在此基础上，我们构建了vLLM，一个基于PagedAttention的高吞吐量分布式LLM服务引擎，在KV缓存内存中实现了近乎零浪费。实现了（1）KV缓存内存接近零浪费和（2）在请求之间灵活共享KV缓存，以进一步减少内存使用。</p>
<ul>
<li>vLLM使用与PagedAttention协同设计的<strong>块级内存管理</strong>和<strong>抢占式请求调度</strong>。</li>
<li>vLLM支持各种大小的流行LLM，如GPT、OPT和LLaMA，包括超出单个GPU内存容量的那些LLM。</li>
</ul>
</li>
<li><p>总结来说，我们做出了以下贡献：</p>
<ul>
<li>• 我们确定了在为LLM提供服务中的内存分配挑战，并量化了它们对服务性能的影响。</li>
<li>• 我们提出了PagedAttention，这是一种在非连续分页内存中存储的KV缓存上运行的注意力算法，灵感来源于操作系统的虚拟内存和分页。</li>
<li>• 我们设计和实现了vLLM，这是一个基于PagedAttention的分布式LLM服务引擎。</li>
<li>• 我们在各种场景下评估了vLLM，并证明它在性能上显著优于之前的先进解决方案，如 FasterTransformer 和 Orca。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>我们的评估表明，与最先进的系统（如FasterTransformer和Orca）相比，vLLM在相同延迟水平下将流行LLMs的吞吐量提高了2-4倍，而且完全没有影响模型精度。随着序列变长、模型变大和解码算法更复杂，这种改进更为明显。</li>
<li>vLLM的源代码在<a class="link" href="https://github.com/vllm-project/vllm%E4%B8%8A%E5%85%AC%E5%BC%80%E3%80%82">https://github.com/vllm-project/vllm上公开。<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><ul>
<li>将虚拟内存和分页技术应用于<strong>其他GPU工作负载</strong>。<ul>
<li>虚拟内存和分页的想法对于管理LLM服务中的KV缓存是有效的，因为工作负载需要动态内存分配（因为输出长度事先未知）并且其性能受限于GPU内存容量。</li>
<li>然而，这并不适用于每个GPU工作负载。例如，在DNN训练中，张量形状通常是<strong>静态</strong>的，因此可以在事先优化内存分配。另一个例子是在服务不是LLM的DNN时，提高内存效率可能不会带来任何性能提升，因为性能<strong>主要受计算限制</strong>。在这种情况下，引入vLLM的技术可能会因为内存间接和非连续块内存的额外开销而降低性能。</li>
<li>然而，我们很期待看到vLLM的技术被应用于具有类似LLM服务特性的其他工作负载。</li>
</ul>
</li>
<li>在应用虚拟内存和分页时<strong>对LLM特定的优化</strong>。<ul>
<li>vLLM通过利用应用特定的语义重新解释和增强虚拟内存和分页的概念。</li>
<li>一个例子是vLLM的全或无交换策略（all-or-nothing swap-out policy），它利用了处理请求需要存储所有相应标记状态在GPU内存中的事实。</li>
<li>另一个例子是恢复被驱逐块的重计算方法，这在操作系统中是不可行的。</li>
<li>此外，vLLM通过融合用于内存访问操作的GPU内核与其他操作（如注意力）的内核来减轻分页中内存间接的开销。</li>
</ul>
</li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3600006.3613165">[1] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient Memory Management for Large Language Model Serving with PagedAttention. In Proceedings of the 29th Symposium on Operating Systems Principles (SOSP ‘23). Association for Computing Machinery, New York, NY, USA, 611–626. https://doi.org/10.1145/3600006.3613165<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>AI-infra</category>
      </categories>
      <tags>
        <tag>大模型,推理优化,vLLM</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记9-前沿-Lyra深度学习调度</title>
    <url>/2023/06/01/literature/literatureNotes9/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Lyra-Elastic-Scheduling-for-Deep-Learning-Clusters》"><a href="#x1f4d6-《Lyra-Elastic-Scheduling-for-Deep-Learning-Clusters》" class="headerlink" title="📖《Lyra: Elastic Scheduling for Deep Learning Clusters》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Lyra: Elastic Scheduling for Deep Learning Clusters》</h1><h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>最近，深度神经网络 (DNN) 在许多应用中取得了巨大的成功。超大规模在线服务提供商已采用 DNN，并构建大规模 GPU 集群来加速 DNN 的训练和推理工作负载。 GPU 集群调度是通过优化作业资源分配和任务放置来有效利用昂贵的基础设施的一项基本且关键的任务。</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>如今，通常的做法是分别构建和管理两种类型的 GPU 集群，一种用于训练，一种用于推理，并使用单独的调度程序来管理它们。这是因为，对于相同的模型，推理比训练需要更少的计算和 GPU 内存，并且不太可能利用训练 GPU 的众多核心。推理集群通常使用较弱的GPU（如Nvidia T4）其资源与训练GPU（如Nvidia V100和A100）相比只是一个很小的部分。<ul>
<li>这种分离给双方都带来了问题：<ul>
<li>当流量负载较低时，推理集群的利用率较低；<ul>
<li>我们的观察基于使用 O(10k) GPU 运行生产集群进行训练甚至更多推理的经验。具体而言，由于昼夜流量模式，推理集群的利用率通常在很长一段时间内都很低 (&lt;40%)。</li>
</ul>
</li>
<li>由于缺乏资源，训练作业经常排长队。<ul>
<li>训练作业在开始前经历了很长的排队时间，从 50,000 多个作业的 15 天跟踪中可以看出，平均排队时间超过 3,000 秒，95% 分位值接近 10,000 秒。排队时间长是由于集群利用率高和GPU资源碎片化导致的。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>我们引入了 Lyra，一种新的集群调度程序。<ul>
<li>Lyra 引入了容量借贷（capacity loaning），借出闲置的推理服务器用于训练作业。</li>
<li>它进一步利用弹性扩展来扩展训练作业的资源分配，以更好地利用借出的服务器。</li>
</ul>
</li>
<li>容量借用和弹性扩展给集群管理带来了新的挑战。<ul>
<li>当借出的服务器需要归还时，我们需要尽量减少作业抢占；</li>
<li>当有更多 GPU 可用时，我们需要将它们分配给弹性作业并最小化作业完成时间 (JCT)。</li>
</ul>
</li>
<li>Lyra 通过有原则的启发式方法解决了这些组合问题。<ul>
<li>它引入了服务器抢占成本的概念，它在服务器回收期间贪婪地降低了成本。</li>
<li>它进一步依赖于为弹性工作的每个额外工人定义的 JCT 减少值来解决调度问题作为多项选择背包问题。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>64 GPU 测试台上的原型实施和对超过 50,000 个生产作业进行 15 天跟踪的大规模模拟表明，Lyra 使平均排队时间和 JCT 分别减少了 1.53 倍和 1.48 倍，并将集群使用率提高了高达 25%。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>智算应用有什么特点，当设计面向智算应用的调度程序时，有什么可以且应当考虑的特殊需求？<blockquote>
<p>如今，通常的做法是分别构建和管理两种类型的 GPU 集群，一种用于训练，一种用于推理，并使用单独的调度程序来管理它们。</p>
</blockquote>
</li>
<li>弹性伸缩时需要考虑什么？需要考虑迁移吗？</li>
</ol>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3552326.3587445">[1] Jiamin Li, Hong Xu, Yibo Zhu, Zherui Liu, Chuanxiong Guo, and Cong Wang. 2023. Lyra: Elastic Scheduling for Deep Learning Clusters. In Proceedings of the Eighteenth European Conference on Computer Systems (EuroSys ‘23). Association for Computing Machinery, New York, NY, USA, 835–850.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>智算管理</tag>
        <tag>调度</tag>
        <tag>待精读</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】精读笔记1-前沿-跨地域资源预留调度</title>
    <url>/2023/12/06/literature/literatureNotesIntensive1/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Characterizing-and-orchestrating-VM-reservation-in-geo-distributed-clouds-to-improve-the-resource-efficiency》"><a href="#x1f4d6-《Characterizing-and-orchestrating-VM-reservation-in-geo-distributed-clouds-to-improve-the-resource-efficiency》" class="headerlink" title="&#x1f4d6;《Characterizing and orchestrating VM reservation in geo-distributed clouds to improve the resource efficiency》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">&#x1f4d6;</span>《Characterizing and orchestrating VM reservation in geo-distributed clouds to improve the resource efficiency》</h1><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h3><ul>
<li>供应商-租户<ul>
<li>供应商：提供资源<ul>
<li>资源特性：跨地域、多类型。带来异构 SLA、异构成本，通过在满足 SLA 的资源中优选，能够降低成本。</li>
</ul>
</li>
<li>单租户：为满足实际需求（使用），预留资源（申请）<ul>
<li>使用&lt;申请。使用为固定信息可以对申请进行调整。</li>
<li>需求负载（使用）呈现出<strong>不同时空模式</strong>。不同时间对不同地域、虚机类型的需求会发生变化。</li>
</ul>
</li>
<li>多租户：需求之间有重合。<ul>
<li>需求负载（使用）类型不一，存在互补关系。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ul>
<li>租户预留资源的方案较贵，有优化的空间。可以从资源地区、资源类型两方面优化。<ul>
<li>（意味着用户所需的资源总量是确定的，只需要进行调整）</li>
<li>以总体部署成本为优化目标。</li>
</ul>
</li>
<li>租户预留的资源经常用不上，可以互补。<ul>
<li>（用户所需的资源总量可以调整？如果调整错了怎么办？如何衡量这种错误？）</li>
<li>以预留资源量为优化目标。</li>
</ul>
</li>
</ul>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="&#x1f3af;需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">&#x1f3af;</span>需求</h2><ul>
<li><strong>云提供商</strong>通常从不同地理区域的多个数据中心构建<strong>地理分布式云</strong>，为不同位置的租户提供服务。<ul>
<li>公共云提供商通常在<strong>不同的地理区域构建多个数据中心</strong>，为不同地点的租户提供服务。数据中心中的硬件资源通常被组织成资源池，云提供商通常提供<strong>不同的虚拟机（VM）类型</strong>供租户选择。由于不同的能源费用和虚拟机性能，这些区域和虚拟机类型通常具有不同的资源成本系数。</li>
</ul>
</li>
<li>运行大规模应用的<strong>租户</strong>，往往会根据其在靠近终端用户的区域的峰值负载来预留资源，以应对不断变化的应用负载，<strong>浪费了大量资源</strong>。<ul>
<li>这些地理分布式云通常托管<strong>大型应用程序</strong>，例如流视频应用程序（如 YouTube）和社交网络应用程序（如 Twitter 和 Facebook）。此类面向租户的应用程序的<strong>实际负载</strong>经常由于计划外负载峰值或每日负载模式而<strong>动态变化</strong>，需要不同数量的资源来实现严格的服务质量（QoS）。</li>
<li>为此，当前的云（例如 AWS、Azure、Google Cloud）允许租户在首选区域中<strong>预留</strong>具有<strong>首选规格</strong>的虚拟机。<strong>租户</strong>经常<strong>申请</strong>根据<strong>靠近最终用户的云区域</strong>中可能的峰值负载来预留虚拟机。</li>
</ul>
</li>
</ul>
<h2 id="🤺挑战"><a href="#🤺挑战" class="headerlink" title="🤺挑战"></a>🤺挑战</h2><ul>
<li><p>因此，我们描述了生产公共地理分布式云中排名靠前的<strong>租户的 VM 请求模式</strong>，并在 4 个月内从云的<strong>前 20 个租户</strong>中开源了 VM 请求跟踪。特征分析表明，<strong>大型租户的资源使用</strong>在<strong>时序、地域、虚拟机</strong>类型等维度上具有<strong>不同的时空模式</strong>，并具有<strong>不同租户间调峰的潜力</strong>，从而进一步降低资源预留成本。</p>
<ul>
<li>在本文中，我们首先分析了具有 17 个区域的生产地理分布式云中这些租户的资源（CPU 核心和内存空间）预留模式。<ul>
<li>我们观察到租户指定的资源预留策略导致两个主要问题。<ul>
<li>1）首先，租户往往<strong>只在短时间内使用</strong>所有预留资源，预留资源造成巨大的资源浪费。例如，在我们的地理分布式云中，最多 68.6% 的预留资源在一个区域中实际使用，而在最坏的情况下只有 1.0% 的预留资源被使用（第 4.1 节）。</li>
<li>2）其次，<strong>预留通常放置在</strong>靠近最终租户的<strong>昂贵区域</strong>或<strong>昂贵的VM类型</strong>上，昂贵区域/VM类型上的资源可能被不必要地预留（第4.2节）。在地理上接近且具有类似性能的更便宜的区域/VM 类型上保留“刚好够用”的资源是有益的，同时仍然确保所需的服务级别协议 (SLA)。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>下图显示了我们跟踪的 84379 个租户的<strong>资源使用</strong>百分比（核心 × 小时）。据观察，<strong>前 20 位租户</strong>使用了所有资源使用量的 54.3%。虽然少数大型租户使用了很大比例的资源，但通过说服他们以较低的价格和有保证的 SLA 允许灵活的<strong>跨数据中心</strong>虚拟机预留/调度，有机会大大提高地理分布式云的资源效率。</p>
</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/2-Figure1-1.png"
                      alt="图1-在我们的地理分布式云中按降序排列的租户的聚合资源使用情况"
                ><figcaption>图1-在我们的地理分布式云中按降序排列的租户的聚合资源使用情况</figcaption></figure><br>（图1-在我们的地理分布式云中按降序排列的租户的聚合资源使用情况）</p>
<ul>
<li><p>利用上述机会并非易事，因为大型租户的资源使用表现出<strong>不同的</strong> <strong>时间</strong>（第 5.1 节）和<strong>空间</strong>（第 5.2 节）<strong>模式</strong>。</p>
<ul>
<li>1）<strong>时间模式</strong>呈现租户随时间的资源使用量。<ul>
<li>例如，视频应用程序通常具有每日负载模式，而社交网络应用程序具有突发新闻的突发请求模式。</li>
</ul>
</li>
<li>2）<strong>空间模式</strong>显示了租户在不同区域和虚拟机类型上的资源使用模式。<ul>
<li>例如，租户可以将虚拟机部署在靠近最终用户的多个区域，以实现较短的响应延迟，或者部署在满足性能要求的各种规格的虚拟机上。</li>
</ul>
</li>
</ul>
</li>
<li><p>此外，我们还观察到一些大租户具有<strong>互补的时间和空间资源使用模式</strong>。</p>
<ul>
<li>当某个租户使用少量资源时（实际预留大量资源），其他一些租户会使用其预留的大部分资源，反之亦然。这是因为这些租户通常运行不同的应用程序，并且他们的最终用户具有不同的访问行为。通过<strong>将这些互补租户的资源编排在</strong>地理分布式云的<strong>同一区域</strong>，可以进一步<strong>降低资源预留成本</strong>。</li>
</ul>
</li>
</ul>
<ul>
<li>从技术上讲，要提高资源效率，需要解决三个挑战。<ul>
<li>1）首先，要<strong>准确预测</strong>租户的<strong>资源使用模式</strong>，以便为租户预留“刚够用”的资源。</li>
<li>2）其次，为了避免在高成本区域或虚拟机类型上不必要地预留过多资源的情况，考虑到<strong>租户的空间资源使用模式</strong>，<strong>跨区域资源编排器</strong>需要仔细地将每个租户的预留资源分配到不同的区域/虚拟机类型。</li>
<li>3）最后，由于应用程序的<strong>负载偶尔会爆发</strong>，因此需要<strong>在线调度机制</strong>来快速为租户分配更多资源。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="&#x1f6a7;现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">&#x1f6a7;</span>现状</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><ul>
<li>云提供商发布了公共云和私有云的生产环境 traces 数据集。由于开源 traces 数据集的数量有限，我们将所有已知的 traces 数据集与我们的进行比较。下表进行了比较。</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/3-Table1-1.png"
                      alt="表1-traces对比"
                ><figcaption>表1-traces对比</figcaption></figure><br>（表1-traces对比）</p>
<ul>
<li>在<strong>私有云</strong>方面，<ul>
<li>1）<strong>谷歌</strong>在 2011 年提供了其 Borg 集群一个月的 traces 数据，并在 2019 年发布了包含 8 个不同集群的 traces 数据扩展版本。<ul>
<li>这些 traces 主要针对其私有云中基于容器的内部工作负载。</li>
</ul>
</li>
<li>2）<strong>阿里云</strong>在 2017 年发布了一个可公开访问的 traces 数据集，在 12 小时内有 1300 台机器，其中包含延迟关键型（LC）和批处理工作负载。2018 年，阿里巴巴又发布了更大规模的 LC 和批量工作负载 traces 数据集，其中包含批量工作负载的 DAG 信息。<ul>
<li>阿里巴巴的 traces 也主要集中在私有云环境下的内部应用。</li>
</ul>
</li>
<li>相反，我们以<strong>公有云的 IaaS 模式</strong>来描述云虚拟机工作负载。</li>
</ul>
</li>
<li>在<strong>公有云</strong>方面，<ul>
<li>1）<strong>微软 Azure</strong> 在 2017 年和 2019 年的三个月内开源了其第一方和第三方虚拟机工作负载，该工作分析了虚拟机的时间行为，以显示其资源使用是可预测的。此外，微软 Azure 还发布了一个专门用于研究其虚拟机调度算法的虚拟机请求 traces 。</li>
<li>与这些 traces 相比，我们的轨迹侧重于我们的<strong>地理分布式云</strong>中<strong>大型租户</strong>虚拟机请求的资源使用的时间和空间<strong>特征</strong>。这种分析视角有助于我们研究在为大型租户预订资源时如何降低部署成本。</li>
</ul>
</li>
<li>还有其他 traces 分析工作，涉及公有云的<strong>其他类型</strong>工作负载。<ul>
<li>1）微软 Azure 分别于 2019 年和 2021 年发布了两份函数 traces 报告。</li>
<li>2）阿里巴巴分别于 2020 年和 2021 年发布了有关机器学习（ML）工作负载和微服务的 traces 分析。</li>
<li>与我们的 traces 分析不同，这些 traces 分析并不涉及 IaaS 模式下的虚拟机工作负载。</li>
</ul>
</li>
</ul>
<h3 id="调度方法"><a href="#调度方法" class="headerlink" title="调度方法"></a>调度方法</h3><ul>
<li>在<strong>数据中心内部的任务调度</strong>方面，人们提出了一系列的工作来调度VM、容器和函数，分类为：<ul>
<li>1）集中式</li>
<li>2）分布式：<ul>
<li>两级式</li>
<li>状态共享式</li>
</ul>
</li>
<li>3）混合式</li>
<li>他们的共同目标是在低延迟调度决策下寻求高调度质量。这些调度程序专注于<strong>数据中心内</strong>的任务级调度，因此它们不能应用于<strong>跨地域</strong>预留资源和调度虚拟机。</li>
</ul>
</li>
<li>在<strong>地理分布式任务调度</strong>方面，大部分工作集中在管理不同数据中心之间的<strong>网络流量</strong>。 <ul>
<li>Yugong通过项目放置、表复制和作业外包来管理网络流量，以节省公共网络带宽。 </li>
<li>Taiji通过将网络流量路由建模为分配问题，在地理上分配流量对象，以满足服务级别目标。 </li>
<li>Gaia消除了数据中心之间无关紧要的通信，同时保持了机器学习算法的正确性。 </li>
<li>ELIS和Nautilus在数据中心和边缘之间部署微服务时优化了公共网络中的网络流量，以实现更好的服务延迟。</li>
<li>然而，这些工作都没有考虑数据中心不同资源成本下的<strong>资源预留</strong>，没有以最小化计算资源预留成本为目的。</li>
</ul>
</li>
<li>此外，当前的云提供商根据<strong>云租户指定</strong>的最大需求量和实例位置来预留资源。但云租户大多数时候<strong>无法充分利用</strong>预留资源，且预留位置可能资源成本系数较高，导致资源预留成本巨大。</li>
<li>此外，纳拉亚南等人提出了一种地理分布式容量规划策略来<strong>优化部署成本</strong>，但<strong>为每个租户独立编排资源</strong>，导致资源效率较差。</li>
<li>综上所述，迄今为止对公有云资源管理和任务调度的研究缺乏对大型商业提供商大租户时空格局关键特征的透彻理解。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="&#x1f6e9;创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">&#x1f6e9;</span>创新</h2><ul>
<li><p>基于以上分析，我们提出了一种名为ROS的资源预留和虚拟机请求调度方案，以在满足虚拟机分配请求的同时最大限度地降低资源预留成本。</p>
</li>
<li><p>因此，我们进一步提出了一种名为 <strong>ROS</strong> 的<strong>运行时方案</strong>来<strong>编排地理分布式云中的资源</strong>。 ROS<strong>根据多个租户的时间和空间资源使用模式</strong>来优化它们的资源编排。 </p>
<ul>
<li>ROS 包括<strong>负载模式预测器</strong>、<strong>跨区域资源协调器</strong>和<strong>突发感知调度器</strong>来解决上述挑战。<ul>
<li>1）<strong>预测器</strong>使用不同的预测方法来预测大租户的资源使用情况。</li>
<li>2）考虑到区域/虚拟机类型的不同成本以及大租户的互补性，<strong>编排器</strong>将预测的负载模式作为输入，将预留资源编排到不同区域/虚拟机类型上，以降低总体部署成本。</li>
<li>3）<strong>在线调度器</strong>对VM请求进行调度，并对运行时的突发请求和不规则请求进行补偿。</li>
</ul>
</li>
</ul>
</li>
<li><p>我们将贡献总结如下：</p>
<ul>
<li>• 我们的生产地理分布式云的开源虚拟机请求数据集。该数据集包括前 20 个租户在 4 个月内的 VM 请求跟踪。据我们所知，这是<strong>地理分布式云</strong>中<strong>第一个</strong> <strong>大型租户</strong>的<strong>虚拟机请求数据集</strong>。</li>
<li>• 对我们生产级地理分布式云中的虚拟机请求进行<strong>全面分析</strong>。从分析中获得的见解确定了通过跨区域预留和调度来降低资源预留成本的机会。</li>
<li>• <strong>资源编排和调度方案</strong>的设计。该方案在满足虚拟机请求的同时，最大限度地降低了资源预留成本。仿真结果表明，它可以降低总体部署成本和预留资源。</li>
</ul>
</li>
<li><p>我们的<strong>主要贡献</strong>是开源跟踪以及对地理分布式云中大型租户的虚拟机使用模式的全面分析。 ROS是基于分析而设计的，也具有多项技术新颖性。</p>
</li>
</ul>
<h2 id="⛰️场景"><a href="#⛰️场景" class="headerlink" title="⛰️场景"></a>⛰️场景</h2><ul>
<li>我们的虚拟机请求跟踪包括 2021 年 4 个月期间 17 个地区前 20 名大型租户和数十种虚拟机类型。每个请求都说明了租户的需求，如地区和虚拟机类型。本节将介绍本文的背景和术语。下图显示了我们的地理分布式云的概览。</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/4-Figure2-1.png"
                      alt="图2-地理分布式云概览"
                ><figcaption>图2-地理分布式云概览</figcaption></figure><br>（图2-地理分布式云概览）</p>
<h3 id="1-云区域和数据中心"><a href="#1-云区域和数据中心" class="headerlink" title="1. 云区域和数据中心"></a>1. 云区域和数据中心</h3><ul>
<li>如上图所示，我们的云平台的数据中心建在<strong>多个地理位置</strong>上。我们的云平台根据地理位置划分<strong>区域（Regions）</strong>。<ul>
<li>弹性计算、块存储和 VPC 网络等公共服务在同一区域内共享。区域内的数据中心通过高速光纤网络连接，以满足云租户跨数据中心构建高可用性系统的要求。</li>
</ul>
</li>
<li>由于<strong>不同的数据中心</strong>处于<strong>相同的地理位置</strong>，大型云租户资源使用的<strong>空间特征</strong>体现在于<strong>对不同区域的选择</strong>。<ul>
<li>我们将<strong>不同区域的资源使用情况</strong>作为<strong>分析空间特征</strong>的一个方面，并为大型租户预留资源，将虚拟机请求调度到不同区域。</li>
</ul>
</li>
<li>在本文中，我们使用 <em>ri</em> 来表示特定区域。此外，为了便于后面数据分析部分的统计，我们<strong>将所有区域划分至三个区域集（Region Sets）</strong>，分别标记为<em>Region Set 1</em>、<em>Region Set 2</em> 和<em>Region Set 3</em>，每个区域集内区域的地理位置都比较接近。</li>
</ul>
<h3 id="2-资源池和虚拟机类型"><a href="#2-资源池和虚拟机类型" class="headerlink" title="2. 资源池和虚拟机类型"></a>2. 资源池和虚拟机类型</h3><ul>
<li>如上图所示，每个区域的<strong>异构硬件资源</strong>被组织成<strong>多种类型的资源池</strong>（用不同颜色标记）。<ul>
<li>每个资源池都有<strong>来自该区域数据中心</strong>的<strong>相同类型</strong>的物理服务器。</li>
<li><strong>不同区域</strong>可能拥有<strong>相同类型的资源池</strong>，因为它们可能拥有相同类型的物理服务器。</li>
</ul>
</li>
<li>不同的资源池具有<strong>不同的容量和成本系数</strong>。<ul>
<li>我们的云平台提供不同类型的虚拟机，并标有不同的虚拟机名称，供云租户根据需求进行选择。<ul>
<li>以名为 “<em>s2.medium.4</em>“ 的虚拟机为例：<ul>
<li>“<em>s2</em>“ 代表虚拟机所在物理服务器的类型，</li>
<li>“<em>medium</em>“ 代表 CPU 内核的数量，</li>
<li>“<em>4</em>“ 代表内存（GB）与 CPU 内核的比例。</li>
</ul>
</li>
<li>因此，”<em>s2</em>“与资源池的类型相对应，我们将其命名为<strong>虚拟机类型</strong>。</li>
</ul>
</li>
<li>对于不同的虚拟机类型，我们使用 <em>vi</em> 来表示特定的虚拟机类型。</li>
</ul>
</li>
<li>由于<strong>不同的大型云租户</strong>对<strong>不同的虚拟机类型</strong>有其特定的资源使用需求，因此我们将<strong>不同虚拟机类型的资源使用情况</strong>作为<strong>分析空间特征</strong>的另一个方面。</li>
<li>此外，结合区域的空间特征，我们的方案<strong>旨在为不同区域的不同虚拟机类型预留资源和调度虚拟机请求</strong>。</li>
</ul>
<h3 id="3-资源预留"><a href="#3-资源预留" class="headerlink" title="3. 资源预留"></a>3. 资源预留</h3><ul>
<li>由于一些<strong>特殊情况</strong>（如计划外负载峰值和大规模虚拟机迁移），租户有时<strong>需要比日常使用量更多</strong>的资源。为处理这些情况，当前的云提供商提供<strong>预留（Reservation）</strong>实例或服务，预留<strong>资源量</strong>和预留<strong>实例位置</strong> <strong>均由云租户自己指定</strong>，如上图右侧所示。（#TODO 没提及实例类型？）<ul>
<li>这些预留方法可确保大型租户的<strong>资源高可用性</strong>，但却给云提供商带来了巨大的<strong>部署成本</strong>。原因在于：<ul>
<li>(1)云租户在大多数时间无法充分利用预留资源，（所以要优化预留的资源量）（#TODO 还没解释如何刻画预留失败的惩罚）</li>
<li>(2)租户指定的预留实例位置可能具有较高的资源成本系数。（所以要优化地理位置和资源类型）</li>
</ul>
</li>
</ul>
</li>
<li>本文分析了大型云租户的<strong>时空模式</strong>，并设计了相应的方法来降<strong>低资源预留的部署成本</strong>。<ul>
<li>限于篇幅，在本文的数据分析中，我们只展示了 CPU 资源的统计结果。内存资源的统计结果与 CPU 的统计结果呈现类似的规律。</li>
</ul>
</li>
</ul>
<h2 id="资源预留状态"><a href="#资源预留状态" class="headerlink" title="资源预留状态"></a>资源预留状态</h2><ul>
<li>在本节中，我们将分析云中<strong>资源预订的现状</strong>。<ul>
<li>我们首先展示了预留资源的<strong>资源利用率</strong>。</li>
<li>然后，我们介绍了不同区域/虚拟机类型的<strong>资源使用分布情况</strong>，</li>
<li>并进一步提出了<strong>可接受的空间范围</strong>（<em>acceptable spatial range</em>）。</li>
</ul>
</li>
</ul>
<h3 id="资源利用率"><a href="#资源利用率" class="headerlink" title="资源利用率"></a>资源利用率</h3><ul>
<li>为确保在大租户需要超过其正常使用量的资源时（如计划外负载峰值）有资源可用，我们会提前为其预留资源。预留资源的数量由<strong>大租户</strong>根据其<strong>最大需求</strong> <strong>自行指定</strong>。<ul>
<li>然而，大多数大型租户的日常资源使用量在大部分时间都<strong>无法充分利用</strong>预留资源，这可能会造成资源浪费。</li>
<li>为了探究资源<strong>浪费的程度</strong>，我们每 10 分钟对不同区域的资源使用情况进行采样，并计算相对于每个区域所有大租户的总预留资源的资源使用率。</li>
<li>下图3报告了所有区域在所有采样点的资源利用率分布情况。<ul>
<li>下图3(a)、下图3(b) 和下图3(c) 分别显示了 <em>Region Set 1</em>、<em>Region Set 2</em> 和 <em>Region Set 3</em> 的结果。<strong>（每个点代表：对于第rx个区域，第百分之x的用户（采样点）利用了百分之y资源）</strong></li>
<li>从下图3(a)、下图3(b) 和下图3(c) 中可以发现，相对于预留资源，<strong>大部分区域的采样点利用率都很低</strong>，但不同区域的<strong>分布并不相似</strong>。</li>
<li>下图3(c)中 <em>r11</em> 的特殊曲线是由于：虽然我们在该区域为大租户预留了一些资源，但<strong>大部分采样点的资源使用量为 0</strong>。</li>
<li>对于下图3(d)所示的<strong>总体资源利用率分布</strong>，采样点<strong>主要分布在 20%-50% 之间</strong>。</li>
</ul>
</li>
<li>下图4显示了不同区域的<strong>相对于其预留资源</strong>的<strong>平均利用率</strong>以及<strong>总利用率</strong>。<ul>
<li><strong>平均值在 1.0%-68.7% 之间</strong>，**平均总利用率为 32.3%**。</li>
</ul>
</li>
<li>这些资源利用率低的结果证明，预留资源<strong>存在大量资源浪费</strong>。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/5-Figure3-1.png"
                      alt="图3-资源利用率分布"
                ><figcaption>图3-资源利用率分布</figcaption></figure><br>（图3-资源利用率分布）</p>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/5-Figure4-1.png"
                      alt="图4-相对于预留总量的平均资源利用率"
                ><figcaption>图4-相对于预留总量的平均资源利用率</figcaption></figure><br>（图4-相对于预留总量的平均资源利用率）</p>
<ul>
<li>如果我们能<strong>根据</strong>大型租户的<strong>资源使用模式</strong>为其<strong>预留资源</strong>，就有可能<strong>减少资源预留浪费</strong>。探索大型租户的<strong>资源使用时间模式</strong>是必要的。</li>
</ul>
<h3 id="资源使用分布情况"><a href="#资源使用分布情况" class="headerlink" title="资源使用分布情况"></a>资源使用分布情况</h3><ul>
<li><p>在地理分布式云环境中，<strong>不同区域或虚拟机类型</strong>可能具有<strong>不同的资源成本系数</strong>。因此，它有望将租户请求<strong>分配给成本系数较小</strong>的区域或虚拟机类型，从而<strong>降低总体部署成本</strong>。</p>
</li>
<li><p>我们首先探讨了大租户在<strong>不同区域</strong>的资源使用分布情况。</p>
<ul>
<li>下图5(a) 显示了<strong>不同区域</strong>的不同<strong>资源成本系数</strong>。<ul>
<li>一个区域的<strong>成本系数</strong>是其<strong>维护成本</strong>（如房地产和电力成本）与区域 r8 的成本进行<strong>归一化</strong>的结果。</li>
<li>我们可以发现， <em>Region Set 1</em> 有 2 个不同的值（1.2 和 0.7），<em>Region Set 2</em> 有 1 个值（1.0），<em>Region Set 3</em> 有 3 个不同的值（1.0、0.8 和 1.66）。<ul>
<li>由于同一区域集中的区域在<strong>地理位置上比较接近</strong>，因此 <em>Region Set i</em> 区域中的大部分虚拟机请求都可以调度到<strong>该范围内的任何区域</strong>，而<strong>不会影响响应时间</strong>（由地理位置造成）。</li>
</ul>
</li>
</ul>
</li>
<li>下图6分别显示了 <em>Region Set 1</em>、<em>Region Set 2</em> 和 <em>Region Set 3</em> 中不同资源成本系数下大型租户当前的资源使用量分布情况。<ul>
<li>我们可以看到，在 <em>Region Set 1</em> 和 <em>Region Set 3</em> 中，分别只有 30.2% 和 14.0% 的资源<strong>被分配到了低成本区域</strong>。</li>
<li>因此，当前租户资源使用分布<strong>并不倾向于低成本区域</strong>。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/5-Figure5-1.png" alt="图5-不同区域/虚机类型的成本系数"><figcaption>图5-不同区域/虚机类型的成本系数</figcaption></figure><br>（图5-不同区域/虚机类型的成本系数）</p>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/5-Figure6-1.png"
                      alt="图6-不同*Region Set*内区域资源使用量分布"
                ><figcaption>图6-不同*Region Set*内区域资源使用量分布</figcaption></figure><br>（图6-不同<em>Region Set</em>内区域资源使用量分布）</p>
<ul>
<li>此外，我们还探讨了<strong>不同虚拟机类型</strong>的资源使用分布情况。<ul>
<li>上图5(b) 显示了 7 种<strong>不同虚拟机类型</strong>的<strong>资源成本系数</strong>。虚拟机类型的<strong>成本系数</strong>是其在 <strong>1vCPU 和 2GiB 内存</strong>条件下的<strong>售价</strong>。<ul>
<li>我们可以发现，这 7 种虚拟机类型有两个不同的资源系数值（0.06 和 0.105）。</li>
<li>此外，在<strong>与大型租户沟通</strong>后，我们了解到他们的<strong>大部分工作负载都可以在这 7 种虚拟机类型中的任何一种上执行</strong>，而<strong>不会</strong>产生<strong>不同</strong>的<strong>执行性能</strong>。</li>
</ul>
</li>
<li>下图7显示了大租户当前在 7 种虚拟机类型上不同资源成本系数下的资源使用分布。<ul>
<li>与区域的结果类似，我们也可以发现只有 19.6% 的资源<strong>分配给了低成本的虚拟机类型</strong>。</li>
<li>这一结果证明了当前租户资源的分布<strong>并不倾向于低成本虚拟机类型</strong>。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/5-Figure7-1.png"
                      alt="图7-不同虚拟机类型资源使用量分布"
                ><figcaption>图7-不同虚拟机类型资源使用量分布</figcaption></figure><br>（图7-不同虚拟机类型资源使用量分布）</p>
<ul>
<li>通过在<strong>低成本区域/虚拟机类型</strong>上预留资源或调度虚拟机来<strong>降低部署成本</strong>具有很大的潜力。因此，我们需要探索大型租户的<strong>空间（区域/虚拟机类型）资源使用模式</strong>。</li>
</ul>
<h3 id="可接受空间范围acceptable-spatial-range"><a href="#可接受空间范围acceptable-spatial-range" class="headerlink" title="可接受空间范围acceptable spatial range"></a>可接受空间范围<em>acceptable spatial range</em></h3><ul>
<li><p><strong>数据中心间的调度</strong>比<strong>数据中心内的调度</strong>更为复杂，因为数据中心的<strong>成本系数</strong>和<strong>网络延迟</strong>各不相同。</p>
<ul>
<li>结合<a href="#%E8%B5%84%E6%BA%90%E4%BD%BF%E7%94%A8%E5%88%86%E5%B8%83%E6%83%85%E5%86%B5">上一节（资源使用分布情况）</a>中的观察结果，我们通过<strong>事先与大租户协商</strong>，确定每个大租户<strong>可接受的资源使用空间范围</strong> <em>acceptable spatial range</em>。（#TODO 目前的可接受空间范围还过于简单？）这有助于我们根据租户对网络延迟和虚拟机性能的服务水平协议，在低成本区域/虚拟机类型上为租户预留资源。</li>
</ul>
</li>
<li><p>可接受空间范围<em>acceptable spatial range</em>考虑了大型租户对网络延迟和虚拟机性能的需求，因此包含两层含义。</p>
<ul>
<li>首先，租户对 <em>ri</em>、…、<em>rj</em> <strong>区域</strong>的预留资源或虚拟机请求可以在<strong>这些区域内任意</strong>预留或调度，因为这些区域在地理位置上比较接近，而且网络延迟对租户来说是可接受的。<ul>
<li>例如，不同的区域集<em>Region Set 1</em>、<em>Region Set 2</em> 和 <em>Region Set 3</em>。（#TODO 目前是对所有用户相同约束？）</li>
</ul>
</li>
<li>其次，租户在 <em>vi</em>、……、<em>vj</em> 等虚拟机类型上的预留资源或虚拟机请求可在<strong>这些虚拟机类型内任意</strong>预留或调度，因为这些虚拟机类型对于该租户的工作负载都具有可接受的性能，满足性能服务级别协议的要求。<ul>
<li>例如，上图 7 中使用的 7 种虚拟机类型。</li>
</ul>
</li>
</ul>
</li>
<li><p>我们的资源协调和调度方案在资源预订和请求调度中考虑了大型租户可接受的空间范围<em>acceptable spatial range</em>，从而在<strong>满足</strong>大型租户所需的<strong>服务水平协议（SLA）</strong>的同时，<strong>最大限度</strong>地<strong>降低</strong> <strong>部署成本</strong>。</p>
</li>
</ul>
<h3 id="主要发现总结"><a href="#主要发现总结" class="headerlink" title="主要发现总结"></a>主要发现总结</h3><ul>
<li>通过对预留资源利用和分配情况的分析，我们现在重申我们的 2 点看法。<ul>
<li>首先，现有为大型租户<strong>预留资源过多</strong>，会造成<strong>巨大的资源浪费</strong>。（调整资源预留量）<ul>
<li>我们希望通过分析租户的资源使用模式，预测租户近期所需的资源量，从而<strong>按需为租户预留资源</strong>，<strong>而不是</strong>始终根据租户指定的<strong>最大值预留资源</strong>。</li>
</ul>
</li>
<li>其次，当前大型租户的<strong>资源使用不合理</strong>，<strong>不了解区域和虚拟机类型的成本</strong>，也会造成<strong>巨大的不必要的成本开销</strong>。（调整资源预留位置/类型）<ul>
<li>具体来说，只有<strong>不到 30%</strong> 的大型租户的资源使用<strong>分布在低成本区域或虚拟机类型</strong>上。因此，<strong>为低成本区域和虚拟机类型</strong>预留资源或安排虚拟机请求以降低整体部署成本大有可为。</li>
</ul>
</li>
</ul>
</li>
<li>总之，无论是减少预留资源还是在低成本区域/虚拟机类型中预留资源，基础都在于<strong>对大型租户资源使用模式的分析</strong>。这促使我们在<a href="#%E6%97%B6%E7%A9%BA%E8%B5%84%E6%BA%90%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%BC%8F">下一节（时空资源使用模式）</a>中分析大型租户的资源使用模式。</li>
</ul>
<h2 id="时空资源使用模式"><a href="#时空资源使用模式" class="headerlink" title="时空资源使用模式"></a>时空资源使用模式</h2><ul>
<li>本节将<strong>分析</strong>大型租户的<strong>资源时间使用模式</strong>，将其<strong>分为多种类型</strong>，并<strong>提出相应的预测方法</strong>。</li>
<li>然后，我们将大型租户的<strong>资源使用情况</strong> <strong>细分</strong>为<strong>区域</strong>和<strong>虚拟机类型</strong>，以<strong>探索其空间特征</strong>。</li>
<li>此外，我们还探讨了<strong>不同租户之间削峰（peak shaving）</strong>的时间和空间潜力。</li>
</ul>
<h3 id="资源时间使用模式"><a href="#资源时间使用模式" class="headerlink" title="资源时间使用模式"></a>资源时间使用模式</h3><ul>
<li>通过分析大型租户的不同时间模式，可以帮助我们预测其资源使用情况，然后根据预测结果储备资源，减少资源浪费。</li>
<li>在本节中，我们将探讨 20 个大型租户的时间模式，并将其分为 4 种不同类型，即<strong>昼夜负载模式</strong>（<em>the diurnal load pattern</em>）、<strong>持续使用模式</strong>（<em>persistent usage pattern</em>）、<strong>突发使用模式</strong>（<em>bursty usage pattern</em>）和<strong>不规则使用模式</strong>（<em>irregular usage pattern</em>）。</li>
</ul>
<h4 id="1）昼夜负载模式-the-diurnal-load-pattern"><a href="#1）昼夜负载模式-the-diurnal-load-pattern" class="headerlink" title="1）昼夜负载模式 the diurnal load pattern"></a>1）昼夜负载模式 the diurnal load pattern</h4><ul>
<li>该模式下通常表现为典型的白天与黑夜交替模式。我们发现，在 20 个顶级大租户中，有 <strong>6</strong> 个呈现出明显的昼夜时间模式，图 8 显示了 3 个示例大租户在一周内的资源使用情况。<ul>
<li>除了明显的昼夜模式外，我们可以发现 3 个示例租户的<strong>峰值时间并不相同</strong>。<ul>
<li>这就为通过不同大租户之间的<strong>削峰</strong>来减少预留资源带来了可能。（#TODO 如果都在白天峰值，削峰的意义有多大？具体如何削峰才能不影响租户？）</li>
</ul>
</li>
<li>此外，租户 3 在<strong>中午和晚上</strong>分别有一个<strong>小峰值</strong>和一个<strong>大峰值</strong>。<ul>
<li>这提醒我们，昼伏夜出的租户在一天中<strong>可能会有多个峰值</strong>。</li>
</ul>
</li>
<li>对于昼伏夜出的租户，我们还发现其整体资源使用量在<strong>长期趋势上存在上升和下降</strong>的情况。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/6-Figure8-1.png"
                      alt="图8-3个典型的昼夜负载模式租户在一周内归一化的资源使用量"
                ><figcaption>图8-3个典型的昼夜负载模式租户在一周内归一化的资源使用量</figcaption></figure><br>（图8-3个典型的昼夜负载模式租户在一周内归一化的资源使用量）</p>
<ul>
<li>结合昼夜租户的<strong>短期和长期模式</strong>，可使用<strong>时间序列预测方法</strong>（如 LSTM 和 ARIMA）预测资源使用情况。</li>
</ul>
<h4 id="2）持续使用模式-persistent-usage-pattern"><a href="#2）持续使用模式-persistent-usage-pattern" class="headerlink" title="2）持续使用模式 persistent usage pattern"></a>2）持续使用模式 persistent usage pattern</h4><ul>
<li>具有持久模式的资源使用通常<strong>在较长时间内变化较少</strong>，并<strong>在一天内保持不变</strong>。我们发现，在 20 个大型租户中，有 <strong>11</strong> 个可归类为持久型。图 9 显示了 3 个具有持续使用模式的大型租户在 4 个月内的使用结果。<ul>
<li>结果显示，这 3 个租户的长期模式可<strong>进一步分为 3 个子类</strong>，即<strong>稳定型</strong>（5 个租户）、<strong>阶梯型</strong>（3 个租户）和<strong>斜线型</strong>（3 个租户）子类。</li>
<li><strong>稳定型</strong>的资源使用量<strong>变化不大</strong>，且长期保持稳定。（#TODO 当发生突增的那几天怎么办？）<ul>
<li>因此，<strong>只需计算前一段时间</strong>（如一周）的日均资源使用量，就能<strong>轻松预测</strong>其资源使用量。</li>
</ul>
</li>
<li><strong>阶梯型</strong>在<strong>一小段时间内</strong>（如相邻两天之间）有<strong>多次小的</strong>资源使用<strong>阶梯切换</strong>。<ul>
<li>我们可以使用<strong>前一段时间</strong>（如一周）的<strong>最大值</strong>为其预留资源。</li>
</ul>
</li>
<li><strong>斜线型</strong>的长期趋势可以看作是一条<strong>斜率稳定</strong>的<strong>连续向上或向下</strong>的斜线。<ul>
<li>对于该子类型，我们可以使用<strong>线性回归法</strong>，根据前一周的资源使用情况预测第二天的资源使用情况。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/7-Figure9-1.png"
                      alt="图9-3个典型的持续模式租户在四个月内归一化的资源使用量"
                ><figcaption>图9-3个典型的持续模式租户在四个月内归一化的资源使用量</figcaption></figure></p>
<ul>
<li>由于长期租户的资源使用量在<strong>长期内变化较小</strong>，因此可以使用<strong>前一时期</strong>的平均值和最大值以及线性回归分析方法来<strong>预测</strong>其使用量。</li>
</ul>
<h4 id="3）突发使用模式-bursty-usage-pattern"><a href="#3）突发使用模式-bursty-usage-pattern" class="headerlink" title="3）突发使用模式 bursty usage pattern"></a>3）突发使用模式 bursty usage pattern</h4><ul>
<li>对于我们云中的大型租户，除了<strong>常规</strong>的<strong>昼夜</strong>资源使用模式外，还可能出现<strong>不可预测的</strong> <strong>极高资源使用率</strong>。我们发现 20 个大型租户中有 2 个存在突发情况。如图 10 所示，我们探讨了它们的不同突发情况。<ul>
<li>突发性案例在<strong>正常时间</strong>都具有<strong>昼夜资源使用模式</strong>，但在<strong>突发性时间</strong>的资源使用量约为正常时间的 <strong>3-7 倍</strong>。</li>
<li>此外，我们还可以观察到，3 个突发性案例的<strong>突发性持续时间</strong> <strong>各不相同</strong>，分别为几十分钟、几小时和几天。</li>
<li>总之，这种使用模式在突发时间、突发资源量和突发持续时间方面都具有不可预测性。</li>
</ul>
</li>
<li>由于突发情况的不可预测性，<strong>很难</strong> <strong>提前预测</strong>资源使用情况并预留足够的资源。因此，突发资源使用的满足必须<strong>依靠在线调度和补偿</strong>。<ul>
<li>例如，对于某个区域的突发负载，我们可以在<strong>运行时</strong>对其进行<strong>监控</strong>，改善预留资源，如果<strong>本地资源</strong>不足，则应用<strong>其他区域的资源</strong>。</li>
<li>此外，由于突发<strong>持续时间不可预测</strong>，我们需要<strong>监控突发持续时间</strong>，并在突发持续时间<strong>结束后</strong>减少预留资源，以减少资源预留的浪费。</li>
<li>最后，由于突发性租户在<strong>正常时间</strong>仍表现出<strong>昼夜规律</strong>，我们可以使用<a href="#1%E6%98%BC%E5%A4%9C%E8%B4%9F%E8%BD%BD%E6%A8%A1%E5%BC%8F-the-diurnal-load-pattern">昼夜负载模式一节</a>中的方法预测正常使用情况。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/7-Figure10-1.png"
                      alt="图10-三个突发模式租户在一周内归一化的资源使用量"
                ><figcaption>图10-三个突发模式租户在一周内归一化的资源使用量</figcaption></figure><br>（图10-三个突发模式租户在一周内归一化的资源使用量）</p>
<ul>
<li>大型租户的突发情况很难预测，我们主要依靠<strong>在线调度和补偿</strong>来满足突发的资源使用需求。</li>
</ul>
<h4 id="4）不规则使用模式-irregular-usage-pattern"><a href="#4）不规则使用模式-irregular-usage-pattern" class="headerlink" title="4）不规则使用模式 irregular usage pattern"></a>4）不规则使用模式 irregular usage pattern</h4><ul>
<li>在我们的跟踪数据中，一些大型租户（20 个大型租户中的 3 个）显示出<strong>不规则</strong>的资源使用情况。图 11 显示了 4 个月内不规则类型大租户的一个示例。我们可以发现，<strong>无论短期还是长期</strong>，它都<strong>没有确定的模式</strong>。<ul>
<li>这种不规则的资源使用情况<strong>很难预测</strong>，我们也<strong>无法</strong>提前进行<strong>精确</strong>的资源<strong>预留</strong>。</li>
<li>因此，我们做了一些<strong>简单的预测</strong>，<strong>主要依靠</strong> <strong>在线调度和补偿</strong>来处理。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/7-Figure11-1.png"
                      alt="图11-1个不规则模式租户在四个月内归一化的资源使用量"
                ><figcaption>图11-1个不规则模式租户在四个月内归一化的资源使用量</figcaption></figure><br>（图11-1个不规则模式租户在四个月内归一化的资源使用量）</p>
<h4 id="主要启示总结"><a href="#主要启示总结" class="headerlink" title="主要启示总结"></a>主要启示总结</h4><ul>
<li>根据对时间模式的观察，我们可以将其分为 4 种不同类型，即昼夜型、持续型、突发型和不规则型。<ul>
<li>针对不同类型的资源使用模式，我们需要<strong>使用相应的方法</strong>进行预测，并<strong>根据预测结果</strong>提前进行资源预留。</li>
</ul>
</li>
<li>此外，由于昼伏夜出的租户会有<strong>不同的高峰时间</strong>，因此有可能<strong>通过峰值分流</strong>来减少租户之间的资源预留。</li>
<li>对于突发型和不规则型租户，由于其<strong>不可预测性</strong>，<strong>区域内或跨区域</strong>的<strong>在线调度和补偿</strong>对满足其需求具有重要意义。</li>
</ul>
<h3 id="资源空间使用模式"><a href="#资源空间使用模式" class="headerlink" title="资源空间使用模式"></a>资源空间使用模式</h3><ul>
<li>不同区域/虚拟机类型的资源成本不同，大型租户<strong>可接受的空间范围也不同</strong>（<a href="#%E8%B5%84%E6%BA%90%E4%BD%BF%E7%94%A8%E5%88%86%E5%B8%83%E6%83%85%E5%86%B5">资源使用分布节</a> 和 <a href="#%E5%8F%AF%E6%8E%A5%E5%8F%97%E7%A9%BA%E9%97%B4%E8%8C%83%E5%9B%B4acceptable-spatial-range">可接受空间范围节</a>）。<ul>
<li>这些<strong>空间特征</strong>促使我们探索资源使用预测和预订在空间上的<strong>潜在差异</strong>。</li>
<li>因此，根据大型租户资源使用的时间特征，我们将资源使用进一步细分为不同的<strong>区域</strong>和<strong>虚拟机类型</strong>，以探索它们的空间模式。</li>
</ul>
</li>
</ul>
<h4 id="1）使用单一主要区域-虚拟机类型"><a href="#1）使用单一主要区域-虚拟机类型" class="headerlink" title="1）使用单一主要区域/虚拟机类型"></a>1）使用单一主要区域/虚拟机类型</h4><ul>
<li>通过对 20 个租户的统计，我们发现分别有 10/20 个和 5/20 个大租户的虚拟机主要使用<strong>一个区域</strong>和<strong>一种虚拟机类型</strong>，而其他区域和虚拟机类型的资源使用量几乎可以忽略不计。<ul>
<li>对于这类租户，我们可以<strong>重点预测</strong>其<strong>主要使用的</strong>一种<strong>区域/虚拟机类型</strong>的资源使用情况。类似的时间模式预测方法可用于预测该区域/虚拟机类型的资源使用情况。</li>
<li>其他区域/虚拟机类型的资源使用量<strong>通常很少且稳定</strong>，因此我们可以为大租户<strong>预留一个固定值</strong>（如以往数据的平均值）的资源。</li>
</ul>
</li>
<li>这些大型租户的<strong>空间（区域/虚拟机类型）模式</strong>与其<strong>时间模式</strong>几乎<strong>没有差别</strong>。</li>
</ul>
<h4 id="2）使用多个区域-虚拟机类型，进行稳定的使用量划分"><a href="#2）使用多个区域-虚拟机类型，进行稳定的使用量划分" class="headerlink" title="2）使用多个区域/虚拟机类型，进行稳定的使用量划分"></a>2）使用多个区域/虚拟机类型，进行稳定的使用量划分</h4><ul>
<li>一些大型租户使用<strong>多个</strong>区域/虚拟机类型，资源使用量划分是<strong>稳定</strong>的，即不同区域/虚拟机类型之间的<strong>资源使用比例</strong>保持稳定。从对 20 个大型租户的统计来看，2/20 和 6/20 个大型租户使用了多个区域和虚拟机类型，资源使用分布比较稳定。<ul>
<li>图 12(a) 显示了一个使用 <strong>3 个区域</strong>的租户实例。<ul>
<li>我们可以发现，<strong>r12</strong> 的资源使用量与<strong>总</strong>资源使用量的<strong>趋势相似</strong>，而<strong>其他两个区域</strong>的资源使用量<strong>基本稳定</strong>，彼此相等。</li>
<li>此外，我们还可以发现 3 个区域的<strong>资源使用比例</strong>是<strong>相当稳定</strong>的。</li>
</ul>
</li>
<li>图 12（b）显示了一个使用 <strong>3 种虚拟机类型</strong>的租户实例。<ul>
<li>我们可以发现 <strong>v3 和 v5</strong> 的资源使用趋势与<strong>总</strong>资源使用<strong>趋势相似</strong>，而 <strong>v10</strong> 则保持<strong>稳定的波动</strong>。</li>
<li>此外，还可以观察到 3 种虚拟机类型的<strong>资源使用比例</strong>是大致<strong>保持稳定</strong>的，这与各地区的情况类似。</li>
</ul>
</li>
<li>对于这类租户，由于不同区域/虚拟机类型的<strong>资源使用划分</strong>相互之间<strong>保持稳定</strong>，我们可以通过租户的<strong>时序预测结果</strong> <strong>乘以</strong> 各区域/虚拟机类型的<strong>比例</strong>，轻松实现各区域/虚拟机类型的资源使用。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/8-Figure12-1.png" alt="图12-两个租户在4个月内使用稳定模式的多个区域/虚拟机类型的归一化资源使用情况"><figcaption>图12-两个租户在4个月内使用稳定模式的多个区域/虚拟机类型的归一化资源使用情况</figcaption></figure><br>（图12-两个租户在4个月内使用稳定模式的多个区域/虚拟机类型的归一化资源使用情况）</p>
<ul>
<li>总之，<strong>虽然</strong>这类租户<strong>使用了多种</strong>区域/虚拟机类型，<strong>但</strong>其<strong>空间（区域/虚拟机类型）模式</strong>与<strong>时间模式</strong>仍然<strong>没有太大区别</strong>。</li>
</ul>
<h4 id="3）使用多个区域-虚拟机类型，进行动态的使用量划分"><a href="#3）使用多个区域-虚拟机类型，进行动态的使用量划分" class="headerlink" title="3）使用多个区域/虚拟机类型，进行动态的使用量划分"></a>3）使用多个区域/虚拟机类型，进行动态的使用量划分</h4><ul>
<li>大多数大型租户使用<strong>多个</strong>区域/虚拟机类型，其资源使用量划分<strong>不断变化</strong>，即不同区域/虚拟机类型之间的<strong>资源使用比例</strong>经常变化。从我们对 20 个大型租户的统计来看，<strong>大多数</strong>租户都属于这种空间模式，区域和虚拟机类型空间模式分别为 8/20 和 9/20。<ul>
<li>图 13（a）显示了一个使用 <strong>4 个区域</strong>的租户实例。<ul>
<li>它们的资源使用比例经常变化，如图 14（a）所示的每周资源使用明细：<ul>
<li>第 1 周的资源使用比例为 <em>r8</em> &gt; <em>r5</em> ≈ <em>r4</em> &gt; <em>r14</em> ≈ 0；</li>
<li>第 2 周至第 6 周，<em>r5</em> &gt; <em>r8</em> &gt; <em>r4</em> &gt; <em>r14</em> ≈ 0；</li>
<li>第 7 周，<em>r5</em> &gt; <em>r8</em> &gt; <em>r4</em> &gt; <em>r14</em>；</li>
<li>第 8 周至第 12 周，<em>r5</em> &gt; <em>r8</em> &gt; <em>r14</em> &gt; <em>r4</em> ≈ 0；</li>
<li>第 13 周起，<em>r5</em> &gt; <em>r14</em> &gt; <em>r8</em> ≈ <em>r4</em> ≈ 0。</li>
</ul>
</li>
<li>此外，<strong>不同区域</strong>的资源使用情况呈现出<strong>不同的模式</strong>，与<strong>整体</strong>的时间模式<strong>并不一定相同</strong>。</li>
</ul>
</li>
<li>图 13(b) 和图 14(b) 的结果也显示了<strong>类似</strong>的<strong>虚拟机类型</strong>空间模式<strong>观察结果</strong>。</li>
</ul>
</li>
<li>这类租户的最小粒度（区域/虚拟机类型）<strong>空间模式</strong>与其整体<strong>时间模式</strong>存在<strong>许多差异</strong>。原因包括：<ul>
<li>(1) 不同区域/虚拟机类型之间的<strong>资源使用比例变化频繁</strong>；</li>
<li>(2) 不同区域/虚拟机类型的<strong>资源使用呈现多种模式</strong>。</li>
</ul>
</li>
<li>此外，由于<strong>不同的大租户</strong>都有<strong>自己可接受的空间范围</strong>，而这些<strong>空间范围</strong>比最小空间粒度（区域/虚拟机类型）<strong>更复杂</strong>，因此它们的空间模式与时间模式的<strong>差异会更大</strong>。</li>
</ul>
<p><figure class="image-caption"><img src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/9-Figure13-1.png" alt="图13-两个租户在4个月内使用变化模式的多个区域/虚拟机类型的归一化资源使用情况"><figcaption>图13-两个租户在4个月内使用变化模式的多个区域/虚拟机类型的归一化资源使用情况</figcaption></figure><br>（图13-两个租户在4个月内使用变化模式的多个区域/虚拟机类型的归一化资源使用情况）<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/9-Figure14-1.png"
                      alt="图14-图13的两个租户的资源使用明细"
                ><figcaption>图14-图13的两个租户的资源使用明细</figcaption></figure><br>（图14-图13的两个租户的资源使用明细）</p>
<ul>
<li>我们可以划分空间粒度，以不同租户可接受的空间范围<em>acceptable spatial range</em>为根据，进一步在相应的空间粒度上进行资源使用预测和资源预订，从而更好地降低资源预订成本。</li>
</ul>
<h4 id="主要启示总结-1"><a href="#主要启示总结-1" class="headerlink" title="主要启示总结"></a>主要启示总结</h4><ul>
<li><p>根据对不同区域/虚拟机类型资源使用情况的分析，我们发现<strong>大多数</strong>租户使用多个区域/虚拟机类型，资源使用情况呈<strong>动态划分</strong>，具有两<strong>个空间特征</strong>。</p>
<ul>
<li>首先，不同区域/虚拟机类型的资源使用情况<strong>呈现出多种模式</strong>，这些模式<strong>不同于</strong>其<strong>总体</strong>资源使用情况的<strong>时间模式</strong>。</li>
<li>其次，不同区域/虚拟机类型之间的<strong>资源使用划分</strong>随着时间的推移<strong>经常发生变化</strong>。</li>
</ul>
</li>
<li><p>考虑到不同大型租户的可接受空间范围更为复杂（见<a href="#%E5%8F%AF%E6%8E%A5%E5%8F%97%E7%A9%BA%E9%97%B4%E8%8C%83%E5%9B%B4acceptable-spatial-range">可接受空间范围节</a>），空间模式与其时间模式的<strong>差异会更大</strong>。</p>
</li>
<li><p><strong>集中式云</strong>不具备这些空间特性，因为对于租户而言，数据中心中裸机的<strong>资源使用模式通常是相同的</strong>。（#TODO 这个结论出自何处？）</p>
</li>
<li><p>空间特征建议我们在租户相应的可接受空间范围内进行资源使用预测和资源预订，以获得更好的预测结果和更高效的资源预订。（#TODO 这个结论的意思是以更粗的粒度设计而非细粒度考虑？）</p>
</li>
</ul>
<h3 id="通过削峰提高资源预留效率的潜力"><a href="#通过削峰提高资源预留效率的潜力" class="headerlink" title="通过削峰提高资源预留效率的潜力"></a>通过削峰提高资源预留效率的潜力</h3><ul>
<li>根据<a href="#%E8%B5%84%E6%BA%90%E6%97%B6%E9%97%B4%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%BC%8F">资源时间使用模式节</a>中对大型租户<strong>时间模式</strong>的分析，我们发现一些租户的资源使用呈现<strong>昼夜模式</strong>。此外，不同的大租户在一天中可能会有<strong>不同的高峰时间</strong>，这就为减少预留资源带来了可能性。因此，我们在本节中探讨了<strong>租户间削峰（peak shaving）</strong>的<strong>时间和空间潜力</strong>。</li>
</ul>
<h4 id="1）时间方面潜力"><a href="#1）时间方面潜力" class="headerlink" title="1）时间方面潜力"></a>1）时间方面潜力</h4><ul>
<li>我们首先探讨了不同大租户之间的<strong>时间潜力</strong>。<ul>
<li>图 15(a) 显示了<strong>两个租户</strong>在一周内<strong>对同一区域和同一虚拟机类型</strong>的资源<strong>使用</strong>情况。<ul>
<li>如图中<strong>红色椭圆</strong>所示，我们可以发现两个租户的资源使用呈现出<strong>不同的峰值时间</strong>。<ul>
<li><strong>租户 1</strong> 总是在<strong>正午至中午</strong>达到峰值负载，而<strong>租户 2</strong> 总是在<strong>夜间</strong>达到峰值负载。</li>
<li>这两个租户的资源使用情况明显互补。</li>
</ul>
</li>
<li>在本例中，我们每天<strong>同时为两个租户预留资源</strong>（#TODO 视为一个整体？），即相互削峰（peak shaving），然后计算其与分别为每个租户预留资源的方法的比率。（#TODO 对比的两种方法具体是怎么做的？都使用过量预测方法决定预留多少资源？）（#TODO 到底哪里使得峰值降低了？更容易预测？还是原本有双倍冗余，现在只有一倍冗余？）<ul>
<li>图 16（a）中的结果显示，本周内<strong>每天的资源使用量</strong>都可以<strong>减少</strong>，平均值为 8.4%。</li>
</ul>
</li>
</ul>
</li>
<li>从这个例子中，我们可以看到不同租户在不同时间段的削峰潜力，而其他租户的资源使用情况也呈现出类似的模式。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/10-Figure15-1.png" alt="图15-削峰的时间和空间（区域/虚拟机类型）潜力的示例（红色椭圆表示互补的资源使用情况）"><figcaption>图15-削峰的时间和空间（区域/虚拟机类型）潜力的示例（红色椭圆表示互补的资源使用情况）</figcaption></figure><br>（图15-削峰的时间和空间（区域/虚拟机类型）潜力的示例（红色椭圆表示互补的资源使用情况））</p>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/10-Figure16-1.png"
                      alt="图16-各租户削峰方案相对于单独预留方案的归一化预留资源"
                ><figcaption>图16-各租户削峰方案相对于单独预留方案的归一化预留资源</figcaption></figure><br>（图16-各租户削峰方案相对于单独预留方案的归一化预留资源）</p>
<h4 id="2）空间方面潜力"><a href="#2）空间方面潜力" class="headerlink" title="2）空间方面潜力"></a>2）空间方面潜力</h4><ul>
<li>我们进一步探讨了不同区域和虚拟机类型的<strong>空间资源使用的削峰潜力</strong>。<ul>
<li>图 15(b) 显示了<strong>两个租户</strong>在<strong>两个区域</strong>使用<strong>两种虚拟机类型</strong>的资源<strong>使用</strong>情况。<ul>
<li>具体来说，<ul>
<li><strong>租户 1</strong> 位于<strong>区域 r14</strong>，<strong>虚拟机类型</strong>为 <strong>v5</strong>，</li>
<li>而<strong>租户 2</strong> 位于<strong>区域 r10</strong>，<strong>虚拟机类型</strong>为 <strong>v1</strong>。</li>
</ul>
</li>
<li>如图中<strong>红色椭圆</strong>所示，两个大租户的资源使用曲线具有<strong>不同的峰值时间</strong>，与时间潜力类似。<ul>
<li>租户 1 总是在<strong>上午</strong>达到负载峰值，而租户 2 总是在<strong>晚上</strong>达到负载峰值。</li>
<li>因此，如果我们将两个租户的请求<strong>调度到同一区域</strong>，并<strong>使用相同的虚拟机类型</strong>，就可以通过削峰来进一步降低资源使用量。</li>
</ul>
</li>
<li>我们采用与图 16（a）相同的方法来计算预留资源比率，图 16（b）显示，每天的资源使用量可以减少更多，平均值为 13.2%，效果更好。</li>
</ul>
</li>
</ul>
</li>
<li>较好的保留资源减少结果证明，在考虑空间因素后，削峰的潜力得到了提升。</li>
</ul>
<h3 id="使用模式分析的启示"><a href="#使用模式分析的启示" class="headerlink" title="使用模式分析的启示"></a>使用模式分析的启示</h3><ul>
<li><p>通过对生产级地理分布式云中大型租户的时间和空间使用模式的全面分析，我们现在总结一下我们的 3 个关键见解。</p>
<ul>
<li>首先，大租户有<strong>不同类型的时间模式</strong>，我们需要<strong>针对</strong>相应的时间模式<strong>使用合适的预测方法</strong>。此外，由于某些时间模式是<strong>不可预测</strong>的（如突发使用模式），因此有必要在<strong>运行时</strong>对其虚拟机请求进行<strong>调度和补偿</strong>。</li>
<li>其次，大多数租户具有<strong>明显的空间模式</strong>，包括<ul>
<li>(1) 不同区域、不同虚拟机类型的资源<strong>使用模式多种多样</strong>，</li>
<li>(2) 不同区域、不同虚拟机类型的资源<strong>使用划分随时间变化频繁</strong>。</li>
<li>这些空间模式建议我们<strong>在大租户对应的可接受空间范围内</strong>进行资源使用预测和资源预留，以达到更好的预测效果并降低资源预留成本。</li>
</ul>
</li>
<li>第三，我们观察到，昼伏夜出的大租户在时间和空间上都有可能通过<strong>相互削峰</strong>来减少预留资源。结合第 4.2 节中的分析，这些观察结果建议我们在<strong>考虑租户间削峰潜力</strong>的同时，在<strong>低成本</strong>区域/虚拟机类型上<strong>协调资源</strong>。</li>
</ul>
</li>
<li><p>综合上述观点，我们提出了一种资源预留和虚拟机调度方案。</p>
<ul>
<li>该方案由资源使用<strong>预测</strong>、<strong>资源协调</strong>、<strong>在线调度和补偿</strong>组成，在满足大型租户虚拟机请求的同时降低总体部署成本。</li>
</ul>
</li>
</ul>
<h2 id="ROS方法"><a href="#ROS方法" class="headerlink" title="ROS方法"></a>ROS方法</h2><ul>
<li>基于上述分析，我们提出了一种名为 <strong>ROS</strong> 的资源协调和调度方案。</li>
<li>在本节中，我们<ul>
<li>首先介绍 ROS 的概述，</li>
<li>然后介绍 ROS 各部分的设计细节。</li>
<li>然后，我们将评估 ROS 在降低部署成本和资源预订方面的有效性。</li>
<li>最后，我们将讨论从跟踪中汲取的经验教训。</li>
</ul>
</li>
</ul>
<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><ul>
<li>图 17 显示了 ROS 的设计概览。<ul>
<li>ROS 由<strong>负载模式预测器</strong>、<strong>跨区域资源协调器</strong>和<strong>突发感知调度器</strong>组成。<ul>
<li><strong>预测器</strong>可<strong>识别</strong>租户的行为，并<strong>估算</strong>每个租户可接受空间范围内的资源使用情况（第 6.2 节）。</li>
<li>根据估计的负载模式，<strong>协调器</strong>会<strong>分配</strong>当天的资源，以最大限度地降低总体部署成本（第 6.3 节）。协调相当于将租户的资源使用量分配给每个区域的每种虚拟机类型，并决定相应的资源预留边界。</li>
<li>在运行时，<strong>调度程序</strong>会根据协调对租户的请求做出响应，并处理计划外的请求，如负载突发导致的突然请求（第 6.4 节）。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/11-Figure17-1.png"
                      alt="图17-ROS的设计概览"
                ><figcaption>图17-ROS的设计概览</figcaption></figure><br>（图17-ROS的设计概览）</p>
<ul>
<li>ROS 倾向于<strong>每天</strong>为租户协调资源，因为租户通常有昼夜负载模式。ROS 的设计逻辑<strong>也适用于其他时段</strong>。在一天中，ROS 的工作步骤如下。<ul>
<li><ol>
<li>在<strong>一天开始时</strong>，预测器会<strong>识别</strong>每个租户的<strong>资源使用模式</strong>，并使用<strong>相应</strong>的<strong>预测方法</strong>，在每个租户<strong>可接受的空间范围内</strong>预测当天的资源使用曲线。</li>
</ol>
<ul>
<li>这里的挑战在于租户的资源使用<strong>模式各不相同</strong>，因此需要<strong>不同的预测模型</strong>。</li>
</ul>
</li>
<li><ol start="2">
<li><strong>收到预测结果后</strong>，ROS 会将<strong>预测的</strong>资源使用情况<strong>协调</strong>到不同区域的不同虚拟机类型上，并<strong>分配相应的资源预留边界</strong>（按预测值预留，#TODO 是否会额外留一部分？）。</li>
</ol>
<ul>
<li>具有挑战性的是，ROS 不仅要考虑<strong>每个区域的资源量</strong>，还要考虑<strong>不同区域</strong>和<strong>不同虚拟机类型</strong>的成本差异。</li>
</ul>
</li>
<li><ol start="3">
<li>在<strong>运行时</strong>，调度程序会分配资源，并监控不同区域不同虚拟机类型的资源需求。如果资源需求超过预留边界，调度器会补偿不足的资源预留。此外，当资源需求下降时，调度器还会降低预留上限。</li>
</ol>
</li>
</ul>
</li>
<li>我们在<strong>生产云中实施并部署</strong>了 ROS。取得的收益与<a href="#%E5%AF%B9-ros-%E7%9A%84%E8%AF%84%E4%BC%B0">对ROS的评估节</a>中的结果类似。（#TODO 评估节中是如何测试的？）</li>
</ul>
<h3 id="负载模式预测"><a href="#负载模式预测" class="headerlink" title="负载模式预测"></a>负载模式预测</h3><ul>
<li>根据<a href="#%E8%B5%84%E6%BA%90%E6%97%B6%E9%97%B4%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%BC%8F">资源时间使用模式节</a>中的分析，大型租户的<strong>资源使用模式</strong>可分为 4 种类型：昼夜模式、持续模式、突发模式和不规则模式。为了达到较高的准确性，ROS 使用<strong>不同的模型</strong>来预测不同模式下的负载变化。（#TODO 不进行额外的资源预留吗？）<ul>
<li>具体来说，ROS 会<strong>预测</strong>每个租户在每个<strong>可接受空间范围内</strong>的<strong>资源使用量（CPU 和内存）</strong>。</li>
</ul>
</li>
<li>为了预测租户的负载模式，我们：<ul>
<li>首先使用 K-means 算法和质量计数差异算法对负载模式进行<strong>分类</strong>。</li>
<li>然后，预测器会<strong>选择</strong>相应的预测<strong>模型</strong>，根据<strong>前一周</strong>的跟踪进行预测，并获得租户<strong>第二天</strong>的资源使用时间曲线。<ul>
<li>预测模型根据这些大租户的<strong>历史资源请求</strong>进行<strong>训练</strong>，并<strong>逐步更新</strong>，以捕捉新的模式变化。</li>
<li>对于云中的新租户，我们会在<strong>第一个月</strong>按照<strong>租户的指定</strong>预留足够的虚拟机。</li>
<li>在此期间，我们每 10 分钟收集一次资源使用数据，并训练模型参数。</li>
</ul>
</li>
</ul>
</li>
<li>对于<strong>昼夜负荷模式</strong>，采用了基于 LSTM 的三层模型来捕捉负荷随时间的变化。<ul>
<li>具体来说，该模型包含两个 LSTM 单元，末端有一个全连接（FC）层。我们为<strong>每个租户</strong>在其可接受的空间范围内<strong>提供一个唯一的</strong> LSTM 模型，LSTM 的输入是前一周的资源使用时间曲线，输出是第二天的资源使用时间曲线。</li>
</ul>
</li>
<li>对于<strong>持续负荷模式</strong>，我们采用了平均值计算、最大值计算和线性回归（LR）分析方法，分别对稳定、阶梯和斜线子类型进行分析。<ul>
<li>我们还为<strong>每个租户</strong>提供了一个独特的预测模型，用于预测该负载模式下每个租户<strong>可接受的空间范围</strong>。</li>
<li>在预测模型方面，<ul>
<li>LR 的输入和输出与 LSTM 相同；</li>
<li>平均值/最大值计算方法的输入与 LSTM 相同，我们使用输入的平均值/最大值作为第二天每个时间点的资源使用量，生成资源使用时间曲线。</li>
</ul>
</li>
</ul>
</li>
<li>具有<strong>突发和不规则负载模式</strong>的租户的资源需求很难预测。因此，对于这些负载模式，我们使用 LSTM 进行<strong>基本的资源使用预测</strong>，并依靠在线调度来快速满足计划外的资源请求。</li>
<li>对于具有昼夜和持续负载模式的<strong>可预测</strong>大型租户，实际负载预测的 <strong>R-平方值为 0.865</strong>。预测租户的负载模式只需 <strong>300 毫秒</strong>。</li>
</ul>
<h3 id="跨区域资源协调"><a href="#跨区域资源协调" class="headerlink" title="跨区域资源协调"></a>跨区域资源协调</h3><ul>
<li><p>我们基于以下两点设计协调器。</p>
<ul>
<li><ol>
<li>在特定大租户<strong>可接受的空间范围内</strong>，某些区域或虚拟机类型的<strong>资源成本较低</strong>（<a href="#%E8%B5%84%E6%BA%90%E4%BD%BF%E7%94%A8%E5%88%86%E5%B8%83%E6%83%85%E5%86%B5">资源使用分布情况节</a>）。如果 ROS 为租户预留资源，就能直接降低部署成本。</li>
</ol>
</li>
<li><ol start="2">
<li>昼夜租户之间的资源使用可能是<strong>互补的</strong>。正如<a href="#%E9%80%9A%E8%BF%87%E5%89%8A%E5%B3%B0%E6%8F%90%E9%AB%98%E8%B5%84%E6%BA%90%E9%A2%84%E7%95%99%E6%95%88%E7%8E%87%E7%9A%84%E6%BD%9C%E5%8A%9B">通过削峰提高资源预留效率的潜力节</a>所分析的，在时间和空间上都有可能通过在大型租户之间削峰来减少资源预留。</li>
</ol>
</li>
</ul>
</li>
<li><p>对于虚拟机预留，如果租户能以所需的性能和网络延迟获得虚拟机，就满足了 <strong>SLA</strong>。</p>
<ul>
<li>在我们的工作中，SLA 是通过<strong>可接受的空间范围</strong>来考虑的。</li>
<li>由于租户通常<strong>已确定了可接受的空间范围</strong>，预订超出这些范围的资源可能会导致违反 SLA。<ul>
<li>例如，在远离终端用户的区域协调实时视频服务资源可能会导致高网络延迟。某些计算密集型工作负载可以部署在多个 CPU 增强型虚拟机类型上，但部署在内存增强型虚拟机类型上会降低性能。</li>
</ul>
</li>
<li>因此，<strong>协调器</strong>会在<strong>每个可接受的空间范围内</strong>确定租户与<strong>每个资源类型</strong>的资源预留。<ul>
<li><strong>资源类型</strong>指的是<strong>某个区域</strong>内的特定<strong>虚拟机类型</strong>。</li>
</ul>
</li>
</ul>
</li>
<li><p>在公式 1 中，我们将资源协调建模为一个<strong>单目标优化问题</strong>。</p>
<ul>
<li>在优化问题中，<strong>最优目标函数</strong>被定义为找到<strong>最小的总部署成本</strong>。<ul>
<li><strong>部署成本</strong>是每种资源类型在一天内的<strong>最大资源使用量</strong>乘以其<strong>成本系数</strong>的总和（#TODO 破案了！最大资源使用量。因此会出现额外的浪费）。</li>
</ul>
</li>
<li>更具体地说，协调器的<strong>输入</strong>是预测器<strong>预测</strong>的大型租户的<strong>资源使用情况</strong>，<strong>输出</strong>是<strong>协调方案</strong>和<strong>每种资源类型的预订界限</strong>。我们提供了一个独特的模型，用于在每个可接受的空间范围内协调大型租户所需的资源。<ul>
<li>假设在一个可接受的空间范围内有 <em>m</em> 个租户，他们所需的资源可以协调到 <em>n</em> 种资源类型上。</li>
<li>我们使用矩阵 <em>Ratio</em> 来表示协调方案。在矩阵中，<em>ratioij</em> 表示 <em>i</em> 租户在第 <em>j</em> 种资源类型上的资源使用百分比。</li>
<li>在公式 1 中，<em>fi(t)</em> 是租户 <em>i</em> 的 CPU 和内存资源使用情况的加权平均资源使用时间曲线，由预测器提供，即 <em>fi(t)</em> = <em>α</em> × <em>CPUi(t)</em> + <em>β</em> × *MEMi(t)*。<ul>
<li><em>α</em> 和 <em>β</em> 分别是单位 CPU 和内存的相对成本。</li>
</ul>
</li>
<li>此外，<em>Cj</em> 代表特定资源类型 <em>j</em> 的成本系数，计算方法是区域成本系数乘以虚拟机类型的成本系数。</li>
<li>优化问题有 3 个约束条件。<ul>
<li>首先，对于每个大租户，资源比率之和必须等于 1，即满足该租户所需的资源使用量。</li>
<li>其次，每种资源的 CPU 和内存使用量不能超过其容量。</li>
</ul>
</li>
<li>通过求解优化问题，可以得到最优协调矩阵 <em>Ratio</em>。表 2 总结了公式 1 中的变量。</li>
</ul>
</li>
</ul>
</li>
<li><p>请注意，<strong>削峰</strong>体现在计算每种资源类型的<strong>最大资源使用量</strong>上（#TODO 通过“把所有用户统一考虑”实现削峰）。</p>
<ul>
<li>其他协调器会独立处理每个租户（如 Narayanan 等人），而方程 1 则会<strong>优化多个租户的预留</strong>，从而实现跨区域的空间削峰。</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/12-Table2-1.png"
                      alt="表2-被使用的变量含义"
                ><figcaption>表2-被使用的变量含义</figcaption></figure><br>（表2-被使用的变量含义）</p>
</li>
<li><p>在一个有 <strong>17 个区域</strong> 和 <strong>7 种虚拟机</strong> 类型的云上（#TODO 小规模资源），ROS 可在 <strong>2.5 分钟</strong> 内协调约 <strong>118,000</strong> 个虚拟机的预留资源。如果对租户/区域/虚拟机类型进行分组，时间会呈指数级下降。（#TODO 分组指什么？）</p>
</li>
</ul>
<h3 id="突发感知的资源调度"><a href="#突发感知的资源调度" class="headerlink" title="突发感知的资源调度"></a>突发感知的资源调度</h3><ul>
<li>即使<strong>离线预测和协调</strong>偶尔会对突发或不规则负载的租户<strong>不准确</strong>，突发感知调度也能针对不准确的资源预留<strong>修改预留边界</strong>。</li>
<li><strong>收到虚拟机请求后</strong>，ROS 会<strong>根据</strong>该租户的<strong>比率矩阵</strong>和<strong>当前资源分配情况</strong>，将请求调度到<strong>其中一种资源类型</strong>。如果调度程序发现某一资源类型的资源使用量<strong>超出了</strong>当前的资源<strong>预留约束</strong>，就会启动<strong>补偿机制</strong>来调整预留约束。</li>
<li>资源预留的<strong>调整</strong>受三条规则的限制。<ul>
<li><ol>
<li>如果当前资源类型仍<strong>有</strong>闲置资源，调度器会<strong>增加</strong>资源预留约束，直到<strong>达到</strong>当前<strong>所需</strong>的资源使用量。</li>
</ol>
</li>
<li><ol start="2">
<li>如果当前资源类型<strong>没有</strong>闲置资源，调度器<strong>在可接受的空间范围内</strong>选择<strong>成本最低</strong>、<strong>有足够闲置资源</strong>的资源类型，并提高其资源预留约束，以满足资源需求。</li>
</ol>
</li>
<li><ol start="3">
<li>如果在<strong>指定的时间</strong> <em>t</em> <strong>内</strong>，某资源类型的资源<strong>使用量</strong>低于预留值，调度器将<strong>逐步减少</strong>其预留。调度器按照提高约束的相反顺序减少预订。（#TODO 是否只对被提高的部分进行减少？相反顺序指的是什么，被提高越多的越先降低？）</li>
</ol>
</li>
</ul>
</li>
<li>由于预留资源的主要增长是由突发负载引起的，因此我们根据突发负载的<strong>最短持续时间</strong>（数十分钟）来定义 <em>t</em>（<a href="#3%E7%AA%81%E5%8F%91%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%BC%8F-bursty-usage-pattern">突发使用模式节</a>）。<ul>
<li>因此，我们将 <em>t</em> 定义为 <strong>30 分钟</strong>，以便快速感知突发负载的结束。</li>
<li>之前的一些研究表明，当负载水平在 30 分钟内低于预定值时，负载可被视为下降。</li>
</ul>
</li>
<li>我们的突发感知资源调度功能与<strong>自动缩放类似</strong>。不过，与当前的自动缩放策略（如 K8S）相比，ROS 为不同租户<strong>引入了可接受的空间范围</strong>（区域和虚拟机类型），从而以<strong>最低成本</strong>实现自动缩放。</li>
</ul>
<h3 id="对-ROS-的评估"><a href="#对-ROS-的评估" class="headerlink" title="对 ROS 的评估"></a>对 ROS 的评估</h3><p><strong>【数据集】</strong></p>
<ul>
<li>我们使用开源的 <strong>4 个月</strong>跟踪数据集对 ROS 进行评估。<ul>
<li>我们使用<strong>第一个月</strong>的跟踪数据来<strong>训练</strong>预测器，并使用<strong>其余 3 个月</strong>的跟踪数据来<strong>评估</strong> ROS。</li>
</ul>
</li>
<li>如<a href="#1-%E4%BA%91%E5%8C%BA%E5%9F%9F%E5%92%8C%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83">云区域和数据中心节</a>所述，<ul>
<li>根据地理位置将区域划分为<strong>三个区域集</strong>（分别为<em>Region Set 1</em>、<em>Region Set 2</em> 和<em>Region Set 3</em>）。三个区域集分别有 <strong>7、2、8 个区域</strong>。</li>
<li>在与大租户协商后，我们提取了 <strong>7 种典型的虚拟机类型</strong>（v1–v7）。大租户的虚拟机请求可以在它们之间安全<strong>切换</strong>。从虚拟机类型来看，（v1–v7）集合被视为<strong>可接受的空间范围</strong>。</li>
</ul>
</li>
</ul>
<p><strong>【实验一：降低部署成本】</strong></p>
<ul>
<li>我们首先将 <strong>ROS</strong> 与大多数云提供商<strong>目前使用的资源预留策略</strong>（即根据<strong>租户指定</strong>的数量和位置预留资源）进行了比较。</li>
<li>我们还将 <strong>ROS</strong> 与<strong>最先进的基准</strong>进行了比较，后者是一种<strong>地理分布式容量规划策略</strong>。<ul>
<li>我们将其<strong>成本最小化模型</strong>应用到我们的方案中，该模型能意识到数据中心的不同成本系数，但能为每个租户<strong>独立协调资源</strong>。在以下实验中，我们将此基线命名为 <strong>Base</strong>。</li>
</ul>
</li>
</ul>
<p><strong>【实验二：协调器有效性】</strong></p>
<ul>
<li>此外，我们还进行了另一项实验，将 <strong>ROS</strong> 与<strong>不带协调器的 ROS 变体（ROS-wo）</strong>进行比较，以探索协调器的有效性。<ul>
<li>ROS-wo 在相应的区域和虚拟机类型上为大租户预留了相当于其每天<strong>最大所需资源</strong>的资源。</li>
<li>在本实验中，我们使用跟踪数据集中的<strong>真实请求使用结果来替代预测结果</strong>，作为 ROS 和 ROS-wo 的输入，以便只关注协调器的有效性。</li>
</ul>
</li>
</ul>
<h4 id="1）降低部署成本"><a href="#1）降低部署成本" class="headerlink" title="1）降低部署成本"></a>1）降低部署成本</h4><p><strong>【证明预测器+协调预留/调度器有效：预测准确+削峰+成本优化】</strong></p>
<ul>
<li>与租户指定的预订相比，ROS 的部署成本降低<ul>
<li>图 18（a）显示了 <strong>ROS</strong> 与 <strong>租户指定策略</strong> 相比在三个区域集每天的归一化<strong>部署成本</strong>。<ul>
<li>从图中可以看出，ROS <strong>降低</strong>了<strong>所有日期</strong>的部署成本。（归一化后值都小于 1）</li>
<li>如图 19（a）中的蓝色条所示，与<strong>租户指定策略</strong>相比，ROS 可以将三个区域集和总的部署成本分别降低 74.9%、78.3%、75.0% 和 75.4%。</li>
</ul>
</li>
<li>图 18（b）显示了 <strong>ROS</strong> 与 <strong>租户指定策略</strong> 相比的归一化<strong>预留资源</strong>。<ul>
<li>我们可以观察到三个区域集每天的<strong>预留资源</strong>都有所<strong>减少</strong>。</li>
<li>如图 19（b）中的蓝色条所示，与特定租户策略相比，三个区域集的预留资源和总资源分别减少了 63.5%、66.2%、47.7% 和 60.1%。</li>
</ul>
</li>
<li>与租户指定的预订相比，ROS 的部署成本降低有三个<strong>原因</strong>。<ul>
<li>首先，ROS 根据<strong>预测</strong>的租户资源使用情况储备资源，而<strong>不是租户指定</strong>的固定资源储备量。</li>
<li>其次，ROS 会将租户预留的不同模式（如<strong>峰值相互错开</strong>）的资源协调到同一区域或同一虚拟机类型中，从而进一步降低预留约束。</li>
<li>第三，ROS 倾向于将租户的预留资源协调到<strong>低成本</strong>区域或虚拟机类型。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>【证明协调预留器有效：削峰】</strong></p>
<ul>
<li>此外，如图 19（a）和图 19（b）所示，<strong>ROS</strong> 还能比 <strong>Base</strong> <strong>降低部署成本和预留资源</strong>。<ul>
<li>据统计，ROS 可以将总部署成本和预留资源分别降低 24.7% 和 12.2%。</li>
<li><strong>Base</strong>系统<strong>表现不佳</strong>的原因是，它对每个租户的资源进行了<strong>独立协调</strong>。这就导致缺乏时间和空间潜力，无法通过在租户之间<strong>削峰</strong>来减少预留资源。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/13-Figure18-1.png"
                      alt="图18-根据三个区域组每天的租户特定策略归一化的ROS部署成本和预留资源"
                ><figcaption>图18-根据三个区域组每天的租户特定策略归一化的ROS部署成本和预留资源</figcaption></figure><br>（图18-根据三个区域组每天的租户特定策略归一化的ROS部署成本和预留资源）</p>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/13-Figure19-1.png"
                      alt="图19-根据租户指定的策略，将ROS和Base的总体部署成本和预留资源归一化"
                ><figcaption>图19-根据租户指定的策略，将ROS和Base的总体部署成本和预留资源归一化</figcaption></figure><br>（图19-根据租户指定的策略，将ROS和Base的总体部署成本和预留资源归一化）</p>
<h4 id="2）资源协调器的有效性"><a href="#2）资源协调器的有效性" class="headerlink" title="2）资源协调器的有效性"></a>2）资源协调器的有效性</h4><p><strong>【证明协调预留器有效：削峰】</strong></p>
<ul>
<li>图 20（a）显示了 <strong>ROS</strong> 与 <strong>ROS-wo</strong> 的<strong>总体部署成本</strong>归一化情况。<ul>
<li>在协调器的作用下，我们可以发现三个区域集的部署成本和总部署成本分别平均降低了 37.7%、44.9%、57.0% 和 45.2%。</li>
</ul>
</li>
<li>图 20（b）显示了 <strong>ROS</strong> 与 <strong>ROS-wo</strong> 的<strong>总体预留资源</strong>归一化情况。<ul>
<li>我们可以看到，三个区域集和总的预订资源平均分别减少了 12.0%、13.5%、8.6% 和 11.2%。</li>
<li>我们的协调器会将大型租户所需的资源<strong>错峰分配</strong>到相同的区域或虚拟机类型中，从而进一步减少资源预留。</li>
</ul>
</li>
</ul>
<p><strong>【证明协调调度器有效：成本优化】</strong></p>
<ul>
<li>图 21 显示了三个区域组中不同资源类型的<strong>资源分配比例</strong>。（#TODO 为什么比例差异这么大？）<ul>
<li><strong>一种资源类型</strong>代表<strong>一个区域的一种虚拟机类型</strong>。</li>
<li>标签代表三个区域集的所有<strong>资源成本系数</strong>，由区域成本系数和虚拟机类型成本系数的乘积计算得出。<ul>
<li>由于某些资源类型的成本系数相同，我们找出所有三个区域集的不同值，并计算每个区域集不同成本系数的资源分配百分比。</li>
</ul>
</li>
<li>可以看出，ROS 将大部分资源分配给了<strong>成本系数较低的资源类型</strong>，而 ROS-wo 则将部分或大量资源分配给了<strong>成本系数较高的资源类型</strong>。协调器倾向于向低成本区域或虚拟机类型预留资源，这可以直接降低整体资源预留成本。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/14-Figure20-1.png"
                      alt="图20-相对于ROS-wo，ROS的总体部署和预留资源归一化"
                ><figcaption>图20-相对于ROS-wo，ROS的总体部署和预留资源归一化</figcaption></figure><br>（图20-相对于ROS-wo，ROS的总体部署和预留资源归一化）</p>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://figures.semanticscholar.org/be6685bc478a5e346fff422bc4228f54c41105d0/14-Figure21-1.png"
                      alt="图21-3个区域组中不同区域的不同虚拟机类型的资源分布情况"
                ><figcaption>图21-3个区域组中不同区域的不同虚拟机类型的资源分布情况</figcaption></figure><br>（图21-3个区域组中不同区域的不同虚拟机类型的资源分布情况）</p>
<h3 id="经验教训"><a href="#经验教训" class="headerlink" title="经验教训"></a>经验教训</h3><ul>
<li>通过分析我们生产的地理分布式云中的资源请求轨迹，我们总结出了几条经验教训：<ul>
<li>1）<strong>租户</strong>，即使是顶级租户，也<strong>不详细了解自己的资源需求</strong>。<ul>
<li>他们经常告诉我们在靠近最终用户的区域预留足够的常用类型的虚拟机，而<strong>不尝试性能相似、价格更低</strong>的其他虚拟机类型或其他区域。</li>
<li>向他们<strong>推荐多种适用的</strong>虚拟机类型和多个区域可能会<strong>帮助租户降低成本</strong>，并帮助我们提高整个地理分布云的利用率。</li>
</ul>
</li>
<li>2）最好<strong>从云提供商方面考虑</strong>资源预留。<ul>
<li>考虑到其他租户的预留，<strong>一个租户</strong>最便宜的<strong>资源预留策略</strong>可能<strong>不再是最优</strong>的。</li>
<li>在这种情况下，为了优化整个资源和成本效率，最好由云提供商进行预留，因为租户不知道其他租户的潜在资源使用情况。</li>
</ul>
</li>
<li>3）可以在<strong>低成本的地方建立数据中心</strong>，并通过<strong>自适应虚拟机协调</strong>提高利用率。<ul>
<li>我们对 ROS 的实际使用表明，这种新的资源预留策略没有任何问题。</li>
<li>我们可以安全地在成本较低的地方建立一些数据中心，并将一些虚拟机从”热门”的昂贵数据中心卸载到成本较低的数据中心。这样，整个云的运行效率就能大大提高。</li>
</ul>
</li>
<li>4）通过<strong>仔细选择</strong>所提供的<strong>虚拟机类型</strong>，有机会进一步优化资源利用率。<ul>
<li>通过统计，我们发现<strong>不同类型</strong>的虚拟机有不同的预订率。</li>
<li>根据主要租户的工作负载调整类型，可以进一步提高资源利用率和效率。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-思考"><a href="#x1f9e0-思考" class="headerlink" title="&#x1f9e0;思考"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">&#x1f9e0;</span>思考</h2><ol>
<li>本文简化了“可接受范围”，对于复杂的“亲和组约束”还需要设计更高效的方案。</li>
<li>没有验证实时调度器的有效性，忽略了 SLA 不被满足时的违约成本。</li>
<li>没有提及实验是基于什么做的，看意思应该是模拟器。</li>
</ol>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="&#x1f9e0;疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">&#x1f9e0;</span>疑问</h2><ol>
<li>为什么面向数据中心内的任务调度架构不能应用于面向跨数据中心的调度？</li>
<li>本文最终采用的架构如何？</li>
<li>将不同用户预留编排在同一区域，是否意味着调整了其预留？也就是当用户都使用所有预留资源时（极端情况），可能出现资源不足的问题？这种情况如何处理？</li>
<li>如果都在白天峰值，削峰的意义有多大？具体如何削峰才能不影响租户？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://dl.acm.org/doi/abs/10.1145/3542929.3563490" >[1] Jiuchen Shi, Kaihua Fu, Quan Chen, Changpeng Yang, Pengfei Huang, Mosong Zhou, Jieru Zhao, Chen Chen, and Minyi Guo. 2022. Characterizing and orchestrating VM reservation in geo-distributed clouds to improve the resource efficiency. In Proceedings of the 13th Symposium on Cloud Computing (SoCC ‘22). Association for Computing Machinery, New York, NY, USA, 94–109. https://doi.org/10.1145/3542929.3563490<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度</tag>
        <tag>大规模</tag>
        <tag>跨地域</tag>
        <tag>资源调度</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】略读笔记50-前沿-微服务容器群体关系分析及预测</title>
    <url>/2024/07/11/literature/literatureNotes50/</url>
    <content><![CDATA[<h1 id="x1f4d6-《GROUP-An-End-to-end-Multi-step-ahead-Workload-Prediction-Approach-Focusing-on-Workload-Group-Behavior》"><a href="#x1f4d6-《GROUP-An-End-to-end-Multi-step-ahead-Workload-Prediction-Approach-Focusing-on-Workload-Group-Behavior》" class="headerlink" title="📖《GROUP: An End-to-end Multi-step-ahead Workload Prediction Approach Focusing on Workload Group Behavior》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《GROUP: An End-to-end Multi-step-ahead Workload Prediction Approach Focusing on Workload Group Behavior》</h1><p>2023 年发表于 CCF-A 类会议 WWW。</p>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><ul>
<li>准确预测工作负载可帮助网络服务提供商实现对应用程序的主动运行时管理，并确保服务质量和成本效益。<ul>
<li>云原生已成为现代网络应用的一种重要设计范式，云原生应用大多以容器化微服务架构的形式产生。微服务架构旨在通过将复杂的应用程序分解为具有单一功能的服务来降低应用程序的耦合度。</li>
</ul>
</li>
<li>对于云原生应用来说，多个容器协同处理用户请求，使得每个容器的工作负载变化都受到工作负载组行为的影响。<ul>
<li>容器是一种内核级虚拟化技术，具有更高的性能和效率。因此，整个应用程序通过多个容器的<strong>协同交互</strong>为用户请求提供服务，这使得容器的工作负载变化不再仅仅是每个容器的个体行为，而是多个容器的<strong>群体行为</strong>。</li>
</ul>
</li>
</ul>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><ul>
<li>然而，现有方法主要分析<strong>每个容器的个体变化</strong>，没有明确模拟容器的工作负载组演化，导致结果不理想。<ul>
<li>现有的大多数工作量预测方法都是对每个容器的工作量变化进行独立建模和预测。由于每个容器的工作负载数据都是以时间序列的形式记录的，因此这些方法认为每个容器的未来工作负载变化<strong>只与其自身</strong>的历史工作负载数据相关，这源于时间序列预测问题的自然时间相关性。然而，云原生应用是一个分布式系统，这表明多个容器共同处理用户请求。因此，关注预测容器的单个行为只能获得<strong>次优结果</strong>。</li>
<li>此外，由于云环境是动态的，历史工作负载数据中存在大量数据噪声，这使得这些方法的准确性对<strong>数据噪声</strong>很敏感。</li>
</ul>
</li>
<li>也有一些方法考虑了工作负载变化的<strong>群体行为</strong>。<ul>
<li>Shaw 等人发现了虚拟机（VM）之间的工作负载变化相关性，但该方法仅适用于考虑资源互补性的共址部署。</li>
<li>Ruta 等人提出了一种基于 BiLSTM 的工作负载预测模型，该模型将所有设备的工作负载序列作为输入，但没有考虑设备间的工作负载变化是否相关。</li>
<li>Banerjee 等人和 Ding 等人则专注于通过获取原始数据上高度相似的工作负载序列作为输入来生成回归预测模型。</li>
<li>但是，对于云原生应用来说，<ul>
<li>首先，不同容器的工作负载变化可能存在两种关系：<strong>相似性</strong>（重复的业务功能运行在复制的容器上）和<strong>相关性</strong>（不同的业务功能运行在属于同一服务调用链的不同容器上），因此上述方法会丢失有价值的数据；</li>
<li>其次，上述方法通过将特征数据输入简单的回归方法，隐含地模拟了工作负载组行为的演变。但工作负载组行为的演变不是单阶段的，而是<strong>多阶段相关</strong>的。隐式方法只能提取部分信息，不足以描述工作负载群行为演变的复杂性。</li>
</ul>
</li>
</ul>
</li>
<li>总之，现有方法仍存在一些重大缺陷，包括缺乏对工作负载组行为及其演变的明确建模，缺乏评估容器之间相关性的有效方法来表示工作负载组行为，以及缺乏系统地利用工作负载组行为进行预测。因此，现有方法对于云原生应用的工作负载预测并不可靠。</li>
</ul>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>要建立一个明确的端到端工作量预测模型，需要解决两个具有挑战性的问题。<ul>
<li>1）根据云原生特性，如何构建表达工作负载群行为的<strong>输入数据</strong>并为预测模型服务？</li>
<li>2）基于表达工作负载群体行为的输入数据，如何设计用于描述工作负载群行为演化关系的<strong>预测模型</strong>，以提供精确的多步超前预测结果？</li>
</ul>
</li>
<li>因此，我们提出了一种工作负载预测方法–GROUP，它实现了工作负载预测重点从个体到群体的转移，工作负载群体行为表示从数据相似性到数据相关性的转移，工作负载群体行为演化从隐式建模到显式建模的转移。<ul>
<li>1）我们从<strong>内部、时间、多特征和多尺度演化</strong>等多个角度对工作负载组行为及其演化进行了系统建模。</li>
<li>2）我们提出了一种容器<strong>相关性计算算法</strong>，该算法考虑了容器的静态和动态信息来表示工作负载组行为。</li>
<li>3）我们提出了一种端到端多步骤超前工作负载<strong>预测模型</strong>，明确描述了工作负载组行为演变与每个容器工作负载变化之间的复杂关系。</li>
</ul>
</li>
</ul>
<h2 id="x1f4ca-效果"><a href="#x1f4ca-效果" class="headerlink" title="📊效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>效果</h2><ul>
<li>公共数据集上的实验证明了 GROUP 的优势。就 MAE 和 RMSE 指标而言，与其他先进方法相比，GROUP 的平均值分别从 2.40% 提高到 24.89%，从 2.39% 提高到 23.50%。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>现有研究核心不足是什么？</li>
</ol>
<ul>
<li>没有考虑群体性、或仅粗暴地隐式学习群体性，没有准确地考虑（显式建模）多种群体关系（“相似性”和“相关性”）。</li>
<li>没有细致讨论到底存在哪些群体关系。</li>
</ul>
<ol start="2">
<li>本文核心贡献：细致讨论了可能存在的群体关系，并设计了模型进行解析。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/abs/10.1145/3543507.3583460">[1] Binbin Feng and Zhijun Ding. 2023. GROUP: An End-to-end Multi-step-ahead Workload Prediction Approach Focusing on Workload Group Behavior. In Proceedings of the ACM Web Conference 2023 (WWW ‘23). Association for Computing Machinery, New York, NY, USA, 3098–3108. https://doi.org/10.1145/3543507.3583460<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】精读笔记2-前沿-用RL进行VM重调度以整理碎片VMR2L-A-整体逻辑精解</title>
    <url>/2025/05/11/literature/literatureNotesIntensive2/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Towards-VM-Rescheduling-Optimization-Through-Deep-Reinforcement-Learning》"><a href="#x1f4d6-《Towards-VM-Rescheduling-Optimization-Through-Deep-Reinforcement-Learning》" class="headerlink" title="📖《Towards VM Rescheduling Optimization Through Deep Reinforcement Learning》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Towards VM Rescheduling Optimization Through Deep Reinforcement Learning》</h1><p>2025 年 UC Merced大学、 UC Berkeley大学、字节跳动团队 发表于 CCF-A 类会议 EuroSys。</p>
<p>系列博客：</p>
<ol>
<li><a href="/2025/04/28/literature/literatureNotes82/" title="VMR2L-初步略读笔记">VMR2L-初步略读笔记</a></li>
<li><a href="/2025/05/11/literature/literatureNotesIntensive2/" title="VMR2L-整体逻辑精解笔记">VMR2L-整体逻辑精解笔记</a></li>
<li><a href="/2025/05/14/literature/literatureNotesIntensive3/" title="VMR2L-相关工作发展脉络梳理笔记">VMR2L-相关工作发展脉络梳理笔记</a>

</li>
</ol>
<p>此外，本篇也已发布于我们团队整理的<a class="link" href="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/tree/main">Awesome Cloud<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>。这是一个关于云计算领域中最优质的论文、工具和信息的精选列表，适合开发者和研究人员参考。欢迎大家前来点赞、star和交流。</p>
<hr>
<h2 id="1-为什么"><a href="#1-为什么" class="headerlink" title="1. 为什么 "></a>1. 为什么 <a id="为什么"></a></h2><p>业界数据中心需要管理大量资源，尤其需要应对大量资源碎片。</p>
<ul>
<li><p>业界存在大规模虚拟机管理需求，具体而言，所涉及对象包括：</p>
<ul>
<li>资源需求：<strong>最终用户（End-users）</strong>需要大量计算资源。</li>
<li>资源供应：<strong>云服务提供商（Cloud Service Providers）</strong>采用资源虚拟化来最大化硬件利用率，将资源分配给最终用户。业界数据中心通常组织成<strong>集群（Cluster）</strong>，每个集群都有数百种<strong>物理机器（PMs）</strong>，每个PM可以托管多个独立运行的<strong>虚拟机（VMs）</strong>。</li>
</ul>
</li>
<li><p>在此前提下，出现大量资源碎片现象。</p>
<ul>
<li>如果PM已经托管了多个VM，并且PM上的其余资源无法满足额外的VM请求，则不能使用剩余的资源称为碎片（fragments）。</li>
<li>由于VM的不断创建和释放，许多小型资源碎片散布在PMs之间。导致了资源的严重浪费。</li>
<li>需要通过重调度等机制应对资源碎片问题。</li>
</ul>
</li>
</ul>
<h3 id="1-1-需求"><a href="#1-1-需求" class="headerlink" title="1.1 需求 "></a>1.1 需求 <a id="需求"></a></h3><p>解决资源碎片的方案：VM重调度。</p>
<p>本文论证了 VM 重调度在业界实践的可行性，具体包括：</p>
<ul>
<li>可行性：前提-请求量有低谷<ul>
<li>VMR 可以在非高峰时段的清晨执行，如图 1 中的红点所示，清晨的 VM 变动较少。这样就有更宽松的时间，可以使用先进算法。</li>
</ul>
</li>
<li>可行性：保底-重调度失败影响小<ul>
<li>如果重新调度操作失败，虚拟机只需停留在原来的 PM 上，不会影响最终用户。</li>
</ul>
</li>
<li>可行性：过程-重调度耗时短<ul>
<li>VMR 可通过实时迁移高效执行，确保停机时间最短。</li>
<li>由于大多数数据中心在管理虚拟机时都将计算与存储分离（即使用云磁盘），因此只需传输内存。具体来说，<ul>
<li>初始复制：我们首先将虚拟机的内存状态从源 PM 复制到目标 PM，同时继续在源 PM 上运行。</li>
<li>后续同步：在此过程中，虚拟机内存的变化（称为 “脏页”）会被跟踪并逐步重新复制，直到剩余的变化很小为止。此时，虚拟机会短暂暂停，进行最终同步。</li>
</ul>
</li>
<li>由于现代数据中心使用高带宽网络进行内部文件传输，因此 VMR 过程产生的开销较低。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-17-1.png?raw=true" alt="图 1"><figcaption>图 1</figcaption></figure></li>
</ul>
</li>
</ul>
<h3 id="1-2-研究现状"><a href="#1-2-研究现状" class="headerlink" title="1.2 研究现状 "></a>1.2 研究现状 <a id="研究现状"></a></h3><h4 id="研究综述"><a href="#研究综述" class="headerlink" title="研究综述"></a>研究综述</h4><p>a. 转化为装箱问题的最优化方法：</p>
<ul>
<li>现状：基于成熟的MIP求解器进行求解加速[48,66]，无法满足严格的延迟要求（5s）。</li>
<li>问题：数据中心中VM和PM的总数很容易达到数千个或更多[63]，远远超过通常不超过几百个对象的装箱问题的典型规模[41,67]。</li>
</ul>
<p>b. 转化为装箱问题的启发式方法：</p>
<ul>
<li>现状：依赖人为设计的启发式方法[27]，导致次优解决方案。</li>
<li>问题：<ul>
<li>首先，VM重调度问题涉及动态调整VM对PM的初始分配，需要考虑已有的VM关系，现有的装箱解决方案通常不考虑这些关系。</li>
<li>其次，重新平衡已经装入箱子中的物品在其他装箱应用的背景下很少受到关注。</li>
</ul>
</li>
</ul>
<p>c. 面向优化问题的强化学习方法：</p>
<ul>
<li>现状：RL被广泛用于选择分支变量等场景[23,25,26]，也可以应用于MIP问题下启发式方法的质量优化[9,58]。</li>
<li>问题：但都只面向传统简单场景，难以在VM重调度问题下获得较好训练结果。</li>
</ul>
<h4 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h4><ul>
<li>前两类研究中，存在复杂性过高或求解质量差问题。</li>
<li>最后一类研究中，存在泛化性和复杂性表现较差问题。</li>
</ul>
<h3 id="1-3-研究挑战"><a href="#1-3-研究挑战" class="headerlink" title="1.3 研究挑战 "></a>1.3 研究挑战 <a id="研究挑战"></a></h3><p>【挑战一】：效率与质量兼顾——在有限的时间内（5s）实现较优的调度效果</p>
<ul>
<li>与大多数组合优化任务不同，VM重调度算法的计算时间显著影响其性能，因为在此期间VM状态发生了动态变化。这要求算法具有极低的计算时间，导致现有方法的扩展性很差。</li>
</ul>
<p>【挑战二】：RL效率——求解缓慢，动作空间过大</p>
<ul>
<li>共<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></svg></mjx-container>个VM、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.378ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 1051 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g></g></g></svg></mjx-container>个PM时，同时重调度<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="5.928ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 2620 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mi" transform="translate(1051,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mi" transform="translate(1939,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g></g></svg></mjx-container>个VM，动作空间大小为 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="14.013ex" height="2.738ex" role="img" focusable="false" viewBox="0 -960 6193.6 1210"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"></path></g><g data-mml-node="mo" transform="translate(763,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msup" transform="translate(1152,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mi" transform="translate(1440,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mo" transform="translate(2328,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(2750,477.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mi" transform="translate(1051,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mi" transform="translate(1939,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5804.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container> 。</li>
<li>当RL代理选择将VM从其源PM重新调度到目标PM时存在复杂约束，导致计算动作惩罚的掩码操作缓慢。如：<ul>
<li>PM必须有足够的可用CPU和内存来托管VM。</li>
<li>在实际场景中为确保服务稳定性，应用程序可能要求某些VM跨不同PM托管，需要反亲和性约束。</li>
</ul>
</li>
</ul>
<p>【挑战三】：RL质量——表征与收敛困难，需要大量训练数据</p>
<ul>
<li>为了有效重调度，必须对状态观察进行表征，其中包括每个单独的PM和VM的特征以及它们的从属关系特征。<ul>
<li>即使在同一个集群中，VM的数量也可能差异很大。这意味着每个时间步的特征大小也是高度动态的。</li>
<li>为了对这些特征进行编码，一种选择是将所有VM和PM的特征连接成一个长向量。然而，这种方法无法处理任意数量的VM，因为神经网络通常需要固定大小的输入，并且还需要具有许多难以训练的参数的模型。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="2-做什么"><a href="#2-做什么" class="headerlink" title="2. 做什么 "></a>2. 做什么 <a id="做什么"></a></h2><h3 id="2-1-创新点"><a href="#2-1-创新点" class="headerlink" title="2.1 创新点 "></a>2.1 创新点 <a id="创新点"></a></h3><p>【挑战一】：效率与质量兼顾——在有限的时间内（5s）实现较优的调度效果 -&gt; 【创新点 1】：转化为RL适用的问题表述，从而便于使用 RL 解决</p>
<p>【挑战二】：RL效率——求解缓慢，动作空间过大 -&gt; 【创新点 2】：两阶段RL求解框架</p>
<p>【挑战三】：RL质量——表征与收敛困难，需要大量训练数据 -&gt; 【创新点 3】：大型数据中心&amp;VMs特征提取模块</p>
<h3 id="2-2-总体框架"><a href="#2-2-总体框架" class="headerlink" title="2.2 总体框架 "></a>2.2 总体框架 <a id="总体框架"></a></h3><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-17-2.png?raw=true" alt="图 2"><figcaption>图 2</figcaption></figure></p>
<hr>
<h2 id="3-做的效果"><a href="#3-做的效果" class="headerlink" title="3. 做的效果 "></a>3. 做的效果 <a id="做的效果"></a></h2><h3 id="3-1-实验设置"><a href="#3-1-实验设置" class="headerlink" title="3.1 实验设置 "></a>3.1 实验设置 <a id="实验设置"></a></h3><h4 id="对比方法"><a href="#对比方法" class="headerlink" title="对比方法"></a>对比方法</h4><ul>
<li>【最优化】<ul>
<li>MIP最优化算法</li>
</ul>
</li>
<li>【启发式】<ul>
<li>基于过滤的启发式算法（HA）</li>
<li>向量装箱问题（𝛼 -VBPP）：将装箱调度问题的经典解决方法VBPP[49]，推广到重调度问题。</li>
<li>分区优化问题（POP）[47]：将问题随机拆分为子问题（每个子问题包含VM和PM的子集），对每个子问题应用MIP求解器，使能够满足五秒的限制。</li>
<li>蒙特卡洛树搜索（MCTS）[67]：使用DDTS[67]来修剪搜索空间，在推理时间内多次搜索。</li>
</ul>
</li>
<li>【RL】<ul>
<li>Decima[44]：使用图神经网络对VM和PM信息进行编码，分解为二阶段动作并使用深度RL进行训练。</li>
<li>NeuPlan[66]：在第一阶段以图作为输入接收，并生成前几个VM迁移以修剪搜索空间。在第二阶段，使用MIP求解器求解剩余MNL（待迁移数量）。</li>
</ul>
</li>
</ul>
<h4 id="实验内容（非常丰富）"><a href="#实验内容（非常丰富）" class="headerlink" title="实验内容（非常丰富）"></a>实验内容（非常丰富）</h4><ul>
<li>【整体实验】本方法与现有最先进算法的差距（§5.2）</li>
<li>【消融实验】每个组件具体能够提高多少效率&amp;质量（§5.3）</li>
<li>【消融实验】两阶段框架如何适应不同的约束：（§5.4）<ul>
<li>i）对原始Medium数据集的约束</li>
<li>ii）多维资源约束</li>
<li>iii）服务亲和性约束？</li>
</ul>
</li>
<li>【扩展性】VMR2L能否优化：（§5.5）<ul>
<li>i）除碎片率FR以外的目标</li>
<li>ii）定义了多种资源类型的混合目标</li>
</ul>
</li>
<li>【扩展性】如何推广到：（§5.6）<ul>
<li>i）不同于训练数据分布的工作负载</li>
<li>ii）在推理时使用不同的MNL（重调度数量）</li>
<li>iii）更多PM和VM</li>
<li>iv）不同的集群、不同工作负载</li>
<li>v）具有不同MNL的不同工作负载？</li>
</ul>
</li>
<li>【扩展性】学习更大的集群更困难吗？（§5.7）</li>
<li>【核心亮点】直觉上的改进来自哪里？（§5.8）</li>
</ul>
<p>可以看出实验内容的丰富性是这篇论文的一大优点，本次暂不详细分析，下次有机会再结合具体研究内容展开介绍。</p>
<h3 id="3-2-实验结果"><a href="#3-2-实验结果" class="headerlink" title="3.2 实验结果 "></a>3.2 实验结果 <a id="实验结果"></a></h3><h4 id="数据集产出"><a href="#数据集产出" class="headerlink" title="数据集产出"></a>数据集产出</h4><ul>
<li>从真实的行业规模数据中心收集两个数据集：<ul>
<li>一个包含多达2089个虚拟机和280个PMs的中等数据集；</li>
<li>一个包含多达4546个虚拟机和1176个PMs的大型数据集。</li>
</ul>
</li>
<li>每个数据集包含4400个映射，它们表示在不同时间点VM到PM的分配。</li>
<li>为了在确保商业运营机密性和避免潜在的训练/测试泄漏的同时发布这些数据集，我们通过随机删除一些现有虚拟机并将虚拟机重新部署到它们可以适应的任何PM来匿名化每个映射。</li>
<li>在实验中，本文将4400个映射分成4000个用于训练，200个用于验证，200个用于测试。</li>
<li>本文设计了一个遵循OpenAI Gym环境[11]的模拟器，允许我们离线训练，模拟器直接支持数据集格式。</li>
</ul>
<blockquote>
<p>据我们所知，这些是基于真实跟踪进行VM重新安排的最大数据集，对社区非常有用。</p>
</blockquote>
<h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><ul>
<li>暂不赘述，感兴趣的同学可以自行精读论文。</li>
</ul>
<hr>
<h2 id="4-展望"><a href="#4-展望" class="headerlink" title="4. 展望 "></a>4. 展望 <a id="展望"></a></h2><h3 id="4-1-未来方向"><a href="#4-1-未来方向" class="headerlink" title="4.1 未来方向 "></a>4.1 未来方向 <a id="未来方向"></a></h3><ul>
<li>总结一：可变数量表征 应用于算力网络场景<ul>
<li>面向具有复杂拓扑的请求时，同样存在“可变数量表征”难题以及“拓扑矩阵稀疏”难题。</li>
<li>需要探究如何用少量信息表征最重要的内容，并解决数量可变问题。</li>
</ul>
</li>
<li>总结二：性能干扰场景研究<ul>
<li>数据中心管理的一个挑战是由嘈杂的邻居（Noisy Neighbors）引起的性能干扰，这些邻居是大量占用共享资源的虚拟机，导致同一PM上的其他VM性能降级。</li>
<li>这种情况下也会需要重调度以避免性能降级，但需研究何种VM共置会产生性能干扰。</li>
</ul>
</li>
</ul>
<h3 id="4-2-EuroSys论文风格"><a href="#4-2-EuroSys论文风格" class="headerlink" title="4.2 EuroSys论文风格 "></a>4.2 EuroSys论文风格 <a id="EuroSys论文风格"></a></h3><ul>
<li><p>总结一：不重视现状&amp;挑战&amp;创新总结</p>
<ul>
<li>关于现状不足和研究挑战，在引言仅提及“最优化方法效率低+启发式方法质量差”，完全没有提及使用RL时会存在什么困难。实际存在较多挑战，但在方法设计部分才零零散散提出。</li>
<li>显得创新性很弱，仅从摘要引言看起来“平平无奇”。阅读挑战大，需自行花大量时间总结。</li>
<li>（仅代表个人意见，如有其他意见欢迎指教！）</li>
</ul>
</li>
<li><p>总结二：撰写风格偏工程</p>
<ul>
<li>在本文引言部分，花费了大量篇幅介绍调度、重调度相关的工程性实践细节。</li>
<li>做了非常丰富的实验和数据分析（7/16页，8个小节），提供了开源数据集。</li>
</ul>
</li>
<li><p>本文引言中囊括了丰富的工程性实践细节！</p>
<ul>
<li>任务：存在两类典型任务<ul>
<li>重调度主要应用于使用硬件虚拟化的VM集群，这些VM提供强大的隔离性并具有高启动成本，使其适用于长时间运行的工作负载，例如开发机器[46]。<ul>
<li>较小的VM（例如代理服务器或例行监控/测试）很容易使用碎片化资源创建，几乎没有供应中断的风险。</li>
<li>相反，许多直接面向消费者的高优先级任务需要中大型虚拟机。因此，我们的研究重点关注16核碎片率，以满足ByteDance的运营需求，其中16核是开发机器的默认VM类型。</li>
</ul>
</li>
<li>对于其他短期任务，如CI/CD或CronJob，重调度是不必要的。它们通过K8s在单独的集群中进行管理，通过操作系统级虚拟化提供快速启动[36]。</li>
</ul>
</li>
<li>资源：通常在集群内少量迁移<ul>
<li>为了系统稳定性，重调度通常仅限于同一集群。一个集群通常涉及不超过几百个PM，因为<ul>
<li>它允许将专用资源分配给不同的用户组，其中特定配置可以更好地优化；</li>
<li>每个集群可以独立监控和管理，允许一个集群升级而不影响其他集群[1]。</li>
</ul>
</li>
<li>设置迁移数量限制（MNL）以控制要迁移的VM数量，通常选择为所有VM的2~3%。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="4-3-论文创新性思考"><a href="#4-3-论文创新性思考" class="headerlink" title="4.3 论文创新性思考 "></a>4.3 论文创新性思考 <a id="论文创新性思考"></a></h3><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Tongji-Large-Scale-Research-Group/Awesome-Cloud/blob/main/images/issue-17-3.png?raw=true" alt="图 3"><figcaption>图 3</figcaption></figure></p>
<ul>
<li><p>联系最近看到一片篇个人认为非常有意思的<a class="link" href="https://github.com/zibuyu/research_tao/blob/master/03_finding_idea.md">文章<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>，作以下总结：</p>
</li>
<li><p>总结一：不确定性→确定性</p>
<ul>
<li>一个想法“新不新”，本质上就是“是否从不确定走向了确定”。</li>
<li>一个开放问题有无数种答案，验证了其中一种，就是推动了确定性，也就是新。</li>
</ul>
</li>
<li><p>总结二：方法新 or 结论新</p>
<ul>
<li><strong>方法新</strong>：是高校主流的（传统的）“新”，重在理论，体现在能否找到一个“新问题”、能否提出一个“新方法”。</li>
<li><strong>结论新</strong>：重在实践，体现在能否通过实践操作得到“新发现”、获得“新结果”。</li>
<li>不必拘泥于前者，后者也很重要。二者相辅相成。</li>
</ul>
</li>
<li><p>总结三：两种创新路线</p>
<ul>
<li>dh 同学（初学者可参考）：从一个反直觉发现出发，逐步落实。</li>
<li>ljw 同学（有积累后可参考）：好奇心驱动，对于好奇的问题不断调研和实验分析。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="问答环节记录"><a href="#问答环节记录" class="headerlink" title="问答环节记录"></a>问答环节记录</h2><ol>
<li>有没有做真实实验？  </li>
</ol>
<ul>
<li>没有，因为目标是碎片率，所以使用真实数据集做模拟实验绰绰有余。  </li>
</ul>
<ol start="2">
<li>迁移多花的时间有多长？  </li>
</ol>
<ul>
<li>本论文没细讲。  </li>
</ul>
<ol start="3">
<li>是否可以没有冷启动？  </li>
</ol>
<ul>
<li>整个内存迁移可能没有冷启动。  </li>
</ul>
<ol start="4">
<li>热迁移是否会因为内存变化太快而失败？  </li>
</ol>
<ul>
<li>会的，可能有保底机制（太长时间不成功就直接冷迁移）。  </li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3689031.3717476">[1] Xianzhong Ding, Yunkai Zhang, Binbin Chen, Donghao Ying, Tieying Zhang, Jianjun Chen, Lei Zhang, Alberto Cerpa, and Wan Du. 2025. Towards VM Rescheduling Optimization Through Deep Reinforcement Learning. In Proceedings of the Twentieth European Conference on Computer Systems (EuroSys ‘25). Association for Computing Machinery, New York, NY, USA, 686–701. https://doi.org/10.1145/3689031.3717476<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>精读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>迁移</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】精读笔记3-前沿-用RL进行VM重调度以整理碎片-B-相关工作发展脉络梳理</title>
    <url>/2025/05/14/literature/literatureNotesIntensive3/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Towards-VM-Rescheduling-Optimization-Through-Deep-Reinforcement-Learning》"><a href="#x1f4d6-《Towards-VM-Rescheduling-Optimization-Through-Deep-Reinforcement-Learning》" class="headerlink" title="📖《Towards VM Rescheduling Optimization Through Deep Reinforcement Learning》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Towards VM Rescheduling Optimization Through Deep Reinforcement Learning》</h1><p>2025 年 UC Merced大学、 UC Berkeley大学、字节跳动团队 发表于 CCF-A 类会议 EuroSys。</p>
<p>系列博客：</p>
<ol>
<li><a href="/2025/04/28/literature/literatureNotes82/" title="VMR2L-初步略读笔记">VMR2L-初步略读笔记</a></li>
<li><a href="/2025/05/11/literature/literatureNotesIntensive2/" title="VMR2L-整体逻辑精解笔记">VMR2L-整体逻辑精解笔记</a></li>
<li><a href="/2025/05/14/literature/literatureNotesIntensive3/" title="VMR2L-相关工作发展脉络梳理笔记">VMR2L-相关工作发展脉络梳理笔记</a>

</li>
</ol>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><h3 id="调度算法"><a href="#调度算法" class="headerlink" title="调度算法"></a>调度算法</h3><ul>
<li>在实践中，字节跳动使用的是最佳拟合[27,50]，它将所有符合当前VM要求的PM根据加入VM前后的FR减少量进行排序，并选择减少量最大的PM。</li>
<li>向量装箱问题（α-VBPP）：VBPP[49]算法</li>
</ul>
<h3 id="重调度算法"><a href="#重调度算法" class="headerlink" title="重调度算法"></a>重调度算法</h3><p>a. 转化为装箱问题的最优化方法：</p>
<ul>
<li>现状：基于成熟的MIP求解器进行求解加速[48,66]，无法满足严格的延迟要求（5s）。<ul>
<li>使用分支限界法[48]来确定最佳解决方案。</li>
<li>混合整数规划（MIP）求解器：通过现成的MIP求解器解决，如CPLEX[2]和Gurobi[3]，它通过分支定界、切割平面等找到接近最优的解。在我们的实验中，我们使用Gurobi。</li>
<li>分区优化问题（POP）[47]：它通过将问题随机拆分为子问题（每个子问题包含VM和PM的子集），对每个子问题应用MIP求解器，最后将结果组合成全局解决方案来解决最优化问题。</li>
<li>蒙特卡洛树搜索（MCTS）[67]：由于传统的基于搜索的方法需要在推理时间内执行多次推出以获得良好的性能，我们使用DDTS[67]来修剪搜索空间。</li>
</ul>
</li>
<li>问题：数据中心中VM和PM的总数很容易达到数千个或更多[63]，远远超过通常不超过几百个对象的装箱问题的典型规模[41,67]。</li>
</ul>
<p>b. 转化为装箱问题的启发式方法：</p>
<ul>
<li>现状：依赖人为设计的启发式方法[27]，导致次优解决方案。<ul>
<li>手工调整的启发式方法基于人类的专业知识，通过修剪搜索空间来克服可扩展性挑战。然而，启发式方法必须针对每个数据中心的不同集群条件单独设计，因为没有适用于所有场景的通用启发式方法。</li>
<li>基于过滤的启发式算法（HA）：为了在短时间内获得可行的解决方案，启发式算法通常用于工业数据中心[4]。它们通常包括两个阶段：过滤和评分。在过滤阶段，我们计算每个VM的FR变化，就好像它从其源PM中删除一样，并且只选择对应于FR下降最多的VM候选。在评分阶段，我们计算FR的变化，就好像选择的VM被迁移到每个合格的PM。然后，我们贪婪地将选择的VM分配给导致FR下降最大的PM。上述两个阶段重复，直到达到MNL。</li>
<li>向量装箱问题（α-VBPP）：我们将初始调度到重新调度的VBPP[49]算法推广。我们首先将整个事件分为 𝑀𝑁 𝐿/𝛼 阶段。在每个阶段，我们贪婪地删除导致最多片段的数量的VM，然后应用VBPP将它们视为传入的VM。我们仔细调整（在我们的情况下为10）以实现最佳的FR减少。</li>
<li></li>
</ul>
</li>
<li>问题：<ul>
<li>首先，VM重调度问题涉及动态调整VM对PM的初始分配，需要考虑已有的VM关系，现有的装箱解决方案通常不考虑这些关系。</li>
<li>其次，重新平衡已经装入箱子中的物品在其他装箱应用的背景下很少受到关注。</li>
</ul>
</li>
</ul>
<p>c. 面向优化问题的强化学习方法：</p>
<ul>
<li>现状：RL被广泛用于选择分支变量等场景[23,25,26]，也可以应用于MIP问题下启发式方法的质量优化[9,58]。<ul>
<li>Decima[44]：Decima使用图神经网络对VM和PM信息进行编码，并使用深度RL进行训练。Decima通过将VM重新安排决策分解为二维动作来平衡动作空间的大小和所需动作的数量，二维动作输出i）需要迁移的VM，ii）选择作为目的地的PM子集的上限。</li>
<li>NeuPlan[66]：在第一阶段，RL代理将问题作为图接收，并生成前几个VM迁移以修剪搜索空间。在第二阶段，它对剩余的MNL使用MIP求解器。松弛因子（在我们的例子中为30）用于控制MIP探索的MNL空间的大小。</li>
</ul>
</li>
<li>问题：但都只面向传统简单场景，难以在VM重调度问题下获得较好训练结果。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>重调度问题应该是一个自分布式系统出现以来就广受关注的问题。直觉上应该已经被研究很久了，在这个老问题下，本文做了什么“新”事？<ul>
<li>VMR2L的特点体现在效率目标（5s）下的质量最优，而这个目标（5s）是根据业界数据集进行模拟实验推导出的，传统方法没有这样大规模的数据集因此也没有条件推导该目标。</li>
</ul>
</li>
<li>更进一步说，作为高校学生，在类似的大规模问题下，该如何有说服力地表明“效率目标”？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3689031.3717476">[1] Xianzhong Ding, Yunkai Zhang, Binbin Chen, Donghao Ying, Tieying Zhang, Jianjun Chen, Lei Zhang, Alberto Cerpa, and Wan Du. 2025. Towards VM Rescheduling Optimization Through Deep Reinforcement Learning. In Proceedings of the Twentieth European Conference on Computer Systems (EuroSys ‘25). Association for Computing Machinery, New York, NY, USA, 686–701. https://doi.org/10.1145/3689031.3717476<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>精读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>迁移</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】精读笔记4-前沿-字节跳动统一调度架构Gödel-B-相关工作发展脉络梳理</title>
    <url>/2025/05/16/literature/literatureNotesIntensive4/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Godel-Unified-Large-Scale-Resource-Management-and-Scheduling-at-ByteDance》"><a href="#x1f4d6-《Godel-Unified-Large-Scale-Resource-Management-and-Scheduling-at-ByteDance》" class="headerlink" title="📖《Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance》</h1><p>2023 年 Virginia大学、字节跳动团队 发表于 CCF-B 类云计算顶级会议 SoCC。</p>
<blockquote>
<p>系列博客：</p>
<ol>
<li><a href="/2024/07/04/literature/literatureNotes45/" title="Gödel-初步略读笔记">Gödel-初步略读笔记</a></li>
<li><a href="/2025/05/16/literature/literatureNotesIntensive4/" title="Gödel-相关工作发展脉络梳理">Gödel-相关工作发展脉络梳理</a></li>
<li><a href="/2025/05/21/literature/literatureNotesIntensive5/" title="Gödel-研究方案梳理">Gödel-研究方案梳理</a></li>
<li><a href="/2025/06/18/literature/literatureNotesIntensive6/" title="Gödel-实验梳理">Gödel-实验梳理</a>
</li>
</ol>
</blockquote>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><p>字节跳动对生产调度系统的主要要求是在异构机器上调度各种工作负载（如表 1 所列），提高资源利用率，跟上每个计算集群不断增长的机器规模，并实现高吞吐量。</p>
<p>在异构机器上需要调度各种工作负载（如下表）。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/2-Table1-1.png" alt="表1：字节跳动的工作负载分解"><figcaption>表1：字节跳动的工作负载分解</figcaption></figure></p>
<h2 id="现状概览"><a href="#现状概览" class="headerlink" title="现状概览"></a>现状概览</h2><h3 id="管理-调度体系"><a href="#管理-调度体系" class="headerlink" title="管理/调度体系"></a>管理/调度体系</h3><p>行业巨头的传统体系为：资源管理、资源调度分级。</p>
<ul>
<li>资源管理 resource management ： 切分资源给业务组</li>
<li>资源调度 resource scheduling ： 调度任务到切分后的资源</li>
</ul>
<p>这种分级架构导致资源碎片和资源浪费（分配给业务组后，业务组没有利用起来）。<br>因此，需要使用统一的体系（资源管理+资源调度一体）进行管理调度。</p>
<h3 id="调度架构"><a href="#调度架构" class="headerlink" title="调度架构"></a>调度架构</h3><p>使用事实上的开源调度器并不能满足我们的所有要求，例如 </p>
<ul>
<li>1）<strong>Kubernetes</strong>[6]，它能为微服务提供灵活的资源分配/亲和性，但存在可扩展性问题；</li>
<li>2）<strong>YARN</strong>[31]，更适合需要复杂调度语义（即 Gang 调度）的批处理作业，但缺乏对微服务的支持。</li>
</ul>
<p>学术界研究了不同的调度系统，如单体调度器、两级调度器和分散式多调度器，但每种调度系统在实现我们的生产目标方面都有不足之处。</p>
<ul>
<li>3）<strong>单体调度器</strong>[16,19,21,30,32,34]面临高吞吐量的挑战，而且难以添加定制的调度策略。</li>
<li>4）<strong>两级调度器</strong>[20]采用资源管理器在不同调度器之间划分资源，但这种悲观的锁定方式会损害资源间的资源弹性。</li>
</ul>
<p>为了满足超大规模的增长，一些业务部门采用了运行不同调度系统（如 Kubernetes、YARN）的方式来管理自己的计算基础架构堆栈，这造成了两大痛点：不同业务部门之间的资源日益分散，不同业务优先级的工作负载之间的资源弹性不足。不同业务群组之间的隔离（及其计算基础设施管理）导致计算资源利用效率低下，无法长期满足业务增长需求。</p>
<ul>
<li>5）在 ByteDance，在 Gödel 之前，我们在同一个计算集群上<strong>同时运行 Kubernetes 和 YARN</strong>，由资源管理器在它们之间调度资源。<ul>
<li>这种方法提高了我们的资源利用率，但在调度器之间转移资源会降低弹性，影响吞吐量。</li>
</ul>
</li>
<li>6）Borg[29,32]、Omega[26] 及其开源实现 Kubernetes[6] 提出的<strong>分散式多调度器</strong>（也叫状态共享调度器）可以使用不同的调度器，每个调度器都可以访问整个计算集群，并使用乐观并发控制解决调度冲突。<ul>
<li>然而，Kubernetes 解决节点级冲突是为了防止资源超用（over-commit），这在调度周期中为时已晚，会降低吞吐量和集群规模。</li>
</ul>
</li>
</ul>
<p>从我们之前的经验和学术研究中，我们发现需要建立一个<strong>统一的调度器</strong>，它可以为不同的工作负载及其调度策略提供丰富的<strong>语义支持</strong>，可以<strong>横向扩展</strong>以满足我们的吞吐量和可扩展性需求，还可以<strong>共同定位</strong>工作负载以提高资源利用率。</p>
<h2 id="🪵动机"><a href="#🪵动机" class="headerlink" title="🪵动机"></a>🪵动机</h2><ul>
<li>本节介绍了字节跳动在集群管理方面面临的挑战，我们想要实现的目标以应对不断增长的规模，以及为什么现有的集群管理解决方案无法满足我们的需求。</li>
</ul>
<h3 id="🪨挑战"><a href="#🪨挑战" class="headerlink" title="🪨挑战"></a>🪨挑战</h3><h4 id="异构性："><a href="#异构性：" class="headerlink" title="异构性："></a><strong>异构性：</strong></h4><p>如表1所示，字节跳动的<strong>作业负载高度异构</strong>。例如：</p>
<ul>
<li><strong>长时间运行的服务</strong>，如内存数据库；</li>
<li><strong>资源密集型短时工作负载</strong>，如机器学习训练任务。</li>
</ul>
<p>这些工作负载具有不同的<strong>业务关键性</strong>。例如，</p>
<ul>
<li><strong>关键工作负载</strong>不应被抢占以确保服务质量（QoS）。</li>
<li>相比之下，<strong>非关键工作负载</strong>可以被抢占以释放资源供关键工作负载使用。</li>
</ul>
<p>更具挑战性的是处理不同工作负载所需的<strong>拓扑约束</strong>。</p>
<ul>
<li>以内存数据库、推理和推荐服务为例，它们都将在内存中保留数据。因此，为了降低内存访问延迟，对于容器而言，使用<strong>固定NUMA节点（</strong>专用或共享）是首选。</li>
</ul>
<h4 id="弹性："><a href="#弹性：" class="headerlink" title="弹性："></a><strong>弹性：</strong></h4><p>资源业务组织架构</p>
<ul>
<li>供给方：在字节跳动，我们运营着包含数十万台<strong>机器</strong>的大型<strong>集群</strong>。像许多其他行业巨头一样，我们将<strong>集群</strong>切分为为<strong>独立的计算基础设施</strong>为不同的<strong>业务组</strong>提供服务。（资源管理 resource management ：切分资源给业务组）</li>
<li>需求方：每个<strong>业务组</strong>可能都有自己的<strong>调度器</strong>来适应其特定的负载行为的<strong>资源需求</strong>。（资源调度 resource scheduling ：调度任务到切分后的资源）</li>
</ul>
<p>问题</p>
<ul>
<li>不幸的是，不同<strong>业务组</strong>的<strong>资源需求</strong>随时间变化，通常速度不同。</li>
<li>这导致<strong>资源利用率降低</strong>，集群间资源<strong>碎片化</strong>，以及由于资源弹性低（即不同集群间资源流动性差）而导致的高运营成本。</li>
</ul>
<p>因此，需要一个<strong>统一资源管理和调度系统</strong>来提高资源利用率，改善调度性能，并降低运营成本。</p>
<h4 id="吞吐量："><a href="#吞吐量：" class="headerlink" title="吞吐量："></a><strong>吞吐量：</strong></h4><p>在字节跳动，为了服务<strong>数十亿终端用户和异构工作负载</strong>，<strong>每秒创建数千个容器</strong>，<strong>每天运行数千万至数亿个容器</strong>。<br>这要求我们的调度系统具有非常高的吞吐量和响应速度，以便在适当的服务器上启动任务。这个标准比今天所有现成的开源解决方案都要高。</p>
<h3 id="现有研究的缺陷"><a href="#现有研究的缺陷" class="headerlink" title="现有研究的缺陷"></a>现有研究的缺陷</h3><h4 id="Kubernetes-6"><a href="#Kubernetes-6" class="headerlink" title="Kubernetes [6]"></a>Kubernetes [6]</h4><p><strong>简介：</strong>Kubernetes是跨机器集群的容器化应用程序的事实上开源编排系统。</p>
<h5 id="问题1：可扩展性差"><a href="#问题1：可扩展性差" class="headerlink" title="问题1：可扩展性差"></a>问题1：可扩展性差</h5><p>当集群扩展到数千个节点时，Kubernetes及其默认调度器会遭受性能下降。</p>
<ul>
<li>我们测试了从<strong>100到5000个节点的</strong>不同集群大小的纯Kubernetes（来自开源社区的默认版本）的调度吞吐量。</li>
<li>Pod提交率固定为<strong>每秒2800个Pod。</strong>如图1所示，纯Kubernetes<strong>每秒只能完成160-180个Pod的</strong>调度。</li>
<li>当集群规模超过<strong>500个节点时</strong>，由于其计算复杂性，其调度吞吐量开始下降。</li>
<li>此外，纯Kubernetes默认只能支持<strong>5000个节点。</strong></li>
</ul>
<p>在字节跳动，典型的集群部署范围在<strong>数万个节点</strong>，因此纯Kubernetes无法适应我们不断增长的超大规模集群。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/3-Figure1-1.png" alt="图1：Vanilla Kubernetes 的调度吞吐量"><figcaption>图1：Vanilla Kubernetes 的调度吞吐量</figcaption></figure></p>
<h5 id="问题2：异构负载感知差"><a href="#问题2：异构负载感知差" class="headerlink" title="问题2：异构负载感知差"></a>问题2：异构负载感知差</h5><p>除了其低效的调度吞吐量外，Kubernetes默认调度器缺乏对工作负载的感知，并且无法很好地调度批处理作业（例如字节跳动典型的大数据处理和机器学习工作负载）。</p>
<ul>
<li>以机器学习为例，我们需要在<strong>具有相同网络前缀</strong>的一组节点上运行任务，或者在<strong>具有同质设备</strong>（例如，相同的GPU型号）的特定节点上运行任务。</li>
</ul>
<p><strong>问题：</strong></p>
<ul>
<li>不幸的是，Kubernetes默认调度器不提供此类功能。</li>
<li>一些社区解决方案（Kube-batch、Volcano）[4, 8]可以部分解决这些挑战。然而，这些解决方案存在其他问题，例如<strong>调度性能</strong>（例如表3）、<strong>系统稳定性</strong>和<strong>在线服务支持不足</strong>，因此它们不适合我们的生产集群。</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/12-Table3-1.png" alt="表3：离线工作负载的调度吞吐量"><figcaption>表3：离线工作负载的调度吞吐量</figcaption></figure></p>
<h5 id="问题3：拓扑感知能力差"><a href="#问题3：拓扑感知能力差" class="headerlink" title="问题3：拓扑感知能力差"></a>问题3：拓扑感知能力差</h5><p>Kubernetes调度器也缺乏拓扑感知能力。<br><strong>定义：</strong>在这篇论文中，<strong>拓扑感知</strong>的概念是指调度器在将Pod放置在节点上时，应遵守<strong>资源之间的拓扑约束</strong>。</p>
<ul>
<li>例如，分配给内存密集型Pod的CPU核心和内存最好位于<strong>同一CPU插槽</strong>上，以最大限度地减少内存访问延迟。</li>
</ul>
<p><strong>问题：</strong></p>
<ul>
<li>借助拓扑管理器、每个节点的代理，如果节点上的资源总量足够，但资源分配无法满足适当的拓扑策略，它可以拒绝Pod启动。</li>
<li>不幸的是，这发生在kubelet接受阶段，此时调度器已经做出了错误的调度决策。</li>
<li>对于其调度器来说，一个更好的行为是拥有每个节点上可用资源的拓扑信息，从而能够选择既能满足资源请求又能满足拓扑约束的适当节点。</li>
</ul>
<h4 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h4><p><strong>简介：</strong>YARN是另一个用于大规模集群的资源管理和作业调度系统。</p>
<p>由于以下限制，YARN不适合我们快速增长的集群舰队（fleet），该舰队托管了许多异构的工作负载。</p>
<h5 id="问题1：可扩展性差（吞吐量仅在批处理作业下高）"><a href="#问题1：可扩展性差（吞吐量仅在批处理作业下高）" class="headerlink" title="问题1：可扩展性差（吞吐量仅在批处理作业下高）"></a>问题1：可扩展性差（吞吐量仅在批处理作业下高）</h5><p>与Kubernetes相比，类似YARN的系统提供了更高的调度吞吐量[9]。</p>
<ul>
<li>然而，YARN只有在运行批处理作业时才能超越Kubernetes的吞吐量。</li>
<li>此外，它不是用于调度长时间运行的在线服务的本地系统，更不用说在同一资源池中调度异构的工作负载了。</li>
</ul>
<h5 id="问题2：异构负载感知差-1"><a href="#问题2：异构负载感知差-1" class="headerlink" title="问题2：异构负载感知差"></a>问题2：异构负载感知差</h5><p>YARN可能需要与对实时处理等高需求工作负载做出妥协，并且无法跟上现代云原生工作负载的需求。</p>
<ul>
<li>这些工作负载正趋向于微服务和短生命周期服务，而不仅仅是大型作业。</li>
</ul>
<h5 id="问题3：拓扑感知能力差-1"><a href="#问题3：拓扑感知能力差-1" class="headerlink" title="问题3：拓扑感知能力差"></a>问题3：拓扑感知能力差</h5><p>此外，YARN在隔离作业和处理依赖控制方面存在不足。YARN还缺乏资源碎片优化，导致资源利用率低。</p>
<ul>
<li>根据我们在专门用于机器学习的YARN集群中的测试，该集群包含1,300个节点（每个节点8个GPU），GPU碎片率**高达30%至40%**。</li>
</ul>
<h4 id="结合-Kubernetes-和-YARN。"><a href="#结合-Kubernetes-和-YARN。" class="headerlink" title="结合 Kubernetes 和 YARN。"></a>结合 Kubernetes 和 YARN。</h4><p>我们解决上述挑战的重要努力之一是通过在两个调度系统之间来回沟通资源供需，将 Kubernetes 和 YARN 结合起来。这种模式在业界许多科技巨头中得到广泛应用。</p>
<h5 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h5><p>大约两年时间里，我们经历了几个阶段，使这种方法得以实现：</p>
<ul>
<li>• 阶段 1：我们分别使用 Kubernetes 和 YARN 在<strong>独立的资源池</strong>中运行在线（即微服务）和离线（即批量）工作负载。</li>
<li>• 阶段 2：我们实现了一个<strong>协调器</strong>，该协调器持续监控 Kubernetes 和 YARN 的资源供需情况，然后根据流量模式在两个系统之间<strong>移动资源</strong>。它还利用历史数据来做出资源分配决策。<ul>
<li>当向 YARN 添加资源时，协调器通过在节点上标记“污点”来将其从在线池中移除，以防止 Kubernetes 调度新的工作负载。</li>
<li>同样，当将资源返回给 Kubernetes 时，协调器从这些节点上移除“污点”，使它们可用于在线工作负载。</li>
<li>如果离线任务仍在新添加的节点上运行，Kubernetes 将无论其进度如何都将其终止。</li>
</ul>
</li>
<li>• 阶段 3：我们进一步改进了协调器和其他机制，使 Kubernetes 和 YARN <strong>代理能够持续通信</strong>。<ul>
<li>两个代理分别向它们的调度器（即 Kube-Scheduler 和 YARN 资源管理器）反馈实时资源使用信息。</li>
<li>这样，两个调度器都可以根据实际资源使用情况做出<strong>动态调度决策</strong>，以便<strong>离线工作负载</strong>可以利用同一节点上<strong>在线工作负载</strong>未使用的潜在资源。</li>
</ul>
</li>
</ul>
<p>尽管有一些早期成功，上述方法也有一些缺点。</p>
<h5 id="问题1：可扩展性差-1"><a href="#问题1：可扩展性差-1" class="headerlink" title="问题1：可扩展性差"></a>问题1：可扩展性差</h5><p>这种方法会产生重大的运营开销。</p>
<ul>
<li>没有统一资源池，导致需要人工协商资源池需求。</li>
<li>例如，在准备特殊事件（如春节）高峰使用时，运营团队必须提前几周开始与多个团队协调，预测扩大资源池的估计需求，这既耗时又无法适应我们不断增长的基础设施。</li>
</ul>
<h5 id="问题2：异构负载感知差-2"><a href="#问题2：异构负载感知差-2" class="headerlink" title="问题2：异构负载感知差"></a>问题2：异构负载感知差</h5><p>其次，交换节点对在其上运行的任务是不可知的。</p>
<ul>
<li>使用这种粗粒度的方法，选择驱逐的节点可能会产生级联失败（例如，驱逐运行Parameter Server的节点会使训练工作者失去所有进度）。</li>
</ul>
<h5 id="问题3：拓扑感知能力差-2"><a href="#问题3：拓扑感知能力差-2" class="headerlink" title="问题3：拓扑感知能力差"></a>问题3：拓扑感知能力差</h5><p>综合解决方案无法帮助放置具有专用要求的工作负载，例如更高的网络带宽、GPU或NUMA亲和力。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li>上述Kubernetes和YARN的不足，以及它们的结合，激励我们追求一种新的解决方案，利用它们的优点和生态系统。与YARN相比，Kubernetes拥有更活跃的社区、更好更大的生态系统以及更广泛的应用场景。因此，如果我们能够增强其默认调度器，以实现针对各种工作负载的高性能调度、高资源利用率和可扩展性，那么一个类似Kubernetes的系统将会更好。</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/4-Table2-1.png" alt="表2：开源解决方案的缺陷"><figcaption>表2：开源解决方案的缺陷</figcaption></figure></p>
<h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>上述讨论激发我们为我们的目标集群管理解决方案设定以下目标：</p>
<h4 id="统一资源池（可扩展性）"><a href="#统一资源池（可扩展性）" class="headerlink" title="统一资源池（可扩展性）"></a>统一资源池（可扩展性）</h4><p>为了提高资源管理和降低运营成本，提供统一资源池至关重要。</p>
<ul>
<li>最终将较小的集群及其工作负载集成到大规模统一集群中。</li>
</ul>
<h4 id="改进资源利用率（可扩展性-异构负载感知）"><a href="#改进资源利用率（可扩展性-异构负载感知）" class="headerlink" title="改进资源利用率（可扩展性+异构负载感知）"></a>改进资源利用率（可扩展性+异构负载感知）</h4><p>随着集群舰队规模的增加，继续优化整体资源利用率至关重要。</p>
<ul>
<li>使用来自高优先级工作负载的未使用资源来协同定位低优先级工作负载将提供最佳平衡。</li>
</ul>
<h4 id="高吞吐量（可扩展性-异构负载感知）"><a href="#高吞吐量（可扩展性-异构负载感知）" class="headerlink" title="高吞吐量（可扩展性+异构负载感知）"></a>高吞吐量（可扩展性+异构负载感知）</h4><p>随着我们将不同类别的负载协同定位（放于一起），保持至少与YARN相同的吞吐量对于短运行任务至关重要，而Kubernetes目前无法对其进行扩展。</p>
<h4 id="高资源弹性（可扩展性-异构负载感知）"><a href="#高资源弹性（可扩展性-异构负载感知）" class="headerlink" title="高资源弹性（可扩展性+异构负载感知）"></a>高资源弹性（可扩展性+异构负载感知）</h4><p>在字节跳动，我们努力将异构工作负载一起运行以实现更高的资源利用率，实施高资源弹性以根据需求在业务关键工作负载和低优先级任务之间转移计算资源至关重要。</p>
<h4 id="拓扑感知调度（拓扑感知）"><a href="#拓扑感知调度（拓扑感知）" class="headerlink" title="拓扑感知调度（拓扑感知）"></a>拓扑感知调度（拓扑感知）</h4><p>我们希望我们的调度器做出更多最优的调度决策，考虑各种拓扑约束，而不是在无法在kubelet admit操作上实现所需拓扑策略时失败Pod启动。</p>
<h2 id="x1f6a7-现状"><a href="#x1f6a7-现状" class="headerlink" title="🚧现状"></a><span class="emoji" alias="construction" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png?v8">🚧</span>现状</h2><p>作为现代集群基础设施的一个基本组成部分，集群调度在近年来得到了广泛研究。</p>
<ul>
<li>我们已介绍两种替代方案，Kubernetes和YARN，它们不符合我们的需求（如前文所述）。</li>
<li>在本节中，我们讨论了同一研究领域的其他相关工作，并简要回顾了四个类别的最先进集群编排调度器：单体调度器、两级调度器、共享状态调度器和分布式/混合调度器。</li>
</ul>
<p>Gödel是一个共享状态调度器，取代了Kubernetes生态系统中的默认调度器。</p>
<h3 id="单体调度器-Monolithic-Schedulers"><a href="#单体调度器-Monolithic-Schedulers" class="headerlink" title="单体调度器 Monolithic Schedulers"></a>单体调度器 Monolithic Schedulers</h3><p>大量工作通过单体调度器完成，这些调度器为整个集群实现集中式调度[16, 18, 19, 21, 29, 30, 32, 34]。</p>
<ul>
<li>Borg[29, 32]在同一单元格中容纳“生产”和“非生产”工作负载。根据定义明确的准入控制和基于队列的高效调度器，Borg实现了显著高的资源利用率。</li>
<li>Firmament[18]提出了一种通过最小成本最大流（MCMF）优化实现亚秒级放置延迟的集中式集群调度器。</li>
<li>Quincy[21]将调度问题，如数据局部性、公平性和避免饥饿，编码到图数据结构中，并提出了一种标准求解器以产生优化的全局成本。</li>
<li>有些人将机器学习技术应用于统一的调度单元，以避免负面干扰和服务质量（QoS）违规[12, 13, 23, 24, 33]。</li>
</ul>
<p>这类调度器在编排决策中，</p>
<ul>
<li>优点：提供集群范围内的可见性</li>
<li>缺点：<ul>
<li><strong>遭受复杂问题</strong>，如服务具有不同需求的异构工作负载。</li>
<li>其次，单体调度器在扩展到我们生产中的集群规模时通常存在<strong>可扩展性问题</strong>。</li>
</ul>
</li>
</ul>
<h3 id="两级调度器-Two-level-Schedulers"><a href="#两级调度器-Two-level-Schedulers" class="headerlink" title="两级调度器 Two-level Schedulers"></a>两级调度器 Two-level Schedulers</h3><ul>
<li>Mesos [20] 首创了这种方法，并为每个子框架提供资源。</li>
<li>Twine [27] 动态地为Twine系统中的Entitlement（一个伪集群）分配资源，通过权益划分调度器。在Twine上构建了多个应用级调度器以支持批处理和机器学习工作负载。这些应用级调度器可以显著减少Twine的工作负载。</li>
<li>YARN [31] 允许调度器从资源管理器请求资源。</li>
</ul>
<p>这类调度器在编排决策中，</p>
<ul>
<li>优点：能够解决单体调度器受集中式调度器的过载而导致的可扩展性问题，两级调度器通过中央协调器和独立任务调度器动态地为不同的工作负载分配资源。</li>
<li>缺点：由于缺乏全局可见性，两级调度器遭受资源碎片、负面干扰和次优问题。</li>
</ul>
<h3 id="共享状态调度器-Shared-state-Schedulers"><a href="#共享状态调度器-Shared-state-Schedulers" class="headerlink" title="共享状态调度器 Shared-state Schedulers"></a>共享状态调度器 Shared-state Schedulers</h3><ul>
<li>在Omega [26]中，每个调度器都有一个私有、频繁更新的副本，并做出独立的编排决策。最后，每个调度器提交其事务，并使用粗粒度或细粒度方法解决冲突。</li>
<li>Nomad [7]将集群状态存储在规划队列中，并支持多个应用程序调度。</li>
<li>ParSync [15]通过将全局状态分成N部分来减轻负面影响，允许调度器根据分区状态做出决定，而Gödel根据集群的总分配和吞吐量动态地在单个分区或多分区之间适应。Gödel还实现了多项增强，以减少即使单个分区时的冲突。</li>
<li>Apollo [9]为每个作业分配一个调度器来管理作业的生命周期，并根据资源监控器的全局状态信息实现基于估计的调度。每当调度器同时做出竞争性决策时，Apollo乐观地推迟任何纠正操作，因为大多数冲突是无害的。</li>
</ul>
<p>这类调度器在编排决策中，</p>
<ul>
<li>优点：共享状态调度器具有全局集群视图，并使用无锁乐观并发控制来解决来自不同调度器的冲突。</li>
</ul>
<p>Gödel是一个共享状态调度器，其中每个调度器实例共享全局状态以做出调度决策。</p>
<ul>
<li>[9, 15]中的调度器将全局状态分区，Gödel中<strong>每个调度器共享全局状态</strong>。</li>
<li>其次，每个调度实例<strong>支持所有调度策略</strong>，使其能够与通过吞吐量进行<strong>水平扩展</strong>的分布式多调度器[26]相比，后者运行不同调度器的一个实例。</li>
<li>最后，与在节点级别解决冲突的Kubernetes相比，Gödel<strong>在调度阶段解决冲突</strong>，显著提高了Gödel的吞吐量。</li>
</ul>
<h3 id="分布式-混合调度器-Distributed-Hybrid-Schedulers"><a href="#分布式-混合调度器-Distributed-Hybrid-Schedulers" class="headerlink" title="分布式/混合调度器 Distributed/Hybrid Schedulers"></a>分布式/混合调度器 Distributed/Hybrid Schedulers</h3><ul>
<li>Sparrow [25] 提出了一种完全分布式调度器，支持在决策中实现高吞吐量。然而，缺乏中央协调器可能会限制其调度灵活性。</li>
<li>相反，混合架构通过结合单体或共享状态设计 [10, 11, 14, 22, 28, 35] 来解决这个问题。</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>问题：在<a href="#%E5%BC%B9%E6%80%A7">弹性部分</a>提到两层调度架构，供给方的资源调度、需求方的任务调度，那么Godel到底是哪一侧的调度器？<ol>
<li>如果是供给方，那么为什么需要考虑具体Pod？</li>
<li>如果是需求方，那么为什么会管理全局资源而非有限局部资源？</li>
<li>还是进行了大一统，作为供给方，但不按传统预分配资源（资源调度），而是只给出配额限制后直接调度Pod到全局资源（资源+任务调度）？</li>
</ol>
<ul>
<li>回答：仔细看了弹性部分的最后一句话，突然理解了之前略读时的疑问——“<strong>统一资源管理和调度系统</strong>”的意思。按这弹性部分的最后一句话来说，上述第三种应该是比较合理的解释，这也就是统一的含义。</li>
</ul>
</li>
<li>像<a href="/2025/05/11/literature/literatureNotesIntensive2/" title="EuroSys'25-VMR2L">EuroSys'25-VMR2L</a>一样，字节的几篇论文质量都非常高！具体体现在，论文中蕴含了很多工程实现的细节，完完全全是可落地的工作、并且能够给我这样难以接触一线的博士生提供很多业界的真实情况，描述地非常清晰。上一篇论文中是提供了很多关于VM重调度的细节，这一篇论文中是提供了很多K8s调度的细节。</li>
<li>YARN 为什么能够比 k8s 效率更高？省略了什么因素？相应地，Godel 是通过什么来提高的效率？能否复用于 volcano？</li>
<li>相比于K8s+YARN，统一资源池为什么就可以避免运营代价？例如，还是需要人工协商以确定未来需求量情况。感觉没说清楚。<ol>
<li>猜想A. 统一资源池后，所有信息打通，更方便自动化分析。</li>
<li>猜想B. K8s 和 YARN 分管的独立资源池只有 2 个大的，剩下还有很多小的集群由某些团队自行管理。当遇到大促等特殊情况时，为避免资源不够，就需要从小的集群中借用，而这是非常复杂的。（感觉这个比较靠谱）</li>
</ol>
</li>
<li>阿里巴巴在很早以前的<a href="/2024/07/01/literature/literatureNotes41/" title="论文">论文</a>就提到过在离线负载混合部署，但在字节的论文中并没有引用以对比。这是什么原因？<ol>
<li>仔细一看发现阿里巴巴居然也是 2023 年才发表的论文，和我的记忆有些冲突，或许还需要再调研一下。</li>
<li>也可以精读阿里巴巴的相关工作，做印证。</li>
</ol>
</li>
<li>为什么只重点将yarn和k8s列为两大选项，它们和其它主流方法有什么区别？（例如 Mesos 之类的）<ol>
<li>根据论文，是将这两者列为“业界实践标准”。其它调度器是学术界的成果。（可以回顾一下 <a href="/2023/07/19/literature/literatureNotes15/" title="Fuxi2.0">Fuxi2.0</a> 以互相印证）</li>
</ol>
</li>
<li>目标部分提了很多（吞吐量、异构感知、……），在实验部分最终用的是什么指标？</li>
<li>对于现状分类的两级式调度类别：<ol>
<li>对YARN的分类有争议，阿里和谷歌的论文中将YARN视为集中式架构。按我们的理解，YARN中ApplicationMaster只负责发起请求和执行任务，并不参与调度，因此应该只有YARN调度器本身负责集中式决策。</li>
<li>第一次看到提及Twine，非常有价值！简单浏览了下是Facebook内部的跨地域集群管理系统，发表于OSDI’20，和我们的思路基本一致：跨地域场景下两级式架构更适合。后续再进行精读。</li>
</ol>
</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3620678.3624663">[1] Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>统一调度</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】精读笔记5-前沿-字节跳动统一调度架构Gödel-C-研究方案梳理</title>
    <url>/2025/05/21/literature/literatureNotesIntensive5/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Godel-Unified-Large-Scale-Resource-Management-and-Scheduling-at-ByteDance》"><a href="#x1f4d6-《Godel-Unified-Large-Scale-Resource-Management-and-Scheduling-at-ByteDance》" class="headerlink" title="📖《Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance》</h1><p>2023 年 Virginia大学、字节跳动团队 发表于 CCF-B 类云计算顶级会议 SoCC。</p>
<blockquote>
<p>系列博客：</p>
<ol>
<li><a href="/2024/07/04/literature/literatureNotes45/" title="Gödel-初步略读笔记">Gödel-初步略读笔记</a></li>
<li><a href="/2025/05/16/literature/literatureNotesIntensive4/" title="Gödel-相关工作发展脉络梳理">Gödel-相关工作发展脉络梳理</a></li>
<li><a href="/2025/05/21/literature/literatureNotesIntensive5/" title="Gödel-研究方案梳理">Gödel-研究方案梳理</a></li>
<li><a href="/2025/06/18/literature/literatureNotesIntensive6/" title="Gödel-实验梳理">Gödel-实验梳理</a>
</li>
</ol>
</blockquote>
<h2 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h2><p>字节跳动对生产调度系统的主要要求是在异构机器上调度各种工作负载（如表 1 所列），提高资源利用率，跟上每个计算集群不断增长的机器规模，并实现高吞吐量。</p>
<p>在异构机器上需要调度各种工作负载（如下表）。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/2-Table1-1.png" alt="表1：字节跳动的工作负载分解"><figcaption>表1：字节跳动的工作负载分解</figcaption></figure></p>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了应对这些挑战，我们提出了一个名为 Gödel 的资源管理和调度系统。<ul>
<li>它为所有业务部门提供了一个统一的计算基础设施，以便在统一的资源池下运行各种工作负载。它将各种工作负载集中在每台机器上，以实现更好的资源利用率和弹性。</li>
<li>Gödel 基于 Kubernetes（事实上的开源容器编排系统）构建，但其核心调度器使用全局共享状态调度器进行了重新发明。相应地，我们还大幅增强了其周边组件。通过替换或增强重要组件，实现适应大规模的各种工作负载。</li>
</ul>
</li>
<li>本文的贡献如下：<ul>
<li>（1）我们引入了一种统一异构资源的<strong>新模式</strong>，以共同定位在线和离线工作负载，从而在超大规模上提供更好的拓扑亲和性、更高的资源弹性和更低的运营开销。</li>
<li>（2）我们在 Kubernetes 的基础上设计并实现了名为 Gödel 的新型资源管理和调度系统。我们对 Kubernetes 进行了多项优化和增强，以提高调度性能。</li>
<li>（3）我们在 ByteDance 的多个数据中心部署了 Gödel，这些数据中心拥有数万台机器，除了在模拟环境中进行密集测试外，我们还在实际工作负载下进行了评估。对 Gödel 的详细评估证明了它的实用性以及如何实现我们的目标。我们的结果表明，Gödel 在各种调度方案中都实现了卓越的性能和效率。</li>
</ul>
</li>
<li>本文报告了我们使用 Gödel 的设计和实施情况。此外，本文还讨论了我们在 ByteDance 大规模生产中开发和运行 Gödel 的经验教训和最佳实践。</li>
</ul>
<h2 id="🏠架构设计"><a href="#🏠架构设计" class="headerlink" title="🏠架构设计"></a>🏠架构设计</h2><a href="/2025/05/16/literature/literatureNotesIntensive4/" title="Gödel-相关工作发展脉络梳理">Gödel-相关工作发展脉络梳理</a>的“动机”一节中的研究表明，粗粒度主机托管技术和单实例调度器方法无法实现我们的目标。因此，我们提出了一种名为 Gödel 的统一调度系统，用于更高效地调度超大规模集群（即 &gt;= 20,000 个节点）中的异构工作负载（即微服务、批处理作业和机器学习作业）。
<p>本节将介绍如何设计 Gödel 来实现我们的目标。</p>
<p>图 2 是 Gödel 的架构概览。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/6-Figure2-1.png" alt="图2：Gödel 的架构概览"><figcaption>图2：Gödel 的架构概览</figcaption></figure></p>
<p>作为一个类似于 Kubernetes 的系统，Gödel 继承了 vanilla Kubernetes 的一些经典设计，不仅简化了开发工作，还为将来的开源铺平了道路。例如，</p>
<ul>
<li>它使用 API server 为 REST 操作提供服务，并为集群的共享状态提供前端，所有其他组件都通过该前端进行交互。</li>
<li>ETCD [1] 或其他键值存储为集群状态和元数据提供后端存储。<ul>
<li>由于我们发现 ETCD 可能成为调度吞吐量的瓶颈，与 Kubernetes 不同，Gödel 默认使用 KubeBrain [5] 作为高性能后端存储（KubeBrain 是一个基于高性能键值存储的元数据服务，由字节跳动开发并开源）。</li>
</ul>
</li>
</ul>
<p>Kubernetes 默认的调度器只有一个实例，所有请求都必须单独处理。因此，其调度效率远低于我们的要求。</p>
<ul>
<li>为了提高调度吞吐量，Gödel调度器被设计和实施为分布式调度系统，多个调度器实例可以并行处理所有 pod 请求。</li>
<li>这种设计提供了比 vanilla Kubernetes 高得多的调度吞吐量。</li>
</ul>
<p>Gödel 调度器主要由以下三个增强或新增组件提供支持：分发器（Dispatcher）、调度器（Scheduler）和绑定器（Binder）。为了处理不同的拓扑约束，Gödel 还依赖于自定义节点资源（CustomNodeResource，CNR）。</p>
<ul>
<li>请注意，即使配置了多个调度器，分发器和绑定器也是单例（单个实例），因为它们在调度阶段不进行直接计算。</li>
</ul>
<h3 id="关键组件"><a href="#关键组件" class="headerlink" title="关键组件"></a>关键组件</h3><h4 id="分发器-Dispatcher"><a href="#分发器-Dispatcher" class="headerlink" title="分发器 Dispatcher"></a>分发器 Dispatcher</h4><p><strong>整体逻辑：</strong>分发器 Dispatcher 是调度逻辑的<strong>入口点</strong>。</p>
<ul>
<li>它<strong>验证</strong>所有接收到的Job请求，并根据其资源请求和QoS优先级将它们存储在<strong>优先级队列</strong>中。</li>
<li>分发器最终将每个有效的请求<strong>转发</strong>到所需的调度器实例。图3表明了调度器的请求处理工作流程。<ul>
<li>当监控到提交的pod请求时，<strong>事件处理器</strong>被调用。</li>
<li><strong>事件处理器</strong>将pod请求发送到<strong>策略管理器</strong>，<strong>策略管理器</strong>使用不同的策略对pod进行<strong>排序</strong>，并从由逻辑队列表示的相应<strong>配额</strong>中扣除它们的资源请求。</li>
<li>所有排序后的pod请求都被追加到<strong>优先级队列</strong>中。</li>
<li><strong>分发器</strong>从优先级队列中<strong>挑选</strong>一个pod请求，并将其<strong>转发</strong>到所需的调度器实例。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/7-Figure3-1.png" alt="图3：Gödel Dispatcher"><figcaption>图3：Gödel Dispatcher</figcaption></figure></li>
</ul>
</li>
</ul>
<p><strong>逻辑队列：</strong>在分发器 Dispatcher 中，我们使用<strong>逻辑队列</strong>来表示分配给不同业务组的资源配额。</p>
<ul>
<li><strong>流程：</strong><ul>
<li>例如，要求（asking） 100 个 CPU 内核和 256GB 内存的业务组会在 Gödel 中获得所需的<strong>配额</strong>，并为其创建一个具有已配置<strong>排序策略</strong>的<strong>逻辑队列</strong>。<ul>
<li>逻辑队列支持多种<strong>排序策略</strong>，如主导资源公平（DRF）[17]、基于优先级的排序策略、最小-最大公平（FairShare）和先进先出（FIFO）。</li>
</ul>
</li>
<li>每次该业务组部署 pod 时，请求都会转发到其预先分配的<strong>队列</strong>，消耗的资源会从其配额中扣除。</li>
</ul>
</li>
<li><strong>作用：</strong><ul>
<li>在生产中，这些使用不同排序策略的逻辑队列通常会协同工作，在考虑公平性、优先级和响应速度的情况下处理我们的异构工作负载。<ul>
<li>例如，哥德尔还能像其他调度器（如 Kubernetes）一样实现基于优先级的调度。<ul>
<li>为了确保具有较高优先级的延迟敏感型工作负载的 SLA，这些工作负载可能会在队列中得到提升，从而以响应更快的方式进行调度。</li>
<li>如果集群中的某些资源不足，对延迟敏感的工作负载还可能抢占（preempt）低优先级工作负载的插槽。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>资源分区：</strong>分发器 Dispatcher 的另一个关键功能是<strong>使用分区（partition）/分片（sharding）</strong>在调度程序之间进行负载平衡。</p>
<ul>
<li><strong>分区数量：</strong><ul>
<li>默认情况下，分发器 Dispatcher 从代表整个计算集群的<strong>一个分区</strong>开始，所有调度器实例都在同一分区上运行。</li>
<li>不过，在某些情况下，如果<strong>集群分配</strong>超过 90%，或<strong>吞吐量</strong>超过 2000 个 pod/秒，且多个调度器之间的<strong>调度冲突</strong>超过 1%（所有阈值均可配置），那么 Dispatcher 会<strong>动态分区（dynamically partitions）</strong>集群，并相应地<strong>为每个调度器实例分配一组分区</strong>。</li>
</ul>
</li>
<li><strong>分区映射：</strong><ul>
<li>启用多个调度程序实例时，群集中的节点总是根据调度程序之间的负载平衡进行分区。</li>
<li>只有在新添加或移除调度器实例时，控制器才会动态调整节点映射。</li>
<li>当一个或多个调度器被移除时，与之相关的节点将根据其当前负载重新分配给其他活动调度器。</li>
<li>重新分配的开销与重新分配的节点数量成正比，但与调度吞吐量无关。</li>
</ul>
</li>
</ul>
<h4 id="调度器-Scheduler"><a href="#调度器-Scheduler" class="headerlink" title="调度器 Scheduler"></a>调度器 Scheduler</h4><p><strong>整体逻辑：</strong></p>
<ul>
<li><strong>流程：</strong>调度器 Scheduler 接收来自调度器的请求，然后就节点选择和 pod 抢占做出调度决定。</li>
<li><strong>对象：</strong>Gödel Scheduler 不对每个 pod 进行单独调度，而是对称为调度单元（<strong>Scheduling Unit</strong>）的 pod 组进行调度。</li>
<li><strong>策略：</strong>与 Kubernetes 类似，调度决策也是通过一系列<strong>可配置插件</strong>做出的。</li>
<li><strong>架构：</strong>如前所述，哥德尔调度器是一个分布式调度系统，可按需配置<strong>多个调度器实例</strong>。<ul>
<li>每个调度器实例可在本地分区或整个集群上<strong>独立做出调度决策</strong>。</li>
<li>多个调度器实例通过<strong>共享状态</strong>（通过调用 API Server 到后备存储）和<strong>乐观并发</strong>进行合作。</li>
</ul>
</li>
</ul>
<p><strong>调度范围权衡：</strong>在本地分区和整个集群上工作之间存在权衡。</p>
<ul>
<li>使用本地分区<strong>优点</strong>：<ul>
<li>a. 在本地分区工作可使调度器实例<strong>避免冲突</strong>，</li>
<li>b. 并<strong>减少节点过滤</strong>的时间消耗，因为扫描的节点会减少。</li>
</ul>
</li>
<li>使用本地分区<strong>缺点</strong>：<ul>
<li>a. 第一个代价是<strong>调度质量</strong>。<ul>
<li>例如，最适合运行 pod 的节点可能在另一个分区，即使我们可以在本地找到一个可接受的节点。</li>
</ul>
</li>
<li>b. 在本地分区工作的另一个缺点是资源碎片化。<ul>
<li>以 Gang 调度为例，如果我们只在本地分区搜索可行的节点，而多个分区都有足够的资源，我们可能会错误地调度失败。</li>
</ul>
</li>
</ul>
</li>
<li>我们的解决方案是：配置<strong>基于需求的调度策略</strong>，以适应更多场景。<ul>
<li>当集群中存在<strong>大量资源</strong>，且调度器实例之间的<strong>冲突可以忽略不计</strong>时，每个调度器实例会在乐观并发控制下<strong>跨分区</strong>选择<strong>最佳节点</strong>。</li>
<li>否则，我们会切换到<strong>分片模式（Sharding mode）</strong>，在这种模式下，每个调度器实例只能从<strong>自己拥有的分区</strong>中寻找可行的节点，以<strong>降低冲突率</strong>。</li>
<li>一种特殊情况是<strong>抢占</strong>，即调度器实例在本地或全局范围内<strong>都找不到</strong>合适的节点。在这种情况下，调度程序会尝试抢占优先级较低的受害 pod（victim Pod，这形容太好笑了 很生动形象），以腾出资源。</li>
</ul>
</li>
</ul>
<p><strong>调度器数量：</strong>Gödel 允许水平扩展，可添加/删除活动调度程序实例，按需处理不同情况。</p>
<ul>
<li>（1）新添加的 schedulers 调度器会自动向 Dispatcher 和 API Server 注册。</li>
<li>（2）然后，Dispatcher 开始将 pod 请求<strong>分派</strong>给新的 scheduler 调度器，而不会主动将 pod <strong>迁移</strong>到现有的调度器。</li>
<li>（3）当特定调度程序变为非活动状态（inactive）时，分配给它们的 pod 将被重新调度（reschedule）到活动的调度程序实例上。</li>
<li>至于调度器实例的首选数量，则取决于<strong>集群规模</strong>和<strong>系统负载</strong>。<ul>
<li>在 5.1 （EVALUATION - Scalability）中，我们将证明 “调度实例越多越好 “并不总是正确的。</li>
</ul>
</li>
</ul>
<h4 id="绑定器-Binder"><a href="#绑定器-Binder" class="headerlink" title="绑定器 Binder"></a>绑定器 Binder</h4><p><strong>整体逻辑：</strong></p>
<ul>
<li><strong>架构：</strong>绑定器 Binder 有<strong>一个领导者实例</strong>和<strong>两个跟随者实例</strong>作为备份（主从单活）。</li>
<li><strong>功能：</strong>绑定器 Binder 使用乐观并发控制来解决调度冲突，支持抢占、共同调度，并最终将 pod 绑定到调度器选择的特定节点上。<ul>
<li>它的工作原理与 Kubernetes 默认调度器的绑定周期（binding cycle）类似，但必须比 vanilla Kubernetes 处理更多冲突，因为 Gödel Schedulers 调度器会在多个调度器实例中并行做出调度决策。</li>
<li>与 Kubernetes 相比，<ul>
<li><strong>（1）调度器 - 静态选择-&gt;动态选择：</strong>在 vanilla Kubernetes 中，可以配置多个不同的调度器，但必须预先配置其中一个用来调度 pod；而 Gödel 会在运行时选择合适的调度器实例。</li>
<li><strong>（2）冲突处理位置 - 节点-&gt;绑定器：</strong>其次，vanilla Kubernetes 在 Kubelet 上解决调度器之间的冲突，这会严重影响吞吐量，而 Gödel 在 Binder 上解决冲突，这使得重试更快、更高效。</li>
</ul>
</li>
</ul>
</li>
<li><strong>流程：</strong>绑定器 Binder 使用<strong>优先队列</strong>来处理多个调度程序发送的调度决定，并按顺序处理 Pod 的绑定。<strong>被拒绝</strong>的 pod 将返回到调度器，重新进行调度。绑定决定流程如下所示：<ul>
<li>绑定器 Binder 使用<strong>细粒度方法</strong>实现乐观并发控制。绑定器 Binder 会检查<strong>单个 pod</strong> 所选<strong>节点</strong>上的所有硬约束是否都已通过，还会检查节点上是否有相同数量的<strong>可用资源</strong>。</li>
<li>对于<strong>抢占</strong>，绑定器 Binder 会检查是否有<strong>多个调度器实例</strong>试图抢占一个节点上的<strong>同一个受害者 Pod</strong>。如果是，绑定器 Binder 会接受第一个抢占，并拒绝同一受害者上的所有其他抢占。</li>
<li>对于 <strong>gang帮派 或 co-scheduling共同调度</strong> 作业，绑定器 Binder 会尝试<strong>解决所有 pod 的冲突</strong>。如果通过，则分别绑定所有 pod。否则，属于同一作业的所有 pod 都会被拒绝。</li>
</ul>
</li>
</ul>
<h4 id="自定义节点资源-Custom-Node-Resource（CNR）"><a href="#自定义节点资源-Custom-Node-Resource（CNR）" class="headerlink" title="自定义节点资源 Custom Node Resource（CNR）"></a>自定义节点资源 Custom Node Resource（CNR）</h4><p><strong>整体逻辑：</strong></p>
<ul>
<li><strong>功能：</strong>CNR 是哥德尔引入的一种特殊的 Kubernetes 客户资源定义（Customer Resource Definition，CRD），用于实现<strong>拓扑感知调度</strong>。我们用它来<strong>定义每个节点</strong>上具有<strong>拓扑结构的</strong>可用资源。<ul>
<li>（1）集群中的<strong>每个活动服务器</strong>都会在数据存储中创建一个 CNR 对象。CNR 对象的<strong>生命周期</strong>与其关联的服务器完全相同。每个 CNR 对象代表一个特定节点的拓扑结构和资源使用情况，以及该节点上每个 pod 的拓扑结构。<ul>
<li>例如，它告诉我们一个节点有多少个 NUMA 或子 NUMA，以及每个 NUMA 的 CPU/内存实时分配情况。</li>
</ul>
</li>
<li>（2）有了这些信息，Gödel 就能在节点上<strong>启动 pod 之前</strong>，根据拓扑限制选择合适的节点来承载作业，从而避免节点代理（即 kubelet）遇到不必要的调度失败。<ul>
<li>例如，通过扫描 CNR，哥德尔就能知道哪个节点有空闲的 NUMA 节点用于内存敏感型作业，哪个节点有空闲带宽充足的网卡用于网络密集型作业，然后做出正确的调度决策。</li>
</ul>
</li>
<li>（3）在创建或删除 pod 时，每个节点上的 Katalyst[3]代理会及时<strong>更新 CNR 对象</strong>。<ul>
<li>Katalyst 是一个资源管理工具，提供 QoS。它由字节跳动开发，并已开源。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="调度单元-Scheduling-Unit"><a href="#调度单元-Scheduling-Unit" class="headerlink" title="调度单元 Scheduling Unit"></a>调度单元 Scheduling Unit</h3><p>我们为 Gödel 引入的最重要的概念之一是调度单元（Scheduling Unit）。</p>
<ul>
<li><strong>目标：</strong>让我们回顾一下，我们希望实现的一个重要目标是<strong>统一资源池</strong>，在这个资源池中，在线或离线的异构工作负载都可以被调度到<strong>同一个集群</strong>中，以充分共享底层资源，而不会产生巨大的运行开销。</li>
<li><strong>功能：</strong>调度单元 Scheduling Unit 是实现这一目标的关键机制。<ul>
<li>每个调度单元由一个或多个运行单元（Running Units）组成，代表最小的可部署计算单元，就像 Kubernetes 的 pod 一样。<ul>
<li>与 Kubernetes 单独调度每个 pod 不同，在 Gödel 中，调度单元是基本的可调度单元。</li>
</ul>
</li>
<li>当作业部署到集群时，部署模板（deployment template，K8s 中定义和管理Pod的一种资源对象）会映射到<strong>两级调度结构</strong>（调度和执行）。<ul>
<li><strong>（1）调度：</strong>部署 Deployment 所代表的作业 Job 被映射到一个调度单元 Scheduling Unit，其中的所有 pod/子任务 subtasks 都被转化（translate）为运行单元 Running Units。在这种情况下，所有运行单元 Running Units 都作为一个整体由 Gödel 调度器处理。</li>
<li><strong>（2）执行：</strong>只有当 Gödel 调度器在集群中找到足够的计算资源，至少可以容纳运行单元 Running Units 的<strong>最小成员数量（Min Member）</strong>时，它们所属的调度单元才会被认定为可调度。否则，不会为该作业启动 pod。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>最小成员数量 Min Member：</strong>上述<code>功能-（2）执行</code>部分中，<strong>最小成员数量 Min Member</strong> 是一个重要的可配置参数。通过为调度单元设置不同的 Min Member 值，我们可以处理许多复杂的场景。</p>
<ul>
<li>例如，为了支持某些<strong>批处理作业</strong>可能需要的 <strong>Gang 调度</strong>，我们可以将它的 Min Member 设置为其 Running Units 数量。这意味着除非我们找到足够的计算资源来一起运行所有作业，否则由调度单元表示的作业不能在集群中进行调度和执行。</li>
<li>另一方面，如果我们使用 Gödel 运行一个<strong>微服务作业</strong>，应该将 Min Member 设置为 1，这意味着只要集群中可以启动任何作业，该作业就是可运行的。此时，这类似于使用 Kubernetes Deployment 部署微服务的情况。</li>
</ul>
<p>目前，我们通常在 ByteDance 生产集群中部署三种或三种以上类型的应用：微服务（在线）、批处理作业（离线）和机器学习（离线）。调度单元 Scheduling Unit 帮助我们填补了在线和离线作业在调度器层面上的语义空白。</p>
<p><strong>原有工具适配：</strong>不过，我们还需要一个 YARN container 适配器，以便将离线作业从原来运行的 YARN 无缝迁移到 Gödel。（YARN具体调度策略见<a href="#refer-anchor-1">[2]</a>）</p>
<ul>
<li><strong>在 YARN 侧</strong>，我们保留了 YARN 框架库，允许用户在不更改配置文件和模板的情况下部署现有作业。</li>
<li><strong>在 Gödel 侧</strong>，<ul>
<li>将 YARN 资源管理器（RM）分配周期决策（allocation cycle decisions）卸载给 Gödel 调度器，并将资源公平分配算法移至 Gödel 调度器。</li>
<li>如图 4 所示，从操作的角度来看，我们创建了多个<strong>自定义资源定义（CRD）</strong>来模仿 YARN 的应用程序（application）、应用程序尝试（app attempts，YARN中会多次尝试运行Application，每次成为一次“运行尝试”，也可称为“运行实例”）和更多对象。<ul>
<li>（1）当 YARN 收到传入请求时，其资源管理器 Resource Manager 会将请求转换为 CRD 和 pod 对应字段，并将请求提交给 Gödel API Server（图里用 Godel Ecosystem 生态来粗略表示）。</li>
<li>（2）资源管理器 Resource Manager 还会订阅 API Server 的更新，以关注更新并做出相应反应。</li>
<li>在这种方法中，我们替换了资源管理器 Resource Manager 的<strong>调度组件 scheduling component</strong>，同时保持了与<strong>接纳管理器 admissions manager</strong>、<strong>应用管理器 application manager</strong> 和<strong>配额管理器 quota manager</strong> 的相同资源管理器操作（Resource Manager’s operations）。</li>
<li>从最终用户的角度来看，迁移是透明的。吞吐量、资源和作业公平性保持不变或更高，已成功将<strong>数十万个节点</strong>从传统的Kubernetes和YARN集群迁移到每天运行<strong>数百万作业</strong>的Gödel集群。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/9-Figure4-1.png" alt="图4：Yodel（YARN + Gödel）架构概述。增加了Gödel调度适配器Scheduler Adaptor以在Gödel和YARN之间转换对象（transform objects）。其次，资源管理器的调度功能（scheduling feature）卸载到Gödel，其余操作保持不变。"><figcaption>图4：Yodel（YARN + Gödel）架构概述。增加了Gödel调度适配器Scheduler Adaptor以在Gödel和YARN之间转换对象（transform objects）。其次，资源管理器的调度功能（scheduling feature）卸载到Gödel，其余操作保持不变。</figcaption></figure></p>
<h3 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h3><p>Gödel 采用与 Kubernetes 类似的顺序来做出计划决策：1)筛选Filter；2)排序Prioritize；3)选择节点Select node。</p>
<ul>
<li><strong>筛选Filter</strong>：调度器注册一系列谓词（predicates，在调度过程中起着“过滤器”的作用，通过过滤掉不符合条件的节点，从而为调度器提供候选节点），寻找符合指定条件的可行节点。<ul>
<li>这种机制用于提高<strong>大规模集群的调度性能</strong>。<ul>
<li>例如，如果节点总数为 1,000 个，需进行评分 scoring 的节点百分比为 10%，则调度器在筛选Filter过程中只需找到 100 个匹配节点。这样就不必筛选所有节点，<strong>减少了需要排序的节点</strong>。</li>
</ul>
</li>
<li>不过，这样做也有<strong>缺陷</strong>，因为作业可能不会被安排到<strong>最合适</strong>的节点上。</li>
</ul>
</li>
<li><strong>排序Prioritize</strong>：这是一种对满足指定条件的节点进行评分 scoring，然后按评分对节点进行排序的方法，有助于为 pod 找到最合适的节点。</li>
<li><strong>选择节点Select node</strong>：选择一个节点作为运行作业的保留节点。该节点在可行节点列表中评分最高。</li>
</ul>
<p>筛选Filter和排序Prioritize是每个调度周期中最<strong>费时（expensive）</strong>的两个步骤。然而，Kubernetes 会<strong>为每个 pod 重复</strong>这两个步骤，导致调度性能不理想。<br>为了让 Gödel 调度器在调度吞吐量方面比 Kubernetes 默认调度器更有效，我们对这些步骤进行了一系列优化。其中最有效的两种机制是<strong>缓存可行节点（Cache Feasible Nodes）</strong>和<strong>减少评分百分比（Reduce Scoring Percentage）</strong>。</p>
<h4 id="缓存可行节点（Cache-Feasible-Nodes）"><a href="#缓存可行节点（Cache-Feasible-Nodes）" class="headerlink" title="缓存可行节点（Cache Feasible Nodes）"></a>缓存可行节点（Cache Feasible Nodes）</h4><p><strong>问题：</strong>筛选Filter和排序Prioritize很<strong>耗时（time-consuming）</strong>。理想情况下，如果能<strong>缩短甚至跳过</strong>这两个步骤，我们就能及时调度更多的 pod。</p>
<p><strong>发现：</strong>ByteDance 的不同部门都在内部使用我们的基础架构。但是，我们观察到，来自<strong>同一用户</strong>的一项作业的 deployment pods 中，约 90%（根据日志分析）通常具有相同的资源请求。</p>
<ul>
<li>例如，社交媒体团队可能要求运行 20,000 个 HTTP Web 服务器，每个服务器配备 4 个 CPU 和 8GB 内存。</li>
<li>同样，一个数据分析团队希望运行一个包含 10,000 个子任务的大数据作业，每个任务需要 1 个 CPU 和 4GB 内存。</li>
<li>当他们提交作业部署到集群中时，每个部署中的所有 pod 都会请求相同的计算资源。</li>
</ul>
<p><strong>思想：</strong>因此，如果通过 “筛选Filter” 和 “排序Prioritize” 流程从一堆节点中选出的可行节点适合一个 pod/任务，那么它也应该适合同一部署中的其他节点。这一观察结果促使我们缓存可行节点，并在更多 pod 中重复使用。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/2023-SOCC-Godel-pseudo-code.png?raw=true" alt="算法1"><figcaption>算法1</figcaption></figure></p>
<p><strong>解决：</strong>算法 1 演示了这一想法背后的伪代码。</p>
<ul>
<li><strong>流程：</strong><ul>
<li>（第20-31行）要运行第一个 pod，我们必须不可避免地检索可行节点列表 a list of feasible nodes，并通过 “筛选Filter” 和 “排序Prioritize” 流程对它们进行评分。<ul>
<li>一般来说，可行列表 the feasible list 中的第一个节点（即得分最高的节点）将被选中运行当前任务。</li>
<li>（第27行）列表中的其他节点将被缓存</li>
</ul>
</li>
<li>（第9-19行）如果下一个 pod 有相同的资源请求，且节点状态未发生变化，则尝试与之匹配。</li>
</ul>
</li>
<li><strong>效果：</strong>这种优化方法在许多情况下将每个运行单元的节点扫描步骤的时间复杂度从 O(n) 降至 O(1)，并显著缩短了整个调度周期。因此，与 vanilla Kubernetes 相比，我们每秒能调度的 pod 数量要多得多。我们将在第 5 节 Evaluation 展示我们的成果。</li>
</ul>
<h4 id="减少评分百分比（Reduce-Scoring-Percentage）"><a href="#减少评分百分比（Reduce-Scoring-Percentage）" class="headerlink" title="减少评分百分比（Reduce Scoring Percentage）"></a>减少评分百分比（Reduce Scoring Percentage）</h4><p><strong>问题：</strong></p>
<ul>
<li>如上段所述，扫描集群 scanning the cluster 以查找可行节点是调度周期中最耗时的步骤。<ul>
<li>尽管我们已通过缓存计算出的可行节点以便重复使用来优化这一步骤，但在作业/部署的每个调度周期中，仍<strong>必须对集群进行至少一次或两次扫描</strong>。<ul>
<li>例如，在每次<strong>调度第一个 pod 时</strong>，或者在<strong>集群状态发生任何变化</strong>（如节点添加/删除）时，都需要扫描集群。</li>
</ul>
</li>
</ul>
</li>
<li>为了找到能够托管指定 pod 的最合适节点，大多数现有的调度器都会<strong>预先选择比所需数量更多的可行节点</strong>作为候选节点。所有这些节点都有足够的资源来运行 pod，目标节点最终将从中选出。<ul>
<li>以 Kubernetes 为例，其默认调度程序会<strong>持续扫描集群</strong>，直到在过滤步骤中获得 <strong>Min（50，集群规模的配置百分比 configured_percentage of cluster size）</strong>可行节点为止。configured_percentage 的值通常大于 5%。</li>
</ul>
</li>
<li>从理论上讲，可行节点列表越长，找到最佳结果的几率就越大。但考虑到节点扫描的成本不可忽略，我们并不建议最大化这个列表。</li>
</ul>
<p><strong>思想：</strong>为了进一步缩短完成时间，Gödel 通过<strong>减少可行节点列表的长度</strong>来调整这一步骤。我们必须在<strong>列表长度和调度质量之间做出权衡</strong>。</p>
<ul>
<li>对于 Gödel，<strong>可行节点列表的最小长度</strong>应该是运行单元 Running Units 的数量。<ul>
<li>它每次都必须为一个调度单元 Scheduling Unit 的所有运行单元 Running Units 找到可行的节点。</li>
</ul>
</li>
</ul>
<p><strong>解决：</strong></p>
<ul>
<li>为了确保我们有足够的候选节点来挑选高质量节点，我们在筛选步骤中选择了（运行单元 Running Units 数量+50）个可行节点。</li>
</ul>
<p><strong>效果：</strong></p>
<ul>
<li>当集群规模较小时，没有明显的区别。</li>
<li>相反，在大规模集群中，尤其是当运行单元数量很少时，这种优化会大大减少节点扫描。</li>
<li>即使一个调度单元中有很多运行单元，导致使用哥德尔技术的第一个 pod 的扫描时间很长，但由于可行节点缓存机制的存在，调度单元的整体调度时间仍然比 vanilla Kubernetes 短得多。</li>
</ul>
<h3 id="评分功能扩展-extend-the-scoring"><a href="#评分功能扩展-extend-the-scoring" class="headerlink" title="评分功能扩展 extend the scoring"></a>评分功能扩展 extend the scoring</h3><p>除了性能优化，我们还扩展了丰富调度策略的评分功能。</p>
<ul>
<li>在 <strong>Kubernetes</strong> 中，评分步骤对候选节点进行排名，以选择最合适的 Pod 放置位置。<ul>
<li>Kubernetes 只支持针对<strong>所有工作负载</strong>的集群级评分策略。</li>
</ul>
</li>
<li><strong>Gödel</strong> 继承了 Kubernetes 的评分机制。<ul>
<li>与 Kubernetes 不同的是，Gödel 调度器允许通过实施<strong>不同的评分插件</strong>来定义<strong>针对特定工作负载</strong>的评分策略。它们在计算分数时会<strong>考虑不同的因素</strong>，以适应表 1 中的异构工作负载。<ul>
<li>例如，为提高整体资源利用率，Gödel 可从<strong>两个维度</strong>进行主机托管。<ul>
<li>（1）它可以将 CPU/Mem 密集型工作负载和网络密集型工作负载放在同一个节点上，以<strong>消耗各种资源</strong>。</li>
<li>（2）它还可以将对延迟敏感的工作负载（如微服务）和批处理作业混合在一起运行。延迟敏感型工作负载的服务水平协议（SLA）将如 4.1 （关键组件 Key Components） 所述得到保证。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>分区（partition）/分片（sharding）/节点随机散装（Node shuffle，图3）之间的区别是什么？</li>
<li>看起来 Gödel 还是在调度之后才使用 binder 进行冲突处理，那么它对 fuxi2.0 的攻击（对冲突的处理过晚）如何成立？</li>
<li>抢占决策是如何做的？是以所有已部署 Pod 为候选、从中选择一个被抢占？感觉会很费时。</li>
<li>目前的翻译中，没有特意区分作业job和任务task，后续会根据原文表述进一步调整。通常作业job和deployment对应，任务task和pod对应。</li>
<li>减少评分百分比（Reduce Scoring Percentage）部分，原文可能有笔误。原文中最终选择的数量是“Scheduling Unit + 50”，但按逻辑应该是一个调度单元 Scheduling Unit 中的运行单元 Running Units 数量的和，即根据 Pod 总数 而非根据 Deployment 总数 来选择筛选数量。</li>
<li>评分功能扩展（extend the scoring）部分，多种类型请求共置操作具体怎么实现没有明确说，感觉具体策略会对调度结果产生很大影响，不过确实不是本文的关注点所在。</li>
<li>Dispatcher部分，多个优先级队列如何汇总到一个优先级队列还是很奇怪</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3620678.3624663">[1] Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://help.aliyun.com/zh/emr/emr-on-ecs/user-guide/yarn-schedulers">[2] YARN调度器<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>统一调度</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】精读笔记6-前沿-字节跳动统一调度架构Gödel-D-实验梳理</title>
    <url>/2025/06/18/literature/literatureNotesIntensive6/</url>
    <content><![CDATA[<h1 id="x1f4d6-《Godel-Unified-Large-Scale-Resource-Management-and-Scheduling-at-ByteDance》"><a href="#x1f4d6-《Godel-Unified-Large-Scale-Resource-Management-and-Scheduling-at-ByteDance》" class="headerlink" title="📖《Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance》</h1><p>2023 年 Virginia大学、字节跳动团队 发表于 CCF-B 类云计算顶级会议 SoCC。</p>
<blockquote>
<p>系列博客：</p>
<ol>
<li><a href="/2024/07/04/literature/literatureNotes45/" title="Gödel-初步略读笔记">Gödel-初步略读笔记</a></li>
<li><a href="/2025/05/16/literature/literatureNotesIntensive4/" title="Gödel-相关工作发展脉络梳理">Gödel-相关工作发展脉络梳理</a></li>
<li><a href="/2025/05/21/literature/literatureNotesIntensive5/" title="Gödel-研究方案梳理">Gödel-研究方案梳理</a></li>
<li><a href="/2025/06/18/literature/literatureNotesIntensive6/" title="Gödel-实验梳理">Gödel-实验梳理</a>
</li>
</ol>
</blockquote>
<h1 id="x1f3af-需求"><a href="#x1f3af-需求" class="headerlink" title="🎯需求"></a><span class="emoji" alias="dart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png?v8">🎯</span>需求</h1><p>字节跳动对生产调度系统的主要要求是在异构机器上调度各种工作负载（如表 1 所列），提高资源利用率，跟上每个计算集群不断增长的机器规模，并实现高吞吐量。</p>
<p>在异构机器上需要调度各种工作负载（如下表）。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/2-Table1-1.png" alt="表1：字节跳动的工作负载分解"><figcaption>表1：字节跳动的工作负载分解</figcaption></figure></p>
<h2 id="x1f6e9-创新"><a href="#x1f6e9-创新" class="headerlink" title="🛩创新"></a><span class="emoji" alias="small_airplane" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e9.png?v8">🛩</span>创新</h2><ul>
<li>为了应对这些挑战，我们提出了一个名为 Gödel 的资源管理和调度系统。<ul>
<li>它为所有业务部门提供了一个统一的计算基础设施，以便在统一的资源池下运行各种工作负载。它将各种工作负载集中在每台机器上，以实现更好的资源利用率和弹性。</li>
<li>Gödel 基于 Kubernetes（事实上的开源容器编排系统）构建，但其核心调度器使用全局共享状态调度器进行了重新发明。相应地，我们还大幅增强了其周边组件。通过替换或增强重要组件，实现适应大规模的各种工作负载。</li>
</ul>
</li>
<li>本文的贡献如下：<ul>
<li>（1）我们引入了一种统一异构资源的<strong>新模式</strong>，以共同定位在线和离线工作负载，从而在超大规模上提供更好的拓扑亲和性、更高的资源弹性和更低的运营开销。</li>
<li>（2）我们在 Kubernetes 的基础上设计并实现了名为 Gödel 的新型资源管理和调度系统。我们对 Kubernetes 进行了多项优化和增强，以提高调度性能。</li>
<li>（3）我们在 ByteDance 的多个数据中心部署了 Gödel，这些数据中心拥有数万台机器，除了在模拟环境中进行密集测试外，我们还在实际工作负载下进行了评估。对 Gödel 的详细评估证明了它的实用性以及如何实现我们的目标。我们的结果表明，Gödel 在各种调度方案中都实现了卓越的性能和效率。</li>
</ul>
</li>
<li>本文报告了我们使用 Gödel 的设计和实施情况。此外，本文还讨论了我们在 ByteDance 大规模生产中开发和运行 Gödel 的经验教训和最佳实践。</li>
</ul>
<h2 id="x1f4ca-实验验证及效果"><a href="#x1f4ca-实验验证及效果" class="headerlink" title="📊实验验证及效果"></a><span class="emoji" alias="bar_chart" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png?v8">📊</span>实验验证及效果</h2><p>本节评估了在模拟的大规模测试环境中 Gödel 的性能。</p>
<ul>
<li>请注意，尽管 Gödel 已<strong>在生产集群中部署了近两年</strong>，但在这些生产集群中进行<strong>密集实验</strong>以评估 Gödel 在高压下的性能是有<strong>风险</strong>的，因为它可能会对正常业务运营造成意外中断。请参阅下一节以了解我们使用 Gödel 的生产经验。</li>
</ul>
<p>我们进行了丰富的实验，以展示 Gödel 调度器：</p>
<ul>
<li>在<strong>单个调度器实例中</strong>与广泛使用的<strong>开源解决方案</strong>（如 Kubernetes 和 Yarn）相比的<strong>调度吞吐量性能</strong>，</li>
<li>以及在<strong>多个调度器实例中</strong>的<strong>可扩展性</strong>。</li>
</ul>
<h3 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h3><p>通过 <strong>Kubemark</strong> 建立了测试平台，它允许我们<strong>改变虚拟节点（也称为空心节点 Hollow Nodes）的数量及其容量</strong>，以测试不同集群规模下 Kubernetes 和 Gödel 的性能。</p>
<ul>
<li>Kubemark 的高保真模拟<strong>与生产集群的主要区别</strong>在于任务执行。<ul>
<li>Kubemark 在每个节点上启动一个 HollowKubelet，假装是一个普通的 Kubelet，消耗请求的计算资源，但并不真正启动任务。</li>
<li>然而，从 Kubemark 集群获得的结果与我们在生产集群中实际运行的 Gödel 调度器的性能非常接近，因为我们的测试床使用与生产集群中运行的相同构建，并应用了生产环境中的相同设置。</li>
</ul>
</li>
</ul>
<h4 id="设置-Settings"><a href="#设置-Settings" class="headerlink" title="设置 Settings"></a>设置 Settings</h4><p>测试平台由 <strong>40 台</strong> Debian x86_64 服务器组成，每台服务器包含 <strong>256 个逻辑 CPU、2TB 内存和 7TB SSD 存储空间</strong>。</p>
<ul>
<li>我们最多使用 21 台服务器作为 Kubemark 主服务器，托管 Gödel 调度器和其他相关组件，包括备份存储集群。</li>
<li>其余 19 台服务器作为空心节点 Hollow Nodes 虚拟托管所有创建的 Pod。</li>
<li>请注意，我们在这里使用了完整的设置用于评估，其中包括所有控制平面组件，这种设置能够支持由 10K - 20K 个生产节点组成的集群。</li>
<li>至于 Gödel 本身，4-6 台服务器（包括备份副本）就足够了。在实践中，Gödel 服务器占整个集群的比例低于 0.05%。</li>
</ul>
<h4 id="合成工作负载-Synthetic-Workloads"><a href="#合成工作负载-Synthetic-Workloads" class="headerlink" title="合成工作负载 Synthetic Workloads"></a>合成工作负载 Synthetic Workloads</h4><p>我们的测试平台允许我们预先配置可部署的工作负载。为了全面了解 Gödel 在不同情况下的性能，我们沿以下维度构建了几种可配置的工作负载：</p>
<ul>
<li>（1）我们配置工作负载中的<strong>任务类型分布</strong>，以确定哪种任务类型<strong>主导工作负载</strong>。例如，我们可以配置由 20% 在线任务和 80% 离线任务组成的目标部署；</li>
<li>（2）我们可以通过配置总体 Pod 数量和提交截止日期来测试不同工作负载提交率。</li>
</ul>
<p>基准 benchmark 会根据配置统一提交作业。</p>
<h4 id="性能指标-Performance-Metrics"><a href="#性能指标-Performance-Metrics" class="headerlink" title="性能指标 Performance Metrics"></a>性能指标 Performance Metrics</h4><p>我们使用<strong>调度吞吐量</strong>作为主要的性能指标。</p>
<ul>
<li><strong>调度吞吐量</strong>是指每秒分配到<strong>首选资源槽</strong>的任务数。<ul>
<li>由于调度器的责任是找到最合适的节点来运行 Pod，因此调度吞吐量计算公式为<strong>每秒在集群中成功创建的 Pod 数量</strong>。</li>
</ul>
</li>
</ul>
<p>我们还报告<strong>冲突的数量</strong>以分析多个调度器实例的性能。</p>
<ul>
<li>请注意，基于 Kubemark 的测试床主要用于评估调度器性能；它不会在集群中执行生产工作负载。</li>
<li>因此，诸如<strong>资源利用率</strong>和<strong>资源弹性</strong>之类的指标无法在此（模拟实验）报告。<ul>
<li>但是，我们将在下一节中展示在生产集群中观察到的这方面结论。</li>
</ul>
</li>
</ul>
<h3 id="可扩展性-Scalability"><a href="#可扩展性-Scalability" class="headerlink" title="可扩展性 Scalability"></a>可扩展性 Scalability</h3><h4 id="在线工作负载-Online-Workloads"><a href="#在线工作负载-Online-Workloads" class="headerlink" title="在线工作负载 Online Workloads"></a>在线工作负载 Online Workloads</h4><h5 id="单调度器实例"><a href="#单调度器实例" class="headerlink" title="单调度器实例"></a>单调度器实例</h5><p>如 <a href="/2025/05/16/literature/literatureNotesIntensive4/" title="Gödel-相关工作发展脉络梳理">Gödel-相关工作发展脉络梳理</a> 所述，Kubernetes默认调度器仅支持<strong>在线工作负载</strong>，并且存在<strong>可扩展性问题</strong>。因此，我们首先通过运行<strong>以在线作业为主</strong>的负载来评估单个 Gödel 调度器实例的性能。</p>
<ul>
<li>我们将Pod提交率配置为<strong>每秒2800个Pod</strong>，这足以使单个调度器饱和。</li>
<li>我们逐步将集群大小从<strong>100个节点</strong>调整到<strong>20,000个节点</strong>，以观察对调度器的可扩展性影响。</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/12-Figure5-1.png" alt="【左-图5】单调度器下的吞吐量对比（作业提交速率为每秒2800个pod）。【中-图6】不同 Gödel 调度器实例下的吞吐量。【右-图7】混合工作负载下的 Gödel 调度吞吐量"><figcaption>【左-图5】单调度器下的吞吐量对比（作业提交速率为每秒2800个pod）。【中-图6】不同 Gödel 调度器实例下的吞吐量。【右-图7】混合工作负载下的 Gödel 调度吞吐量</figcaption></figure></p>
<p>图5显示了Gödel调度器和Kubernetes默认调度器的调度吞吐量。</p>
<ul>
<li>整体：即使只有<strong>一个调度器实例</strong>，Gödel在调度吞吐量方面仍然比纯Kubernetes<strong>高出10倍</strong>。</li>
<li>K8s：在<strong>500个节点</strong>的集群中，Kubernetes的调度吞吐量达到<strong>最佳结果</strong>，而当集群大小<strong>超过5000个节点</strong>时，Kubernetes默认调度器<strong>不再正常工作</strong>。</li>
<li>Gödel调度器：在<strong>5000个节点</strong>时达到<strong>每秒2600个</strong>Pod的<strong>最佳吞吐量</strong>；然后，由于单个实例的不足，调度器的吞吐量<strong>开始下降</strong>。<ul>
<li>与Kubernetes只能支持<strong>最多5000个节点</strong>不同，Gödel即使在<strong>20,000个节点的</strong>集群中也能获得可接受的性能。</li>
</ul>
</li>
<li>K8s+KubeBrain：当集群大小在<strong>5000个节点或更小</strong>时，其<strong>调度吞吐量</strong>几乎是原生K8s（使用ETCD）的两倍，即使集群扩展到<strong>10,000-20,000个节点</strong>，它仍然表现良好。<ul>
<li>Kubernetes难以支持更大集群的一个基本原因是其<strong>存储后端（即ETCD）的不足</strong>。<ul>
<li>为了解决这个问题，字节跳动为Gödel开发了一个名为 <strong>KubeBrain</strong> 的高吞吐量存储后端，以替换ETCD来存储系统元数据。在2022年夏季，我们开源了KubeBrain。</li>
<li>为了公平比较Gödel与Kubernetes，我们将Kubernetes连接到KubeBrain并重新运行了之前的测试。</li>
<li>图5中的橙色条显示了使用KubeBrain作为支持存储的Kubernetes的调度吞吐量。</li>
</ul>
</li>
<li>然而，即使使用KubeBrain，它也只能达到<strong>Gödel约1/10的调度吞吐量</strong>。</li>
</ul>
</li>
</ul>
<p>总结而言，相比之下，Gödel即使在只有一个调度器实例的情况下，也能为大规模集群的编排提供更高的容量。</p>
<h5 id="多调度器实例"><a href="#多调度器实例" class="headerlink" title="多调度器实例"></a>多调度器实例</h5><p>Gödel 被设计为一个分布式调度系统，可以<strong>同时运行多个调度实例</strong>以提高整体调度吞吐量。</p>
<ul>
<li>这个特性对我们业务至关重要，因为我们每天可能操作<strong>数百万个新Pod</strong>。</li>
<li>为了评估<strong>多实例调度的性能</strong>，我们将调度实例<strong>从1个增加到6个</strong>；</li>
<li>在一个<strong>10,000节点集群</strong>中；</li>
<li>运行与上次测试<strong>相同的压力测试</strong>设置，并将Pod提交率增加到<strong>每秒10,000个Pod</strong>，以使多个调度器实例达到饱和状态。</li>
</ul>
<p>为了展示调度实例之间的冲突，这次测试中</p>
<ul>
<li>禁用了“分片模式 sharding mode”（如 <a href="/2025/05/21/literature/literatureNotesIntensive5/" title="Gödel-研究方案梳理">Gödel-研究方案梳理</a> 所述，每个调度器实例只能在<strong>其拥有的分区中</strong>寻找可行节点，以降低冲突率）。</li>
<li>相反，每个调度实例可以从中寻找<strong>整个集群中</strong>最合适的节点。</li>
</ul>
<p>如图6所示，</p>
<ul>
<li>当<strong>2个调度实例</strong>同时运行时，调度吞吐量<strong>显著提高</strong>。</li>
<li>然而，加速并不是线性的。当运行<strong>3-5个实例</strong>时，整体吞吐量<strong>略有增加</strong>。</li>
<li>然后，当添加第<strong>6个调度实例</strong>时，观察到<strong>轻微的退化</strong>。<ul>
<li>原因：同时运行的<strong>实例数量</strong>越多，<strong>冲突数量</strong>就越多（冲突数量参考图6中的蓝色线）。<ul>
<li>冲突是由于<strong>多个调度实例</strong>试图在节点上<strong>消耗相同的资源槽位</strong>。</li>
<li>因此，只有一个请求成功，其他请求将被拒绝并重试。</li>
<li>因此，重试次数与冲突成正比。</li>
<li>高冲突率会负面影响调度吞吐量。</li>
</ul>
</li>
<li>我们正在研究“节点洗牌 node shuffling”等解决方案来解决这个问题。我们将在未来的工作中展示其有效性。</li>
</ul>
</li>
</ul>
<h4 id="离线工作负载-Offline-Workloads"><a href="#离线工作负载-Offline-Workloads" class="headerlink" title="离线工作负载 Offline Workloads"></a>离线工作负载 Offline Workloads</h4><p>Kubernetes 允许运行<strong>自定义调度器</strong>以满足<strong>特定需求</strong>。例如，<strong>k8s-volcano</strong> 是 Kubernetes 社区广泛使用的离线作业调度器。</p>
<ul>
<li>在本实验中，它被选为 YARN 和 Gödel 的对手；</li>
<li>在 <strong>10,000 节点集群</strong>中评估<strong>离线作业调度</strong>的性能；</li>
<li>与先前的案例类似，Pod 提交率仍然是<strong>每秒 2800 个 Pod</strong>。<ul>
<li>离线作业通常<strong>以组group为单位</strong>部署，其中所有作业都<strong>具有相同的资源亲和性</strong>或<strong>必须同时满足</strong>。</li>
<li>在本测试中，<strong>组group大小设置为 10</strong>。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/12-Table3-1.png" alt="表3：离线工作负载的调度吞吐量。"><figcaption>表3：离线工作负载的调度吞吐量。</figcaption></figure></p>
<p>表 3 显示了评估结果。</p>
<ul>
<li>与 k8s-volcano 相比，Gödel 调度吞吐量显著更高（约 <strong>162 倍</strong>）。</li>
<li>即使与擅长调度离线工作负载且已用于此类工作负载超过 10 年的 YARN 相比，Gödel 的吞吐量也<strong>几乎翻倍</strong>。</li>
</ul>
<h3 id="工作负载感知调度-Workloads-Aware-Scheduling"><a href="#工作负载感知调度-Workloads-Aware-Scheduling" class="headerlink" title="工作负载感知调度 Workloads-Aware Scheduling"></a>工作负载感知调度 Workloads-Aware Scheduling</h3><h4 id="异构工作负载混合时的统一调度"><a href="#异构工作负载混合时的统一调度" class="headerlink" title="异构工作负载混合时的统一调度"></a>异构工作负载混合时的统一调度</h4><p>字节跳动生产环境中的工作负载<strong>高度异构</strong>。为了验证 Gödel <strong>是否能够在统一资源池中调度</strong>在线和离线作业，并研究<strong>工作负载类型</strong>对 Gödel 调度器的影响，我们调整了<strong>提交请求的在线/离线百分比</strong>。</p>
<ul>
<li>我们将提交请求中<strong>在线服务的百分比</strong>分别设置为 <strong>0%、25%、50%、75% 和 100%**，其余工作负载为</strong>离线作业**。</li>
<li>基于这两种负载的配置，我们<strong>按比例调整活跃调度器的数量</strong>，以反映调度并发性的实现情况。</li>
<li>我们在一个 <strong>10,000 节点集群</strong>中尝试了<strong>不同的在线/离线组合</strong>。</li>
</ul>
<p>如图 7 所示，我们观察到 Gödel 可以很好地处理在线和离线作业。</p>
<ul>
<li><strong>调度吞吐量非常稳定</strong>，这意味着 Gödel 可以支持异构工作负载，并且不受工作负载混合的影响。</li>
<li>这项测试只使用了<strong>一个调度器实例</strong>，但我们还观察到使用<strong>多个调度器实例</strong>时也有类似的结果。</li>
</ul>
<h4 id="拓扑感知调度"><a href="#拓扑感知调度" class="headerlink" title="拓扑感知调度"></a>拓扑感知调度</h4><p>此外，为了验证我们能否从上述<strong>拓扑感知调度</strong>（将特殊需求POD放置在相同节点上，例如，分配给内存密​​集型POD的CPU内核和存储器优先位于同一CPU插槽上，以便将内存访问延迟最小化）中受益，让我们评估在<strong>有和无拓扑亲和力情况下</strong>的<strong>应用级性能</strong>。</p>
<ul>
<li>以我们的推荐服务为例，它利用AML模型向客户发送准确的广告。为了确保高响应性，预训练模型存储在内存中。</li>
<li>对于此服务，使用<strong>专用CPU集</strong>和<strong>固定NUMA节点</strong>启动Pod会更合适。</li>
</ul>
<p>Gödel适用于此场景，在做出调度决策时，它能够选择具有足够的CPU/内存资源和适当资源分配的节点。为了展示拓扑亲和力的好处，我们：</p>
<ul>
<li>在一个<strong>真实测试集群</strong>中（没说有多少个节点）；</li>
<li>创建了<strong>100个8核-80GB的Pod</strong>；</li>
<li>每个物理节点有<strong>96个逻辑CPU核心和1024GB内存</strong>。</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/13-Table4-1.png" alt="表4：推荐服务的数据获取延迟。"><figcaption>表4：推荐服务的数据获取延迟。</figcaption></figure></p>
<p>表4显示了有和无拓扑感知的数据获取延迟。</p>
<ul>
<li>具有拓扑感知的Gödel能够将<strong>平均和P99延迟</strong>分别<strong>降低21%和22.8</strong>%。</li>
<li>请注意，这些延迟结果是从一个<strong>托管真实节点和流量</strong>的推荐服务集群收集的，而不是空容器。</li>
</ul>
<h3 id="消融实验-优化贡献-Optimization-Contributions"><a href="#消融实验-优化贡献-Optimization-Contributions" class="headerlink" title="消融实验-优化贡献 Optimization Contributions"></a>消融实验-优化贡献 Optimization Contributions</h3><p>为了显著提高Gödel在Kubernetes上的性能，我们除了将其改为分布式而非单实例调度器外，还进行了一系列优化（例如，可行节点缓存和降低评分百分比）。优化细节在 <a href="/2025/05/21/literature/literatureNotesIntensive5/" title="Gödel-研究方案梳理">Gödel-研究方案梳理</a> 中已进行了说明。</p>
<p>我们评估了这些优化，并在本节中展示了每个优化贡献了多少。在这个实验中，</p>
<ul>
<li>我们再次运行了<strong>图5所示的压力测试</strong>。</li>
<li>部署模板中的90%的Pod配置了相同的资源请求，这接近我们在生产集群中观察到的结果。</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/13-Figure8-1.png" alt="图8：调度优化分解"><figcaption>图8：调度优化分解</figcaption></figure></p>
<p>这个实验在一个配置了<strong>一个调度实例</strong>的<strong>10,000节点集群</strong>中进行。我们也观察到了<strong>多个调度实例</strong>场景下类似的结果。</p>
<p>从图8我们可以看出，<strong>可行节点缓存</strong>和<strong>降低评分百分比</strong>的组合对性能的提升**贡献超过90%**。</p>
<ul>
<li>图8(a)分别显示了启用Gödel全功能、禁用可行节点缓存和禁用降低评分百分比时的调度吞吐量。</li>
<li>图8(b)显示了相应的贡献分解。<ul>
<li>对于任何集群规模，可行节点缓存在性能优化中始终发挥着关键作用，其贡献占到了性能提升的<strong>60%以上</strong>。</li>
<li>降低评分百分比的贡献**接近30%**。</li>
</ul>
</li>
</ul>
<h2 id="Godel-生产环境经验与教训-PRODUCTION-EXPERIENCES-AND-LESSONS-LEARNED"><a href="#Godel-生产环境经验与教训-PRODUCTION-EXPERIENCES-AND-LESSONS-LEARNED" class="headerlink" title="Gödel 生产环境经验与教训 PRODUCTION EXPERIENCES AND LESSONS LEARNED"></a>Gödel 生产环境经验与教训 PRODUCTION EXPERIENCES AND LESSONS LEARNED</h2><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5a630c4ee7d075297a26aaad7bfa8ba0cae7d219/14-Figure10-1.png" alt="【左-图9】资源弹性。【中-图10】CPU利用率。【右-图11】GPU分配率。"><figcaption>【左-图9】资源弹性。【中-图10】CPU利用率。【右-图11】GPU分配率。</figcaption></figure></p>
<h3 id="统一调度带来更好的弹性与资源利用率"><a href="#统一调度带来更好的弹性与资源利用率" class="headerlink" title="统一调度带来更好的弹性与资源利用率"></a>统一调度带来更好的弹性与资源利用率</h3><p>在字节跳动，大多数<strong>长期运行</strong>的工作负载运行在<strong>Kubernetes</strong>上，而<strong>短期批处理</strong>工作负载之前运行在<strong>YARN</strong>上。通过统一调度，Gödel通过将它们共置于每台机器上并自动在这些工作负载之间转移资源，为不同的工作负载提供了更好的<strong>资源弹性</strong>。</p>
<ul>
<li>例如，在春节期间，<strong>长期运行的微服务的峰值使用量增加</strong>。<ul>
<li>传统方案下，运维团队需要提前通过从YARN资源池重新分配机器，增加长期运行服务的资源池天数。</li>
<li>Gödel提供了一个统一的资源池，其中跨工作负载的资源调配无缝、透明且按需，这提高了资源管理并减少了运营开销。</li>
</ul>
</li>
</ul>
<p>在图9中，我们看到</p>
<ul>
<li>在2022-08-02早上7点左右，集群的<strong>在线负载增加</strong>，Gödel调度器自动撤销（withdraws）了尽力而为（best-effort）的资源，并驱逐了较低优先级的离线任务。</li>
<li>在2022-08-03凌晨3点左右，看到<strong>在线负载减少</strong>，Gödel调度器自动回收（reclaims）了尽力而为（best-effort）的资源并重新启动了低优先级的离线任务。</li>
<li>上述两个转换在几分钟内无缝完成，无需人工干预。</li>
</ul>
<p>在 Gödel 之前，在我们的生产中，我们</p>
<ul>
<li>实现了一个<strong>附加控制器</strong>来<strong>监视</strong>长时间运行的工作负载的未使用资源（参见 <a href="/2025/05/16/literature/literatureNotesIntensive4/" title="Gödel-相关工作发展脉络梳理">Gödel-相关工作发展脉络梳理</a> ）。</li>
<li>这些未使用资源<strong>提供给YARN</strong>以运行低优先级的可抢占工作负载。</li>
<li>然后，随着在线工作负载需求的增加，相同的资源通过驱逐（evicting）低优先级工作负载重新分配（reassigned）给Kubernetes。<ul>
<li>采用这种方法，我们在共享集群中<strong>提高了CPU利用率至60%**，相比之下，</strong>行业平均CPU利用率不到30%**。</li>
</ul>
</li>
<li>然而，如果资源返回缓慢、并且很少的正在进行的批量任务可以主动终止，有时会遭受尾部延迟的严重影响。</li>
</ul>
<p>在生产中推出 Gödel 调度器后，我们</p>
<ul>
<li>迅速在运行微服务、流、机器学习、有状态应用程序等<strong>工作负载</strong>的包含<strong>数万个节点</strong>的集群中实现了<strong>高达60%的CPU利用率</strong>（图10）。</li>
<li>此外，通过 Gödel 调度器在同一位置共存不同的工作负载类型（co-locating different workload types）并限制工作负载（throttling workloads in place），可以降低被驱逐的概率，更高的吞吐量有可能转化为增加的资源利用率。</li>
</ul>
<h3 id="更好的装箱算法有助于减少碎片化"><a href="#更好的装箱算法有助于减少碎片化" class="headerlink" title="更好的装箱算法有助于减少碎片化"></a>更好的装箱算法有助于减少碎片化</h3><p>在Gödel中实现更好的装箱算法有助于减少 <strong>GPU Pod</strong> 在机器学习工作负载中的碎片化。</p>
<ul>
<li>之前使用YARN时，由于碎片化问题我们<strong>损失了30%的可分配容量</strong>，</li>
<li>而现在这一数字**已经减少到10%**，如图11所示。</li>
</ul>
<h3 id="其它经验教训"><a href="#其它经验教训" class="headerlink" title="其它经验教训"></a>其它经验教训</h3><p>经验教训：在向 Gödel 迁移的过程中，我们遇到了一些挑战，并汲取了以下经验教训。</p>
<ul>
<li>当<strong>集群分配超过60%**时，我们观察到</strong>具有数千个Pod<strong>的作业</strong>冲突率很高**。<ul>
<li>Gang调度或co-scheduling协同调度不允许碎片，这意味着在M个节点上同时调度N个Pod的“全有或全无”方法。</li>
<li>我们在调度器中实现了添加<strong>非保留缓冲节点</strong>（non-reserved buffer nodes，拿一些节点作为缓冲）的功能，当冲突阻止群组中所有Pod调度时，绑定器可以使用这些节点。</li>
</ul>
</li>
<li><strong>实例越多并不一定越好</strong>。<ul>
<li>Gödel支持运行多个调度器实例以提高调度吞吐量。</li>
<li>过度的调度并发（例如，&gt; 5个实例）可能导致高冲突，从而导致吞吐量和调度质量次优。</li>
</ul>
</li>
<li>为了进一步提高调度吞吐量，我们在调度器和绑定器实例中添加了对<strong>并发</strong>的支持，以便每个实例可以运行<strong>多个调度/绑定线程</strong>。这对于提交给单个调度器实例的群组作业尤其有影响。</li>
<li>更建议向<strong>用户展示简化和有限的调度状态</strong>。我们使用了一个<strong>复杂的有限状态机</strong>来跟踪中间调度状态。复杂的状态转换使用户感到困惑，并容易<strong>错误地取消作业部署</strong>。</li>
<li>不时地，值班人员会收到用户的查询，“为什么我的作业没有被调度？”为了减轻操作开销，我们添加了<strong>智能跟踪</strong>，它捕获有关每个硬约束评估的节点、结果、Pod抢占统计、队列配额、实时节点指标等信息。<strong>信息被汇总</strong>并易于用户查询。</li>
</ul>
<h2 id="⛳️未来机会"><a href="#⛳️未来机会" class="headerlink" title="⛳️未来机会"></a>⛳️未来机会</h2><p>未来还有很大的改进空间。</p>
<ol>
<li>目前，dispatcher、scheduler 和 binder 使用的过渡阶段（transitory stages）都是在 ETCD 中（通过 API Server）持久化的。我们正在研究使用<strong>内存缓存</strong>来处理过渡状态，预计其扩展能力将超过 ETCD，吞吐量也将提高近一倍，达到每秒 10,000 个 pod。</li>
<li>此外，Gödel 调度程序的设计基于乐观并发控制，<strong>降低冲突率</strong>对提高吞吐量至关重要。目前，我们观察到的<strong>冲突率平均为 1%**，而在</strong>最糟糕的情况下（集群分配率超过 90%）为 5%<strong>。我们的</strong>目标是实现 0.1% 的冲突率**。</li>
<li>此外，我们还在努力将节点和 pod 智能分配（dispatching）到不同的调度器，以减少冲突并更好地平衡各调度器之间的负载。</li>
<li>最后，我们正在积极研究并在生产中部署Gödel<strong>重调度程序</strong>。重调度器用于监控正在运行的 pod，并采取抢占式行动来减少碎片和资源争用，从而为关键工作负载实现更高的服务质量。重调度程序中实施的一些措施包括对突发工作负载的 CPU 和内存利用率进行节流，平衡集群以实现统一的网络和功耗，以及减少高分配集群中的碎片问题。</li>
<li>多调度器并行导致高冲突，可通过“节点洗牌 node shuffling”等解决方案来解决这个问题。我们将在未来的工作中展示其有效性。</li>
</ol>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>实验环境-为什么用Kubemark？和Kind或Kwok相比有什么优势？</li>
<li>实验环境-“首选资源槽 preferred resource slots”如何定义？如果出现冲突后重调度到次选资源槽，还能够算调度吞吐量吗？<ul>
<li>可能只是笔误，按后续说明，计算方式为“每秒在集群中成功创建的 Pod 数量”。</li>
</ul>
</li>
<li>可扩展性在线工作负载实验-图5中，Gödel为什么在[100,5000]范围内吞吐量逐渐提高？是因为瓶颈为“资源量”，所以无处可调度导致的吞吐量限制？<ul>
<li>根据后续消融实验，可能是因为资源量大时caching更有效（资源量小时在cache中找不到资源就需要重新计算）。</li>
</ul>
</li>
<li>可扩展性在线工作负载实验-为什么不能无限增加调度器？调度器多会有哪些方面的负面影响、尤其是在实践方面？<ul>
<li>在生产经验和教训中总结，只提到了“可能导致高冲突，从而导致吞吐量和调度质量次优”。</li>
</ul>
</li>
<li>可扩展性在线工作负载实验-“节点洗牌 node shuffling”、“分区 partition”和“分片 sharding”之间的区别是什么？各有什么优劣？</li>
<li>可扩展性离线工作负载实验-Volcano的表现为何如此差？感觉和日常认知并不一致，且未说明Volcano和YARN之间的区别。</li>
<li>可扩展性离线工作负载实验-相比在线作业调度效率的2600，离线作业调度效率为何只有不到2000？是因为gang调度的相互依赖导致连锁失败反应？</li>
<li>工作负载感知-统一调度实验-未说明总Pod数量，是什么原因？虽然影响不太大。</li>
<li> 工作负载感知-拓扑感知调度实验-未说明有多少个节点，是什么原因？这可能会影响结果。</li>
<li>消融实验-实验配置说的是“90%的Pod配置了相同的资源请求”，但前文说的是“同一个用户作业的90%Pod配置了相同的资源请求”，不确定两者是否是一个意思（前者假设更强，意味着所有用户所有作业的Pod都配置了相同的资源请求）。</li>
<li>消融实验-如何评估出的百分比？</li>
<li>一个可参考的数据：<strong>行业平均CPU利用率不到30%</strong></li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3620678.3624663">[1] Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>略读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>统一调度</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文】精读笔记7-前沿-Meta跨地域ML训练MAST-B-相关工作发展脉络梳理</title>
    <url>/2025/06/24/literature/literatureNotesIntensive7/</url>
    <content><![CDATA[<h1 id="x1f4d6-《MAST-Global-Scheduling-of-ML-Training-across-Geo-Distributed-Datacenters-at-Hyperscale》"><a href="#x1f4d6-《MAST-Global-Scheduling-of-ML-Training-across-Geo-Distributed-Datacenters-at-Hyperscale》" class="headerlink" title="📖《MAST: Global Scheduling of ML Training across Geo-Distributed Datacenters at Hyperscale》"></a><span class="emoji" alias="book" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8">📖</span>《MAST: Global Scheduling of ML Training across Geo-Distributed Datacenters at Hyperscale》</h1><p>2024 年 Meta、The Ohio State University团队 发表于 CCF-A 类会议 OSDI。</p>
<blockquote>
<p>系列博客：</p>
<ol>
<li><a href="/2025/01/10/literature/literatureNotes78/" title="MAST-初步略读笔记">MAST-初步略读笔记</a></li>
<li><a href="/2025/06/24/literature/literatureNotesIntensive7/" title="MAST-相关工作发展脉络梳理">MAST-相关工作发展脉络梳理</a>
</li>
</ol>
</blockquote>
<h2 id="Meta-公司-机器学习训练背景-Background-of-ML-Training-at-Meta"><a href="#Meta-公司-机器学习训练背景-Background-of-ML-Training-at-Meta" class="headerlink" title="Meta 公司 机器学习训练背景 Background of ML Training at Meta"></a>Meta 公司 机器学习训练背景 Background of ML Training at Meta</h2><h3 id="数据中心和硬件-Datacenter-and-hardware"><a href="#数据中心和硬件-Datacenter-and-hardware" class="headerlink" title="数据中心和硬件 Datacenter and hardware"></a>数据中心和硬件 Datacenter and hardware</h3><p>我们的私有云由数十个区域和数百万台机器组成。</p>
<ul>
<li>一个<strong>区域</strong>包括多个相互靠近的<strong>数据中心</strong>。</li>
<li>跨区域网络<strong>带宽</strong>比区域内数据中心之间的分段带宽低约 10 倍。</li>
<li>数据中心的部分区域被 <strong>ML 训练集群</strong>占据，这些集群的机器配置了<strong>多个 GPU</strong>，并通过 <strong>8x200Gbps RoCE 网络</strong>和 <strong>4x100Gbps 以太网</strong>连接。</li>
</ul>
<p>ML 训练是数据密集型的，因此更倾向于将训练工作负载的<strong>计算和数据放在同一地点</strong>。</p>
<ul>
<li>对于属于同一 ML 训练工作负载的任务，我们倾向于将它们依次放置在同一个机架、集群、数据中心和区域中。</li>
<li>将计算和数据分开放置在不同区域或将任务放置在不同区域<strong>会导致无法接受的性能</strong>。</li>
</ul>
<p>一直以来，<strong>数据中心硬件</strong>都是根据不同时期的具体需求<strong>逐步采购</strong>的，这导致了<strong>硬件类型</strong>在不同地区的<strong>分布不均</strong>。Flux 对此进行了讨论，图 2 也显示了这一点。</p>
<ul>
<li>这种不均衡使得数据和计算<strong>难以同地放置</strong>，需要进行<strong>全局优化</strong>。（根据资源情况，选择数据和计算分布；必要时复制后分别拆开放，而非一股脑堆在一起）</li>
<li>例如，<ul>
<li>由于 Region6 缺少 GPU，因此最好将<strong>基于 CPU</strong> 的分析作业使用的数据放在 Region6。</li>
<li>如果一些基于 GPU 的 ML 训练工作负载与这些分析作业共享相同的数据，我们也应该将它们安排在 Region6 中。</li>
<li>但是，如果此类 ML 工作负载过多，我们就必须将它们的<strong>数据复制到其他区域</strong>并在那里执行。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5ee81aaa497294cc10f6d43b47089516034a52d2/5-Figure2-1.png" alt="图2：硬件在各地区分布不均。存储容量归一化，GPU和CPU按服务器数量归一化。"><figcaption>图2：硬件在各地区分布不均。存储容量归一化，GPU和CPU按服务器数量归一化。</figcaption></figure></p>
<h3 id="动态集群-Dynamic-clusters"><a href="#动态集群-Dynamic-clusters" class="headerlink" title="动态集群 Dynamic clusters"></a>动态集群 Dynamic clusters</h3><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/2024-OSDI-Choudhury-MAST.png" alt="图1：MAST 的概念架构。全局 ML 调度器（GMS）、区域 ML 调度器（RMS）和群集管理器（CM）分别处理不同范围内的不同调度职责：全局、区域和群集。"><figcaption>图1：MAST 的概念架构。全局 ML 调度器（GMS）、区域 ML 调度器（RMS）和群集管理器（CM）分别处理不同范围内的不同调度职责：全局、区域和群集。</figcaption></figure></p>
<p>如图 1 所示，一个名为 <strong>RAS</strong> 的<strong>慢速路径组件</strong>将机器预先分配到动态集群，这在 RAS 论文中被称为 “保留 Reservations”。</p>
<ul>
<li>MAST方案：这样，区域 ML 调度器（RMS）就可以<strong>只搜索</strong> ML 动态集群内的机器，从而实现扩展。<ul>
<li>MAST 消耗 RAS 的输出（即 RAS 创建的动态群集），MAST 的调度决策不会影响或反馈到 RAS。</li>
</ul>
</li>
<li>RAS方案：通常，一个 ML 动态集群包括 GPU 和 CPU 机器。为了更新动态群集，RAS 将一个区域内的<strong>所有机器</strong>作为输入，并对每个动态群集的<strong>预定规模</strong>和对某些<strong>硬件类型的偏好</strong>进行新的或更新的规范。<ul>
<li>RAS 提出了一个 MIP 问题，用于为动态集群分配机器。</li>
</ul>
</li>
</ul>
<p>我们将简要介绍 RAS，详情请读者参阅 RAS 论文<a href="#refer-anchor-1"><sup>[2]</sup></a>。</p>
<ul>
<li>背景：RAS 可确保分配给动态群集的机器<strong>总容</strong>量满足管理员指定的要求，并包含足够的<strong>缓冲区</strong>来处理随机和<strong>相关机器故障</strong>。<strong>相关故障</strong>（如数据中心内大型故障域的断电）可能导致数以万计的机器无法使用。</li>
<li>方案：<ul>
<li>RAS 将动态集群的机器分布在<strong>不同的故障域</strong>中，以确保在大型故障域发生故障时，仍有足够的健康机器可用。</li>
<li>此外，RAS 还能确保每个数据中心的<strong>计算机器与存储机器比例适当</strong>，从而减少不必要的跨数据中心通信。</li>
<li>最后，RAS 会<strong>定期</strong>（如每 30 分钟）<strong>重新运行优</strong>化，以适应变化。<ul>
<li>例如，当新的数据中心上线时，RAS 可以将动态群集的机器进一步分散到这些新的数据中心，从而减少处理相关故障所需的缓冲区大小。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="机器学习训练负载-ML-training-workload"><a href="#机器学习训练负载-ML-training-workload" class="headerlink" title="机器学习训练负载 ML training workload"></a>机器学习训练负载 ML training workload</h3><p>一个训练<strong>工作负载 workload</strong>包含多个异构<strong>作业 jobs</strong>，每个作业 job 包含多个同构的<strong>任务 tasks</strong>，而任务 task 被映射到一个Linux容器 container中。因此，层次结构是<strong>工作负载→作业→任务</strong>。</p>
<ul>
<li>例如，一个训练工作负载可能包括（1）执行反向传播训练的训练作业；（2）数据预处理作业；（3）参数服务器作业；以及（4）评估作业，用于评估生成的模型。</li>
</ul>
<p><strong>工作负载</strong>的所有<strong>任务</strong>需要<strong>集体调度Gang Scheduling</strong>，即它们必须一起分配。</p>
<ul>
<li>理论上，如果一个训练作业使用的GPU少于一个完整的GPU，可以使用多实例GPU（MIG）或其他软件方法将<strong>GPU共享</strong>给多个作业。</li>
<li>然而，在实践中，由于训练数据量庞大，我们所有的训练作业至少使用一个完整的GPU。</li>
</ul>
<h3 id="数据仓库-Data-warehouse"><a href="#数据仓库-Data-warehouse" class="headerlink" title="数据仓库 Data warehouse"></a>数据仓库 Data warehouse</h3><p>我们的数据仓库在<strong>三级层次</strong>结构中存储了<strong>数十亿字节</strong>的数据：数百个命名空间→数百万个表→数十亿个数据分区。</p>
<ul>
<li>分区<strong>一旦创建就不可更改</strong>，但可以在现有表中添加新的分区。<ul>
<li>例如，”user_activity “表每天都可以添加一个新分区，以记录过去 24 小时内的用户活动。</li>
</ul>
</li>
</ul>
<p>有些数据分区同时用于 ML 训练和数据分析，如 Spark 和 Presto。我们开发了一个名为 “俄罗斯方块”（Tetris）的系统，它能在考虑到 Spark、Presto 和 ML 训练作业的数据访问模式的情况下，<strong>优化跨区域的数据放置</strong>。</p>
<h3 id="负载共享数据分区-Sharing-of-data-partitions-by-workload"><a href="#负载共享数据分区-Sharing-of-data-partitions-by-workload" class="headerlink" title="负载共享数据分区 Sharing of data partitions by workload"></a>负载共享数据分区 Sharing of data partitions by workload</h3><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://figures.semanticscholar.org/5ee81aaa497294cc10f6d43b47089516034a52d2/5-Figure3-1.png" alt="图 3：数据分区的热度，以访问每个分区的不同 ML 工作负载的数量来衡量。"><figcaption>图 3：数据分区的热度，以访问每个分区的不同 ML 工作负载的数量来衡量。</figcaption></figure></p>
<p>图 3 显示，数据分区经常被多个 ML 工作负载<strong>共享</strong>。</p>
<ul>
<li>在 P50、P90 和 P99 百分位数下，一个数据分区分别被 3、17 和 45 个不同的工作负载共享。</li>
<li><strong>数据共享</strong>使<strong>数据放置问题</strong>变得复杂，因为<strong>跨区域迁移</strong>一个<strong>数据分区</strong>可能需要迁移依赖于该分区的多个<strong>工作负载</strong>。</li>
<li>此外，为了防止负载失衡，有必要在<strong>多个区域复制</strong>最热门的分区，否则大量依赖于这些分区的工作负载将被迫在少数区域运行。</li>
</ul>
<h3 id="机器学习训练作业的长执行时间-Long-execution-time-of-ML-training-jobs"><a href="#机器学习训练作业的长执行时间-Long-execution-time-of-ML-training-jobs" class="headerlink" title="机器学习训练作业的长执行时间 Long execution time of ML training jobs"></a>机器学习训练作业的长执行时间 Long execution time of ML training jobs</h3><p>ML 训练是<strong>资源密集型</strong>工作，可能需要<strong>很长时间</strong>才能完成。</p>
<ul>
<li>在 Meta，ML 训练工作负载的完成时间往往是 Spark 分析作业的 <strong>10 倍</strong>。因此，<strong>次优放置决策</strong>会对 ML 训练产生更大的负面影响。这就是本文所述的<strong>穷举搜索原则</strong>的动机。</li>
<li>此外，当<strong>工作负载在更多机器上、运行更长时间</strong>时，工作负载调度吞吐量也会下降。<ul>
<li>因此，如图 1 所示，<strong>分别在全局和区域范围内管理</strong>作业队列和资源分配是可行的，而不是在导致更多<strong>碎片</strong>的小集群级别进行管理。</li>
</ul>
</li>
</ul>
<h3 id="配额逾期作业抢占-Quota-and-job-preemption"><a href="#配额逾期作业抢占-Quota-and-job-preemption" class="headerlink" title="配额逾期作业抢占 Quota and job preemption"></a>配额逾期作业抢占 Quota and job preemption</h3><p>不同优先级的训练工作负载按<strong>优先级</strong>分配容量配额。</p>
<ul>
<li>如果一个团队的容量使用<strong>在配额内</strong>，MAST 保证在一定的延迟内启动其培训工作负载。</li>
<li>一旦团队<strong>超出配额</strong>，他们仍可提交工作负载，以最低优先级伺机运行，但当更高优先级的工作负载到来时，他们将被抢占。</li>
<li>因此，出于实验目的的低优先级工作负载总是能充分利用培训集群。</li>
<li>调度新的工作负载往往涉及抢占低优先级作业的复杂决策。这种复杂性使简单的联邦管理器Federation Manager变得不那么有效。</li>
</ul>
<h3 id="用于恢复的检查点-Checkpoint-for-recovery"><a href="#用于恢复的检查点-Checkpoint-for-recovery" class="headerlink" title="用于恢复的检查点 Checkpoint for recovery"></a>用于恢复的检查点 Checkpoint for recovery</h3><p>训练工作负载会定期检查其状态。</p>
<ul>
<li>当一台机器出现<strong>故障</strong>时，集群管理器会在替代机器上<strong>重启</strong>工作负载，使其能够从检查点恢复状态并继续执行。</li>
<li>在为高优先级工作负载<strong>抢占</strong>低优先级工作负载之前，集群管理器还会<strong>保存一个检查点</strong>，以便日后恢复。</li>
<li>随着我们不断<strong>缩短保存检查点所需的时间</strong>，我们正逐步<strong>增加检查点的频率</strong>，以尽量减少恢复过程中两个检查点之间丢失的工作量。</li>
<li>随着大型语言模型的训练工作量不断增加，恢复成本也越来越高，这一点变得越来越重要。</li>
</ul>
<h3 id="对于机器学习-非机器学习负载，使用分离的应用级调度器-Separate-application-level-schedulers-for-ML-and-non-ML-workloads"><a href="#对于机器学习-非机器学习负载，使用分离的应用级调度器-Separate-application-level-schedulers-for-ML-and-non-ML-workloads" class="headerlink" title="对于机器学习/非机器学习负载，使用分离的应用级调度器 Separate application-level schedulers for ML and non-ML workloads"></a>对于机器学习/非机器学习负载，使用分离的应用级调度器 Separate application-level schedulers for ML and non-ML workloads</h3><p>如图 1 所示，ML 和非ML 工作负载由不同的调度器管理。</p>
<ul>
<li>Twine 的可扩展架构允许所有工作负载共享一个用于机器和容器管理的通用集群管理器，同时针对特定工作负载采用不同的应用级调度器。例如，<ul>
<li>MAST 用于 ML 训练工作负载，</li>
<li>Shard Manager 用于有状态数据库，</li>
<li>Turbine 用于流处理，</li>
<li>Chronos 用于分析作业。</li>
</ul>
</li>
<li>每个应用级调度程序都针对特定目的进行了优化。例如，<ul>
<li>Shard Manager 针对数据库的高可用性进行了优化，</li>
<li>Chronos 针对短期分析作业的高调度吞吐量进行了优化，</li>
<li>而 MAST 则针对高质量决策和数据-GPU 主机托管进行了优化。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>本文可作为“跨地域供需不均衡”的论据，且强调了“不同区域资源供应有差异”是历史原因、由于设备都是逐批采购的。</li>
<li>RAS和我们之前考虑过的“动态分区”很像，在Godel中提过这种方案原本在字节服务器中也有使用、但是调整频率还不够高所以有滞后性。</li>
<li>META对任务层级的命名和业界主流不同，不知道是出于什么考虑。不过本质都是一样的三层架构。<ol>
<li>META：<strong>工作负载→作业→任务</strong></li>
<li>业界主流：<strong>作业→任务→实例</strong></li>
</ol>
</li>
<li>Gang Scheduling要求的是“作业中的实例”（或用本文说法就是“工作负载中的任务”），在Volcano的yaml文件中也可以看出。</li>
<li>在META，每个训练作业至少使用一个GPU（因为训练数据量大）。这是一个比较强的假设，可能是为了方便后续形式化定义和算法说明。但想来是有优化空间的。</li>
<li>数据分区（数据集）放置和复制的权衡会是一个需要解决的问题。</li>
<li>在META，ML 训练工作负载的完成时间往往是 Spark 分析作业的 <strong>10 倍</strong>，是一个可以使用的论据。</li>
<li>如果仅在一个小集群内调度，可能会产生更多的碎片，从而导致调度吞吐量下降。</li>
<li>当存在抢占决策时，多调度器运行会变得更困难。</li>
<li>在META中，Twine架构下可同时使用Shard Manager、Turbine、Chronos等管理器，但多种架构同时运行会对MAST调度带来什么影响没有明确？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.usenix.org/conference/osdi24/presentation/choudhury">[1] Choudhury, Arnab, et al. “MAST: Global scheduling of ML training across Geo-Distributed datacenters at hyperscale.” 18th USENIX Symposium on Operating Systems Design and Implementation (OSDI 24). 2024.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://dl.acm.org/doi/10.1145/3477132.3483578">[2] Andrew Newell, Dimitrios Skarlatos, Jingyuan Fan, Pavan Kumar, Maxim Khutornenko, Mayank Pundir, Yirui Zhang, Mingjun Zhang, Yuanlai Liu, Linh Le, Brendon Daugherty, Apurva Samudra, Prashasti Baid, James Kneeland, Igor Kabiljo, Dmitry Shchukin, Andre Rodrigues, Scott Michelson, Ben Christensen, Kaushik Veeraraghavan, and Chunqiang Tang. RAS: Continuously Optimized Region-Wide Datacenter Resource Allocation. In Proceedings of the 28th ACM Symposium on Operating Systems Principles, 2021.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>论文</category>
        <category>精读</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>大规模</tag>
        <tag>跨地域</tag>
        <tag>机器学习训练</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/10/19/test/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a class="link"   href="https://hexo.io/" >Hexo<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>! This is your very first post. Check <a class="link"   href="https://hexo.io/docs/" >documentation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> for more info. If you get any problems when using Hexo, you can find the answer in <a class="link"   href="https://hexo.io/docs/troubleshooting.html" >troubleshooting<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> or you can ask me on <a class="link"   href="https://github.com/hexojs/hexo/issues" >GitHub<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure></div>

<p>More info: <a class="link"   href="https://hexo.io/docs/writing.html" >Writing<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure></div>

<p>More info: <a class="link"   href="https://hexo.io/docs/server.html" >Server<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure></div>

<p>More info: <a class="link"   href="https://hexo.io/docs/generating.html" >Generating<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure></div>

<p>More info: <a class="link"   href="https://hexo.io/docs/deployment.html" >Deployment<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>测试</category>
      </categories>
  </entry>
  <entry>
    <title>MathJax Test</title>
    <url>/2023/05/16/test/testMathJax/</url>
    <content><![CDATA[<p><mjx-container class="MathJax" jax="SVG" display="true" width="full" style="min-width: 35.234ex;"><svg style="vertical-align: -1.943ex; min-width: 35.234ex;" xmlns="http://www.w3.org/2000/svg" width="100%" height="5.018ex" role="img" focusable="false"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(0.0181,-0.0181) translate(0, -1359)"><g data-mml-node="math"><g data-mml-node="mtable" transform="translate(2078,0) translate(-2078,0)"><g transform="translate(0 1359) matrix(1 0 0 -1 0 0) scale(55.25)"><svg data-table="true" preserveAspectRatio="xMidYMid" viewBox="5708.8 -1359 1 2217.9"><g transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mlabeledtr" transform="translate(0,-151)"><g data-mml-node="mtd"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(345,0)"><path data-c="210F" d="M182 599Q182 611 174 615T133 619Q118 619 114 621T109 630Q109 636 114 656T122 681Q125 685 202 688Q272 695 286 695Q304 695 304 684Q304 682 295 644T282 597Q282 592 360 592H399Q430 592 445 587T460 563Q460 552 451 541L442 535H266L251 468Q247 453 243 436T236 409T233 399Q233 395 244 404Q295 441 357 441Q405 441 445 417T485 333Q485 284 449 178T412 58T426 44Q447 44 466 68Q485 87 500 130L509 152H531H543Q562 152 562 144Q562 128 546 93T494 23T415 -13Q385 -13 359 3T322 44Q318 52 318 77Q318 99 352 196T386 337Q386 386 346 386Q318 386 286 370Q267 361 245 338T211 292Q207 287 193 235T162 113T138 21Q128 7 122 4Q105 -12 83 -12Q66 -12 54 -2T42 26L166 530Q166 534 161 534T129 535Q127 535 122 535T112 534Q74 534 74 562Q74 570 77 576T84 585T96 589T109 591T124 592T138 592L182 595V599Z"></path></g><g data-mml-node="mfrac" transform="translate(907,0)"><g data-mml-node="mi" transform="translate(400.5,676)"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><rect width="1127" height="60" x="120" y="220"></rect></g><g data-mml-node="mi" transform="translate(2274,0)"><path data-c="1D713" d="M161 441Q202 441 226 417T250 358Q250 338 218 252T187 127Q190 85 214 61Q235 43 257 37Q275 29 288 29H289L371 360Q455 691 456 692Q459 694 472 694Q492 694 492 687Q492 678 411 356Q329 28 329 27T335 26Q421 26 498 114T576 278Q576 302 568 319T550 343T532 361T524 384Q524 405 541 424T583 443Q602 443 618 425T634 366Q634 337 623 288T605 220Q573 125 492 57T329 -11H319L296 -104Q272 -198 272 -199Q270 -205 252 -205H239Q233 -199 233 -197Q233 -192 256 -102T279 -9Q272 -8 265 -8Q106 14 106 139Q106 174 139 264T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 299 34 333T82 404T161 441Z"></path></g><g data-mml-node="mo" transform="translate(3202.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(4258.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mfrac" transform="translate(5036.6,0)"><g data-mml-node="msup" transform="translate(384.2,676)"><g data-mml-node="mi"><path data-c="210F" d="M182 599Q182 611 174 615T133 619Q118 619 114 621T109 630Q109 636 114 656T122 681Q125 685 202 688Q272 695 286 695Q304 695 304 684Q304 682 295 644T282 597Q282 592 360 592H399Q430 592 445 587T460 563Q460 552 451 541L442 535H266L251 468Q247 453 243 436T236 409T233 399Q233 395 244 404Q295 441 357 441Q405 441 445 417T485 333Q485 284 449 178T412 58T426 44Q447 44 466 68Q485 87 500 130L509 152H531H543Q562 152 562 144Q562 128 546 93T494 23T415 -13Q385 -13 359 3T322 44Q318 52 318 77Q318 99 352 196T386 337Q386 386 346 386Q318 386 286 370Q267 361 245 338T211 292Q207 287 193 235T162 113T138 21Q128 7 122 4Q105 -12 83 -12Q66 -12 54 -2T42 26L166 530Q166 534 161 534T129 535Q127 535 122 535T112 534Q74 534 74 562Q74 570 77 576T84 585T96 589T109 591T124 592T138 592L182 595V599Z"></path></g><g data-mml-node="mn" transform="translate(646.1,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><rect width="1578" height="60" x="120" y="220"></rect></g><g data-mml-node="msup" transform="translate(6854.6,0)"><g data-mml-node="mi"><path data-c="2207" d="M46 676Q46 679 51 683H781Q786 679 786 676Q786 674 617 326T444 -26Q439 -33 416 -33T388 -26Q385 -22 216 326T46 676ZM697 596Q697 597 445 597T193 596Q195 591 319 336T445 80L697 596Z"></path></g><g data-mml-node="mn" transform="translate(866,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mi" transform="translate(8124.1,0)"><path data-c="1D713" d="M161 441Q202 441 226 417T250 358Q250 338 218 252T187 127Q190 85 214 61Q235 43 257 37Q275 29 288 29H289L371 360Q455 691 456 692Q459 694 472 694Q492 694 492 687Q492 678 411 356Q329 28 329 27T335 26Q421 26 498 114T576 278Q576 302 568 319T550 343T532 361T524 384Q524 405 541 424T583 443Q602 443 618 425T634 366Q634 337 623 288T605 220Q573 125 492 57T329 -11H319L296 -104Q272 -198 272 -199Q270 -205 252 -205H239Q233 -199 233 -197Q233 -192 256 -102T279 -9Q272 -8 265 -8Q106 14 106 139Q106 174 139 264T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 299 34 333T82 404T161 441Z"></path></g><g data-mml-node="mo" transform="translate(8997.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(9997.6,0)"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g><g data-mml-node="mi" transform="translate(10766.6,0)"><path data-c="1D713" d="M161 441Q202 441 226 417T250 358Q250 338 218 252T187 127Q190 85 214 61Q235 43 257 37Q275 29 288 29H289L371 360Q455 691 456 692Q459 694 472 694Q492 694 492 687Q492 678 411 356Q329 28 329 27T335 26Q421 26 498 114T576 278Q576 302 568 319T550 343T532 361T524 384Q524 405 541 424T583 443Q602 443 618 425T634 366Q634 337 623 288T605 220Q573 125 492 57T329 -11H319L296 -104Q272 -198 272 -199Q270 -205 252 -205H239Q233 -199 233 -197Q233 -192 256 -102T279 -9Q272 -8 265 -8Q106 14 106 139Q106 174 139 264T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 299 34 333T82 404T161 441Z"></path></g></g></g></g></svg><svg data-labels="true" preserveAspectRatio="xMaxYMid" viewBox="1278 -1359 1 2217.9"><g data-labels="true" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mtd" id="mjx-eqn:1" transform="translate(0,599)"><text data-id-align="true"></text><g data-idbox="true" transform="translate(0,-750)"><g data-mml-node="mtext"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(389,0)"></path><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" transform="translate(889,0)"></path></g></g></g></g></svg></g></g></g></g></svg></mjx-container></p>
]]></content>
      <categories>
        <category>测试</category>
      </categories>
  </entry>
  <entry>
    <title>新功能测试</title>
    <url>/2023/05/16/test/testNewFunction/</url>
    <content><![CDATA[<ul>
<li><p>首页缩略图</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">thumbnail: &quot;IMAGE_LINK&quot;</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>首页文章摘要：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">excerpt: &quot;这是文章摘要 This is the excerpt of the post&quot;</span><br></pre></td></tr></table></figure></div>
<p>or</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">excerpt: false  # 关闭文章摘要</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>文章页头图</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">cover: &quot;IMAGE_LINK&quot;</span><br></pre></td></tr></table></figure></div>
<p>或</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">banner: &quot;IMAGE_LINK&quot;</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<blockquote>
<p>如果你设置了 首页头图 thumbnail(opens in a new tab) ，文章封面也会自动选择为 thumbnail 链接，当然，banner 和 cover 的优先级最高。<br>如果你不想设置文章封面却想保留首页头图，请把 cover 或者 banner 设置成 false</p>
</blockquote>
]]></content>
      <categories>
        <category>测试</category>
      </categories>
  </entry>
  <entry>
    <title>【操作系统】计算机硬件架构基础：CPU执行原理与架构演进</title>
    <url>/2025/07/07/os/os-architecture/</url>
    <content><![CDATA[<!-- > 本系列《操作系统基础知识》计划分为以下几篇，点击查看其它内容。 -->
<!-- > 1. <a href="/2025/07/07/os/os-architecture/" title="计算机硬件架构基础：CPU执行原理与架构演进">计算机硬件架构基础：CPU执行原理与架构演进</a> -->
<!-- > 2. （待续）操作系统内存管理原理 -->
<!-- > 3. （待续）操作系统进程调度机制 -->
<!-- > 4. （待续）操作系统文件系统设计 -->


<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>计算机硬件是操作系统运行的基础，理解硬件架构对于深入学习操作系统至关重要。本文基于小林coding的优质内容<a href="#refer-anchor-1"><sup>[1]</sup></a>，系统梳理计算机硬件的工作原理，重点解析CPU执行程序的机制、32/64位架构的区别，以及x86/x64/ARM64等主流架构的演进历程。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><h2 id="为什么需要理解硬件架构？"><a href="#为什么需要理解硬件架构？" class="headerlink" title="为什么需要理解硬件架构？"></a>为什么需要理解硬件架构？</h2><p>在深入学习操作系统之前，理解计算机硬件架构是必不可少的基础。操作系统作为硬件和软件之间的桥梁，其设计理念和实现机制都深深植根于底层硬件特性。</p>
<h3 id="核心问题"><a href="#核心问题" class="headerlink" title="核心问题"></a>核心问题</h3><ol>
<li><strong>CPU如何执行程序？</strong> - 理解指令执行的基本流程</li>
<li><strong>32位与64位架构的区别？</strong> - 掌握位宽对性能的影响</li>
<li><strong>不同架构的演进历程？</strong> - 了解技术发展的历史脉络</li>
</ol>
<h1 id="🧠问题回答"><a href="#🧠问题回答" class="headerlink" title="🧠问题回答"></a>🧠问题回答</h1><h2 id="问题一：CPU是如何执行程序的？"><a href="#问题一：CPU是如何执行程序的？" class="headerlink" title="问题一：CPU是如何执行程序的？"></a>问题一：CPU是如何执行程序的？</h2><h3 id="基本执行流程"><a href="#基本执行流程" class="headerlink" title="基本执行流程"></a>基本执行流程</h3><p>CPU执行程序的基本流程可以概括为：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">程序编译 → CPU读取指令 → 执行指令 → 跳转下一条指令</span><br></pre></td></tr></table></figure></div>

<ol>
<li><strong>程序编译</strong>：高级语言程序被编译成汇编代码，最终转换为机器指令</li>
<li><strong>指令读取</strong>：CPU从内存中读取指令到指令寄存器</li>
<li><strong>指令执行</strong>：CPU解析指令并执行相应的操作</li>
<li><strong>地址跳转</strong>：程序计数器更新，指向下一条指令</li>
</ol>
<h3 id="冯诺依曼架构"><a href="#冯诺依曼架构" class="headerlink" title="冯诺依曼架构"></a>冯诺依曼架构</h3><p>现代计算机都基于冯诺依曼架构，包含五个核心设备：</p>
<h4 id="CPU内部设备"><a href="#CPU内部设备" class="headerlink" title="CPU内部设备"></a>CPU内部设备</h4><ul>
<li><strong>运算器</strong>：执行算术和逻辑运算</li>
<li><strong>控制器</strong>：协调各组件工作，控制指令执行流程</li>
<li><strong>寄存器组</strong>：（为优化而生，不包含在五个核心组件之内）<ul>
<li><strong>通用寄存器</strong>：存储计算过程中的临时数据</li>
<li><strong>程序计数器（PC）</strong>：存储当前执行指令的内存地址</li>
<li><strong>指令寄存器（IR）</strong>：存储当前正在执行的指令</li>
</ul>
</li>
</ul>
<h4 id="外部设备"><a href="#外部设备" class="headerlink" title="外部设备"></a>外部设备</h4><ul>
<li><strong>存储器</strong>：存储程序和数据</li>
<li><strong>输入设备</strong>：接收外部数据</li>
<li><strong>输出设备</strong>：输出计算结果</li>
</ul>
<h4 id="总线连接（连接CPU内外部设备，不包含在五个核心设备之内）"><a href="#总线连接（连接CPU内外部设备，不包含在五个核心设备之内）" class="headerlink" title="总线连接（连接CPU内外部设备，不包含在五个核心设备之内）"></a>总线连接（连接CPU内外部设备，不包含在五个核心设备之内）</h4><ul>
<li><strong>地址总线</strong>：指定要访问的内存地址</li>
<li><strong>控制总线</strong>：传输控制信号</li>
<li><strong>数据总线</strong>：传输实际数据</li>
</ul>
<h3 id="关键技术细节"><a href="#关键技术细节" class="headerlink" title="关键技术细节"></a>关键技术细节</h3><h4 id="电压表示"><a href="#电压表示" class="headerlink" title="电压表示"></a>电压表示</h4><ul>
<li><strong>0和1的表示</strong>：通过低电压和高电压来表示二进制数据</li>
<li><strong>信号传输</strong>：总线上的电信号传输数字信息</li>
</ul>
<h4 id="总线带宽"><a href="#总线带宽" class="headerlink" title="总线带宽"></a>总线带宽</h4><ul>
<li><strong>地址总线带宽</strong>：决定可访问的内存地址范围</li>
<li><strong>数据总线带宽</strong>：决定一次传输的数据量</li>
<li><strong>带宽匹配</strong>：CPU位宽应与总线带宽匹配以获得最佳性能</li>
</ul>
<h4 id="位宽影响"><a href="#位宽影响" class="headerlink" title="位宽影响"></a>位宽影响</h4><ul>
<li><strong>32位CPU</strong>：理论上可访问4GB内存空间</li>
<li><strong>64位CPU</strong>：可访问巨大的内存空间（理论上限为2^64字节）</li>
</ul>
<h2 id="问题二：32位与64位架构的区别和优劣？"><a href="#问题二：32位与64位架构的区别和优劣？" class="headerlink" title="问题二：32位与64位架构的区别和优劣？"></a>问题二：32位与64位架构的区别和优劣？</h2><h3 id="CPU层面"><a href="#CPU层面" class="headerlink" title="CPU层面"></a>CPU层面</h3><h4 id="计算能力"><a href="#计算能力" class="headerlink" title="计算能力"></a>计算能力</h4><ul>
<li><strong>32位CPU</strong>：一次最多处理32位数据</li>
<li><strong>64位CPU</strong>：一次最多处理64位数据</li>
<li><strong>性能影响</strong>：对于32位以内的计算，两者性能相近；64位计算时，64位CPU有明显优势</li>
</ul>
<h4 id="内存寻址"><a href="#内存寻址" class="headerlink" title="内存寻址"></a>内存寻址</h4><ul>
<li><strong>32位限制</strong>：理论上最多访问4GB内存</li>
<li><strong>64位优势</strong>：可访问巨大的内存空间</li>
</ul>
<h3 id="软件层面"><a href="#软件层面" class="headerlink" title="软件层面"></a>软件层面</h3><h4 id="指令集差异"><a href="#指令集差异" class="headerlink" title="指令集差异"></a>指令集差异</h4><ul>
<li><strong>32位软件</strong>：使用32位指令集</li>
<li><strong>64位软件</strong>：使用64位指令集</li>
<li><strong>兼容性</strong>：64位CPU通常向下兼容32位软件</li>
</ul>
<h4 id="性能影响"><a href="#性能影响" class="headerlink" title="性能影响"></a>性能影响</h4><ul>
<li><strong>寄存器数量</strong>：64位架构通常有更多寄存器</li>
<li><strong>指令效率</strong>：64位指令可以处理更大数据块</li>
<li><strong>内存带宽</strong>：64位架构可以更高效地利用内存带宽</li>
</ul>
<h3 id="操作系统层面"><a href="#操作系统层面" class="headerlink" title="操作系统层面"></a>操作系统层面</h3><p>操作系统也是一种特殊的软件，其位宽决定了：</p>
<ul>
<li><strong>内存管理能力</strong>：64位系统可以管理更大内存</li>
<li><strong>进程地址空间</strong>：64位系统为每个进程提供更大地址空间</li>
<li><strong>系统调用接口</strong>：64位系统提供64位系统调用</li>
</ul>
<h2 id="问题三：主流处理器架构的演进历程"><a href="#问题三：主流处理器架构的演进历程" class="headerlink" title="问题三：主流处理器架构的演进历程"></a>问题三：主流处理器架构的演进历程</h2><h3 id="x86架构（Intel-AMD）"><a href="#x86架构（Intel-AMD）" class="headerlink" title="x86架构（Intel/AMD）"></a>x86架构（Intel/AMD）</h3><h4 id="历史发展"><a href="#历史发展" class="headerlink" title="历史发展"></a>历史发展</h4><ul>
<li><strong>起源</strong>：1978年Intel推出8086处理器，开创x86架构</li>
<li><strong>演进</strong>：从16位（8086）→32位（80386）→64位（x86-64）</li>
<li><strong>特点</strong>：复杂指令集（CISC），指令丰富但复杂</li>
</ul>
<h4 id="代表产品"><a href="#代表产品" class="headerlink" title="代表产品"></a>代表产品</h4><ul>
<li><strong>早期产品</strong>：Intel 8086、80286、80386、80486</li>
<li><strong>经典产品</strong>：Intel Pentium系列（奔腾）</li>
<li><strong>现代产品</strong>：<ul>
<li><strong>Intel</strong>：Core系列（i3/i5/i7/i9）、Xeon系列（服务器）</li>
<li><strong>AMD</strong>：Athlon系列、Phenom系列、Ryzen系列、EPYC系列</li>
</ul>
</li>
</ul>
<h3 id="x64架构（x86-64-AMD64）"><a href="#x64架构（x86-64-AMD64）" class="headerlink" title="x64架构（x86-64/AMD64）"></a>x64架构（x86-64/AMD64）</h3><h4 id="技术特点"><a href="#技术特点" class="headerlink" title="技术特点"></a>技术特点</h4><ul>
<li><strong>64位扩展</strong>：在x86基础上扩展64位能力</li>
<li><strong>向下兼容</strong>：完全兼容32位x86软件</li>
<li><strong>性能提升</strong>：更大的内存空间和更高的计算能力</li>
</ul>
<h4 id="代表产品-1"><a href="#代表产品-1" class="headerlink" title="代表产品"></a>代表产品</h4><ul>
<li><strong>Intel</strong>：Core系列（i3/i5/i7/i9）、Xeon系列</li>
<li><strong>AMD</strong>：Ryzen系列、EPYC系列</li>
</ul>
<h3 id="ARM64架构"><a href="#ARM64架构" class="headerlink" title="ARM64架构"></a>ARM64架构</h3><h4 id="技术特点-1"><a href="#技术特点-1" class="headerlink" title="技术特点"></a>技术特点</h4><ul>
<li><strong>精简指令集</strong>：RISC架构，指令简单高效</li>
<li><strong>低功耗设计</strong>：同等性能下功耗更低</li>
<li><strong>模块化设计</strong>：可根据需求定制处理器核心</li>
</ul>
<h4 id="代表产品-2"><a href="#代表产品-2" class="headerlink" title="代表产品"></a>代表产品</h4><ul>
<li><strong>移动设备</strong>：<ul>
<li><strong>Apple</strong>：A系列芯片（A14、A15、M1、M2等）</li>
<li><strong>Qualcomm</strong>：Snapdragon系列</li>
<li><strong>Huawei</strong>：Kirin系列</li>
<li><strong>Samsung</strong>：Exynos系列</li>
</ul>
</li>
<li><strong>服务器</strong>：Amazon Graviton、Ampere Altra等</li>
</ul>
<h3 id="架构对比总结"><a href="#架构对比总结" class="headerlink" title="架构对比总结"></a>架构对比总结</h3><table>
<thead>
<tr>
<th>特性</th>
<th>x86</th>
<th>x64</th>
<th>ARM64</th>
</tr>
</thead>
<tbody><tr>
<td>指令集</td>
<td>CISC</td>
<td>CISC</td>
<td>RISC</td>
</tr>
<tr>
<td>位宽</td>
<td>32位</td>
<td>64位</td>
<td>64位</td>
</tr>
<tr>
<td>功耗</td>
<td>较高</td>
<td>较高</td>
<td>较低</td>
</tr>
<tr>
<td>性能</td>
<td>中等</td>
<td>高</td>
<td>中等-高</td>
</tr>
<tr>
<td>应用场景</td>
<td>传统PC</td>
<td>主流计算</td>
<td>移动设备+新兴领域</td>
</tr>
</tbody></table>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://xiaolincoding.com/os/1_hardware/how_cpu_run.html">[1] 小林coding - 图解系统<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://blog.csdn.net/qq_41063141/article/details/131444672">[2] x86_64和ARM64的区别以及发展 - CSDN博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://blog.csdn.net/qq_24433609/article/details/125991550">[3] x86-64、amd64、arm、aarch64 都是些什么？ - CSDN博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.cnblogs.com/zhaoqingqing/p/13145115.html">[4] x86 x64 arm64的区别  - 博客园<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.intel.cn/content/www/cn/zh/processors/processor-numbers.html">[5] Intel处理器产品线 - Intel官网<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.amd.com/zh-cn/products/specifications.html">[6] AMD处理器产品线 - AMD官网<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.arm.com/zh-TW/products/silicon-ip-cpu">[7] ARM架构发展历程 - ARM官网<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>计算机架构</tag>
        <tag>CPU</tag>
        <tag>硬件原理</tag>
      </tags>
  </entry>
  <entry>
    <title>testpage</title>
    <url>/2018/07/04/test/testpage/</url>
    <content><![CDATA[<h1 id="1"><a href="#1" class="headerlink" title="1"></a>1</h1><h2 id="2"><a href="#2" class="headerlink" title="2"></a>2</h2><h3 id="3"><a href="#3" class="headerlink" title="3"></a>3</h3><h4 id="4"><a href="#4" class="headerlink" title="4"></a>4</h4><h5 id="5"><a href="#5" class="headerlink" title="5"></a>5</h5>]]></content>
      <categories>
        <category>测试</category>
      </categories>
  </entry>
  <entry>
    <title>【集群】K8S集群解析——大规模能力</title>
    <url>/2024/07/23/k8s/k8s-DataPlane/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><ul>
<li>好奇Kubernetes（下简称 K8S）中是如何管理节点/Pod状态信息的，以及当规模增大时（尤其是节点规模）会在什么地方出现瓶颈，因此开展相关调研。</li>
<li>本文首先介绍K8S整体组件架构，再定位大规模下的数据面瓶颈，最后细分介绍状态数据瓶颈相关组件架构。</li>
</ul>
<h1 id="🖼️背景——K8S组件"><a href="#🖼️背景——K8S组件" class="headerlink" title="🖼️背景——K8S组件"></a>🖼️背景——K8S组件</h1><p>在K8S官方文档中有对组件情况的相关介绍<a href="#refer-anchor-1"><sup>[1]</sup></a>，对象包含资源和业务两方面，组件包含<strong>决策组件-控制平面组件</strong>、<strong>执行组件-Node组件</strong>和<strong>其他组件-插件</strong>。</p>
<ul>
<li>被管理对象：<ul>
<li>1）资源：一组工作机器，被称为节点（Node）。分为Master和Worker。</li>
<li>2）业务：一组应用负载，被称为Pod。Pod是一组关系紧密的容器的集合，是K8S管理的原子单位。<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://kubernetes.io/images/docs/components-of-kubernetes.svg"
                      alt="Kubernetes 集群的组件"
                ><figcaption>Kubernetes 集群的组件</figcaption></figure></li>
</ul>
</li>
<li>管理组件：<ul>
<li>1）<strong>【决策】控制平面组件（Control Plane Components）</strong>：为集群做出全局决策，例如调度资源和检测/响应集群事件。<ul>
<li>1.1）kube-apiserver：API服务器，是控制平面的前端。负责<strong>公开</strong>K8S API，负责处理<strong>接受请求</strong>的工作。</li>
<li>1.2）etcd：一致且高可用的键值<strong>存储</strong>，是K8S所有集群数据的后台数据库。</li>
<li>1.3）kube-scheduler：调度器，是控制平面的后端之一。负责<strong>监视</strong>新创建的、未指定运行节点的Pods，并<strong>选择</strong>节点来让Pod在上面运行。</li>
<li>1.4）kube-controller-manager：控制器管理器，是控制平面的后端之一。负责<strong>运行控制器进程</strong>（逻辑上有多个控制器，实际上在一个文件中实现并被编译成一个进程），例如：<ul>
<li>节点控制器（Node Controller）：负责在节点出现故障时进行通知和响应</li>
<li>任务控制器（Job Controller）：监测代表一次性任务的 Job 对象，然后创建 Pod 来运行这些任务直至完成</li>
<li>端点分片控制器（EndpointSlice controller）：填充端点分片（EndpointSlice）对象（以提供 Service 和 Pod 之间的链接）。</li>
<li>服务账号控制器（ServiceAccount controller）：为新的命名空间创建默认的服务账号（ServiceAccount）。</li>
</ul>
</li>
<li>1.5）cloud-controller-manager：云控制管理器，是控制平面的后端之一。负责将集群<strong>连接到云提供商</strong>的API，嵌入了特定于云平台的控制逻辑，在本地运行集群是不需要该组件。</li>
</ul>
</li>
<li>2）<strong>【执行】Node组件</strong>：在每个节点上运行，负责维护Pod和提供K8S环境。<ul>
<li>2.1）kubelet：节点代理。在每个节点上运行，负责保证容器（containers）都被包装进指定Pod。具体来说，接收PodSpec描述（上面传下来的旨意），确保这些 PodSpec 中描述的容器处于运行状态且健康。</li>
<li>2.2）kube-proxy：节点网络代理。在每个节点上运行，实现K8S服务（Service）。负责维护节点上的一些网络规则，以此允许从集群内外部的网络会话与Pod进行网络通信。</li>
<li>2.3）容器运行时（Container Runtime）：容器运行基础组件。负责使K8S能够有效运行容器，负责管理容器的执行和全生命周期。<ul>
<li>Kubernetes 支持许多容器运行环境，例如 containerd、 CRI-O 以及 Kubernetes CRI (容器运行环境接口) 的其他任何实现。</li>
</ul>
</li>
</ul>
</li>
<li>3）<strong>【其他】插件（Addons）</strong>：提供集群级别的功能，使用 Kubernetes 资源（DaemonSet、 Deployment 等）实现集群功能。 <ul>
<li>3.1）DNS：域名系统（Domain Name System，DNS）服务器，管理K8S内部域名服务。<em>其他插件都并非严格意义上的必需组件，但几乎所有K8S集群都应该有DNS插件。</em></li>
<li>3.2）Web 界面（仪表盘）：基于Web的用户界面。负责提供可视化界面，使用户可以管理集群中运行的应用程序以及集群本身，并进行故障排除。</li>
<li>3.3）容器资源监控：监控服务器。负责将关于容器的一些常见的时间序列度量值保存到一个集中的数据库中， 并提供浏览这些数据的界面。</li>
<li>3.4）集群层面日志：日志服务器。负责将容器的日志数据保存到一个集中的日志存储中， 这种集中日志存储提供搜索和浏览接口。</li>
<li>3.5）网络插件：实现容器网络接口（CNI）规范的软件组件。它们负责为 Pod 分配 IP 地址，并使这些 Pod 能在集群内部相互通信。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="🧠大规模瓶颈"><a href="#🧠大规模瓶颈" class="headerlink" title="🧠大规模瓶颈"></a>🧠大规模瓶颈</h1><ul>
<li>根据K8S官方文档，K8S单个集群支持的最大节点数为5,000<a href="#refer-anchor-2"><sup>[2]</sup></a>。更具体地说：<ul>
<li>每个节点的 Pod 数量不超过 110；</li>
<li>节点数不超过 5,000；</li>
<li>Pod 总数不超过 150,000；</li>
<li>容器总数不超过 300,000。</li>
</ul>
</li>
<li>自然而然地，产生一个好奇：是什么限制了K8S支持的规模？换句话说，当规模增长时，什么组件会出现瓶颈？<ul>
<li>由于本地不具备这么充裕的资源做测试，因此只能通过总结他人经验。好在大佬们已有过相关经验总结：个人博客<a href="#refer-anchor-3"><sup>[3]</sup></a>、阿里巴巴<a href="#refer-anchor-4"><sup>[4]</sup></a>、字节跳动<a href="#refer-anchor-5"><sup>[5-7]</sup></a>。</li>
</ul>
</li>
</ul>
<h2 id="个人博客：《从1k节点增加到5k节点遇到的瓶颈》-3"><a href="#个人博客：《从1k节点增加到5k节点遇到的瓶颈》-3" class="headerlink" title="个人博客：《从1k节点增加到5k节点遇到的瓶颈》[3]"></a>个人博客：《从1k节点增加到5k节点遇到的瓶颈》<a href="#refer-anchor-3"><sup>[3]</sup></a></h2><ul>
<li>简介：K8S自从1.6起便号称可以承载5000个以上的节点，但是在实践中，从10+到5000的路上，还存在许多问题。</li>
</ul>
<h3 id="1-500-个节点"><a href="#1-500-个节点" class="headerlink" title="1 ~ 500 个节点"></a>1 ~ 500 个节点</h3><p>问题：（集群）kubectl 有时会出现 timeout （ p.s. kubectl -v=6 可以显示所有 API 细节指令）<br>原因：ETCD吞吐异常——网络存储写入效率低，需使用每台机器本地临时存储（local temp drive，猜测起到类似于cache的作用）。（从100ms优化至200us）<br>追问：但本地存储带来的问题是什么？全局一致性问题如何解决？</p>
<h3 id="500-1000-个节点"><a href="#500-1000-个节点" class="headerlink" title="500 ~ 1000 个节点"></a>500 ~ 1000 个节点</h3><p>问题：（业务）出现 kube-apiserver 每秒从 etcd 上读取过多数据（高达500mb）情况<br>原因：数据处理业务（如Fluentd、Datadog）抓取数据频率过高</p>
<h3 id="1000-～-2000-个节点"><a href="#1000-～-2000-个节点" class="headerlink" title="1000 ～ 2000 个节点"></a>1000 ～ 2000 个节点</h3><p>问题1：（业务）默认调度策略下，无法再写入数据，报错 cascading failure<br>原因1：业务分散导致网络瓶颈，引发连锁错误</p>
<p>问题2：（业务）解决问题1的集聚调度策略下，经常出现 DNS 查询不到的情况（随机发生）<br>原因2：KubeDNS被集中在单台服务器，请求量过大</p>
<p>问题3：（业务）每次新节点建立起来，docker image pull 都要花 30 分钟<br>原因3：某个大镜像造成堵塞，其他镜像排队时间长</p>
<p>问题4：（业务）业务需要的节点间网络流量，可以达到 10-15GBit/s，但是由于 Flannel 所以导致流量会降到 2GBit/s<br>原因4：Flannel存在性能限制</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>主要出现性能瓶颈的原因还是“业务的巨大网络流量需求”与“有限集群网络”的冲突，这部分与IaaS层集群管理的关系不大，与PaaS层业务管理的关系较大。<br>在IaaS层集群管理方面，可以看到仅仅在500节点时就出现Etcd性能瓶颈，在本文中主要是由于网络传输导致的。本文未细化说明具体解决方案与带来的问题，例如时效性和一致性的权衡。</p>
<h2 id="阿里巴巴：《万级规模K8S集群全局高可用体系之美》-4"><a href="#阿里巴巴：《万级规模K8S集群全局高可用体系之美》-4" class="headerlink" title="阿里巴巴：《万级规模K8S集群全局高可用体系之美》[4]"></a>阿里巴巴：《万级规模K8S集群全局高可用体系之美》<a href="#refer-anchor-4"><sup>[4]</sup></a></h2><ul>
<li>简介：介绍K8S单集群规模不断增大带来的“如何持续保障SLO”。ASI 单集群规模支撑能够超过K8S社区的 5000 台，是非常有意思且具备极大挑战的，本文总结了ASI单集群规模从100到10,000的发展之路。<blockquote>
<p>ASI：Alibaba Serverless infrastructure，阿里巴巴针对云原生应用设计的统一基础设施，ASI 是阿里公共云服务 ACK 的阿里集团企业版。</p>
</blockquote>
</li>
</ul>
<h3 id="性能瓶颈分析"><a href="#性能瓶颈分析" class="headerlink" title="性能瓶颈分析"></a>性能瓶颈分析</h3><ol>
<li>Etcd出现大量读写延迟</li>
<li>控制器无法及时感知数据变化</li>
<li>kube-apiserver查询pods/nodes延迟高，甚至导致oom（Out Of Memory，指系统内存已用完）</li>
</ol>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://ucc.alicdn.com/pic/developer-ecology/8cf1d986cfb040998d715ded91f56e2f.png?x-oss-process=image/resize,w_1400/format,webp"
                      alt="当集群节点超过5000时会发生什么？"
                ><figcaption>当集群节点超过5000时会发生什么？</figcaption></figure></p>
<h3 id="能力列举"><a href="#能力列举" class="headerlink" title="能力列举"></a>能力列举</h3><ol>
<li>【100-&gt;4,000节点】Apiserver性能优化：客户端cache优先；服务端watch优化+cache索引优化。Etcd性能优化：并发读优化；存储上限优化；多备灾能力优化。</li>
<li>【4,000-&gt;8,000节点】</li>
<li>【8,000-&gt;10,000节点】</li>
</ol>
<p>除此之外，还有字节跳动《字节跳动大规模K8s集群管理实践》<a href="#refer-anchor-5"><sup>[5-7]</sup></a>等博客对相关内容进行了介绍，未来将对这些内容进行解析。</p>
<h1 id="🔨状态信息管理组件"><a href="#🔨状态信息管理组件" class="headerlink" title="🔨状态信息管理组件"></a>🔨状态信息管理组件</h1><ul>
<li>根据上述组件介绍，初步分析<a href="#%EF%B8%8F%E8%83%8C%E6%99%AFk8s%E7%BB%84%E4%BB%B6">背景部分</a>所提到的1.2、2.1、3.3负责核心数据的获取和存储，其它控制组件都或多或少需要依赖数据进行相关管理功能的实现。<ul>
<li>1）特别地，状态信息存取方面完全由Etcd负责，因此第一个问题是“数据通过Etcd存取的全过程如何？还涉及哪些组件？以什么样的模式进行状态同步（批次同步or增量同步）？”</li>
<li>2）在上述多篇博客中都提到过Etcd存在性能瓶颈，第二个问题是“Etcd的瓶颈出现在哪个过程？具体量化值为多少？”</li>
<li>3）更进一步地，由于字节已经提出了相应方案解决Etcd的性能瓶颈，第三个问题是“新解决方案/其它组件的代价是什么？是否在解决效率的另一面带来了新的质量问题？” </li>
</ul>
</li>
</ul>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="&#x1f9e0;疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">&#x1f9e0;</span>疑问</h2><ol>
<li>K8S组件中，为什么将“DNS”、“网络插件”归为“插件”？难道不是必须的吗？</li>
<li>看到字节跳动关注一些多集群协同<a href="#refer-anchor-8"><sup>[8]</sup></a>、集群监控<a href="#refer-anchor-9"><sup>[9]</sup></a>的工作，这些场景下的难点是什么？</li>
<li>看到阿里巴巴对 apiserver 和 Etcd 进行了大量优化，难点是否可以归纳为两个：读写慢；数据多。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://kubernetes.io/zh-cn/docs/concepts/overview/components/" >[1] Kubernetes 组件<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link"   href="https://kubernetes.io/zh-cn/docs/setup/best-practices/cluster-large/" >[2] 大规模集群的注意事项<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link"   href="https://www.cnblogs.com/lfl17718347843/p/14480495.html" >[3] k8s集群从一千节点增加到五千台节点遇到的瓶颈<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link"   href="https://developer.aliyun.com/article/784105" >[4] 【深度】阿里巴巴万级规模 K8s 集群全局高可用体系之美<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-5"></div>

<p><a class="link"   href="https://www.51cto.com/article/738336.html" >[5] 字节跳动大规模K8s集群管理实践<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-6"></div>

<p><a class="link"   href="https://www.infoq.cn/article/v81xeo9ooel5elv8m0mk" >[6] 字节跳动高性能 Kubernetes 元信息存储方案探索与实践<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-7"></div>

<p><a class="link"   href="https://www.infoq.cn/article/4i9jtegqlxgvcfeom9gr" >[7] SoCC 论文解读：字节跳动如何在大规模集群中进行统一资源调度<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-8"></div>

<p><a class="link"   href="https://cloud.tencent.com/developer/article/2309967" >[8] 字节跳动开源KubeAdmiral：基于 K8s 的新一代多集群编排调度引擎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-9"></div>

<p><a class="link"   href="https://www.infoq.cn/article/mu-1bfhnmrdd0kybgpxx" >[9] 字节跳动容器化场景下的性能优化实践<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】K8s中Deployment、StatefulSet、DaemonSet介绍与异同</title>
    <url>/2025/03/28/k8s/k8s-Deployment-StatefulSet-DaemonSet/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在Kubernetes中，Deployment、StatefulSet和DaemonSet是三种常见的工作负载类型，它们用于管理Pod的部署和生命周期。本文将介绍这三种工作负载的基本概念、特点、适用场景，并对它们的异同进行详细分析。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><p>在容器编排中，如何高效地管理和调度Pod是一个核心问题。Kubernetes提供了多种工作负载类型来满足不同的需求，其中Deployment、StatefulSet和DaemonSet是最常用的三种类型。理解它们的特点和适用场景对于设计和优化Kubernetes集群至关重要。</p>
<h1 id="🧠思路"><a href="#🧠思路" class="headerlink" title="🧠思路"></a>🧠思路</h1><ol>
<li>介绍Deployment、StatefulSet和DaemonSet的基本概念。</li>
<li>探讨每种工作负载的特点和适用场景。</li>
<li>比较它们之间的异同。</li>
<li>总结如何根据实际需求选择合适的工作负载类型。</li>
</ol>
<h1 id="🔨解决"><a href="#🔨解决" class="headerlink" title="🔨解决"></a>🔨解决</h1><p>总结而言，DaemonSet是一类，Deployment和StatefulSet是一类。</p>
<ul>
<li>DaemonSet不关心Pod副本数量，只关心Pod在每个节点上的运行情况。<a href="#refer-anchor-5"><sup>[5]</sup></a>专用于部署守护进程，与节点绑定，确保每个节点上都有对应的守护进程副本运行。对于需要在一批节点上运行且无需用户干预的持续性后台任务非常有用。应用场景：<ul>
<li>集群存储守护程序，如 glusterd 、 ceph 要部署在每个节点上以提供持久性存储；</li>
<li>节点监视守护进程，如 Prometheus 监控集群，可以在每个节点上运行一个 node-exporter 进程来收集监控节点的信息；</li>
<li>日志收集守护程序，如 fluentd 或 logstash ，在每个节点上运行以收集容器的日志</li>
</ul>
</li>
<li>Deployment和StatefulSet分别专用于部署 <strong>==无状态服务==</strong> 和 <strong>==有状态服务==</strong> 。所谓的“有状态”，主要是针对Pod发生re-schedule后仍然要保持之前的状态（网络标识/持久化存储），根据官方建议是满足以下任一需求：<a href="#refer-anchor-5"><sup>[5]</sup></a><ul>
<li>稳定的、唯一的网络标识。</li>
<li>稳定的、持久的存储。</li>
<li>有序的、优雅的部署和伸缩。</li>
<li>有序的、优雅的删除和停止。</li>
<li>有序的、自动的滚动更新。</li>
</ul>
</li>
</ul>
<h2 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>Deployment 是 Kubernetes 中最常用的工作负载类型，用于管理无状态应用的部署和生命周期。它通过声明式的方式定义Pod的副本数、更新策略等。</p>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul>
<li><strong>无状态</strong>：适用于无状态应用，例如Web服务。</li>
<li><strong>滚动更新</strong>：支持零停机时间的滚动更新和回滚。</li>
<li><strong>副本管理</strong>：可以轻松扩展或缩减Pod的副本数。</li>
</ul>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><ul>
<li>Web服务、API服务等无状态应用。</li>
<li>需要频繁更新的应用。</li>
</ul>
<hr>
<h2 id="StatefulSet"><a href="#StatefulSet" class="headerlink" title="StatefulSet"></a>StatefulSet</h2><h3 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h3><p>StatefulSet 是 Kubernetes 中用于管理有状态应用的工作负载类型。它确保Pod的部署顺序、网络标识和存储是稳定的。</p>
<h3 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h3><ul>
<li><strong>有状态</strong>：每个Pod都有唯一的标识（如<code>pod-0</code>、<code>pod-1</code>）。</li>
<li><strong>稳定的网络标识</strong>：每个Pod都有固定的DNS名称。</li>
<li><strong>持久化存储</strong>：支持为每个Pod分配独立的持久化存储卷。</li>
</ul>
<h3 id="适用场景-1"><a href="#适用场景-1" class="headerlink" title="适用场景"></a>适用场景</h3><ul>
<li>数据库（如MySQL、PostgreSQL）。</li>
<li>分布式系统（如ZooKeeper、Kafka）。</li>
</ul>
<hr>
<h2 id="DaemonSet"><a href="#DaemonSet" class="headerlink" title="DaemonSet"></a>DaemonSet</h2><h3 id="概念-2"><a href="#概念-2" class="headerlink" title="概念"></a>概念</h3><p>DaemonSet 是 Kubernetes 中用于确保每个节点上运行一个Pod的工作负载类型。它通常用于运行集群范围的后台任务。</p>
<h3 id="特点-2"><a href="#特点-2" class="headerlink" title="特点"></a>特点</h3><ul>
<li><strong>每节点一个Pod</strong>：确保每个节点上都有一个Pod运行。</li>
<li><strong>自动适配新节点</strong>：当新节点加入集群时，DaemonSet会自动在新节点上创建Pod。</li>
<li><strong>适用于后台任务</strong>：如日志收集、监控代理等。</li>
</ul>
<h3 id="适用场景-2"><a href="#适用场景-2" class="headerlink" title="适用场景"></a>适用场景</h3><ul>
<li>日志收集（如Fluentd）。</li>
<li>监控代理（如Prometheus Node Exporter）。</li>
<li>网络插件（如Calico、Flannel）。</li>
</ul>
<hr>
<h2 id="Deployment、StatefulSet和DaemonSet的异同"><a href="#Deployment、StatefulSet和DaemonSet的异同" class="headerlink" title="Deployment、StatefulSet和DaemonSet的异同"></a>Deployment、StatefulSet和DaemonSet的异同</h2><table>
<thead>
<tr>
<th>特性</th>
<th>Deployment</th>
<th>StatefulSet</th>
<th>DaemonSet</th>
</tr>
</thead>
<tbody><tr>
<td><strong>状态管理</strong></td>
<td>无状态</td>
<td>有状态</td>
<td>无状态</td>
</tr>
<tr>
<td><strong>Pod标识</strong></td>
<td>不固定</td>
<td>固定</td>
<td>不固定</td>
</tr>
<tr>
<td><strong>存储</strong></td>
<td>不支持持久化存储</td>
<td>支持持久化存储</td>
<td>不支持持久化存储</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>Web服务、API服务</td>
<td>数据库、分布式系统</td>
<td>日志收集、监控代理</td>
</tr>
<tr>
<td><strong>Pod分布</strong></td>
<td>根据副本数分布</td>
<td>根据副本数分布</td>
<td>每节点一个Pod</td>
</tr>
<tr>
<td><strong>更新方式</strong></td>
<td>滚动更新</td>
<td>滚动更新</td>
<td>手动更新</td>
</tr>
</tbody></table>
<hr>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><p>通过对Deployment、StatefulSet和DaemonSet的学习，我对Kubernetes中不同工作负载的特点和适用场景有了更深入的理解。在实际项目中，选择合适的工作负载类型可以显著提高系统的可靠性和可维护性。例如，对于无状态的Web服务，可以选择Deployment；对于需要持久化存储的数据库，可以选择StatefulSet；而对于需要在每个节点上运行的后台任务，则可以选择DaemonSet。</p>
<p>在未来的工作中，我会尝试给出三种方案的具体代码案例<a href="#refer-anchor-4"><sup>[4]</sup></a>，最好能够找到合适的场景将其作为实际应用（也许找些面经会是不错的方向）。也会考虑继续了解其他组件，如Replication Controller（RC）和ReplicaSet（RS）<a href="#refer-anchor-6"><sup>[6]</sup></a>。</p>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://kubernetes.io/docs/concepts/workloads/controllers/" >[1] Kubernetes官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link"   href="https://kubernetes.io/docs/concepts/workloads/controllers/" >[2] Deployment vs StatefulSet vs DaemonSet<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link"   href="https://www.oreilly.com/library/view/kubernetes-patterns/9781492050285/" >[3] Kubernetes Patterns<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link"   href="https://blog.51cto.com/chenfenglove/7343355" >[4] k8s 说一下deployment，statefulset，daemonset 的区别<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-5"></div>

<p><a class="link"   href="https://www.cnblogs.com/zhanchenjin/p/17332200.html" >[5] kubernetes Deployment/Daemonset/StatefulSet区别<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-6"></div>

<p><a class="link"   href="https://www.cnblogs.com/ShineLeBlog/p/17749647.html" >[6] K8S：几种资源调度方式-RC/RS/Deployment/StatefulSet/DaemonSet<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>K8s</tag>
        <tag>Deployment</tag>
        <tag>StatefulSet</tag>
        <tag>DaemonSet</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】K8S集群搭建记录——故障排除：xxx:6443 was refused</title>
    <url>/2023/10/31/k8s/k8s-apiserver/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>搭建基于vm的k8s-on-k8s时发生崩溃，记录排查及修复过程。<br>核心问题在于，vm 中搭建上层 k8s 时将下层配置文件修改了。<br>后续应当考虑 vm 使用独立目录而非和下层服务器共享目录。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><p>使用kubectl控制k8s的任何指令都报错：</p>
<div class="code-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pods</span></span><br><span class="line">The connection to the server xxx.xxx.xxx.xxx:6443 was refused - did you specify the right host or port?</span><br></pre></td></tr></table></figure></div>
<p>（其中 <code>xxx.xxx.xxx.xxx</code> 是服务器 ip，在此隐去）</p>
<h1 id="🧠思路"><a href="#🧠思路" class="headerlink" title="🧠思路"></a>🧠思路</h1><ol>
<li>首先追本溯源，找到上游真正的问题。</li>
<li>对于真正的问题，检查如何修复。</li>
</ol>
<h2 id="⛳️追本溯源"><a href="#⛳️追本溯源" class="headerlink" title="⛳️追本溯源"></a>⛳️追本溯源</h2><h3 id="🤔问题1）是哪个服务崩溃？（6443-端口所对应）"><a href="#🤔问题1）是哪个服务崩溃？（6443-端口所对应）" class="headerlink" title="🤔问题1）是哪个服务崩溃？（6443 端口所对应）"></a>🤔问题1）是哪个服务崩溃？（6443 端口所对应）</h3><ul>
<li>根据相关资料<a href="#refer-anchor-1"><sup>[1]</sup></a>，监听 6443 端口的是 Kubernetes API Server。<blockquote>
<p>默认情况下，Kubernetes API 服务器在第一个非 localhost 网络接口的 6443 端口上进行监听， 受 TLS 保护。</p>
</blockquote>
</li>
</ul>
<h3 id="🤔问题2）为什么崩溃？"><a href="#🤔问题2）为什么崩溃？" class="headerlink" title="🤔问题2）为什么崩溃？"></a>🤔问题2）为什么崩溃？</h3><p>自底向上，先检查基础服务 docker、kubelet 是否正常运行，再进一步检查 docker 上运行的 api-server 等上层k8s服务是否正常运行。</p>
<ul>
<li><p>基础服务状态<br>使用<code>systemctl status ${SERVER_NAME}</code>可以看到名为SERVER_NAME的服务状态，使用<code>journalctl -fu ${SERVER_NAME}</code>可以看到名为SERVER_NAME的服务日志。</p>
<ol>
<li>docker<div class="code-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl status docker</span></span><br><span class="line">● docker.service - Docker Application Container Engine</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since 一 2023-10-30 16:32:15 CST; 19h ago</span><br><span class="line">     Docs: https://docs.docker.com</span><br><span class="line"> Main PID: 1097921 (dockerd)</span><br><span class="line">    Tasks: 17</span><br><span class="line">   Memory: 50.2M</span><br><span class="line">   CGroup: /system.slice/docker.service</span><br><span class="line">           └─1097921 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock</span><br></pre></td></tr></table></figure></div>
<div class="code-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">journalctl -fu docker</span></span><br><span class="line">...</span><br><span class="line">Oct 31 11:57:22 xx-xxx-1 dockerd[1097921]: time="2023-10-31T11:57:22.087791624+08:00" level=info msg="ignoring event" container=1063c7297c759788eaa79e92aade6c96ab23d6156b10982ea13b38fc5734afae module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"</span><br><span class="line">Oct 31 11:58:21 xx-xxx-1 dockerd[1097921]: time="2023-10-31T11:58:21.993922952+08:00" level=info msg="ignoring event" container=781c78be1d7f785fbb02bca8a148e4dc75a70054f41a24f51cb62095bb0c9d79 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"</span><br><span class="line">...</span><br></pre></td></tr></table></figure></div></li>
<li>kubelet<div class="code-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl status kubelet</span></span><br><span class="line">● kubelet.service - kubelet: The Kubernetes Node Agent</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/kubelet.service; enabled; vendor preset: disabled)</span><br><span class="line">  Drop-In: /usr/lib/systemd/system/kubelet.service.d</span><br><span class="line">           └─10-kubeadm.conf</span><br><span class="line">   Active: active (running) since 一 2023-10-30 16:32:22 CST; 19h ago</span><br><span class="line">     Docs: https://kubernetes.io/docs/</span><br><span class="line"> Main PID: 1098656 (kubelet)</span><br><span class="line">    Tasks: 16</span><br><span class="line">   Memory: 45.2M</span><br><span class="line">   CGroup: /system.slice/kubelet.service</span><br><span class="line">           └─1098656 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/...</span><br></pre></td></tr></table></figure></div>
<div class="code-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">journalctl -fu kubelet</span></span><br><span class="line">...</span><br><span class="line">Oct 31 11:58:33 xx-xx-1 kubelet[1098656]: E1031 11:58:33.666668 1098656 kubelet.go:2263] node "xx-xx-1" not found</span><br><span class="line">...</span><br><span class="line">Oct 31 11:58:33 xx-xx-1 kubelet[1098656]: I1031 11:58:33.723526 1098656 scope.go:111] [topologymanager] RemoveContainer - Container ID: bebfb084373c836501ce9c3791089c0ef0945b50bc0364f1e5bf83853b70c64e</span><br><span class="line">Oct 31 11:58:33 xx-xx-1 kubelet[1098656]: E1031 11:58:33.723897 1098656 pod_workers.go:191] Error syncing pod c560f766bceb51cbaca458fd334576d0 ("etcd-xx-xx-1_kube-system(c560f766bceb51cbaca458fd334576d0)"), skipping: failed to "StartContainer" for "etcd" with CrashLoopBackOff: "back-off 5m0s restarting failed container=etcd pod=etcd-xx-xx-1_kube-system(c560f766bceb51cbaca458fd334576d0)"</span><br><span class="line">...</span><br><span class="line">Oct 31 11:58:34 xx-xx-1 kubelet[1098656]: I1031 11:58:34.171287 1098656 kubelet_node_status.go:71] Attempting to register node xx-xx-1</span><br><span class="line">Oct 31 11:58:34 xx-xx-1 kubelet[1098656]: E1031 11:58:34.210170 1098656 kubelet_node_status.go:93] Unable to register node "xx-xx-1" with API server: Post "https://10.244.3.3:6443/api/v1/nodes": dial tcp 10.244.3.3:6443: connect: connection refused</span><br><span class="line">...</span><br><span class="line">Oct 31 11:58:37 xx-xx-1 kubelet[1098656]: E1031 11:58:37.409610 1098656 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://10.244.3.3:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/xx-xx-1?timeout=10s": dial tcp 10.244.3.3:6443: connect: connection refused</span><br><span class="line">...</span><br><span class="line">Oct 31 11:58:38 xx-xx-1 kubelet[1098656]: E1031 11:58:38.779304 1098656 eviction_manager.go:260] eviction manager: failed to get summary stats: failed to get node info: node "xx-xx-1" not found</span><br><span class="line">...</span><br><span class="line">Oct 31 11:58:39 xx-xx-1 kubelet[1098656]: E1031 11:58:39.037767 1098656 pod_workers.go:191] Error syncing pod c64e8855ca75d2d53d6ae0abfc5b2e24 ("kube-controller-manager-xx-xx-1_kube-system(c64e8855ca75d2d53d6ae0abfc5b2e24)"), skipping: failed to "StartContainer" for "kube-controller-manager" with CrashLoopBackOff: "back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-xx-xx-1_kube-system(c64e8855ca75d2d53d6ae0abfc5b2e24)"</span><br><span class="line">Oct 31 11:58:39 xx-xx-1 kubelet[1098656]: I1031 11:58:39.068118 1098656 scope.go:111] [topologymanager] RemoveContainer - Container ID: ca74b5519cfe860b04885270fe4b820c6ac2448f1bb0365a6ee8b8e15ae8fcdc</span><br><span class="line">Oct 31 11:58:39 xx-xx-1 kubelet[1098656]: E1031 11:58:39.070622 1098656 remote_runtime.go:294] RemoveContainer "ca74b5519cfe860b04885270fe4b820c6ac2448f1bb0365a6ee8b8e15ae8fcdc" from runtime service failed: rpc error: code = Unknown desc = failed to get container "ca74b5519cfe860b04885270fe4b820c6ac2448f1bb0365a6ee8b8e15ae8fcdc" log path: failed to inspect container "ca74b5519cfe860b04885270fe4b820c6ac2448f1bb0365a6ee8b8e15ae8fcdc": Error: No such container: ca74b5519cfe860b04885270fe4b820c6ac2448f1bb0365a6ee8b8e15ae8fcdc</span><br><span class="line">Oct 31 11:58:39 xx-xx-1 kubelet[1098656]: E1031 11:58:39.070645 1098656 kuberuntime_gc.go:146] Failed to remove container "ca74b5519cfe860b04885270fe4b820c6ac2448f1bb0365a6ee8b8e15ae8fcdc": rpc error: code = Unknown desc = failed to get container "ca74b5519cfe860b04885270fe4b820c6ac2448f1bb0365a6ee8b8e15ae8fcdc" log path: failed to inspect container "ca74b5519cfe860b04885270fe4b820c6ac2448f1bb0365a6ee8b8e15ae8fcdc": Error: No such container: ca74b5519cfe860b04885270fe4b820c6ac2448f1bb0365a6ee8b8e15ae8fcdc</span><br><span class="line">Oct 31 11:58:39 xx-xx-1 kubelet[1098656]: W1031 11:58:39.072016 1098656 status_manager.go:550] Failed to get status for pod "kube-controller-manager-xx-xx-1_kube-system(c64e8855ca75d2d53d6ae0abfc5b2e24)": Get "https://10.244.3.3:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-xx-xx-1": dial tcp 10.244.3.3:6443: connect: connection refused</span><br><span class="line">...</span><br></pre></td></tr></table></figure></div>
</li>
</ol>
<ul>
<li>根据以上信息可以判断，基础服务正常运行，但 kubelet 也无法连接到对应 k8s服务。</li>
</ul>
</li>
<li><p>上层k8s服务状态<br>使用<code>docker ps -a</code>可以看到Docker上运行的所有容器状态，<code>docker logs ${CONTAINER_NAME}</code>可以看到名为 CONTAINER_NAME 的容器日志情况。</p>
<ol>
<li>docker服务整体情况<div class="code-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker ps -a</span></span><br><span class="line">CONTAINER ID   IMAGE                                               COMMAND                  CREATED              STATUS                          PORTS     NAMES</span><br><span class="line">6e0350f7b16b   7a5d9d67a13f                                        "kube-scheduler --au…"   24 seconds ago       Exited (1) 23 seconds ago                 k8s_kube-scheduler_kube-scheduler-xx-xx-1_kube-system_472d87a90d4ce654500e8615a31c0f8b_242</span><br><span class="line">fc786f3197c6   cdcab12b2dd1                                        "kube-apiserver --ad…"   About a minute ago   Exited (1) About a minute ago             k8s_kube-apiserver_kube-apiserver-xx-xx-1_kube-system_e5cc1328f715a4eba870289759ed1c1f_242</span><br><span class="line">39e716367013   0369cf4303ff                                        "etcd --advertise-cl…"   5 minutes ago        Exited (1) 5 minutes ago                  k8s_etcd_etcd-xx-xx-1_kube-system_c560f766bceb51cbaca458fd334576d0_241</span><br><span class="line">ad141f2d1721   55f13c92defb                                        "kube-controller-man…"   5 minutes ago        Exited (1) 5 minutes ago                  k8s_kube-controller-manager_kube-controller-manager-xx-xx-1_kube-system_c64e8855ca75d2d53d6ae0abfc5b2e24_241</span><br><span class="line">41d5994c0b93   registry.aliyuncs.com/google_containers/pause:3.2   "/pause"                 20 hours ago         Up 20 hours                               k8s_POD_kube-controller-manager-xx-xx-1_kube-system_c64e8855ca75d2d53d6ae0abfc5b2e24_1</span><br><span class="line">7ff1e80d9ddb   registry.aliyuncs.com/google_containers/pause:3.2   "/pause"                 20 hours ago         Up 20 hours                               k8s_POD_kube-scheduler-xx-xx-1_kube-system_472d87a90d4ce654500e8615a31c0f8b_1</span><br><span class="line">6370376fe05b   registry.aliyuncs.com/google_containers/pause:3.2   "/pause"                 20 hours ago         Up 20 hours                               k8s_POD_etcd-xx-xx-1_kube-system_c560f766bceb51cbaca458fd334576d0_1</span><br><span class="line">abce82c8bd1e   registry.aliyuncs.com/google_containers/pause:3.2   "/pause"                 20 hours ago         Up 20 hours                               k8s_POD_kube-apiserver-xx-xx-1_kube-system_e5cc1328f715a4eba870289759ed1c1f_1</span><br><span class="line">e6751f222a36   ubuntu                                              "/sbin/init"             23 hours ago         Up 20 hours                               strange_wu</span><br></pre></td></tr></table></figure></div></li>
<li>kube-apiserver 具体日志情况<div class="code-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker logs fc786f3197c6</span></span><br><span class="line">Error: unknown flag: --insecure-port</span><br></pre></td></tr></table></figure></div>
</li>
</ol>
<ul>
<li>根据以上信息判断，启动参数方面存在问题。</li>
</ul>
</li>
</ul>
<h2 id="🏹修复方案检索"><a href="#🏹修复方案检索" class="headerlink" title="🏹修复方案检索"></a>🏹修复方案检索</h2><p>已将问题定位到“k8s相关启动参数”方面存在错误，因此对修改启动参数的方法进行检索。</p>
<ul>
<li><p>根据相关资料<a href="#refer-anchor-2"><sup>[2]</sup></a>，使用 kubeadm 安装 Kubernetes 集群，Kubernetes 相关组件通过 static pod 启动，其 yaml 文件的位置在 <code>/etc/kubernetes/manifests/</code> 路径下。</p>
</li>
<li><p>检查该文件是否存在问题。</p>
<div class="code-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vim /etc/kubernetes/manifests/kube-apiserver.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 10.244.3.3:6443</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    component: kube-apiserver</span><br><span class="line">    tier: control-plane</span><br><span class="line">  name: kube-apiserver</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-apiserver</span><br><span class="line">    - --advertise-address=10.244.3.3</span><br><span class="line">    - --allow-privileged=true</span><br><span class="line">    - --authorization-mode=Node,RBAC</span><br><span class="line">    - --client-ca-file=/etc/kubernetes/pki/ca.crt</span><br><span class="line">    - --enable-admission-plugins=NodeRestriction</span><br><span class="line">    - --enable-bootstrap-token-auth=true</span><br><span class="line">    - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">    - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt</span><br><span class="line">    - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key</span><br><span class="line">    - --etcd-servers=https://127.0.0.1:2379</span><br><span class="line">    - --insecure-port=0</span><br><span class="line">    - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt</span><br><span class="line">    - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key</span><br><span class="line">    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span><br><span class="line">    - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt</span><br><span class="line">    - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key</span><br><span class="line">    - --requestheader-allowed-names=front-proxy-client</span><br><span class="line">    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt</span><br><span class="line">    - --requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class="line">    - --requestheader-group-headers=X-Remote-Group</span><br><span class="line">    - --requestheader-username-headers=X-Remote-User</span><br><span class="line">    - --secure-port=6443</span><br><span class="line">    - --service-account-issuer=https://kubernetes.default.svc.cluster.local</span><br><span class="line">    - --service-account-key-file=/etc/kubernetes/pki/sa.pub</span><br><span class="line">    - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key</span><br><span class="line">    - --service-cluster-ip-range=10.96.0.0/16</span><br><span class="line">    - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt</span><br><span class="line">    - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key</span><br><span class="line">    image: registry.aliyuncs.com/google_containers/kube-apiserver:v1.28.2</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    livenessProbe:</span><br><span class="line">      failureThreshold: 8</span><br><span class="line">      httpGet:</span><br><span class="line">        host: 10.244.3.3</span><br><span class="line">        path: /livez</span><br><span class="line">        port: 6443</span><br><span class="line">        scheme: HTTPS</span><br><span class="line">      initialDelaySeconds: 10</span><br><span class="line">      periodSeconds: 10</span><br><span class="line">      timeoutSeconds: 15</span><br><span class="line">    name: kube-apiserver</span><br><span class="line">    readinessProbe:</span><br><span class="line">      failureThreshold: 3</span><br><span class="line">      httpGet:</span><br><span class="line">        host: 10.244.3.3</span><br><span class="line">        path: /readyz</span><br><span class="line">        port: 6443</span><br><span class="line">        scheme: HTTPS</span><br><span class="line">      periodSeconds: 1</span><br><span class="line">      timeoutSeconds: 15</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 250m</span><br><span class="line">    startupProbe:</span><br><span class="line">      failureThreshold: 24</span><br><span class="line">      httpGet:</span><br><span class="line">        host: 10.244.3.3</span><br><span class="line">        path: /livez</span><br><span class="line">        port: 6443</span><br><span class="line">        scheme: HTTPS</span><br><span class="line">      initialDelaySeconds: 10</span><br><span class="line">      periodSeconds: 10</span><br><span class="line">      timeoutSeconds: 15</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /etc/ssl/certs</span><br><span class="line">      name: ca-certs</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /etc/pki</span><br><span class="line">      name: etc-pki</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /etc/kubernetes/pki</span><br><span class="line">      name: k8s-certs</span><br><span class="line">      readOnly: true</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  priorityClassName: system-node-critical</span><br><span class="line">  volumes:</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/ssl/certs</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: ca-certs</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/pki</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etc-pki</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/kubernetes/pki</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: k8s-certs</span><br><span class="line">status: {}</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>注意到其中的 ip 都变成了<code>10.244.3.3</code>，根据交流发现该 ip 对应的是运行于服务器上的一台虚拟机。因此出错原因可能是在虚拟机内修改了该文件。</p>
</li>
</ul>
<h1 id="🔨解决"><a href="#🔨解决" class="headerlink" title="🔨解决"></a>🔨解决</h1><ol>
<li>❌将文件中对应 ip 修改为本机 ip。（同时对另外几个组件<code>etcd</code>、<code>kube-controller-manager</code>、<code>kube-scheduler</code>的配置文件也进行修改）</li>
</ol>
<ul>
<li>无效，可能是因为不止这几个内容出错。</li>
</ul>
<ol start="2">
<li>使用 kubeadm 重新配置，<a href="/2023/05/22/k8s/k8s-install/" title="初始化集群">初始化集群</a>。<a href="#refer-anchor-3"><sup>[3]</sup></a></li>
</ol>
<ul>
<li>master 节点<div class="code-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重置集群</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm reset</span></span><br><span class="line">reset] Reading configuration from the cluster...</span><br><span class="line">[reset] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'</span><br><span class="line">W1031 12:34:20.990883 2223588 reset.go:99] [reset] Unable to fetch the kubeadm-config ConfigMap from cluster: failed to get config map: Get "https://10.244.3.3:6443/api/v1/namespaces/kube-system/configmaps/kubeadm-config?timeout=10s": dial tcp 10.244.3.3:6443: connect: connection refused</span><br><span class="line">[reset] WARNING: Changes made to this host by 'kubeadm init' or 'kubeadm join' will be reverted.</span><br><span class="line">[reset] Are you sure you want to proceed? [y/N]: y</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">W1031 12:34:25.107252 2223588 removeetcdmember.go:79] [reset] No kubeadm config, using etcd pod spec to get data directory</span><br><span class="line">[reset] Stopping the kubelet service</span><br><span class="line">[reset] Unmounting mounted directories in "/var/lib/kubelet"</span><br><span class="line">[reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]</span><br><span class="line">[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]</span><br><span class="line">[reset] Deleting contents of stateful directories: [/var/lib/etcd /var/lib/kubelet /var/lib/dockershim /var/run/kubernetes /var/lib/cni]</span><br><span class="line"></span><br><span class="line">The reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d</span><br><span class="line"></span><br><span class="line">The reset process does not reset or clean up iptables rules or IPVS tables.</span><br><span class="line">If you wish to reset iptables, you must do so manually by using the "iptables" command.</span><br><span class="line"></span><br><span class="line">If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)</span><br><span class="line">to reset your system's IPVS tables.</span><br><span class="line"></span><br><span class="line">The reset process does not clean your kubeconfig files and you must remove them manually.</span><br><span class="line">Please, check the contents of the $HOME/.kube/config file.</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<div class="code-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">清除配置</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> -rf /root/.kube</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> -rf /etc/cni/net.d</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install -y ipvsadm</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ipvsadm -C</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -X</span></span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取并修改kubeadm-config.yaml相关配置</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm config <span class="built_in">print</span> init-defaults &gt; kubeadm-config.yaml</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置并初始化</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm init \</span></span><br><span class="line"><span class="language-bash">--config kubeadm-config.yaml \</span></span><br><span class="line"><span class="language-bash">--ignore-preflight-errors=Swap \</span></span><br><span class="line"><span class="language-bash">--upload-certs | \</span></span><br><span class="line"><span class="language-bash"><span class="built_in">tee</span> kubeadm-init.log <span class="comment"># 初始化集群</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装网络插件</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create -f https://docs.projectcalico.org/archive/v3.21/manifests/calico.yaml</span></span><br></pre></td></tr></table></figure></div>
<p>网络插件部分，或参考<a href="#refer-anchor-3">[4]</a>采用 flannel。</p>
<ul>
<li><p>worker 节点</p>
<div class="code-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm reset</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">清除配置</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> -rf /root/.kube</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> -rf /etc/cni/net.d</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> -rf /etc/kubernetes/*</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install -y ipvsadm</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ipvsadm -C</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -X</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm <span class="built_in">join</span> xxx.xxx.xxx.xxx:6443 --token xxx \</span></span><br><span class="line"><span class="language-bash">    --discovery-token-ca-cert-hash sha256:xxx</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li>插曲：跨云厂商节点上 flannel pod 启动失败<br>报错：<div class="code-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">I1031 13:24:29.544239       1 main.go:212] CLI flags config: {etcdEndpoints:http://127.0.0.1:4001,http://127.0.0.1:2379 etcdPrefix:/coreos.com/network etcdKeyfile: etcdCertfile: etcdCAFile: etcdUsername: etcdPassword: version:false kubeSubnetMgr:true kubeApiUrl: kubeAnnotationPrefix:flannel.alpha.coreos.com kubeConfigFile: iface:[eth0] ifaceRegex:[] ipMasq:true ifaceCanReach: subnetFile:/run/flannel/subnet.env publicIP:116.63.136.133 publicIPv6: subnetLeaseRenewMargin:60 healthzIP:0.0.0.0 healthzPort:0 iptablesResyncSeconds:5 iptablesForwardRules:true netConfPath:/etc/kube-flannel/net-conf.json setNodeNetworkUnavailable:true useMultiClusterCidr:false}</span><br><span class="line">W1031 13:24:29.544342       1 client_config.go:617] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work.</span><br><span class="line">E1031 13:24:59.574617       1 main.go:229] Failed to create SubnetManager: error retrieving pod spec for 'kube-flannel/kube-flannel-ds-p95w2': Get "https://10.96.0.1:443/api/v1/namespaces/kube-flannel/pods/kube-flannel-ds-p95w2": dial tcp 10.96.0.1:443: i/o timeout</span><br></pre></td></tr></table></figure></div></li>
</ul>
</li>
<li><p>解决：根据相关资料 <a href="#refer-anchor-3"><sup>[5]</sup></a>，在 flannel.yaml文件中 DaemonSet <code>kube-flannel-ds</code> 的<code>env</code>中补充以下参数，然后重新创建 flannel 即可。</p>
<div class="code-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">- name: KUBERNETES_SERVICE_HOST</span><br><span class="line">  value: "xxx.xxx.xxx.xxx" # ip address of the host where kube-apiservice is running</span><br><span class="line">- name: KUBERNETES_SERVICE_PORT</span><br><span class="line">  value: "6443"</span><br></pre></td></tr></table></figure></div>



</li>
</ul>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><ol>
<li>根据最近执行情况，发现无论是 docker 还是 kvm 搭建的 容器/虚机 Pod，都容易出现上下层配置冲突问题。对于不同虚拟化技术的底层实现还可以进一步了解，到底为什么会产生冲突？能否避免？是虚拟化技术本身的硬伤还是工程实现上的漏洞？</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/security/controlling-access/">[1] Kubernetes API 访问控制<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link" href="https://kuboard.cn/install/faq/apiserver-params.html">[2] 修改 Kubernetes apiserver 启动参数<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link" href="https://www.cnblogs.com/-abm/p/16629954.html">[3] K8S集群重新初始化<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link" href="https://blog.51cto.com/xiaowangzai/5167661">[4] [kubernetes] 跨云厂商使用公网IP搭建k8s v1.20.9集群<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-5"></div>

<p><a class="link" href="https://zhuanlan.zhihu.com/p/638378121">[5] K8S Flannel Pod 无法启动系列问题<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境检修</category>
      </categories>
      <tags>
        <tag>K8S</tag>
        <tag>api-server</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】K8S集群搭建记录——故障排除：K8S 下 Calico 网络配置错误</title>
    <url>/2023/06/05/k8s/k8s-debug/</url>
    <content><![CDATA[<h1 id="🐛-背景：Java-应用无法连接到-Postgresql-容器"><a href="#🐛-背景：Java-应用无法连接到-Postgresql-容器" class="headerlink" title="🐛 背景：Java 应用无法连接到 Postgresql 容器"></a>🐛 背景：Java 应用无法连接到 Postgresql 容器</h1><p>在使用 Kubernetes 部署服务的过程中，我遇到了一个令人头疼的问题：我的 Java 应用无法连接到 Postgresql 容器。我决定展开一系列的 bug 查询和修复，寻找并解决问题的根源。</p>
<h1 id="🚀-过程"><a href="#🚀-过程" class="headerlink" title="🚀 过程"></a>🚀 过程</h1><h2 id="1️⃣-发现-Java-应用无法连接"><a href="#1️⃣-发现-Java-应用无法连接" class="headerlink" title="1️⃣ 发现 Java 应用无法连接"></a>1️⃣ 发现 Java 应用无法连接</h2><ul>
<li>一开始，Java 应用报错并显示无法连接到以数据库服务名<code>postgres-service</code>为地址的 Kubernetes Service，因为应用所在的 Pod 无法与数据库建立连接，导致了 Pod 的无限重启。</li>
<li>通过使用<code>kubectl logs &lt;app-pod-name&gt;</code>，我看到了以下报错：<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">Caused by: org.postgresql.util.PSQLException: The connection attempt failed.</span><br><span class="line">	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:272)</span><br><span class="line">	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)</span><br><span class="line">	at org.postgresql.jdbc.PgConnection.&lt;init&gt;(PgConnection.java:215)</span><br><span class="line">	at org.postgresql.Driver.makeConnection(Driver.java:404)</span><br><span class="line">	at org.postgresql.Driver.connect(Driver.java:272)</span><br><span class="line">	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:95)</span><br><span class="line">	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:101)</span><br><span class="line">	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:341)</span><br><span class="line">	at com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:506)</span><br><span class="line">	... 115 common frames omitted</span><br><span class="line">Caused by: java.net.UnknownHostException: postgres-service</span><br><span class="line">	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)</span><br><span class="line">	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)</span><br><span class="line">	at java.net.Socket.connect(Socket.java:589)</span><br><span class="line">	at org.postgresql.core.PGStream.&lt;init&gt;(PGStream.java:61)</span><br><span class="line">	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:144)</span><br><span class="line">	... 123 common frames omitted</span><br><span class="line">...</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h2 id="2️⃣-检查-DNS-解析问题"><a href="#2️⃣-检查-DNS-解析问题" class="headerlink" title="2️⃣ 检查 DNS 解析问题"></a>2️⃣ 检查 DNS 解析问题</h2><ul>
<li>将情况向 GPT 描述并询问后，我获得了以下建议：</li>
</ul>
<blockquote>
<p>请尝试以下方法来解决这个问题：</p>
<ol>
<li><p>确保您的应用程序使用正确的服务名称。在您的代码中，您应该使用 <code>postgres-service</code> 作为主机名来访问 PostgreSQL 服务。如果您的应用程序和 PostgreSQL 服务位于同一个命名空间中，您可以直接使用 <code>postgres-service</code>。如果它们位于不同的命名空间中，您需要使用完整的服务名称，例如 <code>postgres-service.&lt;namespace&gt;.svc.cluster.local</code>。</p>
</li>
<li><p>检查您的 Kubernetes 集群的 DNS 配置。您可以在应用程序的 Pod 中运行以下命令来检查 DNS 解析是否正常：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl <span class="built_in">exec</span> -it &lt;your-app-pod-name&gt; -- nslookup postgres-service</span><br></pre></td></tr></table></figure></div>
<p>如果 DNS 解析正常，您应该能看到类似以下的输出：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">Server:		10.96.0.10</span><br><span class="line">Address:	10.96.0.10#53</span><br><span class="line"></span><br><span class="line">Name:	postgres-service.default.svc.cluster.local</span><br><span class="line">Address: 10.102.181.13</span><br></pre></td></tr></table></figure></div>
<p>如果您看到类似 <code>server can't find postgres-service: NXDOMAIN</code> 的错误，那么可能是您的 Kubernetes 集群的 DNS 配置有问题。您需要检查您的集群 DNS 配置并修复它。</p>
</li>
<li><p>如果上述方法都无法解决问题，您可以尝试使用 PostgreSQL 服务的 ClusterIP 或者 NodePort 来访问它。您可以通过以下命令获取 ClusterIP 和 NodePort：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get svc postgres-service -o jsonpath=<span class="string">'{.spec.clusterIP}{"\n"}{.spec.ports[0].nodePort}{"\n"}'</span></span><br></pre></td></tr></table></figure></div>
<p>然后在您的应用程序中使用这个 ClusterIP 或者 NodePort 作为主机名和端口号来访问 PostgreSQL 服务。</p>
</li>
</ol>
</blockquote>
<ul>
<li>不得不说，GPT 的建议非常有用，在修复本文所提到的 bug 前，我就是使用第三条建议完成的临时修复</li>
</ul>
<ul>
<li>根据 GPT 的建议，我首先验证了应用所在的 Pod 是否能够正常进行 DNS 解析。通过运行相关命令，我发现 DNS 解析确实存在问题。</li>
</ul>
<h2 id="3️⃣-定位问题到-Kubernetes-网络组件"><a href="#3️⃣-定位问题到-Kubernetes-网络组件" class="headerlink" title="3️⃣ 定位问题到 Kubernetes 网络组件"></a>3️⃣ 定位问题到 Kubernetes 网络组件</h2><ul>
<li>进一步通过<code>kubectl get pods -n kube-system</code>查看 Kubernetes 系统组件的 Pod，我发现其中一个 calico-node Pod 的状态不是 READY。这提示了问题可能出现在 Kubernetes 网络组件上。</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">calico-kube-controllers-7f6768fdfb-gfhvb   1/1     Running   4          76d</span><br><span class="line">calico-node-6llk9                          0/1     Running   0          76d</span><br><span class="line">calico-node-rtgpz                          1/1     Running   0          76d</span><br><span class="line">...</span><br></pre></td></tr></table></figure></div>


<h2 id="4️⃣-检查-Calico-配置"><a href="#4️⃣-检查-Calico-配置" class="headerlink" title="4️⃣ 检查 Calico 配置"></a>4️⃣ 检查 Calico 配置</h2><ul>
<li><p>我开始检查 Calico 的配置，通过执行<code>kubectl describe pod xx</code> 和<code>kubectl logs xx</code>查看日志，但没有找到直接的错误提示。受到日志信息误导，在过程中还调整了各种 calico 参数，例如尝试开启 vxlan 模式和 ipip 模式<a href="#refer-anchor-1"><sup>[1]</sup></a>，安装 calicoctl 工具<a href="#refer-anchor-2"><sup>[2]</sup></a>，以及将报错等级调整为 debug<a href="#refer-anchor-3"><sup>[3]</sup></a>，虽然这让我对 calico 有了更多了解，但也花了我大把时间。</p>
</li>
<li><p>当时看到的 bug 信息有以下三条：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">1. </span><br><span class="line">(combined from similar events): Readiness probe failed: calico/node is not ready: BIRD is not ready: BGP not established with  x. Number of node(s) with BGP peering established = 0</span><br><span class="line"></span><br><span class="line">2. </span><br><span class="line">Failed to query VXLAN device error=Link not found </span><br><span class="line"></span><br><span class="line">3. </span><br><span class="line">Failed to cleanup preexisting XDP state error=failed to load BPF program (/tmp/felix-bpf-270596970): <span class="built_in">stat</span> /sys/fs/bpf/calico/xdp/prefilter_v1_calico_tmp_A: no such file or directory</span><br><span class="line">libbpf: failed to get EHDR from /tmp/felix-bpf-270596970</span><br><span class="line">Error: failed to open object file</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>顺便总结一下，想修改 calico 配置通常在两处，一是configMap，二是 daemonSet，也可以通过 <code>find</code> 查找相关文件，修改方法分别如下：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># configMap</span></span><br><span class="line">$ kubectl edit configmap calico-config -n kube-system</span><br><span class="line"><span class="comment"># daemonSet</span></span><br><span class="line">$ kubectl edit daemonset calico-node -n kube-system</span><br><span class="line"><span class="comment"># find</span></span><br><span class="line">$ find / -name <span class="string">"*calico-node.cfg"</span></span><br></pre></td></tr></table></figure></div>


</li>
</ul>
<h2 id="5️⃣-发现-IP-配置问题"><a href="#5️⃣-发现-IP-配置问题" class="headerlink" title="5️⃣ 发现 IP 配置问题"></a>5️⃣ 发现 IP 配置问题</h2><ul>
<li><p>最终，我发现了问题所在。我注意到在 master 节点的配置中，IP 地址被错误地设置为 “172.18.0.1”，这导致其他节点无法与 master 节点建立连接。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ calicoctl node status</span><br><span class="line">Calico process is running.</span><br><span class="line"></span><br><span class="line">IPv4 BGP status</span><br><span class="line">+--------------+-------------------+-------+----------+-------------+</span><br><span class="line">| PEER ADDRESS |     PEER TYPE     | STATE |  SINCE   |    INFO     |</span><br><span class="line">+--------------+-------------------+-------+----------+-------------+</span><br><span class="line">| 10.60.150.28 | node-to-node mesh | up    | 14:36:17 | Established |</span><br><span class="line">| 172.18.0.1   | node-to-node mesh | start | 15:29:38 | Passive     |</span><br><span class="line">+--------------+-------------------+-------+----------+-------------+</span><br><span class="line"></span><br><span class="line">IPv6 BGP status</span><br><span class="line">No IPv6 peers found.</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>经过进一步排查和调研，发现当 IP 属性被设置为 “autodetect” 时，默认的 “first-found” 算法会导致错误<a href="#refer-anchor-4"><sup>[4]</sup></a>。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl edit daemonset calico-node -n kube-system</span><br><span class="line">...</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - <span class="built_in">env</span>:</span><br><span class="line">        - name: IP</span><br><span class="line">          value: autodetect</span><br><span class="line">        - name: IP_AUTODETECTION_METHOD     <span class="comment"># 新增</span></span><br><span class="line">          value: can-reach=114.114.114.114  <span class="comment"># 新增</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>修复完这个问题后，一切恢复了正常（真美好🤣）。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ calicoctl node status</span><br><span class="line">Calico process is running.</span><br><span class="line"></span><br><span class="line">IPv4 BGP status</span><br><span class="line">+--------------+-------------------+-------+----------+-------------+</span><br><span class="line">| PEER ADDRESS |     PEER TYPE     | STATE |  SINCE   |    INFO     |</span><br><span class="line">+--------------+-------------------+-------+----------+-------------+</span><br><span class="line">| 10.60.150.28 | node-to-node mesh | up    | 14:36:17 | Established |</span><br><span class="line">| 10.60.150.56 | node-to-node mesh | up    | 15:33:23 | Established |</span><br><span class="line">+--------------+-------------------+-------+----------+-------------+</span><br><span class="line"></span><br><span class="line">IPv6 BGP status</span><br><span class="line">No IPv6 peers found.</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>


</li>
</ul>
<h1 id="🤔-反思"><a href="#🤔-反思" class="headerlink" title="🤔 反思"></a>🤔 反思</h1><ul>
<li>今天花费了很大一部分时间在漫无头绪的检查上，缺乏系统性和逻辑性。幸好有 GPT 的帮助，我发现它是一个很好的工具，能够帮助梳理思路。类似于小黄鸭调试法，与 GPT 进行交流过程中，由于给予它的信息越详细和具体，它就越能提供有价值的指导和建议，因此会督促我不断整理和理清思路，而且 GPT 的能力也让我的思维更加开阔。</li>
</ul>
<hr>
<ul>
<li>希望通过分享我的故障排除经历，可以帮助你在类似的问题上更加迅速和高效地解决困扰你的 bug。</li>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://blog.csdn.net/kjkdd/article/details/128631119#:~:text=%E7%AC%AC%E4%BA%8C%E7%AF%87%EF%BC%9Akubernetes%E9%83%A8%E7%BD%B2calico%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6%201%201.%20%E4%B8%8B%E8%BD%BDcalico%E7%9A%84yaml%E6%96%87%E4%BB%B6%20%23%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%20%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E4%BD%8D%E7%BD%AE%EF%BC%9A%20calico.yaml%202,4.%20%E9%AA%8C%E8%AF%81calico%E5%AE%89%E8%A3%85%E7%BB%93%E6%9E%9C%20%E4%B8%8A%E9%9D%A2calico%E8%B5%84%E6%BA%90%E5%AE%89%E8%A3%85%E5%AE%8C%E6%88%90%E5%90%8E%EF%BC%8C%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%22kubectl%20get%20pod%20-A%22%E9%AA%8C%E8%AF%81%E7%BB%93%E6%9E%9C%20%E7%BB%93%E6%9E%9C%E5%A6%82%E4%B8%8B%EF%BC%9A%20">[1] 第二篇：kubernetes部署calico网络插件<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link" href="https://blog.csdn.net/weixin_45015255/article/details/117207177">[2] kubernetes 中 calico 组件的 calicoctl 工具的使用示例及 BGP 相关配置<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link" href="https://blog.csdn.net/qq_24433609/article/details/126411642">[3] 解决 calico-node 无法启动问题<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link" href="https://blog.csdn.net/doyzfly/article/details/121038861">[4] k8s 使用 calico 作为 CNI ，calico-node 启动失败<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境检修</category>
      </categories>
      <tags>
        <tag>K8S</tag>
        <tag>calico</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】K8S集群重启问题排查记录</title>
    <url>/2025/05/19/k8s/k8s-host-restart/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>前段时间机房断电，导致大批量服务器故障。终于恢复正常后发现服务器上的 k8s 无法连接了，因此排查并记录一下过程。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><ul>
<li>机房断电导致服务器重启，k8s 集群无法正常连接。</li>
<li>需要排查权限问题、服务启动问题及解决方案。</li>
</ul>
<h1 id="🧠思路"><a href="#🧠思路" class="headerlink" title="🧠思路"></a>🧠思路</h1><ol>
<li>检查 <code>kubectl get node</code> 报错，判断权限问题。</li>
<li>检查 <code>kubelet</code> 服务状态，判断服务启动问题。</li>
<li>检查 Docker 及相关容器状态，判断组件问题。</li>
<li>记录常见问题与解决方法。</li>
</ol>
<h1 id="🔨解决"><a href="#🔨解决" class="headerlink" title="🔨解决"></a>🔨解决</h1><h2 id="1-权限问题排查"><a href="#1-权限问题排查" class="headerlink" title="1. 权限问题排查"></a>1. 权限问题排查</h2><p>使用 <code>kubectl get node</code> 发现报错：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">The connection to the server localhost:8080 was refused - did you specify the right host or port?</span><br></pre></td></tr></table></figure></div>

<p>根据博客<a href="#refer-anchor-1"><sup>[1,2]</sup></a>，判断是出现权限问题，<code>admin.conf</code>文件未绑定，通过<code>echo $KUBECONFIG</code>发现无输出，证明确实是该问题。<br>通过以下指令绑定相应权限文件：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"export KUBECONFIG=/etc/kubernetes/admin.conf"</span> &gt;&gt; /etc/profile</span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure></div>

<h2 id="2-服务启动问题排查"><a href="#2-服务启动问题排查" class="headerlink" title="2. 服务启动问题排查"></a>2. 服务启动问题排查</h2><p>继续使用 <code>kubectl get node</code> 发现报错：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">The connection to the server xx.xx.xx.xx:6443 was refused - did you specify the right host or port?</span><br></pre></td></tr></table></figure></div>

<p>根据博客<a href="#refer-anchor-1"><sup>[3，4]</sup></a>，判断是服务启动不成功。依次检查<code>6443端口</code>、<code>kubelet</code>、<code>docker及相关容器</code>，发现全都存在问题。具体检查指令及结果如下：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><figcaption><span>检查 6443 端口</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查 6443 端口，发现无输出，说明无应用监听该端口。其对应的是 kubelet，说明 kubelet 可能出现了问题</span></span><br><span class="line">$ ss -antulp | grep :6443</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><figcaption><span>检查 kubelet</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查 kubelet，发现果然未正常启动。</span></span><br><span class="line">$ systemctl status kubelet</span><br><span class="line"><span class="comment"># 尝试重启，再查看状态仍然未正常启动</span></span><br><span class="line">$ systemctl restart kubelet</span><br><span class="line"><span class="comment"># 分析日志</span></span><br><span class="line">$ journalctl -xefu kubelet</span><br><span class="line"><span class="comment"># kubelet[86499]: E0519 23:40:27.056433   86499 run.go:74] "command failed" err="failed to parse kubelet flag: unknown flag: --network-plugin"</span></span><br><span class="line"><span class="comment"># 查看各组件版本</span></span><br><span class="line">$ rpm -qa | grep kube</span><br><span class="line"><span class="comment"># 看到很多博客说 Master 和 Node 节点版本不一致导致出问题，但本服务器只有一个 Master 节点，因此理论上不会有这个问题</span></span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><figcaption><span>检查 docker 及相关容器</span></figcaption><table><tr><td class="code"><pre><span class="line">$ docker ps -a | grep kube-apiserver</span><br><span class="line">$ docker ps -a | grep etcd</span><br><span class="line"><span class="comment"># 发现所有容器都出于 Exit (255) 状态，判断是组件出现了问题。</span></span><br><span class="line"><span class="comment"># 查看 ETCD 报错日志，其中 ETCD_NAME 指上述指令中看到的 ETCD 容器名称</span></span><br><span class="line">$ docker logs <span class="variable">${ETCD}</span></span><br><span class="line"><span class="comment"># 发现一切正常，尝试暴力重启所有组件</span></span><br><span class="line">$ docker start $(docker ps -a | awk <span class="string">'{print $1}'</span> | <span class="built_in">tail</span> -n +2)</span><br><span class="line"><span class="comment"># 部分组件正常，部分组件报错：Error response from daemon: cannot join network of a non running container: xxx</span></span><br><span class="line"><span class="comment"># 猜测是启动顺序问题，重新再执行一次启动即可</span></span><br><span class="line">$ docker start $(docker ps -a | awk <span class="string">'{print $1}'</span> | <span class="built_in">tail</span> -n +2)</span><br><span class="line"><span class="comment"># 一切恢复正常</span></span><br></pre></td></tr></table></figure></div>

<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><ul>
<li>服务器重启后，k8s 集群可能出现权限问题、服务启动问题，需及时排查。</li>
<li>检查 <code>kubelet</code> 服务状态、Docker 容器状态是排查问题的关键步骤。</li>
<li>记录常见问题与解决方法，便于后续参考。</li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://blog.csdn.net/luolianxi/article/details/125925335">[1] k8s重启导致node没有成功连接：The connection to the server localhost:8080 was refused - did you specify the righ<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://blog.csdn.net/whatzhang007/article/details/112579182">[2] 解决The connection to the server localhost:8080 was refused - did you specify the right host or port?<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://blog.csdn.net/qq_21127151/article/details/109302904">[3] k8s重启报错 ：The connection to the server 192.168.102.149:6443 was refused<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://blog.csdn.net/qq_41798158/article/details/138714230">[4] 如何排查解决：The connection to the server ＜HOST＞:6443 was refused - did you specify the right host or port<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境检修</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>集群重启</tag>
        <tag>故障排查</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】K8S集群搭建记录——简易单机集群</title>
    <url>/2023/05/22/k8s/k8s-install/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><ul>
<li>组内师兄弟不小心把集群玩坏了，我们进行重装时遇到各种奇怪的报错，在此记录一下，避免下次遇到同样的情况浪费时间。</li>
<li>本次目标集群较为简单，仅由一台服务器组成。</li>
<li>整体根据<a href="#refer-anchor-1">[1]</a>进行安装。</li>
</ul>
<h1 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h1><ul>
<li>使用yum安装Docker<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">docker_version=20.10.5  <span class="comment"># 根据自己需要可设置为其他版本</span></span><br><span class="line">yum install docker-ce-<span class="variable">$&#123;docker_version&#125;</span> -y</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h2 id="细节问题"><a href="#细节问题" class="headerlink" title="细节问题"></a>细节问题</h2><ul>
<li>由于本机已有Docker环境故跳过了这一步，但得到报错：<blockquote>
<p>[WARNING Service-Docker]: docker service is not enabled, please run ‘systemctl enable docker.service’<br>[WARNING SystemVerification]: this Docker version is not on the list of validated versions: 23.0.4. Latest validated version: 20.10</p>
</blockquote>
</li>
<li>显然是Docker版本过高（可能是由于K8S和Docker近期分道扬镳有关，故对Docker版本进行降级<a href="#refer-anchor-2"><sup>[2]</sup></a>：<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker_version=20.10.5  <span class="comment"># 根据自己需要可设置为其他版本</span></span><br><span class="line">$ yum downgrade --<span class="built_in">setopt</span>=obsoletes=0 -y docker-ce-<span class="variable">$&#123;docker_version&#125;</span> docker-ce-selinux-<span class="variable">$&#123;docker_version&#125;</span>   <span class="comment"># 安装Docker</span></span><br><span class="line"></span><br><span class="line">$ systemctl <span class="built_in">enable</span> docker.service <span class="comment"># 安装完成后启动Docker服务</span></span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h1 id="安装kubelet、kubeadm、kubectl"><a href="#安装kubelet、kubeadm、kubectl" class="headerlink" title="安装kubelet、kubeadm、kubectl"></a>安装kubelet、kubeadm、kubectl</h1><ul>
<li>使用yum安装K8S组件<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ k8s_version=1.23.6  <span class="comment"># 根据自己需要可设置为其他版本</span></span><br><span class="line">$ yum install -y kubelet-<span class="variable">$&#123;k8s_version&#125;</span> kubeadm-<span class="variable">$&#123;k8s_version&#125;</span> kubectl-<span class="variable">$&#123;k8s_version&#125;</span> --disableexcludes=kubernetes    <span class="comment"># disableexcludes参数禁止了除了该仓库外的其他仓库</span></span><br><span class="line"></span><br><span class="line">$ systemctl <span class="built_in">enable</span> --now kubelet  <span class="comment"># 安装完成后启动kubelet服务</span></span><br><span class="line">$ systemctl start kubelet</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h2 id="细节问题-1"><a href="#细节问题-1" class="headerlink" title="细节问题"></a>细节问题</h2><ul>
<li>正常安装后一直卡在其中一步，得到信息：<blockquote>
<p>[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory “/etc/kubernetes/manifests”. This can take up to 4m0s<br>[kubelet-check] Initial timeout of 40s passed.</p>
</blockquote>
</li>
<li>根据[<a href="#refer-anchor-3">3</a>]确认和前面Docker一样是版本问题（发现该问题之前安装组件并未指定版本），对相关组件进行降级：<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ yum remove -y kubelet kubeadm kubectl</span><br><span class="line">$ k8s_version=1.23.6  <span class="comment"># 根据自己需要可设置为其他版本</span></span><br><span class="line">$ yum install -y kubelet-<span class="variable">$&#123;k8s_version&#125;</span> kubeadm-<span class="variable">$&#123;k8s_version&#125;</span> kubectl-<span class="variable">$&#123;k8s_version&#125;</span> <span class="comment"># 安装组件</span></span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h2 id="知识补充"><a href="#知识补充" class="headerlink" title="知识补充"></a>知识补充</h2><ul>
<li><p>kubelet, kubeadm, kubectl是Kubernetes的三个基本工具，它们分别有以下作用：</p>
<ul>
<li>kubelet是运行在每个节点上的代理，它负责管理本机的容器，保证容器都运行在Pod中。kubelet还负责维护容器的生命周期，以及管理存储和网络资源。kubelet会定期向控制平面汇报节点的状态和资源使用情况。</li>
<li>kubeadm是一个用于快速部署Kubernetes集群的工具。kubeadm可以通过简单的命令来初始化集群、添加节点、升级集群等。kubeadm会执行一系列的操作，如生成证书、配置kubeconfig文件、启动控制平面组件、安装网络插件等。</li>
<li>kubectl是一个用于与Kubernetes集群交互的命令行工具。kubectl可以用来管理集群本身，以及在集群上部署和运维容器化应用。kubectl支持多种操作，如创建、删除、更新、查看资源对象，执行命令，查看日志等。</li>
</ul>
</li>
<li><p>一些具体的例子：</p>
<ul>
<li>如果想在节点上查看运行中的Pod，可以使用kubelet提供的API接口：<code>curl -s http://localhost:10255/pods | jq .items[].metadata.name</code></li>
<li>如果想在主节点上初始化一个集群，可以使用kubeadm init命令：<code>kubeadm init --apiserver-advertise-address=192.168.0.10 --pod-network-cidr=10.244.0.0/16</code></li>
<li>如果想在工作节点上加入一个集群，可以使用kubeadm join命令：<code>kubeadm join 192.168.0.10:6443 --token abcdef.1234567890abcdef --discovery-token-ca-cert-hash sha256:1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef</code></li>
<li>如果想在集群上创建一个Deployment对象，可以使用kubectl create命令：<code>kubectl create deployment nginx --image=nginx</code></li>
<li>如果想在集群上查看所有的节点，可以使用kubectl get命令：<code>kubectl get nodes</code></li>
</ul>
</li>
</ul>
<h1 id="集群初始化"><a href="#集群初始化" class="headerlink" title="集群初始化"></a>集群初始化</h1><ul>
<li>创建并设置配置文件<a href="#refer-anchor-4"><sup>[4]</sup></a><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubeadm config <span class="built_in">print</span> init-defaults &gt; kubeadm-config.yaml</span><br><span class="line">$ vim kubeadm-config.yaml</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  advertiseAddress: 1.2.3.4   <span class="comment"># 修改为本机ip，对应 --apiserver-advertise-address</span></span><br><span class="line">nodeRegistration:</span><br><span class="line">  name: node  <span class="comment"># 修改为本机hostname（使用hostname命令查看）</span></span><br><span class="line">imageRepository: registry.aliyuncs.com/google_containers   <span class="comment"># 修改为国内源</span></span><br><span class="line">networking:</span><br><span class="line">  serviceSubnet: 10.96.0.0.1/12 <span class="comment"># 猜测与 --service-cidr对应 //TODO</span></span><br><span class="line">  podSubnet: 10.100.0.1/24  <span class="comment"># 对应 --pod-network-cidr</span></span><br></pre></td></tr></table></figure></div></li>
<li>初始化集群<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubeadm init \</span><br><span class="line">--config kubeadm-config.yaml \</span><br><span class="line">--ignore-preflight-errors=Swap \</span><br><span class="line">--upload-certs | \</span><br><span class="line"><span class="built_in">tee</span> kubeadm-init.log <span class="comment"># 初始化集群</span></span><br></pre></td></tr></table></figure></div>
<ul>
<li><code>--upload-certs</code>：可以在后续执行加入节点时自动分发证书文件</li>
<li><code>tee kubeadm-init.log</code>：输出日志</li>
</ul>
</li>
<li>初始化成功或后获得信息：<blockquote>
<p>To start using your cluster, you need to run the following as a regular user:<br>  mkdir -p $HOME/.kube<br>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config<br>  sudo chown $(id -u):$(id -g) $HOME/.kube/config</p>
<p>Alternatively, if you are the root user, you can run:<br>  export KUBECONFIG=/etc/kubernetes/admin.conf</p>
<p>You should now deploy a pod network to the cluster.<br>Run “kubectl apply -f [podnetwork].yaml” with one of the options listed at:<br>  <a class="link"   href="https://kubernetes.io/docs/concepts/cluster-administration/addons/" >https://kubernetes.io/docs/concepts/cluster-administration/addons/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>Then you can join any number of worker nodes by running the following on each as root:</p>
<p>kubeadm join x.x.x.x:6443 –token abcdef.0123456789abcdef \<br>–discovery-token-ca-cert-hash sha256:b45c9d150ca4a2f658b8316ae0246844733cafb36ed2883b3fd4be5e7fd554e8</p>
</blockquote>
</li>
<li>根据信息配置：<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">$ <span class="built_in">sudo</span> <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">$ <span class="built_in">sudo</span> <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line">$ <span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><ul>
<li>上述信息中提及修改path的多种方式，如果希望对所有系统用户永久生效，将上述最后两行替换为指令重新执行：<a href="#refer-anchor-5"><sup>[5]</sup></a><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> -e <span class="string">&quot;\n#k8s\nexport KUBECONFIG=/etc/kubernetes/admin.conf&quot;</span> &gt;&gt; /etc/profile</span><br><span class="line">$ <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h1 id="安装网络插件"><a href="#安装网络插件" class="headerlink" title="安装网络插件"></a>安装网络插件</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 二选一，推荐calico</span></span><br><span class="line"><span class="comment"># calico</span></span><br><span class="line">$ kubectl create -f https://docs.projectcalico.org/archive/v3.21/manifests/calico.yaml</span><br><span class="line"><span class="comment"># flannel</span></span><br><span class="line">$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure></div>

<h2 id="网络参数问题"><a href="#网络参数问题" class="headerlink" title="网络参数问题"></a>网络参数问题</h2><ul>
<li>如果使用flannel网络插件，必须指定–pod-network-cidr配置选项，否则名为coredns-xxxxxxxxxx-xxxxx的Pod无法启动，一直处于ContainerCreating状态，查看详细信息，可见类似如下错误信息：<a href="#refer-anchor-6"><sup>[6]</sup></a><blockquote>
<p>networkPlugin cni failed to set up pod “coredns-7f89b7bc75-9vrrl_kube-system” network: open /run/flannel/subnet.env: no such file or directory</p>
</blockquote>
</li>
<li>因为太麻烦，最后决定更换为Calico网络插件<a href="#refer-anchor-7"><sup>[7]</sup></a></li>
</ul>
<h1 id="修改kube-controller-manager参数"><a href="#修改kube-controller-manager参数" class="headerlink" title="修改kube-controller-manager参数"></a>修改kube-controller-manager参数</h1><ul>
<li>某些情况下会希望修改kube-controller-manager参数，使用以下方法进行修改：<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ vim /etc/kubernetes/manifests/kube-controller-manager.yaml</span><br><span class="line">...</span><br><span class="line">进行相应修改</span><br><span class="line">...</span><br><span class="line">$ systemctl restart kubelet</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h1 id="环境汇总"><a href="#环境汇总" class="headerlink" title="环境汇总"></a>环境汇总</h1><blockquote>
<p>CentOS Linux release 7.9.2009 (Core)<br>docker_version=20.10.5<br>k8s_version=1.23.6</p>
</blockquote>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><ul>
<li>后续可能会有复杂集群搭建的问题，到时候再继续记录复杂版本</li>
<li>理论上K8S和Docker分道扬镳后应当有新的安装方式，本次使用的强制降级方法不是很自然，后续有机会再更新新版安装方式</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://blog.csdn.net/rockstics/article/details/110850423" >[1] Centos安装部署Kubernetes（K8s）<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link"   href="https://blog.csdn.net/zhanremo3062/article/details/114652850" >[2] docker降级操作，20.10降级到19.03版本<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link"   href="https://blog.csdn.net/weixin_46601322/article/details/126722529" >[3] k8s初始化报错[kubelet-check] Initial timeout of 40s passed.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link"   href="https://chinalhr.github.io/post/kubeadm-install-kubernetes/" >[4] 使用kubeadm部署Kubernetes集群实践<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-5"></div>

<p><a class="link"   href="https://blog.csdn.net/huangfei711/article/details/53044539" >[5] CentOS 添加环境变量的三种方法<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-6"></div>

<p><a class="link"   href="https://blog.csdn.net/m0_60028455/article/details/121694140" >[6] Kubernetes 使用kubeadm创建集群<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-7"></div>

<p><a class="link"   href="https://www.cnblogs.com/yangzp/p/16835280.html" >[7] Kubernetes 安装网络插件(calico)<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】K8S集群搭建记录——kind搭建隔离测试环境</title>
    <url>/2025/05/19/k8s/k8s-kind-install/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在日常开发和测试中，常常需要一个独立的 Kubernetes 集群环境进行实验或验证新功能。由于本机已有集群且承担其他任务，不希望相互干扰，因此选择在服务器上通过 kind（Kubernetes IN Docker）快速搭建一个虚拟集群。本文记录了 kind 的安装与使用过程，供有类似需求的同学参考。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><ul>
<li>本机已有 k8s 集群，承担日常开发任务，不便随意更改。</li>
<li>需要一个”干净”的测试环境，且希望部署和销毁都足够方便。</li>
<li>服务器资源充足，适合运行 Docker 容器。</li>
<li>kind 支持在 Docker 容器中运行多节点 k8s 集群，适合测试和 CI 场景。</li>
</ul>
<h1 id="🧠思路"><a href="#🧠思路" class="headerlink" title="🧠思路"></a>🧠思路</h1><ol>
<li>在服务器上安装 Docker。</li>
<li>安装 kind 工具。</li>
<li>使用 kind 创建一个新的 k8s 虚拟集群。</li>
<li>配置 kubectl 访问新集群。</li>
<li>验证集群可用性，进行简单测试。</li>
<li>记录常见问题与解决方法。</li>
</ol>
<h1 id="🔨解决"><a href="#🔨解决" class="headerlink" title="🔨解决"></a>🔨解决</h1><h2 id="1-安装-Docker"><a href="#1-安装-Docker" class="headerlink" title="1. 安装 Docker"></a>1. 安装 Docker</h2><p>如果服务器尚未安装 Docker，可参考相关参考资料。<a href="#refer-anchor-1"><sup>[1,9,10,11]</sup></a></p>
<p>对于 centos，可使用如下命令：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> yum install docker-ce docker-ce-cli containerd.io</span><br><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> docker</span><br><span class="line"><span class="built_in">sudo</span> systemctl start docker</span><br></pre></td></tr></table></figure></div>

<p>对于 Ubuntu，可使用如下命令：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 更新软件包</span></span><br><span class="line"><span class="built_in">sudo</span> apt update</span><br><span class="line"><span class="built_in">sudo</span> apt upgrade -y</span><br><span class="line"><span class="comment"># 安装 Docker 依赖</span></span><br><span class="line"><span class="built_in">sudo</span> apt install -y ca-certificates curl gnupg lsb-release</span><br><span class="line"><span class="comment"># 添加 Docker 的官方 GPG 密钥以确保下载的软件包是安全的</span></span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | <span class="built_in">sudo</span> gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg</span><br><span class="line"><span class="comment"># 添加 Docker 仓库</span></span><br><span class="line"><span class="built_in">sudo</span> add-apt-repository <span class="string">"deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu <span class="subst">$(lsb_release -cs)</span> stable"</span></span><br><span class="line"><span class="comment"># 或使用以下指令添加 Docker 仓库</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"deb [arch=<span class="subst">$(dpkg --print-architecture)</span> signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] http://mirrors.aliyun.com/docker-ce/linux/ubuntu <span class="subst">$(lsb_release -cs)</span> stable"</span> | <span class="built_in">sudo</span> <span class="built_in">tee</span> /etc/apt/sources.list.d/docker.list &gt; /dev/null</span><br><span class="line"><span class="comment"># 更新 apt 包索引</span></span><br><span class="line"><span class="built_in">sudo</span> apt update</span><br><span class="line"><span class="comment"># 列出所有可用 Docker CE 软件包版本（确保上述指令正常）</span></span><br><span class="line">apt-cache madison docker-ce</span><br><span class="line"><span class="comment"># 安装 Docker</span></span><br><span class="line"><span class="built_in">sudo</span> apt install -y docker-ce docker-ce-cli containerd.io</span><br><span class="line"><span class="comment"># 启用并启动 Docker 服务</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> docker</span><br><span class="line"><span class="built_in">sudo</span> systemctl start docker</span><br></pre></td></tr></table></figure></div>

<p>镜像及其它设置：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 配置镜像</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mkdir</span> -p /etc/docker</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">tee</span> /etc/docker/daemon.json &lt;&lt;-<span class="string">'EOF'</span></span><br><span class="line">{</span><br><span class="line">  <span class="string">"registry-mirrors"</span>: [<span class="string">"https://docker.m.daocloud.io"</span>]</span><br><span class="line">}</span><br><span class="line">EOF</span><br><span class="line"><span class="built_in">sudo</span> systemctl daemon-reload</span><br><span class="line"><span class="built_in">sudo</span> systemctl restart docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># （可选）以非 root 用户身份运行 Docker</span></span><br><span class="line"><span class="built_in">sudo</span> usermod -aG docker <span class="variable">$USER</span></span><br><span class="line"><span class="comment"># 使用该命令后需要重启终端才生效</span></span><br></pre></td></tr></table></figure></div>

<p>测试：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> docker run hello-world</span><br><span class="line"><span class="comment"># 非 root 用户测试</span></span><br><span class="line">docker run hello-world</span><br></pre></td></tr></table></figure></div>

<h2 id="2-安装-kind"><a href="#2-安装-kind" class="headerlink" title="2. 安装 kind"></a>2. 安装 kind</h2><p>kind 只是一个二进制文件，因此下载下来放到 bin 目录即可<a href="#refer-anchor-1"><sup>[2]</sup></a>。<br>推荐使用官方 release 版本：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.22.0/kind-linux-amd64</span><br><span class="line"><span class="built_in">chmod</span> +x ./kind</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mv</span> ./kind /usr/local/bin/kind</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>可通过 <code>kind --version</code> 验证安装。</p>
</blockquote>
<h2 id="3-创建-kind-集群"><a href="#3-创建-kind-集群" class="headerlink" title="3. 创建 kind 集群"></a>3. 创建 kind 集群</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kind create cluster --name test-cluster</span><br></pre></td></tr></table></figure></div>

<ul>
<li>默认会创建一个单节点集群，若需多节点可自定义配置文件。</li>
<li>kind 会自动生成 kubeconfig 文件，默认路径为 <code>~/.kube/config</code>。</li>
<li>若非管理员用户，可能会出现以下 docker 权限报错，需要在指令前加上 <code>sudo</code>（即<code>sudo kind create cluster --name test-cluster</code>），但后续所有命令都需要加<code>sudo</code>所以很麻烦。也可以参考<a href="#refer-anchor-1">[5,6]</a>增加用户组<code>docker</code>。<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><figcaption><span>权限问题报错</span></figcaption><table><tr><td class="code"><pre><span class="line">ERROR: failed to create cluster: failed to list nodes: <span class="built_in">command</span> <span class="string">"docker ps -a --filter label=io.x-k8s.kind.cluster=test-cluster --format '{{.Names}}'"</span> failed with error: <span class="built_in">exit</span> status 1</span><br><span class="line">Command Output: permission denied <span class="keyword">while</span> trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get <span class="string">"http://%2Fvar%2Frun%2Fdocker.sock/v1.44/containers/json?all=1&amp;filters=%7B%22label%22%3A%7B%22io.x-k8s.kind.cluster%3Dtest-cluster%22%3Atrue%7D%7D"</span>: dial unix /var/run/docker.sock: connect: permission denied</span><br></pre></td></tr></table></figure></div>
<ul>
<li>永久增加用户组方法（若使用 vscode 等软件远程连接，则需要关闭窗口重新打开，否则将会无效。白白害我排查半天。）<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><figcaption><span>增加用户组方法</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Docker组</span></span><br><span class="line"><span class="built_in">sudo</span> groupadd docker</span><br><span class="line"><span class="comment"># 将您的用户添加到docker组中（以下指令三选一）</span></span><br><span class="line"><span class="built_in">sudo</span> usermod -aG docker <span class="variable">${USER}</span></span><br><span class="line"><span class="built_in">sudo</span> gpasswd -a <span class="variable">${USER}</span> docker</span><br><span class="line">newgrp - docker <span class="comment"># 将当前用户加入 docker 组</span></span><br><span class="line"><span class="comment"># 您需要注销并重新登录，以便重新评估您的群组成员资格，或者输入以下命令：</span></span><br><span class="line">su -s <span class="variable">${USER}</span></span><br><span class="line"><span class="comment"># ≈查看用户所属组</span></span><br><span class="line"><span class="built_in">groups</span> <span class="variable">${USER}</span></span><br><span class="line"><span class="comment"># 验证你可以不使用 sudo 运行 docker 命令</span></span><br><span class="line">docker run hello-world</span><br></pre></td></tr></table></figure></div></li>
<li>一次性赋权方法（每次 docker 重启都需要重新设置）<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><figcaption><span>一次性赋权方法</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">chmod</span> 666 /var/run/docker.sock</span><br></pre></td></tr></table></figure></div></li>
</ul>
</li>
<li>若非管理员用户，还会出现以下 K8s 权限报错，需要在指令前加上 <code>sudo</code>（即<code>sudo kind create cluster --name test-cluster</code>），但后续所有命令都需要加<code>sudo</code>所以很麻烦。也可以参考<a href="#refer-anchor-1">[7]</a>增加用户专属配置文件。<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><figcaption><span>权限问题报错</span></figcaption><table><tr><td class="code"><pre><span class="line">ERROR: failed to create cluster: failed to lock config file: open /etc/kubernetes/admin.conf.lock: permission denied</span><br></pre></td></tr></table></figure></div>
<ul>
<li>增加用户专属配置文件（根据<a href="#refer-anchor-1">[8]</a>，环境变量配置一般放在<code>~/.bash_profile</code>而非<code>~/.bashrc</code>。rc系列修改之后，只要重新打开一个终端窗口就可以生效，所以其中内容可以被多次加载；profile系列，需要重新开启新的会话才能生效，所以其中内容仅仅在登录的时候被加载一次。）<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><figcaption><span>增加用户专属配置文件方法</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># 复制config文件</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chown</span> -R $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/</span><br><span class="line"><span class="comment"># 配置环境变量</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"export KUBECONFIG=<span class="variable">$HOME</span>/.kube/config"</span> &gt;&gt; ~/.bash_profile</span><br><span class="line"><span class="built_in">source</span> ~/.bash_profile</span><br></pre></td></tr></table></figure></div></li>
</ul>
</li>
<li>此外，由于统版内核版本过低（目前服务器还是<code>CentOS Linux release 7.9.2009 (Core)</code>，已经停止维护，之前还出现过 vscode 不支持问题，真是麻烦），导致较新版 k8s 不兼容，通过降低 k8s 版本进行解决。（目前以验证可行的是 KIND v0.17.0、镜像 kindest/node:v1.25.3）具体报错如下：<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">ERROR: failed to create cluster: <span class="built_in">command</span> <span class="string">"docker run --name test-cluster-control-plane --hostname test-cluster-control-plane --label io.x-k8s.kind.role=control-plane --privileged --security-opt seccomp=unconfined --security-opt apparmor=unconfined --tmpfs /tmp --tmpfs /run --volume /var --volume /lib/modules:/lib/modules:ro -e KIND_EXPERIMENTAL_CONTAINERD_SNAPSHOTTER --detach --tty --label io.x-k8s.kind.cluster=test-cluster --net kind --restart=on-failure:1 --init=false --cgroupns=private --volume /dev/mapper:/dev/mapper --publish=127.0.0.1:44259:6443/TCP -e KUBECONFIG=/etc/kubernetes/admin.conf kindest/node:v1.29.2@sha256:51a1434a5397193442f0be2a297b488b6c919ce8a3931be0ce822606ea5ca245"</span> failed with error: <span class="built_in">exit</span> status 125</span><br><span class="line">Command Output: WARNING: Your kernel does not support cgroup namespaces.  Cgroup namespace setting discarded.</span><br><span class="line">ca8cbcec785528161581ddbb744194bed718bc8cbfe3e6ac73300312d3d0e6d1</span><br><span class="line">docker: Error response from daemon: failed to create task <span class="keyword">for</span> container: failed to create shim task: OCI runtime create failed: runc create failed: cgroup namespaces aren<span class="string">'t enabled in the kernel: unknown.</span></span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h2 id="4-配置-kubectl"><a href="#4-配置-kubectl" class="headerlink" title="4. 配置 kubectl"></a>4. 配置 kubectl</h2><p>Kind 只负责创建集群（会配置好 kubeconfig），后续操作集群的话需要手动安装 kubectl<a href="#refer-anchor-1"><sup>[2]</sup></a>。<br>如未安装 kubectl，可参考：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">curl -LO <span class="string">"https://dl.k8s.io/release/<span class="subst">$(curl -L -s https://dl.k8s.io/release/stable.txt)</span>/bin/linux/amd64/kubectl"</span></span><br><span class="line"><span class="built_in">chmod</span> +x kubectl</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mv</span> kubectl /usr/local/bin/</span><br></pre></td></tr></table></figure></div>

<p>验证集群连接：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl cluster-info --context kind-test-cluster</span><br><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure></div>

<h2 id="5-常用操作"><a href="#5-常用操作" class="headerlink" title="5. 常用操作"></a>5. 常用操作</h2><ul>
<li><p>删除集群：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kind delete cluster --name test-cluster</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>查看集群列表：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kind get clusters</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>切换集群：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl config use-context kind-<span class="variable">${CLUSTER_NAME}</span></span><br></pre></td></tr></table></figure></div>
</li>
<li><p>自定义集群配置（如多节点、端口映射等），可参考官方文档。</p>
</li>
<li><p>切换回原 K8s</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看 `${KUBECONFIG}` 文件中 `contexts` 下原`context`的 `name`，假设为`CONTEXT_NAME`</span></span><br><span class="line"><span class="comment"># 通常路径为： "KUBECONFIG=/etc/kubernetes/admin.conf"</span></span><br><span class="line"><span class="comment"># 使用以下命令，相当于修改 `${KUBECONFIG}` 文件中 `current-context` 为 ${CONTEXT_NAME}</span></span><br><span class="line">$ kubectl config use-context <span class="variable">${CONTEXT_NAME}</span></span><br><span class="line"><span class="comment"># 查看修改后的集群环境</span></span><br><span class="line">$ kubectl cluster-info</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h2 id="6-常见问题"><a href="#6-常见问题" class="headerlink" title="6. 常见问题"></a>6. 常见问题</h2><ul>
<li><strong>端口冲突</strong>：如需暴露端口，需在 kind 配置文件中映射主机端口。</li>
<li><strong>网络问题</strong>：服务器需能访问外网拉取镜像，或提前下载好所需镜像。</li>
<li><strong>权限问题</strong>：如遇到 <code>permission denied</code>，请检查 Docker 及 kind 的执行权限。</li>
</ul>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><ul>
<li>kind 适合开发、测试、CI 场景，不建议用于生产环境。</li>
<li>虚拟集群资源消耗依赖于 Docker 容器，建议合理分配服务器资源。</li>
<li>kind 支持多节点和自定义配置，灵活性较高，适合多种测试需求。</li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://yeasy.gitbook.io/docker_practice/install">[1] 安装 Docker<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.lixueduan.com/posts/kubernetes/15-kind-kubernetes-in-docker/">[2] Kubernetes教程(十五)—使用 kind 在本地快速部署一个 k8s集群<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.cnblogs.com/zouzou-busy/p/16388186.html">[3] k8s–kind 搭建 k8s 集群<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.chenshaowen.com/blog/practice-guide-to-kind.html">[4] kind 实用指南<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.digitalocean.com/community/questions/how-to-fix-docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socket">[5] How to fix docker: Got permission denied while trying to connect to the Docker daemon socket<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a href="https://blog.csdn.net/luckytonyzhang/article/details/89059415">[6] 关于Docker时的权限问题解决dial unix /var/run/docker.sock: connect: <code>permission denied</code></a></p>
<p><a class="link" href="https://stackoverflow.com/questions/53727197/kubernetes-permission-denied-error-on-config-lock">[7] Kubernetes permission denied error on config.lock<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://blog.csdn.net/weixin_41712499/article/details/101439882">[8] bashrc、bash_profile傻傻分不清楚？<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://blog.csdn.net/qq_52153601/article/details/140440040">[9] 小白 Ubuntu 安装Docker全教程（已成功！）<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.cnblogs.com/ag-chen/p/18677273">[10] Ubuntu 安装Docker<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://blog.csdn.net/Tester_muller/article/details/131440306">[11] 最详细的ubuntu 安装 docker教程<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>kind</tag>
        <tag>虚拟集群</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】KubeSphere搭建记录——ks-installer 解析</title>
    <url>/2024/01/19/k8s/k8s-kubesphere-installer/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>KubeSphere 部署后，Prometheus 一直无法正常部署，排查后发现是底层 NFS 系统出了故障，但想修改 Prometheus 的存储配置却无从下手。<br>因此，对 ks-installer 组件自动安装器进行了解析。</p>
<h1 id="🫎修改配置方法"><a href="#🫎修改配置方法" class="headerlink" title="🫎修改配置方法"></a>🫎修改配置方法</h1><p>根据对 ks-installer 组件极其核心脚本分析，想修改 monitoring 模块的 Prometheus 组件配置方式如下：</p>
<p>假设<code>/root/wxl/cluster-configuration.yaml</code>配置文件对应的<code>cluster-configuration</code>已部署，相关属性如下：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">ClusterConfiguration（简称cc）</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">ks-installer</span></span><br><span class="line"><span class="attr">namespace:</span> <span class="string">kubesphere-system</span></span><br></pre></td></tr></table></figure></div>
<p>可通过以下命令修改：<code>kubectl edit cc -n kubesphere-system ks-installer</code></p>
<ol>
<li><p>删除出错prometheus对应的<code>pvc</code>（因为<code>monitoring</code>会获取历史配置）<br>见<code>/kubesphere/roles/roles/ks-monitor/tasks/get_old_config.yaml:4</code></p>
</li>
<li><p>在已部署的<code>cluster-configuration</code>中删除<code>status:monitoring</code>（或改为满足以下条件：<code>"status.monitoring is not defined or status.monitoring.status is not defined or status.monitoring.status != 'enabled'"</code>）</p>
</li>
<li><p>修改相关参数。当ks-installer检测到<code>ClusterConfiguration</code>变化则会重新部署。</p>
</li>
</ol>
<p>ps：如果想取消 Prometheus 持久化，只要把storage属性完全删掉就可以了。</p>
<h1 id="🧠解析：自动化安装Prometheus逻辑-1"><a href="#🧠解析：自动化安装Prometheus逻辑-1" class="headerlink" title="🧠解析：自动化安装Prometheus逻辑[1]"></a>🧠解析：自动化安装Prometheus逻辑<a href="#refer-anchor-1"><sup>[1]</sup></a></h1><p>ks-installer本质是一个脚本执行器（shell-operator），发生变化时自动执行部署脚本。（部署在shell-operator中的脚本可以订阅预设的钩子，钩子发生变化后触发脚本）</p>
<p>shell-operator支持以下三类钩子：</p>
<ol>
<li>OnStartup：启动后即运行</li>
<li>schedule：crontab格式的定时任务</li>
<li>kubernetes：监控Kubernetes资源，根据定义的事件类型来响应</li>
</ol>
<p>ks-installer的pod中/hooks/kubesphere目录下包含两个文件：</p>
<ul>
<li>installRunner.py：部署ks-installer</li>
<li>schedule.sh：定期执行任务，检查状态、注册</li>
</ul>
<p>查看安装日志：<code>kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f</code></p>
<p>通过进入pod查看ks-installer文件，可以理解安装Prometheus逻辑<a href="#refer-anchor-2"><sup>[2]</sup></a>：<code>kubectl -n kubesphere-system exec -it $(kubectl get pod -n kubesphere-system -l app=ks-installer -o jsonpath='{.items[0].metadata.name}') -- bash</code></p>
<p>根据<a href="#refer-anchor-2"><sup>[2]</sup></a>发现Prometheus的相关配置在<code>/kubesphere/kubesphere/prometheus</code>目录下。找到使我们报错的文件：<code>/kubesphere/kubesphere/prometheus/prometheus/prometheus-prometheus.yaml</code></p>
<h1 id="🖼️解析：ks-installer-核心脚本"><a href="#🖼️解析：ks-installer-核心脚本" class="headerlink" title="🖼️解析：ks-installer 核心脚本"></a>🖼️解析：ks-installer 核心脚本</h1><ul>
<li><code>installRunner.py</code> 文件位置：</li>
</ul>
<ol>
<li>进入 ks-installer pod<br><code>kubectl exec -it -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -- bash</code></li>
<li>进入钩子目录<br><code>cd /hooks/kubesphere</code></li>
</ol>
<h2 id="逻辑解析：以-monitoring-组件为例"><a href="#逻辑解析：以-monitoring-组件为例" class="headerlink" title="逻辑解析：以 monitoring 组件为例"></a>逻辑解析：以 monitoring 组件为例</h2><ol>
<li><p>在 configFile 文件中配置enabled（部分组件默认enabled，无需单独配置）</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /kubesphere/config/ks-config.json</span></span><br><span class="line">  <span class="attr">monitoring:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></div></li>
<li><p>配置 Ansible playbook 脚本，说明流程</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /kubesphere/playbooks/monitoring.yaml</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">localhost</span>  <span class="comment"># 表示 playbook 中的任务将在 localhost上执行。</span></span><br><span class="line"><span class="attr">gather_facts:</span> <span class="literal">false</span>   <span class="comment"># 表示 Ansible 不会收集关于 localhost 的 facts。Facts 是 Ansible 收集的关于系统的信息，包括操作系统、网络接口、硬件、环境变量等等。如果你不需要这些信息，可以设置 gather_facts: false 来提高 playbook 的执行速度。</span></span><br><span class="line"><span class="attr">roles:</span>    <span class="comment"># 一个列表，定义了应用于 localhost 的 Ansible roles。Roles 是一种组织 playbook 的方式，它们包含了一系列相关的任务、变量、模板等等。在这个例子中，有两个 roles：kubesphere-defaults 和 ks-monitor。这意味着 Ansible 将执行这两个 roles 中定义的任务。</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">kubesphere-defaults</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ks-monitor</span></span><br></pre></td></tr></table></figure></div>
</li>
<li><p>查看 roles 定义的任务（核心在3.2.3）</p>
</li>
</ol>
<ul>
<li><p>3.1 kubesphere-defaults</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /kubesphere/roles/kubesphere-defaults/tasks/main.yaml</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">images'</span> <span class="string">namespace</span> <span class="string">override</span></span><br><span class="line"><span class="attr">set_fact:</span> <span class="comment"># 当local_registry被设置为北京阿里云仓库、或zone被设置为cn时，设置 namespace_override 变量</span></span><br><span class="line">    <span class="attr">namespace_override:</span> <span class="string">"kubesphereio"</span></span><br><span class="line"><span class="attr">when:</span> <span class="string">(local_registry</span> <span class="string">is</span> <span class="string">defined</span> <span class="string">and</span> <span class="string">local_registry</span> <span class="string">==</span> <span class="string">"registry.cn-beijing.aliyuncs.com"</span><span class="string">)</span> <span class="string">or</span> <span class="string">(zone</span> <span class="string">is</span> <span class="string">defined</span> <span class="string">and</span> <span class="string">zone</span> <span class="string">==</span> <span class="string">"cn"</span><span class="string">)</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Configuring</span> <span class="string">defaults</span></span><br><span class="line"><span class="attr">debug:</span>    <span class="comment"># 输出信息msg到日志</span></span><br><span class="line">    <span class="attr">msg:</span> <span class="string">"Check roles/kubesphere-defaults/defaults/main.yml"</span></span><br><span class="line"><span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">always</span></span><br></pre></td></tr></table></figure></div>
</li>
<li><p>3.2 ks-monitor</p>
<ul>
<li><p>3.2.1 main</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /kubesphere/roles/ks-monitor/tasks/main.yaml</span></span><br><span class="line"><span class="comment"># 导入一系列其他的任务文件（import_tasks）和执行一个 shell 命令</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">prometheus-stack.yaml</span>   <span class="comment"># 导入 prometheus-stack.yaml 文件中定义的任务，并在 common.monitoring.type 未定义或者不等于 'external' 时执行。</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"common.monitoring.type is not defined or common.monitoring.type != 'external'"</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">monitoring-dashboard.yaml</span>   <span class="comment"># 当没有monitoring的status时，初始化monitoring</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"status.monitoring is not defined or status.monitoring.status is not defined or status.monitoring.status != 'enabled'"</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">ks-istio-monitoring.yaml</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"servicemesh.enabled is defined and servicemesh.enabled"</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">gpu-monitoring.yaml</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"status.monitoring is not defined or status.monitoring.status is not defined or status.monitoring.status != 'enabled'"</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Monitoring</span> <span class="string">|</span> <span class="string">Importing</span> <span class="string">ks-monitoring</span> <span class="string">status</span></span><br><span class="line"><span class="attr">shell:</span> <span class="string">&gt;</span></span><br><span class="line"><span class="string">    {{ bin_dir }}/kubectl patch cc ks-installer</span></span><br><span class="line"><span class="string">    --type merge</span></span><br><span class="line"><span class="string">    -p '{"status": {"monitoring": {"status": "enabled", "enabledTime": "{{ lookup('pipe','date  +%Y-%m-%dT%H:%M:%S%Z') }}"}}}'</span></span><br><span class="line"><span class="string">    -n kubesphere-system</span></span><br><span class="line"><span class="string"></span><span class="attr">register:</span> <span class="string">cc_result</span></span><br><span class="line"><span class="attr">failed_when:</span> <span class="string">"cc_result.stderr and 'Warning' not in cc_result.stderr"</span></span><br><span class="line"><span class="attr">until:</span> <span class="string">cc_result</span> <span class="string">is</span> <span class="string">succeeded</span></span><br><span class="line"><span class="attr">retries:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">delay:</span> <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">thanos-ruler.yaml</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">alerting</span> <span class="string">is</span> <span class="string">defined</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">alerting.enabled</span> <span class="string">is</span> <span class="string">defined</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">alerting.enabled</span> <span class="string">==</span> <span class="literal">true</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"status.alerting is not defined or status.alerting.status is not defined or status.alerting.status != 'enabled'"</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">alert-migrate.yaml</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">alerting</span> <span class="string">is</span> <span class="string">defined</span> <span class="string">and</span> <span class="string">alerting.enabled</span> <span class="string">is</span> <span class="string">defined</span> <span class="string">and</span> <span class="string">alerting.enabled</span> <span class="string">==</span> <span class="literal">true</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"status.alerting is not defined or status.alerting.status is not defined or status.alerting.status != 'enabled'"</span></span><br></pre></td></tr></table></figure></div>
</li>
<li><p>3.2.2 prometheus-stack</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /kubesphere/roles/ks-monitor/tasks/prometheus-stack.yaml</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">cleanup.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">generate_manifests.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">prometheus-operator.yaml</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"status.monitoring is not defined or status.monitoring.status is not defined or status.monitoring.status != 'enabled'"</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">node-exporter.yaml</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"status.monitoring is not defined or status.monitoring.status is not defined or status.monitoring.status != 'enabled'"</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">kube-state-metrics.yaml</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"status.monitoring is not defined or status.monitoring.status is not defined or status.monitoring.status != 'enabled'"</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">grafana.yaml</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">monitoring.grafana</span> <span class="string">is</span> <span class="string">defined</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">monitoring.grafana.enabled</span> <span class="string">is</span> <span class="string">defined</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">monitoring.grafana.enabled</span> <span class="string">==</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">prometheus.yaml</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"status.monitoring is not defined or status.monitoring.status is not defined or status.monitoring.status != 'enabled'"</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">etcd.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">k8s-monitor.yaml</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"status.monitoring is not defined or status.monitoring.status is not defined or status.monitoring.status != 'enabled'"</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">ks-core-monitor.yaml</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"status.monitoring is not defined or status.monitoring.status is not defined or status.monitoring.status != 'enabled'"</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">alertmanager.yaml</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"status.monitoring is not defined or status.monitoring.status is not defined or status.monitoring.status != 'enabled'"</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">notification-manager.yaml</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"status.monitoring is not defined or status.monitoring.status is not defined or status.monitoring.status != 'enabled'"</span></span><br></pre></td></tr></table></figure></div>
</li>
<li><p>3.2.3 generate_manifests</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /kubesphere/roles/ks-monitor/tasks/generate_manifests.yaml</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Monitoring</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">ks-monitoring</span> <span class="string">installation</span> <span class="string">files</span></span><br><span class="line"><span class="attr">copy:</span></span><br><span class="line">    <span class="attr">src:</span> <span class="string">"<span class="template-variable">{{ item }}</span>"</span></span><br><span class="line">    <span class="attr">dest:</span> <span class="string">"<span class="template-variable">{{ kubesphere_dir }}</span>/"</span></span><br><span class="line"><span class="attr">loop:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"prometheus"</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">import_tasks:</span> <span class="string">get_old_config.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Monitoring</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">manifests</span></span><br><span class="line"><span class="attr">template:</span></span><br><span class="line">    <span class="attr">src:</span> <span class="string">"<span class="template-variable">{{ item.file }}</span>.j2"</span></span><br><span class="line">    <span class="attr">dest:</span> <span class="string">"<span class="template-variable">{{ kubesphere_dir }}</span>/<span class="template-variable">{{ item.path }}</span>/<span class="template-variable">{{ item.file }}</span>"</span></span><br><span class="line"><span class="attr">with_items:</span></span><br><span class="line">    <span class="bullet">-</span> { <span class="attr">path:</span> <span class="string">prometheus/prometheus-operator</span>, <span class="attr">file:</span> <span class="string">prometheus-operator-deployment.yaml</span> }</span><br><span class="line">    <span class="bullet">-</span> { <span class="attr">path:</span> <span class="string">prometheus/prometheus</span>, <span class="attr">file:</span> <span class="string">prometheus-prometheus.yaml</span> }</span><br><span class="line">    <span class="bullet">-</span> { <span class="attr">path:</span> <span class="string">prometheus/prometheus</span>, <span class="attr">file:</span> <span class="string">prometheus-podDisruptionBudget.yaml</span>}</span><br><span class="line">    <span class="bullet">-</span> { <span class="attr">path:</span> <span class="string">prometheus/kube-state-metrics</span>, <span class="attr">file:</span> <span class="string">kube-state-metrics-deployment.yaml</span> }</span><br><span class="line">    <span class="bullet">-</span> { <span class="attr">path:</span> <span class="string">prometheus/node-exporter</span>, <span class="attr">file:</span> <span class="string">node-exporter-daemonset.yaml</span> }</span><br><span class="line">    <span class="bullet">-</span> { <span class="attr">path:</span> <span class="string">prometheus/alertmanager</span>, <span class="attr">file:</span> <span class="string">alertmanager-alertmanager.yaml</span> }</span><br><span class="line">    <span class="bullet">-</span> { <span class="attr">path:</span> <span class="string">prometheus/alertmanager</span>, <span class="attr">file:</span> <span class="string">alertmanager-podDisruptionBudget.yaml</span> }</span><br><span class="line">    <span class="bullet">-</span> { <span class="attr">path:</span> <span class="string">prometheus/grafana</span>, <span class="attr">file:</span> <span class="string">grafana-deployment.yaml</span> }</span><br><span class="line">    <span class="bullet">-</span> { <span class="attr">path:</span> <span class="string">prometheus/etcd</span>, <span class="attr">file:</span> <span class="string">prometheus-serviceMonitorEtcd.yaml</span> }</span><br><span class="line">    <span class="bullet">-</span> { <span class="attr">path:</span> <span class="string">prometheus/etcd</span>, <span class="attr">file:</span> <span class="string">prometheus-endpointsEtcd.yaml</span> }</span><br><span class="line">    <span class="bullet">-</span> { <span class="attr">path:</span> <span class="string">prometheus/thanos-ruler</span>, <span class="attr">file:</span> <span class="string">thanos-ruler-thanosRuler.yaml</span> }</span><br><span class="line">    <span class="bullet">-</span> { <span class="attr">path:</span> <span class="string">prometheus/thanos-ruler</span>, <span class="attr">file:</span> <span class="string">thanos-ruler-podDisruptionBudget.yaml</span> }</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>3.2.4 get_old_config</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /kubesphere/roles/roles/ks-monitor/tasks/get_old_config.yaml</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Monitoring</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">Prometheus</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">shell:</span> <span class="string">&gt;</span></span><br><span class="line"><span class="string">    {{ bin_dir }}/kubectl get pvc -n kubesphere-monitoring-system prometheus-k8s-db-prometheus-k8s-0 -o jsonpath='{.spec.resources.requests.storage}'</span></span><br><span class="line"><span class="string"></span><span class="attr">register:</span> <span class="string">prometheus_pvc</span></span><br><span class="line"><span class="attr">failed_when:</span> <span class="literal">false</span>    <span class="comment"># 即使命令执行失败，也不会停止 playbook 的执行</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Monitoring</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">Prometheus</span> <span class="string">data</span> <span class="string">pv</span> <span class="string">size</span></span><br><span class="line"><span class="attr">set_fact:</span></span><br><span class="line">    <span class="attr">prometheus_pv_size:</span> <span class="string">"<span class="template-variable">{{ prometheus_pvc.stdout }}</span>"</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">prometheus_pvc.rc</span> <span class="string">==</span> <span class="number">0</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">prometheus_pvc.stdout</span> <span class="type">!=</span> <span class="string">""</span></span><br><span class="line"><span class="attr">failed_when:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Monitoring</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">Prometheus</span> <span class="string">retention</span> <span class="string">days</span></span><br><span class="line"><span class="attr">shell:</span> <span class="string">&gt;</span></span><br><span class="line"><span class="string">    {{ bin_dir }}/kubectl get prometheuses.monitoring.coreos.com -n kubesphere-monitoring-system k8s -o jsonpath='{.spec.retention}'</span></span><br><span class="line"><span class="string"></span><span class="attr">register:</span> <span class="string">prometheus_retention</span></span><br><span class="line"><span class="attr">failed_when:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Monitoring</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">Prometheus</span> <span class="string">retention</span> <span class="string">days</span></span><br><span class="line"><span class="attr">set_fact:</span></span><br><span class="line">    <span class="attr">prometheus_retention_duration:</span> <span class="string">"<span class="template-variable">{{ prometheus_retention.stdout }}</span>"</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">prometheus_retention.rc</span> <span class="string">==</span> <span class="number">0</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">prometheus_retention.stdout</span> <span class="type">!=</span> <span class="string">""</span></span><br><span class="line"><span class="attr">failed_when:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Monitoring</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">Prometheus</span> <span class="string">node</span> <span class="string">selector</span></span><br><span class="line"><span class="attr">shell:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    {{ bin_dir }}/kubectl get prometheuses.monitoring.coreos.com -n kubesphere-monitoring-system k8s -o go-template --template="{{ '{{' }}range \$key, \$value := .spec.nodeSelector{{ '}}' }}    {{ '{{' }}\$key{{ '}}' }}: {{ '{{' }}\$value{{ '}}' }}</span></span><br><span class="line"><span class="string">    {{ '{{' }}end{{ '}}' }}"</span></span><br><span class="line"><span class="string"></span><span class="attr">register:</span> <span class="string">prometheus_node_selector</span></span><br><span class="line"><span class="attr">failed_when:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Monitoring</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">Prometheus</span> <span class="string">node</span> <span class="string">selector</span></span><br><span class="line"><span class="attr">set_fact:</span></span><br><span class="line">    <span class="attr">prometheus_node_selector_map:</span> <span class="string">"<span class="template-variable">{{ prometheus_node_selector.stdout }}</span>"</span></span><br><span class="line"><span class="attr">when:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">prometheus_node_selector.rc</span> <span class="string">==</span> <span class="number">0</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">prometheus_node_selector.stdout</span> <span class="type">!=</span> <span class="string">""</span></span><br><span class="line"><span class="attr">failed_when:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></div>
</li>
<li><p>3.2.5 monitoring-dashboard</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /kubesphere/roles/ks-monitor/tasks/monitoring-dashboard.yaml</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Monitoring</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">monitoring-dashboard</span> <span class="string">installation</span> <span class="string">files</span></span><br><span class="line"><span class="attr">copy:</span></span><br><span class="line">    <span class="attr">src:</span> <span class="string">"<span class="template-variable">{{ item }}</span>"</span>   <span class="comment"># 遍历loop中的值，此处只有monitoring-dashboard</span></span><br><span class="line">    <span class="attr">dest:</span> <span class="string">"<span class="template-variable">{{ kubesphere_dir }}</span>/"</span></span><br><span class="line"><span class="attr">loop:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"monitoring-dashboard"</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Monitoring</span> <span class="string">|</span> <span class="string">Installing</span> <span class="string">monitoring-dashboard</span></span><br><span class="line"><span class="attr">shell:</span> <span class="string">&gt;</span></span><br><span class="line">    {{ <span class="string">bin_dir</span> }}<span class="string">/kubectl</span> <span class="string">apply</span> <span class="string">-f</span> {{ <span class="string">kubesphere_dir</span> }}<span class="string">/monitoring-dashboard</span></span><br></pre></td></tr></table></figure></div>

</li>
</ul>
</li>
</ul>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://blog.csdn.net/styshoo/article/details/124623953">[1] Kubesphere之ks-installer介绍<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link" href="https://kubesphere.io/zh/docs/v3.3/faq/observability/byop/">[2] 集成您自己的 Prometheus<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link" href="https://github.com/kubesphere/ks-installer/blob/ef79beead3285698cdce559dd5505c79fe11dbff/roles/ks-monitor/templates/prometheus-prometheus.yaml.j2#L111">[3] 生成prometheus-prometheus.yaml文件的模板<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>K8S</tag>
        <tag>KubeSphere</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】K8S集群搭建记录——kwok搭建轻量测试环境</title>
    <url>/2025/05/20/k8s/k8s-kwok-install/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>为了在单机上测试大规模性能，需要安装 kwok 创建轻量的测试环境。前期已经通过 kind 创建了虚拟测试环境，现在记录一下安装和使用 kwok 的方法、问题以及常用操作。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><ul>
<li>需要测试大规模 Kubernetes 集群的性能和资源调度。</li>
<li>实际硬件资源有限，无法部署大量真实节点。</li>
<li>kwok 可以模拟大量虚拟节点，适合性能测试场景。</li>
<li>前期已经通过 kind 搭建了基础测试环境。</li>
</ul>
<h1 id="🧠思路"><a href="#🧠思路" class="headerlink" title="🧠思路"></a>🧠思路</h1><ol>
<li>在已有 kind 集群上安装 kwok。</li>
<li>配置 kwok 模拟节点。</li>
<li>验证虚拟节点状态。</li>
<li>进行性能测试。</li>
<li>记录常见问题与解决方法。</li>
</ol>
<h1 id="🔨解决"><a href="#🔨解决" class="headerlink" title="🔨解决"></a>🔨解决</h1><h2 id="0-安装-Go"><a href="#0-安装-Go" class="headerlink" title="0. 安装 Go"></a>0. 安装 Go</h2><p>安装 kwok 和 kwokctl 时会使用 <code>go env</code> 命令获取系统信息。同时，为了更好的兼容性和未来可能的扩展，建议安装 Go。以下是安装步骤：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下载最新版本的 Go（以 1.22.3、1.23.10 为例）</span></span><br><span class="line">wget https://go.dev/dl/go1.22.3.linux-amd64.tar.gz</span><br><span class="line">wget https://go.dev/dl/go1.23.10.linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除旧版本（如果存在）</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">rm</span> -rf /usr/local/go</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压到 /usr/local</span></span><br><span class="line"><span class="built_in">sudo</span> tar -C /usr/local -xzf go1.22.3.linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置环境变量（如果使用 bash）</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'export PATH=$PATH:/usr/local/go/bin'</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证安装</span></span><br><span class="line">go version</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>注意：如果不想安装 Go，也可以手动指定系统信息：</p>
<ul>
<li>对于 Linux 系统，可以直接使用 <code>linux-amd64</code> 替代 <code>$(go env GOOS)-$(go env GOARCH)</code></li>
<li>对于 MacOS 系统，可以使用 <code>darwin-amd64</code> 或 <code>darwin-arm64</code>（M1/M2芯片）</li>
<li>对于 Windows 系统，可以使用 <code>windows-amd64</code></li>
</ul>
</blockquote>
<h2 id="1-安装-kwok-和-kwokctl"><a href="#1-安装-kwok-和-kwokctl" class="headerlink" title="1. 安装 kwok 和 kwokctl"></a>1. 安装 kwok 和 kwokctl</h2><p>组件作用：<br>• kwokctl — 也是一个 CLI 管理，允许你使用 Docker 建立独立集群（类似于 Kind 集群）。如果已经有 kind 就不需要使用 kwokctl 了。<br>• kwok — 负责模拟集群及其资源的资源控制器。</p>
<p>kwok 提供了多种安装方式，这里使用二进制安装方式。</p>
<p>a. 首先配置相关变量</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 配置变量 KWOK repository</span></span><br><span class="line">KWOK_REPO=kubernetes-sigs/kwok</span><br><span class="line"><span class="comment"># 配置变量 Get latest</span></span><br><span class="line">KWOK_LATEST_RELEASE=$(curl <span class="string">"https://api.github.com/repos/<span class="variable">${KWOK_REPO}</span>/releases/latest"</span> | jq -r <span class="string">'.tag_name'</span>)</span><br></pre></td></tr></table></figure></div>

<p>b. 安装 kwokctl</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装最新版本 kwokctl</span></span><br><span class="line">wget -O kwokctl -c <span class="string">"https://github.com/<span class="variable">${KWOK_REPO}</span>/releases/download/<span class="variable">${KWOK_LATEST_RELEASE}</span>/kwokctl-<span class="subst">$(go env GOOS)</span>-<span class="subst">$(go env GOARCH)</span>"</span></span><br><span class="line"><span class="built_in">chmod</span> +x kwokctl</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mv</span> kwokctl /usr/local/bin/kwokctl</span><br></pre></td></tr></table></figure></div>

<p>c. 安装 kwok</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装最新版本 kwok</span></span><br><span class="line">wget -O kwok -c <span class="string">"https://github.com/<span class="variable">${KWOK_REPO}</span>/releases/download/<span class="variable">${KWOK_LATEST_RELEASE}</span>/kwok-<span class="subst">$(go env GOOS)</span>-<span class="subst">$(go env GOARCH)</span>"</span></span><br><span class="line"><span class="built_in">chmod</span> +x kwok</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mv</span> kwok /usr/local/bin/kwok</span><br></pre></td></tr></table></figure></div>

<h2 id="2-创建虚拟集群"><a href="#2-创建虚拟集群" class="headerlink" title="2. 创建虚拟集群"></a>2. 创建虚拟集群</h2><p>因为已经有 kind 就不需要使用 kwokctl 再创建了。</p>
<p>如果没有使用 kind 的话，按照以下指令进行创建：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建虚拟集群</span></span><br><span class="line">kwokctl create cluster --name kwok-cluster</span><br><span class="line"><span class="comment"># 验证是否已创建</span></span><br><span class="line">kwokctl get clusters</span><br><span class="line"><span class="comment"># 如果需要删除，和 kind 指令类似</span></span><br><span class="line">kwokctl delete cluster --name=kwok-cluster</span><br></pre></td></tr></table></figure></div>

<h2 id="3-启动-kwok-控制器"><a href="#3-启动-kwok-控制器" class="headerlink" title="3. 启动 kwok 控制器"></a>3. 启动 kwok 控制器</h2><p>根据<a href="#refer-anchor-1">[4]</a>，</p>
<ul>
<li>可以通过在集群外运行 kwok 控制器（如此处演示，通过 kubeconfig 监控和模拟），需要单独开一个终端用来维持，一旦终端关闭则 kwok 控制器关闭；<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kwok \</span><br><span class="line">  --kubeconfig=~/.kube/config \</span><br><span class="line">  --manage-all-nodes=<span class="literal">true</span></span><br><span class="line"><span class="comment"># 上面的命令启动 kwok 控制器，并通过`manage-all-nodes=true`参数指定该控制器将所有节点作为 Kwok 节点进行管理（其它参数参阅 kwok 文档）。</span></span><br><span class="line"><span class="comment"># 仅当将整个集群都用来测试时才能这样（例如使用 kind 或 kwokctl创建的集群），否则应该添加其他参数来过滤 Kwok 节点和资源。</span></span><br></pre></td></tr></table></figure></div>
<ul>
<li>以上只是示例，实际使用时应当多使用一些参数描述 kwok 需管理的对象，为其添加污点等描述，从而避免与真实节点 or 其他架构管理的节点（如 kind）产生冲突。<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kwok \</span><br><span class="line">  --kubeconfig=~/.kube/config \</span><br><span class="line">  --manage-all-nodes=<span class="literal">false</span> \</span><br><span class="line">  --manage-nodes-with-annotation-selector=kwok.x-k8s.io/node=fake \</span><br><span class="line">  --manage-nodes-with-label-selector= \</span><br><span class="line">  --manage-single-node= \</span><br><span class="line">  --cidr=10.0.0.1/24 \</span><br><span class="line">  --node-ip=10.0.0.1 \</span><br><span class="line">  --node-lease-duration-seconds=40</span><br></pre></td></tr></table></figure></div></li>
</ul>
</li>
<li>也可以在集群中运行 kwok 控制器（通过 CRD 方式，使用 k8s 管理 kwok 的执行。有关详细信息，请参阅 kwok 文档<a href="#refer-anchor-1"><sup>[1]</sup></a>）。<ul>
<li>变量准备<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># KWOK repository</span></span><br><span class="line">KWOK_REPO=kubernetes-sigs/kwok</span><br><span class="line"><span class="comment"># Get latest</span></span><br><span class="line">KWOK_LATEST_RELEASE=$(curl <span class="string">"https://api.github.com/repos/<span class="variable">${KWOK_REPO}</span>/releases/latest"</span> | jq -r <span class="string">'.tag_name'</span>)</span><br></pre></td></tr></table></figure></div></li>
<li>部署 kwok 并设置自定义资源定义 (CRD)（必需）<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f <span class="string">"https://github.com/<span class="variable">${KWOK_REPO}</span>/releases/download/<span class="variable">${KWOK_LATEST_RELEASE}</span>/kwok.yaml"</span></span><br></pre></td></tr></table></figure></div></li>
<li>设置<code>自定义资源类型-Stage</code>的默认自定义资源 (CR)（必需）<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 注意：这将配置 Pod/Node 仿真行为，如果不这样做，kwok 将无法执行任何模拟操作。</span></span><br><span class="line">kubectl apply -f <span class="string">"https://github.com/<span class="variable">${KWOK_REPO}</span>/releases/download/<span class="variable">${KWOK_LATEST_RELEASE}</span>/stage-fast.yaml"</span></span><br></pre></td></tr></table></figure></div></li>
<li>设置<code>自定义资源类型-resource usage资源使用情况</code>的默认自定义资源 (CR)（可选）<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 这允许模拟节点、Pod 和容器的资源使用情况。</span></span><br><span class="line">kubectl apply -f <span class="string">"https://github.com/<span class="variable">${KWOK_REPO}</span>/releases/download/<span class="variable">${KWOK_LATEST_RELEASE}</span>/metrics-usage.yaml"</span></span><br><span class="line"><span class="comment"># 上述配置将由 kwok 管理的所有容器的 CPU 和内存使用量分别设置为 1m 和 1Mi。要覆盖默认值，您可以向伪 Pod 添加注释 "kwok.x-k8s.io/usage-cpu"（用于 CPU 使用量）和 "kwok.x-k8s.io/usage-memory"（用于内存使用量），其中包含您想要的任何数量值。</span></span><br></pre></td></tr></table></figure></div>

</li>
</ul>
</li>
</ul>
<h2 id="4-创建虚拟节点"><a href="#4-创建虚拟节点" class="headerlink" title="4. 创建虚拟节点"></a>4. 创建虚拟节点</h2><h3 id="4-1-简单创建方式"><a href="#4-1-简单创建方式" class="headerlink" title="4.1 简单创建方式"></a>4.1 简单创建方式</h3><p>若使用 <code>kwokctl</code> 管理集群：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kwokctl scale node --replicas=1000</span><br></pre></td></tr></table></figure></div>

<h4 id="使用-KIND-时批量创建节点小技巧"><a href="#使用-KIND-时批量创建节点小技巧" class="headerlink" title="使用 KIND 时批量创建节点小技巧"></a>使用 KIND 时批量创建节点小技巧</h4><p>由于某些众所周知的原因，我个人使用<code>kwokctl</code>时经常出现镜像拉取失败，因此还是选择使用 KIND，但这就导致批量创建节点很麻烦。</p>
<p>求助之后，获得了<a class="link" href="https://github.com/hwdef">@hwdef<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>的解答与说明，在此感谢！</p>
<blockquote>
<p>kwok也可以用kwokctl create cluster —runtime kind与kind集成，这样可以直接scale kind集群的node。</p>
</blockquote>
<h3 id="4-2-根据配置文件创建方式"><a href="#4-2-根据配置文件创建方式" class="headerlink" title="4.2 根据配置文件创建方式"></a>4.2 根据配置文件创建方式</h3><p>创建虚拟节点配置文件 <code>virtual-nodes.yaml</code>：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Node</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kwok-node-1</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">kwok.x-k8s.io/node:</span> <span class="string">fake</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">taints:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kwok.x-k8s.io/node</span></span><br><span class="line">    <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Node</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kwok-node-2</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">kwok.x-k8s.io/node:</span> <span class="string">fake</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">taints:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kwok.x-k8s.io/node</span></span><br><span class="line">    <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br></pre></td></tr></table></figure></div>

<p>或者使用 kwok 官网介绍的属性更丰富的 Node 配置：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Node</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">node.alpha.kubernetes.io/ttl:</span> <span class="string">"0"</span></span><br><span class="line">    <span class="attr">kwok.x-k8s.io/node:</span> <span class="string">fake</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">beta.kubernetes.io/arch:</span> <span class="string">amd64</span></span><br><span class="line">    <span class="attr">beta.kubernetes.io/os:</span> <span class="string">linux</span></span><br><span class="line">    <span class="attr">kubernetes.io/arch:</span> <span class="string">amd64</span></span><br><span class="line">    <span class="attr">kubernetes.io/hostname:</span> <span class="string">kwok-node-0</span></span><br><span class="line">    <span class="attr">kubernetes.io/os:</span> <span class="string">linux</span></span><br><span class="line">    <span class="attr">kubernetes.io/role:</span> <span class="string">agent</span></span><br><span class="line">    <span class="attr">node-role.kubernetes.io/agent:</span> <span class="string">""</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">kwok</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kwok-node-0</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">taints:</span> <span class="comment"># Avoid scheduling actual running pods to fake Node</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">    <span class="attr">key:</span> <span class="string">kwok.x-k8s.io/node</span></span><br><span class="line">    <span class="attr">value:</span> <span class="string">fake</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="attr">allocatable:</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="number">32</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">256Gi</span></span><br><span class="line">    <span class="attr">pods:</span> <span class="number">110</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="number">32</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">256Gi</span></span><br><span class="line">    <span class="attr">pods:</span> <span class="number">110</span></span><br><span class="line">  <span class="attr">nodeInfo:</span></span><br><span class="line">    <span class="attr">architecture:</span> <span class="string">amd64</span></span><br><span class="line">    <span class="attr">bootID:</span> <span class="string">""</span></span><br><span class="line">    <span class="attr">containerRuntimeVersion:</span> <span class="string">""</span></span><br><span class="line">    <span class="attr">kernelVersion:</span> <span class="string">""</span></span><br><span class="line">    <span class="attr">kubeProxyVersion:</span> <span class="string">fake</span></span><br><span class="line">    <span class="attr">kubeletVersion:</span> <span class="string">fake</span></span><br><span class="line">    <span class="attr">machineID:</span> <span class="string">""</span></span><br><span class="line">    <span class="attr">operatingSystem:</span> <span class="string">linux</span></span><br><span class="line">    <span class="attr">osImage:</span> <span class="string">""</span></span><br><span class="line">    <span class="attr">systemUUID:</span> <span class="string">""</span></span><br><span class="line">  <span class="attr">phase:</span> <span class="string">Running</span></span><br></pre></td></tr></table></figure></div>

<p>应用配置：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f virtual-nodes.yaml</span><br></pre></td></tr></table></figure></div>

<h2 id="5-验证节点状态"><a href="#5-验证节点状态" class="headerlink" title="5. 验证节点状态"></a>5. 验证节点状态</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure></div>

<h2 id="6-常用操作"><a href="#6-常用操作" class="headerlink" title="6. 常用操作"></a>6. 常用操作</h2><ul>
<li>根据配置文件 <code>virtual-pod.yaml</code>创建虚拟 Pod ：</li>
</ul>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">kwok-node-1</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure></div>

<p>或者使用 kwok 官网介绍的属性更丰富的 Pod 配置：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fake-pod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">fake-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">fake-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">nodeAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">            <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">type</span></span><br><span class="line">                <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                <span class="attr">values:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">kwok</span></span><br><span class="line">      <span class="comment"># A taints was added to an automatically created Node.</span></span><br><span class="line">      <span class="comment"># You can remove taints of Node or add this tolerations.</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">"kwok.x-k8s.io/node"</span></span><br><span class="line">        <span class="attr">operator:</span> <span class="string">"Exists"</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">"NoSchedule"</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fake-container</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">fake-image</span></span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f virtual-pod.yaml</span><br></pre></td></tr></table></figure></div>

<ul>
<li>查看节点资源使用情况：</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl describe node kwok-node-1</span><br></pre></td></tr></table></figure></div>

<ul>
<li>停止 kwok 控制器：</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">pkill kwok</span><br></pre></td></tr></table></figure></div>

<h2 id="7-常见问题"><a href="#7-常见问题" class="headerlink" title="7. 常见问题"></a>7. 常见问题</h2><h3 id="7-1-创建集群时出现网络超时"><a href="#7-1-创建集群时出现网络超时" class="headerlink" title="7.1 创建集群时出现网络超时"></a>7.1 创建集群时出现网络超时</h3><p>当使用 <code>kwokctl create cluster</code> 时出现类似以下错误：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">Error response from daemon: Head <span class="string">"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/etcd/manifests/3.5.21-0"</span>: dial tcp 108.177.97.82:443: i/o <span class="built_in">timeout</span></span><br></pre></td></tr></table></figure></div>
<p>只能在其他机器上拉取镜像后传递到本服务器上。</p>
<h3 id="7-2-批量创建虚拟节点"><a href="#7-2-批量创建虚拟节点" class="headerlink" title="7.2 批量创建虚拟节点"></a>7.2 批量创建虚拟节点</h3><p>除了使用 <code>kwokctl scale node</code> 命令外，还可以使用以下方法：</p>
<ol>
<li>使用 kubectl 的 <code>--dry-run=client -o yaml</code> 生成模板，通过脚本自动撰写 yaml 配置文件（一个文件中会有 1000 个节点的信息，看起来有点笨笨的）：<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成一个节点模板</span></span><br><span class="line">kubectl create node kwok-node-1 --dry-run=client -o yaml &gt; node-template.yaml</span><br><span class="line"><span class="comment"># 使用脚本批量生成</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> {1..1000}; <span class="keyword">do</span> sed <span class="string">"s/kwok-node-1/kwok-node-<span class="variable">$i</span>/g"</span> node-template.yaml &gt;&gt; nodes.yaml; <span class="keyword">done</span></span><br><span class="line"><span class="comment"># 应用配置</span></span><br><span class="line">kubectl apply -f nodes.yaml</span><br></pre></td></tr></table></figure></div>

</li>
</ol>
<p>从 kwok 官方 GitHub 仓库的一条 <a class="link" href="https://github.com/kubernetes-sigs/kwok/discussions/1354">Discussion<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 中也能看到，目前仅支持使用一个巨大的 yaml 文件来创建。</p>
<h3 id="7-3-关闭-kwok-后节点仍然存在"><a href="#7-3-关闭-kwok-后节点仍然存在" class="headerlink" title="7.3 关闭 kwok 后节点仍然存在"></a>7.3 关闭 kwok 后节点仍然存在</h3><p>这是因为 kwok 控制器只是模拟节点的状态，并不会真正创建或删除节点。要删除这些节点，需要：</p>
<ol>
<li><p>手动删除节点：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl delete node kwok-node-1 kwok-node-2 ...</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>或者使用标签选择器批量删除：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl delete node -l kwok.x-k8s.io/node=fake</span><br></pre></td></tr></table></figure></div>

</li>
</ol>
<p>这些虚拟节点不会对实际集群造成影响，因为：</p>
<ul>
<li>它们只是模拟的节点，不会消耗实际资源</li>
<li>它们有特殊的污点（taint），不会调度实际的 Pod</li>
<li>它们的状态是 kwok 控制器模拟的，不会影响实际集群的运行</li>
</ul>
<h3 id="7-4-kwok-到底起了什么作用"><a href="#7-4-kwok-到底起了什么作用" class="headerlink" title="7.4 kwok 到底起了什么作用"></a>7.4 kwok 到底起了什么作用</h3><p>kwok 是一个轻量级的 Kubernetes 资源模拟器，它的工作原理如下：</p>
<ol>
<li><p>资源模拟机制：</p>
<ul>
<li>kwok 控制器会监听 Kubernetes API 服务器的请求</li>
<li>当 Kubernetes API Server 请求资源状态时，kwok 会返回模拟的状态信息</li>
<li>这些状态信息包括节点的 CPU、内存、网络等资源使用情况</li>
<li>kwok 不会真正创建或运行任何容器，只是”欺骗” Kubernetes API Server</li>
</ul>
</li>
<li><p>与 Kubernetes 的交互：</p>
<ul>
<li>当使用 <code>kubectl apply</code> 创建资源时：<ol>
<li>kubectl 将请求发送到 Kubernetes API Server</li>
<li>Kubernetes API Server 将资源信息存储在 etcd 中</li>
<li>kwok 控制器检测到新资源，开始模拟其状态</li>
<li>当其他组件（如调度器）查询资源状态时，kwok 返回模拟数据</li>
</ol>
</li>
<li>当关闭 kwok 控制器时：<ol>
<li>资源定义仍然存在于 etcd 中</li>
<li>但 kwok 不再提供模拟状态</li>
<li>API 服务器会返回这些资源的真实状态（通常是 NotReady）</li>
<li>这些资源不会影响实际集群的运行，因为：<ul>
<li>它们有特殊的污点（taint），不会被调度实际的工作负载</li>
<li>它们不消耗实际的系统资源</li>
<li>它们只是 etcd 中的一些记录</li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
<li><p>实际应用场景：</p>
<ul>
<li>性能测试：可以模拟 1000 个节点，测试调度器性能</li>
<li>开发测试：快速验证资源配置，无需等待实际资源创建</li>
<li>演示环境：创建演示集群，展示 Kubernetes 功能</li>
<li>学习环境：理解 Kubernetes 概念，无需实际资源</li>
</ul>
</li>
<li><p>优势：</p>
<ul>
<li>轻量级：不消耗实际系统资源</li>
<li>快速：可以瞬间创建大量节点</li>
<li>安全：不会影响实际集群的运行</li>
<li>灵活：可以模拟各种资源状态</li>
</ul>
</li>
<li><p>限制：</p>
<ul>
<li>不能运行实际的容器</li>
<li>不能测试实际的网络通信</li>
<li>不能测试实际的存储操作</li>
<li>主要用于测试 Kubernetes 控制平面的功能</li>
</ul>
</li>
</ol>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><ul>
<li>kwok 适合大规模集群的性能测试场景。</li>
<li>虚拟节点资源是模拟的，不能完全替代真实节点。</li>
<li>建议结合 kind 等工具使用，构建完整的测试环境。</li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://kwok.kubernetes.ac.cn/">[1] KWOK (Kubernetes WithOut Kubelet)  官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/blog/2023/03/01/introducing-kwok/">[2] 介绍 KWOK（Kubernetes WithOut Kubelet，没有 Kubelet 的 Kubernetes） - Kubernetes 博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://imliuda.com/post/1506">[3] 使用kwok测试kube-scheduler<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://juejin.cn/post/7263035818047078455">[4] KWOK: 1000节点集群，5秒搭建好<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>kwok</tag>
        <tag>性能测试</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】K8S集群、KubeSphere管理平台搭建记录——故障排除：Node Exporter connection refused</title>
    <url>/2024/01/24/k8s/k8s-network-node-exporter/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在多节点KubeSphere管理的K8S集群上部署监控组件后，通过Prometheus看到NodeExporter出现<code>Get "https://xx.xx.xx.xx:9100/metrics": context deadline exceeded</code>和<code>Get "https://xx.xx.xx.xx:9100/metrics": dial tcp xx.xx.xx.xx:9100: connect: connection refused</code>报错。</p>
<p>本篇博客将先进行信息收集，构建导致报错的因果链，再基于因果链逐步断点排查。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><p>在四个跨运营商的公有云节点上，通过KubeSphere部署kube-Prometheus相关组件。</p>
<h2 id="🕸️组件信息"><a href="#🕸️组件信息" class="headerlink" title="🕸️组件信息"></a>🕸️组件信息</h2><p>组件部署于 <code>kubesphere-monitoring-system</code> namespace，具体信息如下：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get all -n kubesphere-monitoring-system -o wide</span><br><span class="line">NAME                                                   READY   STATUS             RESTARTS   AGE   IP                NODE          NOMINATED NODE   READINESS GATES</span><br><span class="line">pod/alertmanager-main-0                                1/2     CrashLoopBackOff   354        24h   10.244.3.20       huawei-2      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/alertmanager-main-1                                1/2     CrashLoopBackOff   353        24h   10.244.2.122      huawei-1      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/alertmanager-main-2                                2/2     Running            0          24h   10.244.1.104      ali-2         &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/kube-state-metrics-554c8c5d65-f9bbw                3/3     Running            0          24h   10.244.3.19       huawei-2      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/node-exporter-7nmsl                                2/2     Running            0          24h   xx.xx.xx.xx       huawei-2      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/node-exporter-jxfjw                                2/2     Running            0          23h   xx.xx.xx.xx       ali-2         &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/node-exporter-tnscj                                2/2     Running            0          24h   xx.xx.xx.xx       ali-1         &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/node-exporter-wr86r                                2/2     Running            0          24h   xx.xx.xx.xx       huawei-1      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/notification-manager-deployment-566fb6ccf5-5lxpk   2/2     Running            0          24h   10.244.3.23       huawei-2      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/notification-manager-deployment-566fb6ccf5-s8r25   2/2     Running            0          24h   10.244.3.24       huawei-2      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/notification-manager-operator-8694799c76-lzt67     2/2     Running            0          24h   10.244.3.21       huawei-2      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/prometheus-k8s-0                                   2/2     Running            0          24h   10.244.3.25       huawei-2      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/prometheus-k8s-1                                   2/2     Running            0          24h   10.244.2.123      huawei-1      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/prometheus-operator-8955bbd98-f5tx5                2/2     Running            0          24h   10.244.3.18       huawei-2      &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">NAME                                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGE   SELECTOR</span><br><span class="line">service/alertmanager-main                         NodePort    10.109.250.252   &lt;none&gt;        9093:31459/TCP,8080:30479/TCP   24h   app.kubernetes.io/component=alert-router,app.kubernetes.io/instance=main,app.kubernetes.io/name=alertmanager,app.kubernetes.io/part-of=kube-prometheus</span><br><span class="line">service/alertmanager-operated                     ClusterIP   None             &lt;none&gt;        9093/TCP,9094/TCP,9094/UDP      24h   app.kubernetes.io/name=alertmanager</span><br><span class="line">service/kube-state-metrics                        ClusterIP   None             &lt;none&gt;        8443/TCP,9443/TCP               24h   app.kubernetes.io/component=exporter,app.kubernetes.io/name=kube-state-metrics,app.kubernetes.io/part-of=kube-prometheus</span><br><span class="line">service/node-exporter                             NodePort    10.103.67.182    &lt;none&gt;        9100:31949/TCP                  13h   app.kubernetes.io/component=exporter,app.kubernetes.io/name=node-exporter,app.kubernetes.io/part-of=kube-prometheus</span><br><span class="line">service/notification-manager-controller-metrics   ClusterIP   10.100.32.249    &lt;none&gt;        8443/TCP                        24h   control-plane=controller-manager</span><br><span class="line">service/notification-manager-svc                  ClusterIP   10.108.111.18    &lt;none&gt;        19093/TCP                       24h   app=notification-manager,notification-manager=notification-manager</span><br><span class="line">service/notification-manager-webhook              ClusterIP   10.110.130.35    &lt;none&gt;        443/TCP                         24h   control-plane=controller-manager</span><br><span class="line">service/prometheus-k8s                            NodePort    10.111.211.251   &lt;none&gt;        9090:31038/TCP,8080:31761/TCP   24h   app.kubernetes.io/component=prometheus,app.kubernetes.io/instance=k8s,app.kubernetes.io/name=prometheus,app.kubernetes.io/part-of=kube-prometheus</span><br><span class="line">service/prometheus-operated                       ClusterIP   None             &lt;none&gt;        9090/TCP                        24h   app.kubernetes.io/name=prometheus</span><br><span class="line">service/prometheus-operator                       ClusterIP   None             &lt;none&gt;        8443/TCP                        24h   app.kubernetes.io/component=controller,app.kubernetes.io/name=prometheus-operator,app.kubernetes.io/part-of=kube-prometheus</span><br><span class="line"></span><br><span class="line">NAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE   CONTAINERS                      IMAGES                                                         SELECTOR</span><br><span class="line">daemonset.apps/node-exporter   4         4         4       4            4           kubernetes.io/os=linux   24h   node-exporter,kube-rbac-proxy   prom/node-exporter:v1.3.1,kubesphere/kube-rbac-proxy:v0.11.0   app.kubernetes.io/component=exporter,app.kubernetes.io/name=node-exporter,app.kubernetes.io/part-of=kube-prometheus</span><br><span class="line"></span><br><span class="line">NAME                                              READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS                                                     IMAGES                                                                                                       SELECTOR</span><br><span class="line">deployment.apps/kube-state-metrics                1/1     1            1           24h   kube-state-metrics,kube-rbac-proxy-main,kube-rbac-proxy-self   kubesphere/kube-state-metrics:v2.6.0,kubesphere/kube-rbac-proxy:v0.11.0,kubesphere/kube-rbac-proxy:v0.11.0   app.kubernetes.io/component=exporter,app.kubernetes.io/name=kube-state-metrics,app.kubernetes.io/part-of=kube-prometheus</span><br><span class="line">deployment.apps/notification-manager-deployment   2/2     2            2           24h   notification-manager,tenant                                    kubesphere/notification-manager:v2.3.0,kubesphere/notification-tenant-sidecar:v3.2.0                         app=notification-manager,notification-manager=notification-manager</span><br><span class="line">deployment.apps/notification-manager-operator     1/1     1            1           24h   kube-rbac-proxy,notification-manager-operator                  kubesphere/kube-rbac-proxy:v0.11.0,kubesphere/notification-manager-operator:v2.3.0                           control-plane=controller-manager</span><br><span class="line">deployment.apps/prometheus-operator               1/1     1            1           24h   prometheus-operator,kube-rbac-proxy                            kubesphere/prometheus-operator:v0.55.1,kubesphere/kube-rbac-proxy:v0.11.0                                    app.kubernetes.io/component=controller,app.kubernetes.io/name=prometheus-operator,app.kubernetes.io/part-of=kube-prometheus</span><br><span class="line"></span><br><span class="line">NAME                                                         DESIRED   CURRENT   READY   AGE   CONTAINERS                                                     IMAGES                                                                                                       SELECTOR</span><br><span class="line">replicaset.apps/kube-state-metrics-554c8c5d65                1         1         1       24h   kube-state-metrics,kube-rbac-proxy-main,kube-rbac-proxy-self   kubesphere/kube-state-metrics:v2.6.0,kubesphere/kube-rbac-proxy:v0.11.0,kubesphere/kube-rbac-proxy:v0.11.0   app.kubernetes.io/component=exporter,app.kubernetes.io/name=kube-state-metrics,app.kubernetes.io/part-of=kube-prometheus,pod-template-hash=554c8c5d65</span><br><span class="line">replicaset.apps/notification-manager-deployment-566fb6ccf5   2         2         2       24h   notification-manager,tenant                                    kubesphere/notification-manager:v2.3.0,kubesphere/notification-tenant-sidecar:v3.2.0                         app=notification-manager,notification-manager=notification-manager,pod-template-hash=566fb6ccf5</span><br><span class="line">replicaset.apps/notification-manager-operator-8694799c76     1         1         1       24h   kube-rbac-proxy,notification-manager-operator                  kubesphere/kube-rbac-proxy:v0.11.0,kubesphere/notification-manager-operator:v2.3.0                           control-plane=controller-manager,pod-template-hash=8694799c76</span><br><span class="line">replicaset.apps/prometheus-operator-8955bbd98                1         1         1       24h   prometheus-operator,kube-rbac-proxy                            kubesphere/prometheus-operator:v0.55.1,kubesphere/kube-rbac-proxy:v0.11.0                                    app.kubernetes.io/component=controller,app.kubernetes.io/name=prometheus-operator,app.kubernetes.io/part-of=kube-prometheus,pod-template-hash=8955bbd98</span><br><span class="line"></span><br><span class="line">NAME                                 READY   AGE   CONTAINERS                     IMAGES</span><br><span class="line">statefulset.apps/alertmanager-main   1/3     24h   alertmanager,config-reloader   prom/alertmanager:v0.23.0,kubesphere/prometheus-config-reloader:v0.55.1</span><br><span class="line">statefulset.apps/prometheus-k8s      2/2     24h   prometheus,config-reloader     prom/prometheus:v2.39.1,kubesphere/prometheus-config-reloader:v0.55.1</span><br></pre></td></tr></table></figure></div>

<p>ps：对于Prometheus的target界面各项内容，通过ServiceMonitor资源定义<a href="#refer-anchor-1"><sup>[1]</sup></a>。<br>ps：<code>prometheus-operator</code> 和直接部署 <code>prometheus</code> 区别是 <code>prometheus-operator</code> 把 <code>prometheus</code> 、 <code>alertmanager server</code> 的配置, 还有 <code>scape config</code> 、 <code>record/alert rule</code> 包装成了 k8s 中的 <code>CRD</code> 。对于Prometheus 的 Configuration 界面各项配置，通过以下CRD定义：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get crd | grep monitoring</span><br><span class="line">alertmanagerconfigs.monitoring.coreos.com             2024-01-02T16:36:57Z</span><br><span class="line">alertmanagers.monitoring.coreos.com                   2024-01-02T16:33:32Z</span><br><span class="line">clusterdashboards.monitoring.kubesphere.io            2024-01-02T16:47:04Z</span><br><span class="line">dashboards.monitoring.kubesphere.io                   2024-01-02T16:47:06Z</span><br><span class="line">podmonitors.monitoring.coreos.com                     2024-01-02T16:33:13Z</span><br><span class="line">probes.monitoring.coreos.com                          2024-01-02T16:37:23Z</span><br><span class="line">prometheusagents.monitoring.coreos.com                2023-12-11T08:45:32Z</span><br><span class="line">prometheuses.monitoring.coreos.com                    2024-01-02T16:33:29Z</span><br><span class="line">prometheusrules.monitoring.coreos.com                 2024-01-02T16:33:28Z</span><br><span class="line">scrapeconfigs.monitoring.coreos.com                   2023-12-11T08:45:33Z</span><br><span class="line">servicemonitors.monitoring.coreos.com                 2024-01-02T16:33:12Z</span><br><span class="line">thanosrulers.monitoring.coreos.com                    2024-01-02T16:34:09Z</span><br></pre></td></tr></table></figure></div>
<p>查看Configuration界面，可看到以下配置：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">global:</span></span><br><span class="line">  <span class="attr">scrape_interval:</span> <span class="string">1m</span></span><br><span class="line">  <span class="attr">scrape_timeout:</span> <span class="string">10s</span></span><br></pre></td></tr></table></figure></div>
<p>对于超时问题，可以修改<code>prometheuses.monitoring.coreos.com</code>类型资源的 <code>scrapeTimeout</code> 参数。（本次修改后发现仍然报错）</p>
<h2 id="💥报错信息"><a href="#💥报错信息" class="headerlink" title="💥报错信息"></a>💥报错信息</h2><p><code>Node Exporter</code> 出现 <code>Get "https://xx.xx.xx.xx:9100/metrics": context deadline exceeded</code> （ali-2） 和 <code>Get "https://xx.xx.xx.xx:9100/metrics": dial tcp xx.xx.xx.xx:9100: connect: connection refused</code> （ali-1、huawei-1） 报错。</p>
<p>除 <code>Node Exporter</code> 外，<code>kubelet</code>、<code>kubelet/cadvisor</code> 也有报错：ali-2 节点 <code>Get "https://xx.xx.xx.xx:10250/metrics": context deadline exceeded</code>，<code>Scrape Timeout</code>为<code>10s</code>、<code>1m</code>时都报错。</p>
<h2 id="🔗因果链"><a href="#🔗因果链" class="headerlink" title="🔗因果链"></a>🔗因果链</h2><p>自底向上分析：</p>
<ol>
<li>底层4个<code>节点</code>通过网络连接（可通过 ping 确认正常连通）。</li>
<li>4个节点上部署 <code>Node-Exporter Pod</code>，监控指标（可通过访问 Pod 、查看 Pod log 确认正常运行）。</li>
<li>4个节点上暴露 <code>Node-Exporter Service</code> Endpoint 端口，暴露指标（可通过从每个节点访问本机 Service Endpoint 确认正常运行）。</li>
<li>某个节点上 Prometheus 通过 ServiceMonitor 规则监控 Service 的 Endpoint（可通过从 Prometheus 所在节点访问 Service Endpoint 确认正常运行）。</li>
</ol>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/8/5/16c60f0f543d5498~tplv-t2oaga2asx-jj-mark:3024:0:0:0:q75.png" alt="Prometheus Operator 架构图"><figcaption>Prometheus Operator 架构图</figcaption></figure></p>
<h1 id="🧠排查思路"><a href="#🧠排查思路" class="headerlink" title="🧠排查思路"></a>🧠排查思路</h1><h2 id="1️⃣节点正常连通"><a href="#1️⃣节点正常连通" class="headerlink" title="1️⃣节点正常连通"></a>1️⃣节点正常连通</h2><p>步骤：</p>
<ol>
<li>进入Node-Exporter唯一不报错的节点（理论上应该是Prometheus所在节点）。</li>
<li>Ping其他3个节点。<br>结果：<br>均能正常连接。说明节点正常联通。</li>
</ol>
<h2 id="2️⃣Pod正常运行"><a href="#2️⃣Pod正常运行" class="headerlink" title="2️⃣Pod正常运行"></a>2️⃣Pod正常运行</h2><p>步骤：</p>
<ul>
<li>通过<code>kubectl exec -it -n kubesphere-monitoring-system $(kubectl get pod -n kubesphere-monitoring-system --field-selector spec.nodeName=$NodeName -l app.kubernetes.io/name=node-exporter -o jsonpath='{.items[0].metadata.name}') -c node-exporter -- sh</code>（将<code>$NodeName</code>替换为所需要进入的pod所在节点名）<br>结果：</li>
<li>发现<code>ali-1</code>、<code>huawei-1</code>、<code>huawei-2</code>上的Pod均正常，<code>ali-2</code>上的Pod连接超时：<code>Error from server: error dialing backend: dial tcp xx.xx.xx.xx:10250: i/o timeout</code></li>
</ul>
<h2 id="3️⃣Service正常暴露"><a href="#3️⃣Service正常暴露" class="headerlink" title="3️⃣Service正常暴露"></a>3️⃣Service正常暴露</h2><p>步骤：</p>
<ol>
<li>依次登录每个节点</li>
<li>访问本节点服务<br>a. <code>curl localhost:9100</code> 均正常响应<br>b. <code>curl ${本机ip}:9100</code> 均响应<code>Client sent an HTTP request to an HTTPS server.</code><br>c. <code>curl https://${本机ip}:9100</code> 均响应<code>curl: (60) Peer's certificate issuer has been marked as not trusted by the user.</code><br>d. <code>curl https://${本机ip}:9100 -k</code> 均响应 <code>Unauthorized</code>，根据<a href="#refer-anchor-4">[4]</a>了解需要增加认证<br>e. <code>curl https://${本机ip}:9100/metrics -k --header 'Authorization: Bearer '$(kubectl exec -it -n kubesphere-monitoring-system prometheus-k8s-0 cat /var/run/secrets/kubernetes.io/serviceaccount/token)</code> 正常响应<br>结果：</li>
<li>每个服务均正常运行（包括上一步出错的<code>ali-2</code>，所以怀疑是k8s至ali-2的网络配置有问题）</li>
<li>通过非localhost的访问均失败</li>
</ol>
<h2 id="4️⃣Service正常访问"><a href="#4️⃣Service正常访问" class="headerlink" title="4️⃣Service正常访问"></a>4️⃣Service正常访问</h2><p>同上，访问<code>其他节点ip:9100</code>无效</p>
<h1 id="🛠️解决方法"><a href="#🛠️解决方法" class="headerlink" title="🛠️解决方法"></a>🛠️解决方法</h1><h2 id="🔨方法1：暴露接口（不安全）"><a href="#🔨方法1：暴露接口（不安全）" class="headerlink" title="🔨方法1：暴露接口（不安全）"></a>🔨方法1：暴露接口（不安全）</h2><ol>
<li>对于<code>daemonset</code>类型资源<code>node-exporter</code>，配置文件中限制<code>127.0.0.1</code>，即仅通过本机访问时才可成功，因此都修改为<code>0.0.0.0</code>。具体如下：<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">exporter</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">node-exporter</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">kube-prometheus</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.3</span><span class="number">.1</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">node-exporter</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubesphere-monitoring-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="string">...</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="string">...</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--web.listen-address=0.0.0.0:9100</span></span><br><span class="line"><span class="comment">#        - --web.listen-address=127.0.0.1:9100</span></span><br><span class="line">        <span class="string">...</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">node-exporter</span></span><br><span class="line">        <span class="string">...</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">        <span class="string">...</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--secure-listen-address=[$(IP)]:9100</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--upstream=http://0.0.0.0:9100/</span></span><br><span class="line"><span class="comment">#        - --upstream=http://127.0.0.1:9100/</span></span><br><span class="line">        <span class="string">...</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">kube-rbac-proxy</span></span><br><span class="line">        <span class="string">...</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9100</span></span><br><span class="line">          <span class="attr">hostPort:</span> <span class="number">9100</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">http</span>    <span class="comment"># 只是名字，可以不修改。注意要和ServiceMonitor中对应。</span></span><br><span class="line"><span class="comment">#           name: https </span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">        <span class="string">...</span></span><br></pre></td></tr></table></figure></div></li>
<li>进一步地，存在报错<code>Get "https://xx.xx.xx.xx:9100/metrics": http: server gave HTTP response to HTTPS client</code>。调整 Prometheus ServiceMonitor 协议由 https 改为 http。<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">monitoring.coreos.com/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceMonitor</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">exporter</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">node-exporter</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">kube-prometheus</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/vendor:</span> <span class="string">kubesphere</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.3</span><span class="number">.1</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">node-exporter</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubesphere-monitoring-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">endpoints:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">...</span></span><br><span class="line">    <span class="attr">scheme:</span> <span class="string">http</span></span><br><span class="line"><span class="comment">#    scheme: https</span></span><br></pre></td></tr></table></figure></div></li>
<li>初次设定时，发现 node-exporter Pod 疯狂重启。<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">NAME                                               READY   STATUS             RESTARTS   AGE</span><br><span class="line">node-exporter-4bdcq                                1/2     CrashLoopBackOff   508        42h</span><br><span class="line">node-exporter-pxfvd                                1/2     CrashLoopBackOff   508        42h</span><br><span class="line">node-exporter-qwb56                                1/2     Error              509        42h</span><br><span class="line">node-exporter-tq29h                                1/2     CrashLoopBackOff   170        42h</span><br></pre></td></tr></table></figure></div>
通过<code>kubectl log</code>查看日志，对于<code>node-exporter</code>容器一切正常，对于<code>kube-rbac-proxy</code>容器存在以下报错：<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">I0126 02:53:41.152101    7520 main.go:180] Valid token audiences:</span><br><span class="line">I0126 02:53:41.152228    7520 main.go:284] Generating self signed cert as no cert is provided</span><br><span class="line">I0126 02:53:41.493354    7520 main.go:334] Starting TCP socket on [xx.xx.xx.xx]:9100</span><br><span class="line">F0126 02:53:41.493523    7520 main.go:337] failed to listen on secure address: listen tcp xx.xx.xx.xx:9100: <span class="built_in">bind</span>: address already <span class="keyword">in</span> use</span><br><span class="line">goroutine 1 [running]:</span><br><span class="line">k8s.io/klog/v2.stacks(0xc00000e001, 0xc0000e61e0, 0x8a, 0x97)</span><br><span class="line">	/home/runner/go/pkg/mod/k8s.io/klog/v2@v2.3.0/klog.go:996 +0xb9</span><br><span class="line">k8s.io/klog/v2.(*loggingT).output(0x22af0c0, 0xc000000003, 0x0, 0x0, 0xc000572a10, 0x2207d01, 0x7, 0x151, 0x0)</span><br><span class="line">	/home/runner/go/pkg/mod/k8s.io/klog/v2@v2.3.0/klog.go:945 +0x191</span><br><span class="line">k8s.io/klog/v2.(*loggingT).<span class="built_in">printf</span>(0x22af0c0, 0x3, 0x0, 0x0, 0x1783952, 0x26, 0xc0000dfbe8, 0x1, 0x1)</span><br><span class="line">	/home/runner/go/pkg/mod/k8s.io/klog/v2@v2.3.0/klog.go:733 +0x17a</span><br><span class="line">k8s.io/klog/v2.Fatalf(...)</span><br><span class="line">	/home/runner/go/pkg/mod/k8s.io/klog/v2@v2.3.0/klog.go:1463</span><br><span class="line">main.main()</span><br><span class="line">	/home/runner/work/kube-rbac-proxy/kube-rbac-proxy/main.go:337 +0x2717</span><br><span class="line"></span><br><span class="line">goroutine 6 [chan receive]:</span><br><span class="line">k8s.io/klog/v2.(*loggingT).flushDaemon(0x22af0c0)</span><br><span class="line">	/home/runner/go/pkg/mod/k8s.io/klog/v2@v2.3.0/klog.go:1131 +0x8b</span><br><span class="line">created by k8s.io/klog/v2.init.0</span><br><span class="line">	/home/runner/go/pkg/mod/k8s.io/klog/v2@v2.3.0/klog.go:416 +0xd8</span><br></pre></td></tr></table></figure></div>
但通过<code>lsof</code>和<code>netstat</code>排查，并无其他程序占用该端口。回头一想，应该是<code>node-exporter</code>和<code>kube-rbac-proxy</code>两个容器发生了冲突。</li>
</ol>
<p>对yaml文件中的关键参数进行解析：</p>
<ol>
<li><code>node-exporter</code> 容器中的 <code>web.listen-address</code> 参数：<ul>
<li><strong>作用：</strong> 指定Node Exporter监听的网络地址和端口。这是Node Exporter提供监控指标的地址，Prometheus通过这个地址来获取节点的监控数据。</li>
<li><strong>例子：</strong> <code>--web.listen-address=127.0.0.1:9100</code> 表示Node Exporter会监听本地地址的9100端口。</li>
</ul>
</li>
<li><code>kube-rbac-proxy</code> 容器中的 <code>secure-listen-address</code> 参数:<ul>
<li><strong>作用：</strong> 指定Node Exporter启用安全连接时的监听地址和端口。这通常用于启用HTTPS连接，以确保监控数据的传输安全。</li>
<li><strong>例子：</strong> <code>--secure-listen-address=[$(IP)]:9100</code> 表示以安全方式监听在指定的IP地址的9100端口。</li>
</ul>
</li>
<li><code>kube-rbac-proxy</code> 容器中的 <code>upstream</code> 参数:<ul>
<li><strong>作用：</strong> 指定一个上游的Node Exporter地址，用于代理请求。这在一些网络配置中可能会用到，例如在使用代理的情况下，将请求代理到指定的Node Exporter地址。</li>
<li><strong>例子：</strong> <code>--upstream=http://127.0.0.1:9100/</code> 表示将请求代理到本地地址的9100端口。</li>
</ul>
</li>
</ol>
<p>因此，当 <code>node-exporter</code> 容器中的 <code>--web.listen-address</code> 和 <code>kube-rbac-proxy</code> 容器中的 <code>secure-listen-address</code> 参数一样时，会发生冲突。因此设置为不同的端口分别暴露即可。</p>
<p>ps：至此可以看出，本方法本质上是绕过了 <code>kube-rbac-proxy</code> 容器，直接让 <code>node-exporter</code> 容器暴露端口给Prometheus。因此可能导致不安全的访问（例如数据完全暴露，任何人都可以随意访问）</p>
<h2 id="🔨方法2：调试-kube-rbac-proxy"><a href="#🔨方法2：调试-kube-rbac-proxy" class="headerlink" title="🔨方法2：调试 kube-rbac-proxy"></a>🔨方法2：调试 <code>kube-rbac-proxy</code></h2><p>恢复原始配置后，根据<a href="#refer-anchor-4">[4]</a>一步步排查：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://kubesphere.io/forum/assets/files/2023-02-02/1675338865-33039-image.png" alt="node-exporter 故障定位及修复措施"><figcaption>node-exporter 故障定位及修复措施</figcaption></figure></p>
<p>在 Node-Export yaml 配置文件中看到几个配置<a href="#refer-anchor-5"><sup>[5]</sup></a><a href="#refer-anchor-6"><sup>[6]</sup></a>：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li>修改如下：<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line"><span class="comment">#      dnsPolicy: ClusterFirst</span></span><br><span class="line"><span class="comment">#      hostNetwork: true</span></span><br><span class="line">      <span class="attr">dnsPolicy:</span> <span class="string">ClusterFirstWithHostNet</span></span><br><span class="line">      <span class="attr">hostNetwork:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<p>发现当 <code>hostNetwork: true</code> 时，<code>curl localhost:9100/metrics</code> 始终无响应。<br>发现当 <code>dnsPolicy: ClusterFirst</code> 时，<code>curl 其他节点ip:9100/metrics</code> 始终无响应。（但<code>hostNetwork: false</code>时<code>dnsPolicy</code>应当无效才对）</p>
<p>修改为以上配置后，监控恢复正常。（对该部分调整后似乎数据仍然正常，可能其实是修改了其他配置导致的修复，还有待进一步确定）</p>
<h2 id="🔨方法3：检查防火墙"><a href="#🔨方法3：检查防火墙" class="headerlink" title="🔨方法3：检查防火墙"></a>🔨方法3：检查防火墙</h2><p>本方法针对 ali-2 节点的 <code>Get "https://xx.xx.xx.xx:9100/metrics": context deadline exceeded</code> 报错。<br>由于是租用的公有云服务器，因此特意配置了安全组（相当于公有云提供的外部防火墙）开放特定端口，但仍然报错。提交工单咨询售后工程师后，发现服务器内部还有防火墙需要配置。</p>
<p>对接过程中，检查流程如下：（在明确服务本身正常运行，只可能是网络联通问题的前提下）</p>
<ol>
<li>确定出问题的端口号。如本次调试 Node-Exporter 组件，涉及的端口号为<code>9100</code>。</li>
<li>从外部检测端口联通性。<code>telnet ${ip} ${port}</code>。若不通，首先检查并配置外部防火墙（公有云安全组）。</li>
<li>从内部检测端口联通性。进入服务器，执行<code>telnet  127.0.0.1 ${port}</code>。若不通，检查内部防火墙，手动开放防火墙端口<code>iptables -I INPUT -p tcp --dport 9100 -j ACCEPT</code>（临时开放端口）。</li>
<li>检查内部防火墙规则。<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ netstat -ntulp</span><br><span class="line">$ firewall-cmd --list-all</span><br><span class="line">$ iptables -nL</span><br></pre></td></tr></table></figure></div></li>
<li>检查内部防火墙启动情况。<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl status iptables.service </span><br><span class="line">ufw status</span><br></pre></td></tr></table></figure></div>

</li>
</ol>
<p>排查后，首先确认端口被防火墙拦截。进一步检查防火墙型号，发现没有安装 iptables 防火墙，但是安装了 ufw 防火墙。<br>因此，开放端口或关闭防火墙即可。</p>
<ul>
<li>开放端口：<code>ufw allow 9100</code></li>
<li>关闭防火墙：<code>ufw disable</code></li>
</ul>
<p>关闭防火墙后，所有 target 状态变绿（Nice！）。</p>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><ol>
<li>构建因果链排错的效率很高，以后要继续保持。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://finolo.gy/2019/12/Kubernetes%E7%9B%91%E6%8E%A7%E6%96%B9%E6%A1%88kube-prometheus-prometheus-node-exporter-grafana/">[1] Kubernetes监控方案kube-prometheus(prometheus, node-exporter, grafana)<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link" href="https://developer.aliyun.com/article/1124546">[2] Prometheus-Operator模式下的Prometheus配置<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link" href="https://blog.csdn.net/w2009211777/article/details/124005822">[3] 总结：Promethus配置文件<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link" href="https://ask.kubesphere.io/forum/d/22113-v331-suo-you-zu-jian-du-jian-kang-dan-shi-mei-you-ren-he-jian-kong-shu-ju">[4] KubeSphere开发者社区：v3.3.1 所有组件都健康，但是没有任何监控数据<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-5"></div>

<p><a class="link" href="https://blog.csdn.net/kozazyh/article/details/79468508">[5] kubernetes hostNetwork: true 网络<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-6"></div>

<p><a class="link" href="https://vividcode.io/fix-context-deadline-exceeded-error-in-prometheus-operator/">[6] Fix Context Deadline Exceeded Error in Prometheus Operator<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境检修</category>
      </categories>
      <tags>
        <tag>K8S</tag>
        <tag>NodeExporter</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】K8S集群搭建记录——Prometheus持久化设置</title>
    <url>/2023/07/23/k8s/k8s-persistence/</url>
    <content><![CDATA[<h1 id="🐛-背景：Prometheus数据丢失"><a href="#🐛-背景：Prometheus数据丢失" class="headerlink" title="🐛 背景：Prometheus数据丢失"></a>🐛 背景：Prometheus数据丢失</h1><ul>
<li>近期项目验收，需要重新操作主动式伸缩云平台，却发现好多数据丢失、系统崩溃的问题，在修复 bug、备份数据的同时，顺便把 Prometheus 升级，配置持久化功能。</li>
</ul>
<h1 id="🚀-相关知识"><a href="#🚀-相关知识" class="headerlink" title="🚀 相关知识"></a>🚀 相关知识</h1><p>转载声明：以下内容主要来自于文档<a href="#refer-anchor-1">[1]</a>和<a href="#refer-anchor-2">[2]</a>。</p>
<h2 id="1️⃣-k8s-之-Volume"><a href="#1️⃣-k8s-之-Volume" class="headerlink" title="1️⃣ k8s 之 Volume"></a>1️⃣ k8s 之 Volume</h2><ul>
<li><p>先来介绍docker里的volume<a href="#refer-anchor-1"><sup>[1]</sup></a>：</p>
<ul>
<li>对于docker容器来说，由于镜像的只读性，难以进行数据持久化。<ul>
<li>镜像是分层构建的且每一层都是只读的，只读就意味着不能修改数据；</li>
<li>只有当一个镜像运行为容器以后，在镜像的最顶端才会加上一个可写层。而一旦这个容器被删除，对应可写层上的数据也随之被删除，因此难以数据持久化。</li>
</ul>
</li>
<li>为了解决docker容器上的数据持久化的问题，docker使用了volume。<ul>
<li>在docker上volume有两种管理方式，<ul>
<li>第一种是用户手动指定把宿主机（对于宿主机上的目录可能是挂载存储系统上的某目录）上的某个目录挂载到容器某个目录，这种管理方式叫做绑定挂载卷；</li>
<li>还有一种就是docker自身维护把某个目录挂载到容器某个目录，这种叫docker自己管理的卷。</li>
</ul>
</li>
<li>不管使用哪种方式管理的volume，它都是容器直接关联宿主机上的某个目录或文件。</li>
<li>docker中的volume解决了容器生命周期内产生的数据在容器终止后能够持久化保存的问题</li>
</ul>
</li>
</ul>
</li>
<li><p>进一步考虑 k8s 的情况：</p>
<ul>
<li>k8s也有同样的烦恼，不同的是k8s面对的是pod。<ul>
<li>pod是k8s上最小调度单元，一个pod被删除以后，pod里运行的容器也随之被删除。因此pod里容器产生的数据也存在难以被持久化的问题。</li>
</ul>
</li>
<li>为了解决这个问题，我们先来看看pod的组成<a href="#refer-anchor-1"><sup>[1]</sup></a>：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/k8s1.png?raw=true" alt="pod的组成"><figcaption>pod的组成</figcaption></figure><ul>
<li>在k8s上pod里可以运行一个或多个容器，运行多个容器。<ul>
<li>其中一个容器我们叫主容器，其他的容器是用来辅助主容器，我们叫做sidecar。</li>
</ul>
</li>
<li>对于pod来说，不管里面运行多少个容器，在最底层都会运行一个pause容器，该容器最主要用来为pod提供基础架构支撑。并且位于同一个pod中的容器都共享pause容器的网络名称空间以及IPC和UTS。</li>
</ul>
</li>
<li>因此，如果我们要想给pod里的容器提供存储卷，首先要把存储卷关联到pause容器，然后在容器里挂载pause里的存储卷；如下图所示<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/k8s2.png?raw=true" alt="挂载示意图"><figcaption>挂载示意图</figcaption></figure><ul>
<li>提示：<ul>
<li>对于pause容器来说，可以关联存储A，也可以关联存储B。对于pause关联的某个存储，其位于同一pod中的其他容器就也可以挂载pause里关联的存储目录或文件。</li>
<li>对于k8s来说，存储本来就不属于k8s内部组件，而是一个外来系统。要想k8s使用外部存储系统，首先要求pause容器有适配其对应存储系统的驱动。如果同一宿主机上运行的多个容器共享同一内核上，即宿主机内核上，有对应存储系统的驱动，pause就可以使用对应的驱动去适配对应的存储。</li>
</ul>
</li>
<li></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="2️⃣-k8s-之-PV、PVC、SC-2"><a href="#2️⃣-k8s-之-PV、PVC、SC-2" class="headerlink" title="2️⃣ k8s 之 PV、PVC、SC[2]"></a>2️⃣ k8s 之 PV、PVC、SC<a href="#refer-anchor-2"><sup>[2]</sup></a></h2><ul>
<li><p>volume的基础使用中，需要我们手动向不同类型存储接口传递不同的参数，才能实现把外部存储映射到k8s上的一个volume对象，使得pod才能正常的挂载对应的存储卷，对应pod里的容器才能正常使用。</p>
</li>
<li><p>这种使用方式的前提是用户必须了解对应的存储系统，了解对应类型的存储接口，以及相关参数。这使得用户在k8s上使用存储卷变得有些复杂。</p>
</li>
<li><p>为了简化这一过程，在k8s上使用pv和pvc资源来把对应底层存储接口给隐藏了，用户使用存储卷不再关心底层存储系统接口，不管底层是那种类型的存储，用户只需面对一个pvc接口即可。</p>
</li>
<li><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/k8s3.png?raw=true" alt="PV、PVC和K8s集群以及pod的关系"><figcaption>PV、PVC和K8s集群以及pod的关系</figcaption></figure></p>
</li>
<li><p>补充：</p>
<ul>
<li>NFS 是 Network File System 的缩写，即网络文件系统。功能是通过网络让不同的机器、不同的操作系统能够彼此分享文件。</li>
<li>Persistent Volume(PV) 是存储卷，它代表了实际存储空间。<ul>
<li>它主要作用是把后端存储中的某个逻辑单元，映射为k8s上的pv资源。</li>
<li>pv是集群级别的资源，任意名称空间都可以直接关联某一个pv，关联pv的过程我们叫做绑定pv。</li>
</ul>
</li>
<li>Persistent Volume Claim (PVC) 是存储卷声明，它代表了对存储卷的请求。当容器被重新部署到其他节点时，PVC 会将数据挂载到该节点上，从而确保数据不会丢失。<ul>
<li>pvc就是持久存储卷申请，在一个名称空间下创建一个pvc就是把对应名称空间同集群上的某一pv做绑定。</li>
<li>一旦一个名称空间绑定了一个pv后，对应的pv就会从available状态转变成bond状态，其他名称空间将不能再使用，只有对应pv是available状态才能正常的被其他名称空间关联绑定。</li>
</ul>
</li>
<li>用户在创建pod时使用存储卷只需要关心对应名称空间的pvc对象，而对应pv由集群管理管理员定义，后端存储是专门的存储管理员负责管理。而对应名称空间关联某一pv需要使用pvc资源来定义。<ul>
<li>简单讲pvc和pv的关系是一一对应的，一个pv只能对应一个pvc；至于同一名称空间下的多个pod是否能够同时使用一个PVC取决pv是否允许多路读写，对应pv是否支持多路读写取决后端存储系统。<ul>
<li>不同类型的存储系统，对应访问模式也有所不同。访问模式有三种，单路读写(ReadWriteOnce简称RWO)，多路读写(ReadWriteMany简称RWX)，多路只读(ReadOnlyMany简称ROX)；</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>下面我们再来说一下sc资源。</p>
<ul>
<li>SC 是 StorageClass的缩写，表示存储类。<ul>
<li>这种资源主要用来对pv资源的自动供给提供接口。<ul>
<li>所谓自动供给是指用户无需手动创建pv，而是在创建pvc时对应pv会由persistentVolume-controller自动创建并完成pv和pvc的绑定。</li>
</ul>
</li>
<li>使用sc资源的前提是对应后端存储必须支持restful类型接口的管理接口，并且pvc必须指定对应存储类名称来引用SC。</li>
<li>简单讲SC资源就是用来为后端存储提供自动创建pv并关联对应pvc的接口。如下图<ul>
<li><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/k8s4.png?raw=true" alt="SC与 PV、PVC 关系"><figcaption>SC与 PV、PVC 关系</figcaption></figure></li>
<li>使用sc动态创建pv，对应pvc必须也属于该sc。</li>
<li>上图主要描述了用户在创建pvc时，引用对应的sc以后，sc会调用底层存储系统的管理接口，创建pv并关联至对应pvc。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="🚢-配置过程"><a href="#🚢-配置过程" class="headerlink" title="🚢 配置过程"></a>🚢 配置过程</h1><ul>
<li>根据相关文档，我们采用 NFS 创建 SC，再进一步开展 Prometheus 的持久化绑定。</li>
</ul>
<h2 id="1️⃣-部署-NFS-Server-3"><a href="#1️⃣-部署-NFS-Server-3" class="headerlink" title="1️⃣ 部署 NFS-Server[3]"></a>1️⃣ 部署 NFS-Server<a href="#refer-anchor-3"><sup>[3]</sup></a></h2><ul>
<li>在 master 节点部署 NFS</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入存储卷目录</span></span><br><span class="line">$ <span class="built_in">cd</span> /mnt/data/prometheus_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 部署 NFS-Server</span></span><br><span class="line">$ yum install nfs-utils -y rpcbind</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 nfs 存储目录</span></span><br><span class="line">$ <span class="built_in">mkdir</span> k8s-volume -p</span><br><span class="line">$ <span class="built_in">chmod</span> 755 k8s-volume</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑 nfs 配置文件</span></span><br><span class="line">$ vim /etc/exports</span><br><span class="line">/mnt/data/prometheus_data/k8s-volume *(rw,no_root_squash,<span class="built_in">sync</span>)</span><br><span class="line"><span class="comment">#存储目录，*允许所有人连接，rw读写权限，sync文件同时写入硬盘及内存，no_root_squash 使用者root用户自动修改为普通用户</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动 rpcbind</span></span><br><span class="line">$ systemctl start rpcbind</span><br><span class="line">$ systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line">$ systemctl status rpcbind</span><br><span class="line">● rpcbind.service - RPC <span class="built_in">bind</span> service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/rpcbind.service; enabled; vendor preset: enabled)</span><br><span class="line">   Active: active (running) since 一 2022-08-22 21:31:14 CST; 11 months 0 days ago</span><br><span class="line"> Main PID: 1168 (rpcbind)</span><br><span class="line">   CGroup: /system.slice/rpcbind.service</span><br><span class="line">           └─1168 /sbin/rpcbind -w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动 NFS</span></span><br><span class="line">$ systemctl restart nfs</span><br><span class="line">$ systemctl <span class="built_in">enable</span> nfs</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/nfs-server.service to /usr/lib/systemd/system/nfs-server.service.</span><br><span class="line">$ systemctl status nfs</span><br><span class="line">● nfs-server.service - NFS server and services</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/nfs-server.service; enabled; vendor preset: disabled)</span><br><span class="line">  Drop-In: /run/systemd/generator/nfs-server.service.d</span><br><span class="line">           └─order-with-mounts.conf</span><br><span class="line">   Active: active (exited) since 日 2023-07-23 23:22:56 CST; 15s ago</span><br><span class="line"> Main PID: 14007 (code=exited, status=0/SUCCESS)</span><br><span class="line">    Tasks: 0</span><br><span class="line">   Memory: 0B</span><br><span class="line">   CGroup: /system.slice/nfs-server.service</span><br><span class="line"></span><br><span class="line">7月 23 23:22:55 k8s-node2 systemd[1]: Starting NFS server and services...</span><br><span class="line">7月 23 23:22:56 k8s-node2 systemd[1]: Started NFS server and services.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#检查 rpcbind 及 nfs 是否正常</span></span><br><span class="line">$ rpcinfo | grep nfs</span><br><span class="line">    100003    3    tcp       0.0.0.0.8.1            nfs        superuser</span><br><span class="line">    100003    4    tcp       0.0.0.0.8.1            nfs        superuser</span><br><span class="line">    100227    3    tcp       0.0.0.0.8.1            nfs_acl    superuser</span><br><span class="line">    100003    3    udp       0.0.0.0.8.1            nfs        superuser</span><br><span class="line">    100227    3    udp       0.0.0.0.8.1            nfs_acl    superuser</span><br><span class="line">    100003    3    tcp6      ::.8.1                 nfs        superuser</span><br><span class="line">    100003    4    tcp6      ::.8.1                 nfs        superuser</span><br><span class="line">    100227    3    tcp6      ::.8.1                 nfs_acl    superuser</span><br><span class="line">    100003    3    udp6      ::.8.1                 nfs        superuser</span><br><span class="line">    100227    3    udp6      ::.8.1                 nfs_acl    superuser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看nfs目录挂载权限</span></span><br><span class="line">$ <span class="built_in">cat</span> /var/lib/nfs/etab</span><br><span class="line">/mnt/data/prometheus_data/k8s-volume	*(rw,<span class="built_in">sync</span>,wdelay,hide,nocrossmnt,secure,no_root_squash,no_all_squash,no_subtree_check,secure_locks,acl,no_pnfs,anonuid=65534,anongid=65534,sec=sys,rw,secure,no_root_squash,no_all_squash)</span><br></pre></td></tr></table></figure></div>

<ul>
<li>在所有需要 NFS 挂在的集群节点安装</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ yum install -y nfs-utils rpcbind</span><br><span class="line">$ systemctl start rpcbind</span><br><span class="line">$ systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line">$ systemctl start nfs</span><br><span class="line">$ systemctl <span class="built_in">enable</span> nfs</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/nfs-server.service to /usr/lib/systemd/system/nfs-server.service.</span><br></pre></td></tr></table></figure></div>

<h2 id="2️⃣-创建-SC-3"><a href="#2️⃣-创建-SC-3" class="headerlink" title="2️⃣ 创建 SC[3]"></a>2️⃣ 创建 SC<a href="#refer-anchor-3"><sup>[3]</sup></a></h2><ul>
<li>进入存储卷目录</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /mnt/data/prometheus_data</span><br><span class="line">$ <span class="built_in">mkdir</span> nfs_yaml/</span><br><span class="line">$ <span class="built_in">cd</span> nfs_yaml</span><br></pre></td></tr></table></figure></div>

<ul>
<li>创建 NFS-Client</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># nfs-client.yaml</span></span><br><span class="line"><span class="comment"># 为 prometheus pod 提供支持，避免无法Running</span></span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nfs-client-provisioner</span><br><span class="line">  strategy:</span><br><span class="line">    <span class="built_in">type</span>: Recreate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nfs-client-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: nfs-client-provisioner</span><br><span class="line">      containers:</span><br><span class="line">        - name: nfs-client-provisioner</span><br><span class="line">          image: quay.io/external_storage/nfs-client-provisioner:latest</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: nfs-client-root</span><br><span class="line">              mountPath: /persistentvolumes</span><br><span class="line">          <span class="built_in">env</span>:</span><br><span class="line">            - name: PROVISIONER_NAME</span><br><span class="line">              value: fuseim.pri/ifs</span><br><span class="line">            - name: NFS_SERVER</span><br><span class="line">              value: k8s-node2           <span class="comment">#nfs server 地址</span></span><br><span class="line">            - name: NFS_PATH</span><br><span class="line">              value: /mnt/data/prometheus_data/k8s-volume     <span class="comment">#nfs共享目录</span></span><br><span class="line">      volumes:</span><br><span class="line">        - name: nfs-client-root</span><br><span class="line">          nfs:</span><br><span class="line">            server: k8s-node2           <span class="comment">#nfs server 地址</span></span><br><span class="line">            path: /mnt/data/prometheus_data/k8s-volume     <span class="comment">#nfs共享目录</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li>创建 nfs-client rbac 文件</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># nfs-rbac.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">  namespace: monitoring</span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner-runner</span><br><span class="line">  namespace: monitoring</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [<span class="string">""</span>]</span><br><span class="line">    resources: [<span class="string">"persistentvolumes"</span>]</span><br><span class="line">    verbs: [<span class="string">"get"</span>,<span class="string">"list"</span>,<span class="string">"watch"</span>,<span class="string">"create"</span>,<span class="string">"delete"</span>]</span><br><span class="line">  - apiGroups: [<span class="string">""</span>]</span><br><span class="line">    resources: [<span class="string">"persistentvolumeclaims"</span>]</span><br><span class="line">    verbs: [<span class="string">"get"</span>,<span class="string">"list"</span>,<span class="string">"watch"</span>,<span class="string">"update"</span>]</span><br><span class="line">  - apiGroups: [<span class="string">"storage.k8s.io"</span>]</span><br><span class="line">    resources: [<span class="string">"storageclasses"</span>]</span><br><span class="line">    verbs: [<span class="string">"get"</span>,<span class="string">"list"</span>,<span class="string">"watch"</span>]</span><br><span class="line">  - apiGroups: [<span class="string">""</span>]</span><br><span class="line">    resources: [<span class="string">"events"</span>]</span><br><span class="line">    verbs: [<span class="string">"list"</span>,<span class="string">"watch"</span>,<span class="string">"create"</span>,<span class="string">"update"</span>,<span class="string">"patch"</span>]</span><br><span class="line">  - apiGroups: [<span class="string">""</span>]</span><br><span class="line">    resources: [<span class="string">"endpoints"</span>]</span><br><span class="line">    verbs: [<span class="string">"create"</span>,<span class="string">"delete"</span>,<span class="string">"get"</span>,<span class="string">"list"</span>,<span class="string">"watch"</span>,<span class="string">"patch"</span>,<span class="string">"update"</span>]</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: run-nfs-client-provisioner</span><br><span class="line">  namespace: monitoring</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: nfs-client-provisioner</span><br><span class="line">    namespace: monitoring</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: nfs-client-provisioner-runner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure></div>

<ul>
<li>执行文件，创建对象</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl apply -f nfs-rbac.yaml</span><br><span class="line">$ kubectl apply -f nfs-client.yaml</span><br><span class="line">$ kubectl get pod -n tongji-cluster</span><br></pre></td></tr></table></figure></div>

<ul>
<li>创建StorageClass对象</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># prometheus-storageclass.yaml</span></span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus-data-db</span><br><span class="line">  namespace: monitoring</span><br><span class="line">provisioner: fuseim.pri/ifs</span><br></pre></td></tr></table></figure></div>
<ul>
<li>声明Storageclass对象，其中<code>provisioner=fuseim.pri/ifs</code>，对应的是本集群中使用NFS作为后端存储</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl apply -f prometheus-storageclass.yaml</span><br></pre></td></tr></table></figure></div>

<h2 id="3️⃣-Prometheus-持久化绑定"><a href="#3️⃣-Prometheus-持久化绑定" class="headerlink" title="3️⃣ Prometheus 持久化绑定"></a>3️⃣ Prometheus 持久化绑定</h2><ul>
<li>前提：本文所用集群使用 Prometheus Operator 方式部署监控相关组件。<a href="#refer-anchor-4"><sup>[4]</sup></a></li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入 Prometheus 文件目录</span></span><br><span class="line">$ <span class="built_in">cd</span> /etc/kubernetes/prom_yaml/</span><br><span class="line"><span class="comment"># 修改文件</span></span><br><span class="line">$ vim prometheus/prometheus-prometheus.yaml</span><br></pre></td></tr></table></figure></div>

<ul>
<li>添加如下配置：</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># prometheus/prometheus-prometheus.yaml</span></span><br><span class="line">...</span><br><span class="line">spec: </span><br><span class="line">  storage:</span><br><span class="line">    volumeClaimTemplate:</span><br><span class="line">      spec:</span><br><span class="line">        storageClassName: prometheus-data-db</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 100Gi</span><br><span class="line">....</span><br><span class="line"> </span><br><span class="line"><span class="comment">#只需要在sepc:中添加对应的信息，storageClassName为刚刚创建的名称，storage为资源对象大小</span></span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 执行修改</span></span><br><span class="line">$ kubectl apply -f prometheus/prometheus-prometheus.yaml</span><br></pre></td></tr></table></figure></div>

<h2 id="4️⃣-查看结果"><a href="#4️⃣-查看结果" class="headerlink" title="4️⃣ 查看结果"></a>4️⃣ 查看结果</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get pod -n monitoring</span><br><span class="line">NAME                                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">grafana-6f7b49c756-br788                 1/1     Running   4          344d</span><br><span class="line">kube-state-metrics-78c9d96848-n5748      3/3     Running   6          439d</span><br><span class="line">nfs-client-provisioner-96dc64d6d-lk9m4   1/1     Running   0          4m38s</span><br><span class="line">node-exporter-2mjlt                      2/2     Running   0          439d</span><br><span class="line">node-exporter-fs7nf                      2/2     Running   0          313d</span><br><span class="line">node-exporter-x26l8                      2/2     Running   4          439d</span><br><span class="line">prometheus-k8s-0                         2/2     Running   1          64s</span><br><span class="line">prometheus-k8s-1                         2/2     Running   1          64s</span><br><span class="line">prometheus-operator-547c9cf9fd-cs4kv     2/2     Running   0          154d</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ kubectl get pv -n monitoring | grep prom</span><br><span class="line">pvc-e786b1a8-d2ef-453d-9f5d-b1cb4b2b5574   100Gi      RWO            Delete           Bound    monitoring/prometheus-k8s-db-prometheus-k8s-1   prometheus-data-db            3m5s</span><br><span class="line">pvc-fd9f1223-8131-4b0f-b070-661a2bcfd782   100Gi      RWO            Delete           Bound    monitoring/prometheus-k8s-db-prometheus-k8s-0   prometheus-data-db            3m5s</span><br><span class="line"></span><br><span class="line">$ kubectl get pvc -n monitoring</span><br><span class="line">prometheus-k8s-db-prometheus-k8s-0   Bound    pvc-fd9f1223-8131-4b0f-b070-661a2bcfd782   100Gi      RWO            prometheus-data-db   3m20s</span><br><span class="line">prometheus-k8s-db-prometheus-k8s-1   Bound    pvc-e786b1a8-d2ef-453d-9f5d-b1cb4b2b5574   100Gi      RWO            prometheus-data-db   3m20s</span><br></pre></td></tr></table></figure></div>

<ul>
<li>可以测试一下把 pod 删掉数据是否还保存<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl delete pods -n monitoring prometheus-k8s-0</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h1 id="🤔-反思"><a href="#🤔-反思" class="headerlink" title="🤔 反思"></a>🤔 反思</h1><ul>
<li>以目标为导向可以大大提高效率。<ul>
<li>本次实现过程中，<ul>
<li>先查询“Prometheus 持久化”发现了些教程，但意识到大部分名词看不懂；</li>
<li>于是转向查询相关名词。<ul>
<li>看相关名词的过程中，头脑逐渐迷糊，渐渐忘记主线，开始陷入细节中。</li>
<li>上了个厕所，复盘发现自己效率有点低，于是立马警醒自己。</li>
</ul>
</li>
<li>接下来回顾最初查到的教程，以看懂教程为目标，缩小名词排查范围，只关注“PV、PVC、SC”等概念，效率回升。</li>
</ul>
</li>
</ul>
</li>
<li>就我个人而言，很容易陷入细节里。原因就是干着干着会忘记主线，只想把文档里的每个字都看懂，从而积累小小成就感。从大局看，有点捡了芝麻丢了西瓜，还是得时刻问自己“我现在在干什么？”，同时记录工作过程方便自己理清思路。</li>
</ul>
<hr>
<ul>
<li>希望通过分享我配置k8s持久化的经历，可以帮助你在类似的问题上更加迅速和高效地解决困扰你的问题。</li>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.cnblogs.com/qiuhom-1874/p/14180752.html">[1] 容器编排系统K8s之Volume的基础使用<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link" href="https://www.cnblogs.com/qiuhom-1874/p/14188621.html">[2] 容器编排系统K8s之PV、PVC、SC资源<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link" href="https://i4t.com/4586.html">[3] Prometheus Operator 持久化存储<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link" href="https://www.cnblogs.com/ssgeek/p/14441149.html">[4] 使用kube-prometheus部署k8s监控(最新版)<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Go 项目解析与并发编程实践</title>
    <url>/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li>
<li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li>
<li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li>
<li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li>
<li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li>
<li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li>
<li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li>
<li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li>
<li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li>
<li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li>
<li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li>
<li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li>
<li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li>
<li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a>
</li>
</ol>
</blockquote>
<p>前期在 <a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a> 中我们深入解析了 <strong>审计日志 → Exporter → Prometheus+Grafana</strong> 的端到端链路，但仅关注 <code>kube-scheduling-performance</code> 项目本身（只负责开展测试、部署 Exporter 工具）。本篇将聚焦于实现了 Exporter 逻辑的 <code>kube-apiserver-audit-exporter</code> 项目细节，顺便以此为例介绍从 Go 语言项目结构到并发编程实践，帮助读者全面掌握云原生监控工具的开发模式。</p>
<p>下图给出了本篇的核心内容结构：</p>
<pre class="mermaid">graph TD
  subgraph Go 项目解析
    A[项目结构] --&gt; B[包结构]
    B --&gt; C[文件结构]
    C --&gt; D[函数/方法/类型]
  end
  
  subgraph 并发编程实践
    E[Goroutine] --&gt; F[Channel]
    F --&gt; G[操作符 &lt;-]
    G --&gt; H[WaitGroup 同步]
  end
  
  subgraph 实际应用
    I[审计日志处理] --&gt; J[指标收集]
    J --&gt; K[监控数据暴露]
  end</pre>

<hr>
<h1 id="1️⃣-kube-apiserver-audit-exporter-项目解析"><a href="#1️⃣-kube-apiserver-audit-exporter-项目解析" class="headerlink" title="1️⃣ kube-apiserver-audit-exporter 项目解析"></a>1️⃣ kube-apiserver-audit-exporter 项目解析</h1><h2 id="项目背景介绍"><a href="#项目背景介绍" class="headerlink" title="项目背景介绍"></a>项目背景介绍</h2><p><code>kube-apiserver-audit-exporter</code> 是一个专门用于将 Kubernetes API Server 审计日志转换为 Prometheus 指标的工具。在云原生环境中，监控和可观测性是至关重要的，而审计日志包含了所有 API 请求的详细信息，是分析系统行为的重要数据源。</p>
<p><strong>核心功能</strong>：</p>
<ul>
<li><strong>并发处理</strong>：为每个审计日志文件创建独立的 Exporter 协程，实现并行处理</li>
<li><strong>重放控制</strong>：支持历史审计日志的时间间隔重放，用于性能回归测试</li>
<li><strong>指标转换</strong>：将 JSON 格式的审计事件转换为 Prometheus 指标</li>
<li><strong>多维度标签</strong>：提取集群、命名空间、用户、资源等维度信息</li>
<li><strong>实时监控</strong>：持续读取审计日志文件，实时处理新增内容并更新指标</li>
</ul>
<h2 id="项目目录结构介绍"><a href="#项目目录结构介绍" class="headerlink" title="项目目录结构介绍"></a>项目目录结构介绍</h2><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">kube-apiserver-audit-exporter/</span><br><span class="line">├── cmd/                           # 可执行程序入口</span><br><span class="line">│   └── kube-apiserver-audit-exporter/</span><br><span class="line">│       └── main.go               # 主程序入口</span><br><span class="line">├── exporter/                      # 核心业务逻辑包</span><br><span class="line">│   ├── exporter.go               # 导出器核心逻辑</span><br><span class="line">│   ├── metrics.go                # Prometheus 指标定义</span><br><span class="line">│   ├── model.go                  # 数据模型定义</span><br><span class="line">│   └── utils.go                  # 工具函数</span><br><span class="line">├── go.mod                        # Go 模块定义文件</span><br><span class="line">├── go.sum                        # 依赖版本锁定文件</span><br><span class="line">├── audit-policy.yaml            # 审计策略配置</span><br><span class="line">└── README.md                     # 项目说明</span><br></pre></td></tr></table></figure></div>

<p><strong>目录结构特点</strong>：</p>
<ul>
<li><strong>cmd/</strong>: 遵循 Go 项目标准布局，存放可执行程序入口</li>
<li><strong>exporter/</strong>: 核心业务逻辑，采用包级别的模块化设计</li>
<li><strong>根目录</strong>: 包含项目配置文件和依赖管理文件</li>
</ul>
<h2 id="项目关键点介绍"><a href="#项目关键点介绍" class="headerlink" title="项目关键点介绍"></a>项目关键点介绍</h2><h3 id="1-并发处理架构"><a href="#1-并发处理架构" class="headerlink" title="1. 并发处理架构"></a>1. 并发处理架构</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// main.go 中的并发启动</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> {</span><br><span class="line">    <span class="keyword">go</span> monitorAndStartExporters()  <span class="comment">// 异步启动监控器</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> err := exporter.ListenAndServe(address); err != <span class="literal">nil</span> {</span><br><span class="line">        slog.Error(<span class="string">"Failed to start metrics server"</span>, <span class="string">"err"</span>, err)</span><br><span class="line">        os.Exit(<span class="number">1</span>)</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// main.go 中为每个日志文件创建 Exporter</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">monitorAndStartExporters</span><span class="params">()</span></span> {</span><br><span class="line">    <span class="keyword">for</span> i, path := <span class="keyword">range</span> paths {</span><br><span class="line">        e := exporter.NewExporter(  <span class="comment">// 创建 Exporter 实例</span></span><br><span class="line">            exporter.WithReplay(replay),</span><br><span class="line">            exporter.WithFile(path),</span><br><span class="line">            exporter.WithClusterLabel(labels[i]),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">go</span> e.Run()  <span class="comment">// 启动 Exporter 协程</span></span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>设计亮点</strong>：</p>
<ul>
<li><strong>主线程</strong>：运行 HTTP 服务器，提供 <code>/metrics</code> 端点</li>
<li><strong>工作协程</strong>：每个日志文件对应一个独立的 Exporter 协程</li>
<li><strong>并发处理</strong>：多个 Exporter 协程并行处理不同的日志文件</li>
<li><strong>独立运行</strong>：每个协程独立监控自己的日志文件，互不干扰</li>
</ul>
<h3 id="2-重放控制机制"><a href="#2-重放控制机制" class="headerlink" title="2. 重放控制机制"></a>2. 重放控制机制</h3><p>重放控制是该项目的一个重要特性，用于按照原始时间间隔重放历史审计日志，支持性能回归测试。</p>
<h4 id="重放控制原理"><a href="#重放控制原理" class="headerlink" title="重放控制原理"></a>重放控制原理</h4><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// exporter.go 中的重放控制逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Exporter)</span></span> processFileUpdate(path <span class="type">string</span>) <span class="type">error</span> {</span><br><span class="line">    <span class="comment">// ... 文件读取逻辑 ...</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">var</span> event auditv1.Event</span><br><span class="line">    <span class="keyword">if</span> err := json.Unmarshal(line, &amp;event); err != <span class="literal">nil</span> {</span><br><span class="line">        <span class="keyword">return</span> fmt.Errorf(<span class="string">"json decode error: %w"</span>, err)</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 重放控制：如果启用重放模式，控制时间差</span></span><br><span class="line">    <span class="keyword">if</span> p.replay {</span><br><span class="line">        <span class="keyword">if</span> p.timeDiff == <span class="number">0</span> {</span><br><span class="line">            <span class="comment">// 第一次事件：记录当前时间与事件时间戳的差值作为基准</span></span><br><span class="line">            p.timeDiff = time.Since(event.StageTimestamp.Time)</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            <span class="comment">// 后续事件：如果当前时间与事件时间戳的差值小于基准，跳过该事件</span></span><br><span class="line">            <span class="keyword">if</span> time.Since(event.StageTimestamp.Time) &lt; p.timeDiff {</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">nil</span>  <span class="comment">// 跳过，等待时间到达</span></span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    p.updateMetrics(p.clusterLabel, event)</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h4 id="重放控制工作流程"><a href="#重放控制工作流程" class="headerlink" title="重放控制工作流程"></a>重放控制工作流程</h4><ol>
<li><p><strong>基准时间计算</strong>：</p>
<ul>
<li>当 <code>p.timeDiff == 0</code> 时，表示这是第一个事件</li>
<li>计算 <code>time.Since(event.StageTimestamp.Time)</code> 作为基准时间差</li>
<li>这个差值表示从事件发生到当前处理的时间间隔</li>
</ul>
</li>
<li><p><strong>时间间隔控制</strong>：</p>
<ul>
<li>对于后续事件，计算当前时间与事件时间戳的差值</li>
<li>如果差值小于基准时间差，说明还没到处理这个事件的时间</li>
<li>直接 <code>return nil</code> 跳过该事件，等待下次循环</li>
</ul>
</li>
<li><p><strong>重放效果</strong>：</p>
<ul>
<li>事件会按照原始的时间间隔被处理</li>
<li>如果原始日志中两个事件间隔 1 秒，重放时也会间隔 1 秒</li>
<li>实现了真实的时间模拟，而不是快速连续处理</li>
</ul>
</li>
</ol>
<h4 id="重放控制示例"><a href="#重放控制示例" class="headerlink" title="重放控制示例"></a>重放控制示例</h4><p>假设审计日志中有以下事件：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">事件1: 2024-01-01 10:00:00 (处理时间: 10:00:05) → timeDiff = 5秒</span><br><span class="line">事件2: 2024-01-01 10:00:02 (处理时间: 10:00:05) → 5秒 &lt; 5秒? 否，处理</span><br><span class="line">事件3: 2024-01-01 10:00:03 (处理时间: 10:00:05) → 5秒 &lt; 5秒? 否，处理</span><br><span class="line">事件4: 2024-01-01 10:00:10 (处理时间: 10:00:05) → 5秒 &lt; 5秒? 否，处理</span><br></pre></td></tr></table></figure></div>

<p><strong>重放控制特点</strong>：</p>
<ul>
<li><strong>时间差计算</strong>：记录第一个事件的时间差作为基准</li>
<li><strong>重放模拟</strong>：按照原始时间间隔重放审计事件</li>
<li><strong>性能测试</strong>：支持历史数据的性能回归测试</li>
<li><strong>真实模拟</strong>：保持原始事件的时间关系，而不是快速连续处理</li>
</ul>
<h3 id="3-指标标签提取"><a href="#3-指标标签提取" class="headerlink" title="3. 指标标签提取"></a>3. 指标标签提取</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// metrics.go 中的标签提取逻辑</span></span><br><span class="line">labels := []<span class="type">string</span>{</span><br><span class="line">    clusterLabel,                           <span class="comment">// 集群标识</span></span><br><span class="line">    ns,                                     <span class="comment">// 命名空间</span></span><br><span class="line">    extractUserAgent(event.UserAgent),      <span class="comment">// 用户代理</span></span><br><span class="line">    event.Verb,                            <span class="comment">// HTTP 方法</span></span><br><span class="line">    extractResourceName(event),            <span class="comment">// 资源名称</span></span><br><span class="line">    strconv.Itoa(<span class="type">int</span>(event.ResponseStatus.Code)), <span class="comment">// 状态码</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>数据丰富性</strong>：</p>
<ul>
<li><strong>多维度标签</strong>：支持按集群、命名空间、用户等维度聚合</li>
<li><strong>状态码过滤</strong>：只处理成功的 API 调用（200-299）</li>
<li><strong>资源类型识别</strong>：自动识别 Pod、Job 等不同资源类型</li>
</ul>
<h2 id="关键点调用关系与数据流向"><a href="#关键点调用关系与数据流向" class="headerlink" title="关键点调用关系与数据流向"></a>关键点调用关系与数据流向</h2><h3 id="1-程序启动流程"><a href="#1-程序启动流程" class="headerlink" title="1. 程序启动流程"></a>1. 程序启动流程</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// main.go - 程序入口</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> {</span><br><span class="line">    <span class="keyword">go</span> monitorAndStartExporters()  <span class="comment">// 启动监控器协程</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> err := exporter.ListenAndServe(address); err != <span class="literal">nil</span> {  <span class="comment">// 启动HTTP服务</span></span><br><span class="line">        slog.Error(<span class="string">"Failed to start metrics server"</span>, <span class="string">"err"</span>, err)</span><br><span class="line">        os.Exit(<span class="number">1</span>)</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="2-Exporter-创建与启动"><a href="#2-Exporter-创建与启动" class="headerlink" title="2. Exporter 创建与启动"></a>2. Exporter 创建与启动</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// main.go - 为每个日志文件创建 Exporter</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">monitorAndStartExporters</span><span class="params">()</span></span> {</span><br><span class="line">    <span class="keyword">for</span> i, path := <span class="keyword">range</span> paths {</span><br><span class="line">        e := exporter.NewExporter(  <span class="comment">// 创建 Exporter 实例</span></span><br><span class="line">            exporter.WithReplay(replay),</span><br><span class="line">            exporter.WithFile(path),</span><br><span class="line">            exporter.WithClusterLabel(labels[i]),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">go</span> e.Run()  <span class="comment">// 启动 Exporter 协程</span></span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="3-文件监控与事件处理"><a href="#3-文件监控与事件处理" class="headerlink" title="3. 文件监控与事件处理"></a>3. 文件监控与事件处理</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// exporter.go - Exporter 运行循环</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Exporter)</span></span> Run() {</span><br><span class="line">    ticker := time.NewTicker(time.Second)</span><br><span class="line">    <span class="keyword">defer</span> ticker.Stop()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">range</span> ticker.C {</span><br><span class="line">        p.handleFileEvent(p.file)  <span class="comment">// 处理文件事件</span></span><br><span class="line">        ticker.Reset(time.Second)</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// exporter.go - 文件事件处理</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Exporter)</span></span> handleFileEvent(path <span class="type">string</span>) {</span><br><span class="line">    <span class="keyword">if</span> err := p.processFileUpdate(path); err != <span class="literal">nil</span> {  <span class="comment">// 处理文件更新</span></span><br><span class="line">        slog.Error(<span class="string">"Error processing file"</span>, <span class="string">"cluster"</span>, p.clusterLabel, <span class="string">"error"</span>, err)</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="4-日志解析与重放控制"><a href="#4-日志解析与重放控制" class="headerlink" title="4. 日志解析与重放控制"></a>4. 日志解析与重放控制</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// exporter.go - 文件更新处理</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Exporter)</span></span> processFileUpdate(path <span class="type">string</span>) <span class="type">error</span> {</span><br><span class="line">    <span class="comment">// ... 文件读取逻辑 ...</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">var</span> event auditv1.Event</span><br><span class="line">    <span class="keyword">if</span> err := json.Unmarshal(line, &amp;event); err != <span class="literal">nil</span> {  <span class="comment">// JSON 解析</span></span><br><span class="line">        <span class="keyword">return</span> fmt.Errorf(<span class="string">"json decode error: %w"</span>, err)</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 重放控制</span></span><br><span class="line">    <span class="keyword">if</span> p.replay {</span><br><span class="line">        <span class="keyword">if</span> p.timeDiff == <span class="number">0</span> {</span><br><span class="line">            p.timeDiff = time.Since(event.StageTimestamp.Time)</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            <span class="keyword">if</span> time.Since(event.StageTimestamp.Time) &lt; p.timeDiff {</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    p.updateMetrics(p.clusterLabel, event)  <span class="comment">// 更新指标</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="5-指标处理与标签提取"><a href="#5-指标处理与标签提取" class="headerlink" title="5. 指标处理与标签提取"></a>5. 指标处理与标签提取</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// metrics.go - 指标更新入口</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Exporter)</span></span> updateMetrics(clusterLabel <span class="type">string</span>, event auditv1.Event) {</span><br><span class="line">    <span class="comment">// 状态码过滤</span></span><br><span class="line">    <span class="keyword">if</span> event.ResponseStatus == <span class="literal">nil</span> ||</span><br><span class="line">        (event.ResponseStatus.Code &lt; <span class="number">200</span> || event.ResponseStatus.Code &gt;= <span class="number">300</span>) {</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 标签提取</span></span><br><span class="line">    labels := []<span class="type">string</span>{</span><br><span class="line">        clusterLabel,</span><br><span class="line">        ns,</span><br><span class="line">        extractUserAgent(event.UserAgent),      <span class="comment">// 提取用户代理</span></span><br><span class="line">        event.Verb,</span><br><span class="line">        extractResourceName(event),            <span class="comment">// 提取资源名称</span></span><br><span class="line">        strconv.Itoa(<span class="type">int</span>(event.ResponseStatus.Code)),</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    apiRequests.WithLabelValues(labels...).Inc()  <span class="comment">// 更新指标</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="6-HTTP-服务与指标暴露"><a href="#6-HTTP-服务与指标暴露" class="headerlink" title="6. HTTP 服务与指标暴露"></a>6. HTTP 服务与指标暴露</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// exporter.go - HTTP 服务启动</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ListenAndServe</span><span class="params">(addr <span class="type">string</span>)</span></span> <span class="type">error</span> {</span><br><span class="line">    mux := http.NewServeMux()</span><br><span class="line">    handler := promhttp.HandlerFor(registry, promhttp.HandlerOpts{</span><br><span class="line">        EnableOpenMetrics: <span class="literal">true</span>,</span><br><span class="line">    })</span><br><span class="line">    mux.Handle(<span class="string">"/metrics"</span>, handler)  <span class="comment">// 注册指标端点</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> http.ListenAndServe(addr, mux)  <span class="comment">// 启动 HTTP 服务</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="数据流向总结"><a href="#数据流向总结" class="headerlink" title="数据流向总结"></a>数据流向总结</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">审计日志文件 → processFileUpdate() → JSON解析 → 重放控制 → updateMetrics() → Prometheus指标 → /metrics端点 → 外部监控系统</span><br></pre></td></tr></table></figure></div>

<hr>
<h1 id="2️⃣-Go-项目解析"><a href="#2️⃣-Go-项目解析" class="headerlink" title="2️⃣ Go 项目解析"></a>2️⃣ Go 项目解析</h1><p>以该项目为例，我们可以看到一个 Go 语言项目的组成。</p>
<h2 id="项目结构层级"><a href="#项目结构层级" class="headerlink" title="项目结构层级"></a>项目结构层级</h2><p>Go 语言有清晰的层级结构，从大到小排列：</p>
<h3 id="项目-Project-Module"><a href="#项目-Project-Module" class="headerlink" title="项目 (Project/Module)"></a>项目 (Project/Module)</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">kube-apiserver-audit-exporter/          # 项目根目录</span><br><span class="line">├── go.mod                              # 模块定义</span><br><span class="line">└── go.sum                              # 依赖锁定</span><br></pre></td></tr></table></figure></div>

<h3 id="包-Package"><a href="#包-Package" class="headerlink" title="包 (Package)"></a>包 (Package)</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">exporter/                               # 包目录</span><br><span class="line">├── exporter.go                         # package exporter</span><br><span class="line">├── metrics.go                          # package exporter  </span><br><span class="line">├── model.go                            # package exporter</span><br><span class="line">└── utils.go                            # package exporter</span><br><span class="line"></span><br><span class="line">cmd/kube-apiserver-audit-exporter/     # 另一个包</span><br><span class="line">└── main.go                             # package main</span><br></pre></td></tr></table></figure></div>

<h3 id="文件-File"><a href="#文件-File" class="headerlink" title="文件 (File)"></a>文件 (File)</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">exporter.go                             # 单个 .go 文件</span><br><span class="line">├── package exporter                    # 包声明</span><br><span class="line">├── import (...)                        # 导入语句</span><br><span class="line">├── type Exporter struct {...}          # 类型定义</span><br><span class="line">├── func NewExporter(...) {...}         # 函数定义</span><br><span class="line">└── func (e *Exporter) Run() {...}      # 方法定义</span><br></pre></td></tr></table></figure></div>

<h3 id="函数-方法-Function-Method"><a href="#函数-方法-Function-Method" class="headerlink" title="函数/方法 (Function/Method)"></a>函数/方法 (Function/Method)</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewExporter</span><span class="params">(opts ...Option)</span></span> *Exporter {  <span class="comment">// 函数</span></span><br><span class="line">    <span class="comment">// 函数体</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *Exporter)</span></span> Run() {                    <span class="comment">// 方法</span></span><br><span class="line">    <span class="comment">// 方法体</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h2 id="包结构详解"><a href="#包结构详解" class="headerlink" title="包结构详解"></a>包结构详解</h2><h3 id="1-包的作用域机制"><a href="#1-包的作用域机制" class="headerlink" title="1. 包的作用域机制"></a>1. 包的作用域机制</h3><p><strong>在 <code>exporter</code> 包中</strong>：</p>
<ul>
<li><code>exporter.go</code> 声明：<code>package exporter</code></li>
<li><code>metrics.go</code> 声明：<code>package exporter</code></li>
<li><code>model.go</code> 声明：<code>package exporter</code></li>
<li><code>utils.go</code> 声明：<code>package exporter</code></li>
</ul>
<p><strong>关键特点</strong>：</p>
<ul>
<li><strong>同一个包内的所有文件共享命名空间</strong></li>
<li><strong>不需要显式 import</strong>：同一个包内的文件可以直接访问彼此的公开标识符</li>
<li><strong>公开标识符</strong>：首字母大写的函数、变量、类型可以被外部包访问</li>
</ul>
<h3 id="2-包间调用关系"><a href="#2-包间调用关系" class="headerlink" title="2. 包间调用关系"></a>2. 包间调用关系</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在 main.go 中调用 exporter 包</span></span><br><span class="line"><span class="keyword">import</span> <span class="string">"github.com/wzshiming/kube-apiserver-audit-exporter/exporter"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> {</span><br><span class="line">    exporter.NewExporter(...)  <span class="comment">// 通过包名访问</span></span><br><span class="line">    exporter.ListenAndServe(address)  <span class="comment">// 通过包名访问</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h2 id="文件结构详解"><a href="#文件结构详解" class="headerlink" title="文件结构详解"></a>文件结构详解</h2><h3 id="1-Go-文件的基本组成"><a href="#1-Go-文件的基本组成" class="headerlink" title="1. Go 文件的基本组成"></a>1. Go 文件的基本组成</h3><p>一个典型的 Go 文件包含以下部分（按顺序）：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> declaration    <span class="comment">// 包声明</span></span><br><span class="line"><span class="keyword">import</span> statements     <span class="comment">// 导入语句</span></span><br><span class="line"><span class="keyword">type</span> declarations     <span class="comment">// 类型声明</span></span><br><span class="line"><span class="keyword">var</span> declarations      <span class="comment">// 变量声明</span></span><br><span class="line"><span class="keyword">const</span> declarations    <span class="comment">// 常量声明</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">declarations</span>     // 函数声明</span></span><br></pre></td></tr></table></figure></div>

<h3 id="2-关键概念解析"><a href="#2-关键概念解析" class="headerlink" title="2. 关键概念解析"></a>2. 关键概念解析</h3><h4 id="package-main-和-main-函数"><a href="#package-main-和-main-函数" class="headerlink" title="package main 和 main 函数"></a><code>package main</code> 和 <code>main</code> 函数</h4><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main  <span class="comment">// 可执行包，只有 main 包才能编译成可执行文件</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> {  <span class="comment">// 程序入口点，必须存在且唯一</span></span><br><span class="line">    <span class="comment">// 程序逻辑</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h4 id="import-语句"><a href="#import-语句" class="headerlink" title="import 语句"></a><code>import</code> 语句</h4><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">"log/slog"</span>    <span class="comment">// 标准库 - 结构化日志</span></span><br><span class="line">    <span class="string">"os"</span>          <span class="comment">// 标准库 - 操作系统接口</span></span><br><span class="line">    <span class="string">"strings"</span>     <span class="comment">// 标准库 - 字符串处理</span></span><br><span class="line">    <span class="string">"time"</span>        <span class="comment">// 标准库 - 时间处理</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">"github.com/spf13/pflag"</span>  <span class="comment">// 第三方库 - 命令行参数解析</span></span><br><span class="line">    <span class="string">"github.com/wzshiming/kube-apiserver-audit-exporter/exporter"</span>  <span class="comment">// 本地包</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></div>

<h4 id="var-变量声明"><a href="#var-变量声明" class="headerlink" title="var 变量声明"></a><code>var</code> 变量声明</h4><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">    auditLogPath = []<span class="type">string</span>{<span class="string">"./audit.log"</span>}  <span class="comment">// 审计日志路径，默认值</span></span><br><span class="line">    address      = <span class="string">":8080"</span>                  <span class="comment">// HTTP 服务地址，默认值</span></span><br><span class="line">    cluster      = <span class="string">""</span>                       <span class="comment">// 集群标签，默认值</span></span><br><span class="line">    replay       = <span class="literal">false</span>                    <span class="comment">// 是否重放日志，默认值</span></span><br><span class="line">    delay        time.Duration              <span class="comment">// 启动延迟，默认值</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></div>

<h4 id="init-函数"><a href="#init-函数" class="headerlink" title="init 函数"></a><code>init</code> 函数</h4><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> {</span><br><span class="line">    pflag.StringArrayVar(&amp;auditLogPath, <span class="string">"audit-log-path"</span>, auditLogPath, <span class="string">"Path to audit log files"</span>)</span><br><span class="line">    pflag.StringVar(&amp;address, <span class="string">"address"</span>, address, <span class="string">"Address to listen on"</span>)</span><br><span class="line">    pflag.StringVar(&amp;cluster, <span class="string">"cluster-label"</span>, cluster, <span class="string">"Default cluster label of metrics"</span>)</span><br><span class="line">    pflag.BoolVar(&amp;replay, <span class="string">"replay"</span>, replay, <span class="string">"replay the audit log"</span>)</span><br><span class="line">    pflag.DurationVar(&amp;delay, <span class="string">"delay"</span>, <span class="number">0</span>, <span class="string">"delay to start"</span>)</span><br><span class="line">    pflag.Parse()</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>执行顺序</strong>：</p>
<ol>
<li><strong>包级别变量初始化</strong>：先执行 <code>var</code> 声明</li>
<li><strong>init 函数执行</strong>：然后执行所有 <code>init</code> 函数</li>
<li><strong>main 函数执行</strong>：最后执行 <code>main</code> 函数</li>
</ol>
<h2 id="函数-方法-类型结构"><a href="#函数-方法-类型结构" class="headerlink" title="函数/方法/类型结构"></a>函数/方法/类型结构</h2><h3 id="1-选项模式-Option-Pattern"><a href="#1-选项模式-Option-Pattern" class="headerlink" title="1. 选项模式 (Option Pattern)"></a>1. 选项模式 (Option Pattern)</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Option <span class="function"><span class="keyword">func</span><span class="params">(e *Exporter)</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithFile</span><span class="params">(file <span class="type">string</span>)</span></span> Option {</span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(e *Exporter)</span></span> {</span><br><span class="line">        e.file = file</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithReplay</span><span class="params">(replay <span class="type">bool</span>)</span></span> Option {</span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(e *Exporter)</span></span> {</span><br><span class="line">        e.replay = replay</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewExporter</span><span class="params">(opts ...Option)</span></span> *Exporter {</span><br><span class="line">    e := &amp;Exporter{</span><br><span class="line">        podCreationTimes:      <span class="keyword">map</span>[target]*time.Time{},</span><br><span class="line">        batchJobCreationTimes: <span class="keyword">map</span>[target]*time.Time{},</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> _, opt := <span class="keyword">range</span> opts {</span><br><span class="line">        opt(e)  <span class="comment">// 应用每个选项</span></span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> e</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>选项模式的优势</strong>：</p>
<ul>
<li><strong>灵活配置</strong>：可以传递任意数量的选项</li>
<li><strong>可选参数</strong>：不需要的参数可以不传递</li>
<li><strong>可扩展性</strong>：添加新选项不需要修改构造函数签名</li>
<li><strong>可读性</strong>：调用时意图清晰明确</li>
</ul>
<h3 id="2-结构体方法"><a href="#2-结构体方法" class="headerlink" title="2. 结构体方法"></a>2. 结构体方法</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Exporter <span class="keyword">struct</span> {</span><br><span class="line">    file   <span class="type">string</span></span><br><span class="line">    offset <span class="type">int64</span></span><br><span class="line">    clusterLabel <span class="type">string</span></span><br><span class="line">    replay       <span class="type">bool</span></span><br><span class="line">    timeDiff     time.Duration</span><br><span class="line">    podCreationTimes      <span class="keyword">map</span>[target]*time.Time</span><br><span class="line">    batchJobCreationTimes <span class="keyword">map</span>[target]*time.Time</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Exporter)</span></span> Run() {</span><br><span class="line">    ticker := time.NewTicker(time.Second)</span><br><span class="line">    <span class="keyword">defer</span> ticker.Stop()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">range</span> ticker.C {</span><br><span class="line">        p.handleFileEvent(p.file)</span><br><span class="line">        ticker.Reset(time.Second)</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<hr>
<h1 id="3️⃣-Go-并发编程实践"><a href="#3️⃣-Go-并发编程实践" class="headerlink" title="3️⃣ Go 并发编程实践"></a>3️⃣ Go 并发编程实践</h1><h2 id="并发编程核心概念"><a href="#并发编程核心概念" class="headerlink" title="并发编程核心概念"></a>并发编程核心概念</h2><h3 id="1-Goroutine-vs-线程"><a href="#1-Goroutine-vs-线程" class="headerlink" title="1. Goroutine vs 线程"></a>1. Goroutine vs 线程</h3><table>
<thead>
<tr>
<th>特性</th>
<th>Goroutine</th>
<th>线程</th>
</tr>
</thead>
<tbody><tr>
<td><strong>内存占用</strong></td>
<td>2KB 初始栈，可动态增长</td>
<td>通常 1-2MB</td>
</tr>
<tr>
<td><strong>创建成本</strong></td>
<td>极低</td>
<td>较高</td>
</tr>
<tr>
<td><strong>调度方式</strong></td>
<td>M:N 模型（用户态调度）</td>
<td>1:1 模型（内核调度）</td>
</tr>
<tr>
<td><strong>并发数量</strong></td>
<td>可创建数百万个</td>
<td>通常几千个</td>
</tr>
</tbody></table>
<h3 id="2-Channel-通信机制"><a href="#2-Channel-通信机制" class="headerlink" title="2. Channel 通信机制"></a>2. Channel 通信机制</h3><p>Channel 是 Go 协程间通信的管道，遵循”通过通信共享内存”的设计哲学。</p>
<blockquote>
<p>在Effective Go 中对并发的描述中有这样一句话：<br>“Do not communicate by sharing memory; instead, share memory by communicating.</p>
</blockquote>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建 channel</span></span><br><span class="line">tasks := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, <span class="number">100</span>)  <span class="comment">// 带缓冲的 channel</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 发送数据</span></span><br><span class="line">tasks &lt;- i  <span class="comment">// 将数据发送到 channel</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 接收数据</span></span><br><span class="line">task := &lt;-tasks  <span class="comment">// 从 channel 接收数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 关闭 channel</span></span><br><span class="line"><span class="built_in">close</span>(tasks)  <span class="comment">// 通知接收方没有更多数据</span></span><br></pre></td></tr></table></figure></div>

<h3 id="3-WaitGroup-同步机制"><a href="#3-WaitGroup-同步机制" class="headerlink" title="3. WaitGroup 同步机制"></a>3. WaitGroup 同步机制</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line"></span><br><span class="line">wg.Add(<span class="number">1</span>)    <span class="comment">// 增加等待计数</span></span><br><span class="line"><span class="keyword">defer</span> wg.Done()  <span class="comment">// 协程结束时减少计数</span></span><br><span class="line">wg.Wait()    <span class="comment">// 等待所有协程完成</span></span><br></pre></td></tr></table></figure></div>

<h2 id="实战示例：5个协程并行输出数字1-100"><a href="#实战示例：5个协程并行输出数字1-100" class="headerlink" title="实战示例：5个协程并行输出数字1-100"></a>实战示例：5个协程并行输出数字1-100</h2><h3 id="方案1：Channel-WaitGroup（推荐）"><a href="#方案1：Channel-WaitGroup（推荐）" class="headerlink" title="方案1：Channel + WaitGroup（推荐）"></a>方案1：Channel + WaitGroup（推荐）</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">"fmt"</span></span><br><span class="line">    <span class="string">"sync"</span></span><br><span class="line">    <span class="string">"time"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> {</span><br><span class="line">    fmt.Println(<span class="string">"5个协程并行输出数字1-100（无重复）"</span>)</span><br><span class="line">    fmt.Println(<span class="string">"====================================="</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 创建任务 channel</span></span><br><span class="line">    tasks := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, <span class="number">100</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 使用 WaitGroup 等待所有协程完成</span></span><br><span class="line">    <span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 启动 5 个 worker 协程</span></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ {</span><br><span class="line">        wg.Add(<span class="number">1</span>) <span class="comment">// 增加等待计数</span></span><br><span class="line">        <span class="keyword">go</span> worker(i, tasks, &amp;wg)</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 发送任务到 channel</span></span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> {</span><br><span class="line">        <span class="keyword">for</span> i := <span class="number">1</span>; i &lt;= <span class="number">100</span>; i++ {</span><br><span class="line">            tasks &lt;- i</span><br><span class="line">        }</span><br><span class="line">        <span class="built_in">close</span>(tasks) <span class="comment">// 关闭 channel，通知 workers 没有更多任务</span></span><br><span class="line">    }()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 等待所有协程完成</span></span><br><span class="line">    wg.Wait()</span><br><span class="line">    fmt.Println(<span class="string">"\n所有任务完成！"</span>)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// worker 函数：处理任务的协程</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">worker</span><span class="params">(workerID <span class="type">int</span>, tasks &lt;-<span class="keyword">chan</span> <span class="type">int</span>, wg *sync.WaitGroup)</span></span> {</span><br><span class="line">    <span class="keyword">defer</span> wg.Done() <span class="comment">// 协程结束时减少等待计数</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> task := <span class="keyword">range</span> tasks {</span><br><span class="line">        fmt.Printf(<span class="string">"协程 %d 处理数字: %d\n"</span>, workerID, task)</span><br><span class="line">        <span class="comment">// 模拟一些处理时间</span></span><br><span class="line">        time.Sleep(<span class="number">10</span> * time.Millisecond)</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>运行结果</strong>：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">5个协程并行输出数字1-100（无重复）</span><br><span class="line">=====================================</span><br><span class="line">协程 1 处理数字: 1</span><br><span class="line">协程 2 处理数字: 2</span><br><span class="line">协程 3 处理数字: 3</span><br><span class="line">协程 4 处理数字: 4</span><br><span class="line">协程 0 处理数字: 5</span><br><span class="line">协程 0 处理数字: 6</span><br><span class="line">协程 4 处理数字: 7</span><br><span class="line">协程 1 处理数字: 8</span><br><span class="line">协程 2 处理数字: 9</span><br><span class="line">协程 3 处理数字: 10</span><br><span class="line">...</span><br><span class="line">协程 2 处理数字: 99</span><br><span class="line">协程 3 处理数字: 100</span><br><span class="line"></span><br><span class="line">所有任务完成！</span><br></pre></td></tr></table></figure></div>

<h3 id="方案2：互斥锁（不推荐，性能较差）"><a href="#方案2：互斥锁（不推荐，性能较差）" class="headerlink" title="方案2：互斥锁（不推荐，性能较差）"></a>方案2：互斥锁（不推荐，性能较差）</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mutexApproach</span><span class="params">()</span></span> {</span><br><span class="line">    <span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">    <span class="keyword">var</span> mu sync.Mutex</span><br><span class="line">    counter := <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ {</span><br><span class="line">        wg.Add(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(workerID <span class="type">int</span>)</span></span> {</span><br><span class="line">            <span class="keyword">defer</span> wg.Done()</span><br><span class="line">            <span class="keyword">for</span> {</span><br><span class="line">                mu.Lock()</span><br><span class="line">                <span class="keyword">if</span> counter &gt; <span class="number">100</span> {</span><br><span class="line">                    mu.Unlock()</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                }</span><br><span class="line">                current := counter</span><br><span class="line">                counter++</span><br><span class="line">                mu.Unlock()</span><br><span class="line">                </span><br><span class="line">                fmt.Printf(<span class="string">"Worker %d: %d\n"</span>, workerID, current)</span><br><span class="line">            }</span><br><span class="line">        }(i)</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    wg.Wait()</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="方案3：原子操作（高性能）"><a href="#方案3：原子操作（高性能）" class="headerlink" title="方案3：原子操作（高性能）"></a>方案3：原子操作（高性能）</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">atomicApproach</span><span class="params">()</span></span> {</span><br><span class="line">    <span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">    <span class="keyword">var</span> counter <span class="type">int64</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ {</span><br><span class="line">        wg.Add(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(workerID <span class="type">int</span>)</span></span> {</span><br><span class="line">            <span class="keyword">defer</span> wg.Done()</span><br><span class="line">            <span class="keyword">for</span> {</span><br><span class="line">                current := atomic.AddInt64(&amp;counter, <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">if</span> current &gt; <span class="number">100</span> {</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                }</span><br><span class="line">                fmt.Printf(<span class="string">"Worker %d: %d\n"</span>, workerID, current)</span><br><span class="line">            }</span><br><span class="line">        }(i)</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    wg.Wait()</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h2 id="操作符-lt-详解"><a href="#操作符-lt-详解" class="headerlink" title="操作符 <- 详解"></a>操作符 <code>&lt;-</code> 详解</h2><h3 id="1-Channel-操作符"><a href="#1-Channel-操作符" class="headerlink" title="1. Channel 操作符"></a>1. Channel 操作符</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 发送操作</span></span><br><span class="line">ch &lt;- value  <span class="comment">// 将 value 发送到 channel ch</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 接收操作</span></span><br><span class="line">value := &lt;-ch  <span class="comment">// 从 channel ch 接收值</span></span><br><span class="line">value, ok := &lt;-ch  <span class="comment">// 接收值并检查 channel 是否关闭</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 关闭操作</span></span><br><span class="line"><span class="built_in">close</span>(ch)  <span class="comment">// 关闭 channel</span></span><br></pre></td></tr></table></figure></div>

<h3 id="2-方向性-Channel"><a href="#2-方向性-Channel" class="headerlink" title="2. 方向性 Channel"></a>2. 方向性 Channel</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 只发送</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">sendOnly</span><span class="params">(ch <span class="keyword">chan</span>&lt;- <span class="type">int</span>)</span></span> {</span><br><span class="line">    ch &lt;- <span class="number">42</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只接收</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">receiveOnly</span><span class="params">(ch &lt;-<span class="keyword">chan</span> <span class="type">int</span>)</span></span> {</span><br><span class="line">    value := &lt;-ch</span><br><span class="line">    fmt.Println(value)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 双向（默认）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">bidirectional</span><span class="params">(ch <span class="keyword">chan</span> <span class="type">int</span>)</span></span> {</span><br><span class="line">    ch &lt;- <span class="number">42</span></span><br><span class="line">    value := &lt;-ch</span><br><span class="line">    fmt.Println(value)</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="3-Select-语句"><a href="#3-Select-语句" class="headerlink" title="3. Select 语句"></a>3. Select 语句</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> {</span><br><span class="line"><span class="keyword">case</span> msg1 := &lt;-ch1:</span><br><span class="line">    fmt.Println(<span class="string">"收到消息1:"</span>, msg1)</span><br><span class="line"><span class="keyword">case</span> msg2 := &lt;-ch2:</span><br><span class="line">    fmt.Println(<span class="string">"收到消息2:"</span>, msg2)</span><br><span class="line"><span class="keyword">case</span> &lt;-time.After(<span class="number">1</span> * time.Second):</span><br><span class="line">    fmt.Println(<span class="string">"超时"</span>)</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">    fmt.Println(<span class="string">"没有消息"</span>)</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h2 id="并发编程最佳实践"><a href="#并发编程最佳实践" class="headerlink" title="并发编程最佳实践"></a>并发编程最佳实践</h2><h3 id="1-推荐方案：Channel-WaitGroup"><a href="#1-推荐方案：Channel-WaitGroup" class="headerlink" title="1. 推荐方案：Channel + WaitGroup"></a>1. 推荐方案：Channel + WaitGroup</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 优点：</span></span><br><span class="line"><span class="comment">// - 代码清晰易读</span></span><br><span class="line"><span class="comment">// - 符合 Go 的"通过通信共享内存"理念</span></span><br><span class="line"><span class="comment">// - 自动处理协程同步</span></span><br><span class="line"><span class="comment">// - 避免竞态条件</span></span><br><span class="line"></span><br><span class="line">tasks := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, <span class="number">100</span>)</span><br><span class="line"><span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ {</span><br><span class="line">    wg.Add(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(workerID <span class="type">int</span>)</span></span> {</span><br><span class="line">        <span class="keyword">defer</span> wg.Done()</span><br><span class="line">        <span class="keyword">for</span> task := <span class="keyword">range</span> tasks {</span><br><span class="line">            <span class="comment">// 处理任务</span></span><br><span class="line">        }</span><br><span class="line">    }(i)</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="2-Go-并发设计哲学"><a href="#2-Go-并发设计哲学" class="headerlink" title="2. Go 并发设计哲学"></a>2. Go 并发设计哲学</h3><blockquote>
<p><strong>“Don’t communicate by sharing memory; share memory by communicating.”</strong></p>
<p><strong>“不要通过共享内存来通信；要通过通信来共享内存。”</strong></p>
</blockquote>
<p>简单解析：</p>
<blockquote>
<p>多个goroutine同时操作同一个变量（communicate by sharing memory），会有数据竞争的问题，尽量不要用这种方式；而推荐用传递共享方式，一个goroutine处理完了以后传递给另一个goroutine继续处理（share memory by communicating）</p>
<p>作者：水慕华<br>链接：<a class="link" href="https://www.zhihu.com/question/27596075/answer/593672097">https://www.zhihu.com/question/27596075/answer/593672097<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>来源：知乎</p>
</blockquote>
<p>这就是为什么 Channel 是 Go 并发编程的首选方案！</p>
<h3 id="3-实际应用场景"><a href="#3-实际应用场景" class="headerlink" title="3. 实际应用场景"></a>3. 实际应用场景</h3><p>这种模式在实际项目中非常常见：</p>
<ul>
<li><strong>Web 服务器</strong>：每个请求一个协程</li>
<li><strong>数据处理</strong>：批量处理文件、数据库操作</li>
<li><strong>微服务</strong>：并发调用多个服务</li>
<li><strong>爬虫</strong>：并发抓取网页</li>
</ul>
<hr>
<p><em>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</em><br><em>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</em></p>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><p><a class="link" href="https://github.com/wzshiming/kube-apiserver-audit-exporter">[1] Github - kube-apiserver-audit-exporter<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://golang.org/doc/effective_go.html#concurrency">[2] Go 官方文档 - 并发编程<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://golang.org/ref/spec#Channel_types">[3] Go 官方文档 - Channel<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/audit/">[4] Kubernetes官方文档 - 审计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>K8s</tag>
        <tag>Go</tag>
        <tag>并发编程</tag>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</title>
    <url>/2025/07/01/k8s/k8s-scheduler-performance-test-debug/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li>
<li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li>
<li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li>
<li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a>
</li>
</ol>
</blockquote>
<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><blockquote>
<p><strong>📖 文档定位</strong>：本文为 kube-scheduling-perf 项目的<strong>实际部署篇</strong>，与 <a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="理论介绍文档">理论介绍文档</a> 形成互补。理论介绍文档重点解析项目的架构设计和自动化原理，而本文则专注于解决实际部署过程中的各种技术难题。</p>
</blockquote>
<p><strong>适用场景</strong>：如果您已经阅读了理论介绍文档，并计划在实际环境中部署和使用 kube-scheduling-perf 工具，那么本文档将为您提供必要的技术支持和故障排除指南。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><h2 id="为什么需要这份注意事项文档？"><a href="#为什么需要这份注意事项文档？" class="headerlink" title="为什么需要这份注意事项文档？"></a>为什么需要这份注意事项文档？</h2><p>kube-scheduling-perf 项目虽然提供了完善的自动化测试框架，但在实际部署过程中，由于以下因素，用户往往会遇到各种技术障碍：</p>
<h3 id="1-环境差异"><a href="#1-环境差异" class="headerlink" title="1. 环境差异"></a>1. 环境差异</h3><ul>
<li><strong>网络环境</strong>：国内用户访问海外镜像仓库时经常遇到网络超时问题</li>
<li><strong>系统版本</strong>：不同Linux发行版和内核版本对Docker、Kubernetes的支持程度不同</li>
<li><strong>硬件配置</strong>：老旧服务器可能无法运行最新版本的容器和工具</li>
</ul>
<h3 id="2-权限和配置问题"><a href="#2-权限和配置问题" class="headerlink" title="2. 权限和配置问题"></a>2. 权限和配置问题</h3><ul>
<li><strong>用户权限</strong>：Docker容器运行时的用户权限配置不当</li>
<li><strong>目录权限</strong>：自动生成的目录和文件所有权问题</li>
<li><strong>系统配置</strong>：内核参数、cgroup配置等系统级设置</li>
</ul>
<h3 id="3-版本兼容性"><a href="#3-版本兼容性" class="headerlink" title="3. 版本兼容性"></a>3. 版本兼容性</h3><ul>
<li><strong>Go版本</strong>：不同Go版本对测试代码的兼容性差异</li>
<li><strong>Docker版本</strong>：容器运行时版本与Kubernetes版本的匹配问题</li>
<li><strong>Kubernetes版本</strong>：API版本变化导致的兼容性问题</li>
</ul>
<h2 id="文档价值"><a href="#文档价值" class="headerlink" title="文档价值"></a>文档价值</h2><p>本文档基于实际部署经验总结，提供了：</p>
<ul>
<li><strong>系统性的问题分类</strong>：将常见问题按类型进行归类</li>
<li><strong>详细的解决方案</strong>：每个问题都提供具体的解决步骤</li>
<li><strong>预防性建议</strong>：帮助用户提前避免可能遇到的问题</li>
<li><strong>故障排除指南</strong>：快速定位和解决部署过程中的技术难题</li>
</ul>
<p>希望通过本文档，帮助大家避免重复踩坑，提高部署效率，顺利运行测试工具～</p>
<h1 id="🔨注意事项"><a href="#🔨注意事项" class="headerlink" title="🔨注意事项"></a>🔨注意事项</h1><h2 id="注意1：加速镜像拉取"><a href="#注意1：加速镜像拉取" class="headerlink" title="注意1：加速镜像拉取"></a>注意1：加速镜像拉取</h2><p>在国内环境下需要使用CDN加速镜像拉取<a href="#refer-anchor-1"><sup>[2]</sup></a>。</p>
<h3 id="Go-相关包"><a href="#Go-相关包" class="headerlink" title="Go 相关包"></a>Go 相关包</h3><p>在<code>Makefile</code>文件中替换<code>GOPROXY ?= https://proxy.golang.org,direct</code>为<code>GOPROXY ?= https://mirrors.aliyun.com/goproxy/,direct</code>。</p>
<h3 id="Docker-相关包"><a href="#Docker-相关包" class="headerlink" title="Docker 相关包"></a>Docker 相关包</h3><p>在执行 <code>make</code> 命令时，由于需要从海外服务器拉取镜像，频繁出现超时错误：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">Error response from daemon: Head "https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/kwok/kwok/manifests/v0.6.1": dial tcp 142.250.157.82:443: i/o timeout</span><br><span class="line">Error response from daemon: Get "https://registry.k8s.io/v2/": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)</span><br></pre></td></tr></table></figure></div>

<p><a class="link" href="https://github.com/DaoCloud/public-image-mirror">DaoCloud 镜像仓库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>提供了非常方便的解决方案，感恩！使用 DaoCloud 镜像加速，只需要在镜像前加上前缀 <code>m.daocloud.io/</code>。</p>
<h4 id="修改内容"><a href="#修改内容" class="headerlink" title="修改内容"></a>修改内容</h4><p><strong>1. Makefile 配置</strong></p>
<div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改前</span></span><br><span class="line">IMAGE_PREFIX ?= </span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改后  </span></span><br><span class="line">IMAGE_PREFIX ?= m.daocloud.io/</span><br></pre></td></tr></table></figure></div>

<p><strong>2. 脚本配置</strong><br>在 <code>hack/local-registry-with-load-images.sh</code> 中：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改前</span></span><br><span class="line">IMAGE_PREFIX=<span class="string">"<span class="variable">${IMAGE_PREFIX:-}</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改后</span></span><br><span class="line">IMAGE_PREFIX=<span class="string">"<span class="variable">${IMAGE_PREFIX:-m.daocloud.io/}</span>"</span></span><br></pre></td></tr></table></figure></div>

<h4 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h4><ul>
<li><strong>镜像处理流程</strong>：所有镜像通过 <code>hack/local-registry-with-load-images.sh</code> 脚本处理</li>
<li><strong>DaoCloud 加速</strong>：脚本会自动从 <code>m.daocloud.io/</code> 拉取镜像，然后推送到本地仓库 <code>localhost:5001/</code></li>
<li><strong>容器内 Docker</strong>：即使使用容器内的 Docker，也会通过 <code>IMAGE_PREFIX</code> 环境变量传递镜像前缀</li>
</ul>
<h2 id="注意2：内核版本适配"><a href="#注意2：内核版本适配" class="headerlink" title="注意2：内核版本适配"></a>注意2：内核版本适配</h2><h3 id="问题说明"><a href="#问题说明" class="headerlink" title="问题说明"></a>问题说明</h3><p>如之前<a href="/2025/05/19/k8s/k8s-kind-install/" title="KIND安装博客">KIND安装博客</a>所述，本人所使用服务器内核版本过低（3.10.0-1160.71.1.el7.x86_64），无法运行较高版本的Kubernetes和Kind，权衡之计是进行版本降级以解决兼容性问题。</p>
<ul>
<li>降级之后，仍然会收到报错：<code>✗ Preparing nodes 📦 ; Command Output: WARNING: Your kernel does not support cgroup namespaces.  Cgroup namespace setting discarded.</code><ul>
<li>具体分析后发现 Kind 自动添加 cgroupns 参数：从日志中可以看到，kind 在创建集群时自动添加了 –cgroupns=private 参数，这是较新版本 kind 的默认行为。</li>
<li>解决方案：修改 kind 配置，<code>./hack/kind-with-local-registry.sh</code>中，在<code>kind create ...</code>之前增加以下代码：<div class="code-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment"># 新增以下代码：Disable cgroup namespaces for older kernels</span></span><br><span class="line"><span class="built_in">export</span> KIND_EXPERIMENTAL_DISABLE_CGROUP_NAMESPACES=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create kind cluster with containerd registry configuration</span></span><br><span class="line">kind create cluster --config <span class="string">"<span class="variable">${KIND_CONFIG:-}</span>"</span> --name <span class="string">"<span class="variable">${KIND_CLUSTER_NAME:-kind}</span>"</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
</li>
</ul>
<h3 id="版本降级目标"><a href="#版本降级目标" class="headerlink" title="版本降级目标"></a>版本降级目标</h3><ul>
<li><strong>Go版本</strong>: 1.24 → 1.23.10</li>
<li><strong>Kind版本</strong>: v0.27.0 → v0.19.0</li>
<li><strong>Kubernetes版本</strong>: v1.25.3 → v1.27.1</li>
</ul>
<h3 id="修改列表"><a href="#修改列表" class="headerlink" title="修改列表"></a>修改列表</h3><h4 id="Go"><a href="#Go" class="headerlink" title="Go"></a>Go</h4><ul>
<li><code>go.mod</code>中：<code>go 1.24</code> → <code>go 1.23.10</code>。</li>
<li><code>Makefile</code>中：<code>GO_IMAGE ?= $(IMAGE_PREFIX)docker.io/library/golang:1.24</code> → <code>GO_IMAGE ?= $(IMAGE_PREFIX)docker.io/library/golang:1.23.10</code></li>
</ul>
<h4 id="Kind"><a href="#Kind" class="headerlink" title="Kind"></a>Kind</h4><ul>
<li><code>go.mod</code>中：<code>sigs.k8s.io/kind v0.27.0</code> → <code>sigs.k8s.io/kind v0.19.0</code>。</li>
</ul>
<h4 id="节点Kubernetes："><a href="#节点Kubernetes：" class="headerlink" title="节点Kubernetes："></a>节点Kubernetes：</h4><ul>
<li><code>go.mod</code>中：修改k8s配置 <code>v0.32.1</code> → <code>v0.27.1</code><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line">k8s.io/api v0<span class="number">.27</span><span class="number">.1</span></span><br><span class="line">k8s.io/apimachinery v0<span class="number">.27</span><span class="number">.1</span></span><br><span class="line">k8s.io/apiextensions-apiserver v0<span class="number">.27</span><span class="number">.1</span> <span class="comment">// indirect</span></span><br><span class="line">k8s.io/client-<span class="keyword">go</span> v0<span class="number">.27</span><span class="number">.1</span> <span class="comment">// indirect</span></span><br><span class="line">k8s.io/component-base v0<span class="number">.27</span><span class="number">.1</span> <span class="comment">// indirect</span></span><br></pre></td></tr></table></figure></div></li>
<li>在<code>./cluster</code>目录下的<code>kueue</code>、<code>volcano</code>、<code>yunikorn</code>、<code>overview</code>四个目录中修改<code>kind.yaml</code>文件：<code>docker.io/kindest/node:v1.32.2</code> → <code>docker.io/kindest/node:v1.27.1</code>；</li>
</ul>
<h4 id="go-sum-版本管理文件-3"><a href="#go-sum-版本管理文件-3" class="headerlink" title="go.sum 版本管理文件[3]"></a>go.sum 版本管理文件<a href="#refer-anchor-1"><sup>[3]</sup></a></h4><ul>
<li>修改<code>go.mod</code>后，需要删除<code>go.sum</code>并执行<code>go mod tidy</code>以重新生成<code>go.sum</code>以匹配新的依赖版本。</li>
<li>必要时开启CDN镜像加速<code>export GOPROXY=https://mirrors.aliyun.com/goproxy/,direct</code>。</li>
<li>如果一直出现奇怪的错误，例如<code>go: github.com/wzshiming/kube-scheduling-perf/gopath/pkg/mod/github.com/pkg/errors@v0.9.1: import path "github.com/wzshiming/kube-scheduling-perf/gopath/pkg/mod/github.com/pkg/errors@v0.9.1" should not have @version</code>，可能是因为已安装的旧版本未删除，应该删除旧的 gopath 并重新构建，以确保参数生效：  <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">rm</span> -rf gopath</span><br><span class="line"> make</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h4 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h4><ul>
<li>之后<code>./hack/local-registry-with-load-images.sh</code>会自动提前拉取镜像。</li>
<li>注意：如果你是通过 Makefile 自动构建 bin/kind，请务必删除旧的 bin/kind 并重新构建，以确保新参数生效：  <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">rm</span> -f bin/kind</span><br><span class="line">   make bin/kind</span><br></pre></td></tr></table></figure></div></li>
<li>注意：同理，如果修改版本前已经下载了相关go包，也应该删除旧的 gopath 并重新构建，以确保参数生效：  <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">rm</span> -rf gopath</span><br><span class="line">make</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h2 id="注意3：Go-版本兼容性问题"><a href="#注意3：Go-版本兼容性问题" class="headerlink" title="注意3：Go 版本兼容性问题"></a>注意3：Go 版本兼容性问题</h2><h3 id="问题说明-1"><a href="#问题说明-1" class="headerlink" title="问题说明"></a>问题说明</h3><p>降级 Go 版本后，测试代码中出现编译错误：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">test/yunikorn/batch_job_test.go:10:29: t.Context undefined (type *"testing".T has no field or method Context, but does have unexported field context)</span><br></pre></td></tr></table></figure></div>

<h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><p><code>t.Context()</code> 方法在 Go 1.23.10 中可能不被完全支持或存在兼容性问题，导致测试代码无法编译。</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>将所有测试文件中的 <code>t.Context()</code> 替换为 <code>context.Background()</code>。</p>
<h4 id="修改文件"><a href="#修改文件" class="headerlink" title="修改文件"></a>修改文件</h4><p><strong>1. test/yunikorn/batch_job_test.go</strong></p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 修改前</span></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">"testing"</span></span><br><span class="line">	<span class="string">"github.com/wzshiming/kube-scheduling-perf/test/utils"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestInit</span><span class="params">(t *testing.T)</span></span> {</span><br><span class="line">	err := provider.AddNodes(t.Context())</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 修改后</span></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">"context"</span></span><br><span class="line">	<span class="string">"testing"</span></span><br><span class="line">	<span class="string">"github.com/wzshiming/kube-scheduling-perf/test/utils"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestInit</span><span class="params">(t *testing.T)</span></span> {</span><br><span class="line">	err := provider.AddNodes(context.Background())</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>2. test/volcano/batch_job_test.go</strong></p>
<ul>
<li>同样添加 <code>"context"</code> 导入</li>
<li>将所有 <code>t.Context()</code> 替换为 <code>context.Background()</code></li>
</ul>
<p><strong>3. test/kueue/batch_job_test.go</strong></p>
<ul>
<li>同样添加 <code>"context"</code> 导入</li>
<li>将所有 <code>t.Context()</code> 替换为 <code>context.Background()</code></li>
</ul>
<h2 id="注意4：Docker-容器权限问题"><a href="#注意4：Docker-容器权限问题" class="headerlink" title="注意4：Docker 容器权限问题"></a>注意4：Docker 容器权限问题</h2><h3 id="问题说明-2"><a href="#问题说明-2" class="headerlink" title="问题说明"></a>问题说明</h3><p>执行 <code>make</code> 命令时出现权限错误：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">mv: 无法将"./logs" 移动至"./tmp/logs": 权限不够</span><br></pre></td></tr></table></figure></div>

<p>检查发现多个目录（<code>./logs</code>、<code>./bin</code>、<code>./gopath</code>、<code>./registry-data</code>）的归属者是 <code>root</code>，而不是当前用户（当使用非 root 用户时）。</p>
<h3 id="原因分析-1"><a href="#原因分析-1" class="headerlink" title="原因分析"></a>原因分析</h3><p>Makefile 中的 <code>GO_IN_DOCKER</code> 命令使用 Docker 容器执行，容器内进程默认以 root 用户运行，导致创建的文件/目录归属 root。</p>
<h3 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="1-修改-Makefile，让容器以当前用户身份运行"><a href="#1-修改-Makefile，让容器以当前用户身份运行" class="headerlink" title="1. 修改 Makefile，让容器以当前用户身份运行"></a>1. 修改 Makefile，让容器以当前用户身份运行</h4><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改前</span></span><br><span class="line">GO_IN_DOCKER = docker run --rm --network host \</span><br><span class="line">	-v <span class="variable">$(<span class="built_in">shell</span> pwd)</span>:/workspace/ -w /workspace/ \</span><br><span class="line">	-e GOOS=<span class="variable">$(GOOS)</span> -e CGO_ENABLED=0 -e GOPATH=/workspace/gopath/ -e GOPROXY=<span class="variable">$(GOPROXY)</span> <span class="variable">$(GO_IMAGE)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改后</span></span><br><span class="line">GO_IN_DOCKER = docker run --rm --network host \</span><br><span class="line">	-u <span class="variable">$(<span class="built_in">shell</span> id -u)</span>:<span class="variable">$(<span class="built_in">shell</span> id -g)</span> \</span><br><span class="line">	-v <span class="variable">$(<span class="built_in">shell</span> pwd)</span>:/workspace/ -w /workspace/ \</span><br><span class="line">	-e GOOS=<span class="variable">$(GOOS)</span> -e CGO_ENABLED=0 -e GOPATH=/workspace/gopath/ -e GOPROXY=<span class="variable">$(GOPROXY)</span> <span class="variable">$(GO_IMAGE)</span></span><br></pre></td></tr></table></figure></div>

<h4 id="2-创建目录权限修复脚本"><a href="#2-创建目录权限修复脚本" class="headerlink" title="2. 创建目录权限修复脚本"></a>2. 创建目录权限修复脚本</h4><p><strong>hack/ensure-directories.sh</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"><span class="built_in">set</span> -o errexit</span><br><span class="line"><span class="built_in">set</span> -o nounset</span><br><span class="line"><span class="built_in">set</span> -o pipefail</span><br><span class="line"></span><br><span class="line">DIR=<span class="string">"<span class="subst">$(dirname <span class="string">"<span class="variable">${BASH_SOURCE[0]}</span>"</span>)</span>"</span></span><br><span class="line">ROOT_DIR=<span class="string">"<span class="subst">$(realpath <span class="string">"<span class="variable">${DIR}</span>/.."</span>)</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Function to ensure directory has correct ownership</span></span><br><span class="line"><span class="function"><span class="title">ensure_directory</span></span>() {</span><br><span class="line">    <span class="built_in">local</span> <span class="built_in">dir</span>=<span class="string">"<span class="variable">$1</span>"</span></span><br><span class="line">    <span class="built_in">local</span> owner=$(<span class="built_in">stat</span> -c <span class="string">'%U'</span> <span class="string">"<span class="variable">$dir</span>"</span> 2&gt;/dev/null || <span class="built_in">echo</span> <span class="string">"none"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> [[ <span class="string">"<span class="variable">$owner</span>"</span> == <span class="string">"root"</span> ]]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Removing root-owned directory: <span class="variable">$dir</span>"</span></span><br><span class="line">        <span class="built_in">sudo</span> <span class="built_in">rm</span> -rf <span class="string">"<span class="variable">$dir</span>"</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">mkdir</span> -p <span class="string">"<span class="variable">$dir</span>"</span></span><br><span class="line">    <span class="built_in">chmod</span> 755 <span class="string">"<span class="variable">$dir</span>"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"Created/updated directory: <span class="variable">$dir</span>"</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create all necessary directories</span></span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> logs bin gopath registry-data output results tmp; <span class="keyword">do</span></span><br><span class="line">    ensure_directory <span class="string">"<span class="variable">${ROOT_DIR}</span>/<span class="variable">${d}</span>"</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></div>

<h4 id="3-在-Makefile-中集成权限修复"><a href="#3-在-Makefile-中集成权限修复" class="headerlink" title="3. 在 Makefile 中集成权限修复"></a>3. 在 Makefile 中集成权限修复</h4><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: ensure-directories</span></span><br><span class="line"><span class="section">ensure-directories:</span></span><br><span class="line">	./hack/ensure-directories.sh</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: default</span></span><br><span class="line"><span class="section">default: ensure-directories</span></span><br><span class="line">	<span class="comment"># ... existing content ...</span></span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: serial-test</span></span><br><span class="line"><span class="section">serial-test: ensure-directories bin/kind</span></span><br><span class="line">	<span class="comment"># ... existing content ...</span></span><br></pre></td></tr></table></figure></div>

<h4 id="4-修改镜像处理脚本"><a href="#4-修改镜像处理脚本" class="headerlink" title="4. 修改镜像处理脚本"></a>4. 修改镜像处理脚本</h4><p>在 <code>hack/local-registry-with-load-images.sh</code> 中确保 registry-data 目录正确创建：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Ensure registry-data directory exists with correct permissions</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="string">"<span class="variable">${ROOT_DIR}</span>/registry-data"</span></span><br></pre></td></tr></table></figure></div>

<h3 id="验证方法"><a href="#验证方法" class="headerlink" title="验证方法"></a>验证方法</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 运行权限修复脚本</span></span><br><span class="line">./hack/ensure-directories.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查目录权限</span></span><br><span class="line"><span class="built_in">ls</span> -la | grep -E <span class="string">"(logs|bin|gopath|registry-data)"</span></span><br></pre></td></tr></table></figure></div>

<h2 id="注意5：Go-构建缓存权限问题"><a href="#注意5：Go-构建缓存权限问题" class="headerlink" title="注意5：Go 构建缓存权限问题"></a>注意5：Go 构建缓存权限问题</h2><h3 id="问题说明-3"><a href="#问题说明-3" class="headerlink" title="问题说明"></a>问题说明</h3><p>在执行 <code>make</code> 命令时出现 Go 构建缓存权限错误：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">failed to initialize build cache at /.cache/go-build: mkdir /.cache: permission denied</span><br></pre></td></tr></table></figure></div>

<h3 id="原因分析-2"><a href="#原因分析-2" class="headerlink" title="原因分析"></a>原因分析</h3><ol>
<li><strong>Docker 容器用户权限</strong>：当使用 <code>-u $(shell id -u):$(shell id -g)</code> 让容器以当前用户身份运行时，容器内的 <code>$HOME</code> 变量变为 <code>/</code>（因为没有为普通用户设置 home 目录）</li>
<li><strong>Go 默认行为</strong>：Go 在没有明确设置 <code>GOCACHE</code> 环境变量时，会尝试在 <code>$HOME/.cache/go-build</code> 或 <code>/.cache/go-build</code> 下创建构建缓存</li>
<li><strong>权限冲突</strong>：普通用户没有权限在容器根目录 <code>/</code> 下创建 <code>.cache</code> 目录，导致权限被拒绝</li>
</ol>
<h3 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="1-设置-Go-构建缓存目录"><a href="#1-设置-Go-构建缓存目录" class="headerlink" title="1. 设置 Go 构建缓存目录"></a>1. 设置 Go 构建缓存目录</h4><p>在 Makefile 的 <code>GO_IN_DOCKER</code> 命令中添加 <code>GOCACHE</code> 环境变量：</p>
<div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改前</span></span><br><span class="line">GO_IN_DOCKER = docker run --rm --network host \</span><br><span class="line">	-u <span class="variable">$(<span class="built_in">shell</span> id -u)</span>:<span class="variable">$(<span class="built_in">shell</span> id -g)</span> \</span><br><span class="line">	-v <span class="variable">$(<span class="built_in">shell</span> pwd)</span>:/workspace/ -w /workspace/ \</span><br><span class="line">	-e GOOS=<span class="variable">$(GOOS)</span> -e CGO_ENABLED=0 -e GOPATH=/workspace/gopath/ -e GOPROXY=<span class="variable">$(GOPROXY)</span> <span class="variable">$(GO_IMAGE)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改后</span></span><br><span class="line">GO_IN_DOCKER = docker run --rm --network host \</span><br><span class="line">	-u <span class="variable">$(<span class="built_in">shell</span> id -u)</span>:<span class="variable">$(<span class="built_in">shell</span> id -g)</span> \</span><br><span class="line">	-v <span class="variable">$(<span class="built_in">shell</span> pwd)</span>:/workspace/ -w /workspace/ \</span><br><span class="line">	-e GOOS=<span class="variable">$(GOOS)</span> -e CGO_ENABLED=0 -e GOPATH=/workspace/gopath/ -e GOPROXY=<span class="variable">$(GOPROXY)</span> -e GOCACHE=/workspace/.cache <span class="variable">$(GO_IMAGE)</span></span><br></pre></td></tr></table></figure></div>

<h4 id="2-设计原理"><a href="#2-设计原理" class="headerlink" title="2. 设计原理"></a>2. 设计原理</h4><ul>
<li><strong>权限一致性</strong>：通过设置 <code>GOCACHE=/workspace/.cache</code>，确保 Go 构建缓存在挂载的工作目录下创建，当前用户有完全权限</li>
<li><strong>兼容性</strong>：这个修改不会影响其他构建逻辑，只是改变了缓存存储位置</li>
<li><strong>最佳实践</strong>：这是使用非 root 用户运行 Docker 容器时的标准做法</li>
</ul>
<h3 id="验证方法-1"><a href="#验证方法-1" class="headerlink" title="验证方法"></a>验证方法</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 测试 Go 构建是否正常</span></span><br><span class="line">make bin/test-kueue</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查缓存目录是否创建</span></span><br><span class="line"><span class="built_in">ls</span> -la .cache/</span><br></pre></td></tr></table></figure></div>

<h3 id="预期效果"><a href="#预期效果" class="headerlink" title="预期效果"></a>预期效果</h3><p>修改后：</p>
<ol>
<li>Go 构建缓存会在项目根目录的 <code>.cache</code> 文件夹下创建</li>
<li>缓存目录属于当前用户，权限正确</li>
<li>不再出现 <code>permission denied</code> 错误</li>
<li>构建过程正常进行</li>
</ol>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul>
<li>这个问题<strong>只有在使用 <code>-u</code> 参数让容器以非 root 用户运行时才会出现</strong></li>
<li>如果使用默认的 root 用户运行容器，不会有此问题，但会导致生成的文件归 root 所有</li>
<li>设置 <code>GOCACHE</code> 是使用非 root 用户运行 Go 容器的标准做法</li>
</ul>
<h2 id="注意6：Kueue-Webhook-连接问题"><a href="#注意6：Kueue-Webhook-连接问题" class="headerlink" title="注意6：Kueue Webhook 连接问题"></a>注意6：Kueue Webhook 连接问题</h2><h3 id="问题说明-4"><a href="#问题说明-4" class="headerlink" title="问题说明"></a>问题说明</h3><p>在执行 Kueue 测试时，经常出现 webhook 连接被拒绝的错误：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">Internal error occurred: failed calling webhook "mresourceflavor.kb.io": failed to call webhook: </span><br><span class="line">Post "https://kueue-webhook-service.kueue-system.svc:443/mutate-kueue-x-k8s-io-v1beta1-resourceflavor?timeout=10s": </span><br><span class="line">dial tcp 10.96.33.70:443: connect: connection refused</span><br></pre></td></tr></table></figure></div>

<h3 id="原因分析-3"><a href="#原因分析-3" class="headerlink" title="原因分析"></a>原因分析</h3><ol>
<li><strong>Webhook 服务未就绪</strong>：Kueue 的 webhook 服务在部署后需要时间启动和初始化</li>
<li><strong>证书生成延迟</strong>：webhook 服务器需要生成 TLS 证书，这个过程可能需要几秒钟</li>
<li><strong>服务端点未配置</strong>：webhook 服务的端点（endpoints）可能还未正确配置</li>
<li><strong>缺少等待机制</strong>：原有的部署流程没有等待 webhook 服务完全就绪</li>
</ol>
<h3 id="解决方案-3"><a href="#解决方案-3" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="1-创建-Webhook-等待脚本"><a href="#1-创建-Webhook-等待脚本" class="headerlink" title="1. 创建 Webhook 等待脚本"></a>1. 创建 Webhook 等待脚本</h4><p><strong>hack/wait-for-webhook.sh</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"><span class="built_in">set</span> -o errexit</span><br><span class="line"><span class="built_in">set</span> -o nounset</span><br><span class="line"><span class="built_in">set</span> -o pipefail</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取脚本参数</span></span><br><span class="line">SCHEDULER_NAME=<span class="string">"<span class="variable">${1:-}</span>"</span></span><br><span class="line"><span class="keyword">if</span> [[ -z <span class="string">"<span class="variable">$SCHEDULER_NAME</span>"</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"Usage: <span class="variable">$0</span> &lt;scheduler-name&gt;"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"Example: <span class="variable">$0</span> kueue"</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置变量</span></span><br><span class="line">KUBECONFIG=<span class="string">"<span class="variable">${KUBECONFIG:-./kubeconfig.yaml}</span>"</span></span><br><span class="line">NAMESPACE=<span class="string">"<span class="variable">${SCHEDULER_NAME}</span>-system"</span></span><br><span class="line">WEBHOOK_SERVICE=<span class="string">"<span class="variable">${SCHEDULER_NAME}</span>-webhook-service"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"等待 <span class="variable">${SCHEDULER_NAME}</span> webhook 服务就绪..."</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 等待 webhook 证书生成</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"检查 webhook 证书..."</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> $(<span class="built_in">seq</span> 1 30); <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> kubectl --kubeconfig=<span class="string">"<span class="variable">$KUBECONFIG</span>"</span> get secret -n <span class="string">"<span class="variable">$NAMESPACE</span>"</span> <span class="string">"<span class="variable">${SCHEDULER_NAME}</span>-webhook-server-cert"</span> &gt;/dev/null 2&gt;&amp;1; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"✓ Webhook 证书已生成"</span></span><br><span class="line">        <span class="built_in">break</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> [[ <span class="variable">$i</span> -eq 30 ]]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"✗ 等待 webhook 证书超时"</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">sleep</span> 2</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 等待 webhook Pod 就绪</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"等待 webhook Pod 就绪..."</span></span><br><span class="line">kubectl --kubeconfig=<span class="string">"<span class="variable">$KUBECONFIG</span>"</span> <span class="built_in">wait</span> --<span class="keyword">for</span>=condition=ready pod -l control-plane=controller-manager -n <span class="string">"<span class="variable">$NAMESPACE</span>"</span> --<span class="built_in">timeout</span>=120s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等待 webhook 服务端点就绪</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"等待 webhook 服务端点..."</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> $(<span class="built_in">seq</span> 1 30); <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> kubectl --kubeconfig=<span class="string">"<span class="variable">$KUBECONFIG</span>"</span> get endpoints -n <span class="string">"<span class="variable">$NAMESPACE</span>"</span> <span class="string">"<span class="variable">$WEBHOOK_SERVICE</span>"</span> -o jsonpath=<span class="string">'{.subsets[0].addresses}'</span> | grep -q .; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"✓ Webhook 服务端点已就绪"</span></span><br><span class="line">        <span class="built_in">break</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> [[ <span class="variable">$i</span> -eq 30 ]]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"✗ 等待 webhook 服务端点超时"</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">sleep</span> 2</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"✓ <span class="variable">${SCHEDULER_NAME}</span> webhook 服务已完全就绪"</span></span><br></pre></td></tr></table></figure></div>

<h4 id="2-修改-Kueue-部署流程"><a href="#2-修改-Kueue-部署流程" class="headerlink" title="2. 修改 Kueue 部署流程"></a>2. 修改 Kueue 部署流程</h4><p>在 <code>clusters/kueue/Makefile</code> 中的 <code>create-kueue</code> 目标中添加 webhook 等待：</p>
<div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: create-kueue</span></span><br><span class="line"><span class="section">create-kueue:</span></span><br><span class="line">	KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl kustomize ../../schedulers/kueue | ../../hack/local-registry-with-load-images.sh</span><br><span class="line">	KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl create -k ../../schedulers/kueue</span><br><span class="line">	KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl patch deploy -n kueue-system kueue-controller-manager --type json \</span><br><span class="line">		-p '[{<span class="string">"op"</span>: <span class="string">"replace"</span>, <span class="string">"path"</span>: <span class="string">"/spec/template/spec/containers/0/resources"</span>, <span class="string">"value"</span>: {<span class="string">"requests"</span>:{<span class="string">"cpu"</span>: <span class="string">"500m"</span>}, <span class="string">"limits"</span>:{<span class="string">"cpu"</span>: <span class="variable">$(LIMIT_CPU)</span>}}}, {<span class="string">"op"</span>: <span class="string">"replace"</span>, <span class="string">"path"</span>: <span class="string">"/spec/template/spec/containers/1/resources"</span>, <span class="string">"value"</span>: {<span class="string">"requests"</span>:{<span class="string">"cpu"</span>: <span class="string">"500m"</span>}, <span class="string">"limits"</span>:{<span class="string">"cpu"</span>: <span class="variable">$(LIMIT_CPU)</span>}}}]'</span><br><span class="line">	sleep 1</span><br><span class="line">	KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> ../../hack/wait-for-webhook.sh kueue</span><br></pre></td></tr></table></figure></div>

<h4 id="3-设计原理"><a href="#3-设计原理" class="headerlink" title="3. 设计原理"></a>3. 设计原理</h4><p>参考 Makefile 中现有的 <code>wait</code> 目标设计：</p>
<div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: wait</span></span><br><span class="line"><span class="section">wait:</span></span><br><span class="line">	-for i in $<span class="variable">$(seq 1 60)</span>; do \</span><br><span class="line">		KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl wait -A \</span><br><span class="line">			--for=condition=Ready=True pod \</span><br><span class="line">			--all \</span><br><span class="line">			--timeout=100s &gt;/dev/null 2&gt;&amp;1 &amp;&amp; break; \</span><br><span class="line">	done</span><br><span class="line">	sleep 1</span><br></pre></td></tr></table></figure></div>

<p>webhook 等待脚本采用相同的设计模式：</p>
<ul>
<li><strong>循环检查</strong>：使用 for 循环定期检查状态</li>
<li><strong>超时机制</strong>：设置合理的超时时间避免无限等待</li>
<li><strong>详细日志</strong>：提供清晰的进度信息</li>
<li><strong>错误处理</strong>：在超时或失败时提供明确的错误信息</li>
</ul>
<h3 id="验证方法-2"><a href="#验证方法-2" class="headerlink" title="验证方法"></a>验证方法</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 手动测试 webhook 等待脚本</span></span><br><span class="line"><span class="built_in">cd</span> clusters/kueue</span><br><span class="line">KUBECONFIG=./kubeconfig.yaml ../../hack/wait-for-webhook.sh kueue</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查 webhook 服务状态</span></span><br><span class="line">kubectl get pods -n kueue-system -l control-plane=controller-manager</span><br><span class="line">kubectl get service kueue-webhook-service -n kueue-system</span><br><span class="line">kubectl get endpoints kueue-webhook-service -n kueue-system</span><br></pre></td></tr></table></figure></div>

<h3 id="预期效果-1"><a href="#预期效果-1" class="headerlink" title="预期效果"></a>预期效果</h3><p>修改后，每次执行 <code>make prepare-kueue</code> 时：</p>
<ol>
<li>Kueue 集群正常启动</li>
<li>Webhook 服务自动部署</li>
<li>脚本等待 webhook 完全就绪</li>
<li>测试可以正常进行，不再出现连接拒绝错误</li>
</ol>
<h2 id="注意7：目录结构说明"><a href="#注意7：目录结构说明" class="headerlink" title="注意7：目录结构说明"></a>注意7：目录结构说明</h2><h3 id="核心目录"><a href="#核心目录" class="headerlink" title="核心目录"></a>核心目录</h3><ul>
<li><p><strong>hack/</strong>: 存放辅助脚本，如权限修复、镜像处理、结果保存等</p>
<ul>
<li><code>ensure-directories.sh</code>: 确保目录权限正确</li>
<li><code>local-registry-with-load-images.sh</code>: 处理镜像拉取和本地仓库</li>
<li><code>save-result-images.sh</code>: 保存测试结果和监控图表</li>
<li><code>kind-with-local-registry.sh</code>: 创建带本地仓库的 kind 集群</li>
</ul>
</li>
<li><p><strong>clusters/</strong>: 各调度器的集群配置和生命周期管理</p>
<ul>
<li><code>kueue/</code>: Kueue 调度器集群配置</li>
<li><code>volcano/</code>: Volcano 调度器集群配置  </li>
<li><code>yunikorn/</code>: YuniKorn 调度器集群配置</li>
<li><code>overview/</code>: 监控集群配置（Prometheus + Grafana）</li>
</ul>
</li>
<li><p><strong>test/</strong>: 测试代码和测试用例</p>
<ul>
<li><code>utils/</code>: 通用测试工具和辅助函数</li>
<li><code>kueue/</code>: Kueue 调度器测试代码</li>
<li><code>volcano/</code>: Volcano 调度器测试代码</li>
<li><code>yunikorn/</code>: YuniKorn 调度器测试代码</li>
</ul>
</li>
</ul>
<h3 id="生成目录"><a href="#生成目录" class="headerlink" title="生成目录"></a>生成目录</h3><ul>
<li><strong>bin/</strong>: 自动生成的二进制文件<ul>
<li><code>kind</code>: 用于创建 Kubernetes 集群的工具</li>
<li><code>test-kueue</code>: Kueue 测试可执行文件</li>
<li><code>test-volcano</code>: Volcano 测试可执行文件</li>
<li><code>test-yunikorn</code>: YuniKorn 测试可执行文件</li>
</ul>
</li>
<li><strong>gopath/</strong>: Go 模块缓存和依赖<ul>
<li><code>pkg/mod/</code>: Go 模块缓存</li>
<li><code>src/</code>: 源代码（如果使用 GOPATH 模式）</li>
</ul>
</li>
</ul>
<h3 id="数据目录"><a href="#数据目录" class="headerlink" title="数据目录"></a>数据目录</h3><ul>
<li><strong>logs/</strong>: 审计日志和测试日志<ul>
<li><code>kube-apiserver-audit.*.log</code>: Kubernetes API 服务器审计日志</li>
<li>其他测试过程中生成的日志文件</li>
</ul>
</li>
<li><strong>registry-data/</strong>: 本地 Docker 仓库数据<ul>
<li>存储从远程仓库拉取的镜像</li>
<li>供 kind 集群使用的本地镜像仓库</li>
</ul>
</li>
<li><strong>output/</strong>: 测试输出和监控数据<ul>
<li><code>panel-*.png</code>: Grafana 监控图表</li>
<li>其他测试输出文件</li>
</ul>
</li>
<li><strong>results/</strong>: 测试结果归档<ul>
<li>按时间戳组织的测试结果目录</li>
<li>包含环境变量、日志、输出等完整信息</li>
</ul>
</li>
<li><strong>tmp/</strong>: 临时文件目录<ul>
<li>测试过程中的临时文件</li>
<li>结果归档前的临时存储</li>
</ul>
</li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://learnku.com/go/wikis/38122">[2] Go 国内加速镜像<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://cloud.tencent.com/developer/article/2020911">[3] 深入理解 Go Modules 的 go.mod 与 go.sum<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度器</tag>
        <tag>K8s</tag>
        <tag>性能测试</tag>
        <tag>Volcano</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：本地环境测试结果与视频对比分析</title>
    <url>/2025/07/23/k8s/k8s-scheduler-performance-test-local/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li>
<li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li>
<li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li>
<li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a>
</li>
</ol>
</blockquote>
<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="上一篇博客">上一篇博客</a>中，我们详细介绍了 <code>kube-scheduling-perf</code> 项目的自动化测试框架。本文记录了笔者在本地环境中实际运行该测试工具的过程，并将测试结果与 <a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="KubeCon 技术分享">KubeCon 技术分享</a> 中的视频结果进行对比分析。</p>
<p>通过对比发现，虽然整体趋势基本一致，但在某些测试场景下存在显著差异，这些差异主要源于硬件配置、软件版本等因素的影响。本文分析了这些差异的原因，为读者在实际部署和测试时提供参考。</p>
<h1 id="🖼️测试环境配置"><a href="#🖼️测试环境配置" class="headerlink" title="🖼️测试环境配置"></a>🖼️测试环境配置</h1><h2 id="硬件配置"><a href="#硬件配置" class="headerlink" title="硬件配置"></a>硬件配置</h2><p>应 <a class="link" href="https://github.com/hwdef">@hwdef<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 建议，想办法更换了系统和实验环境，避免了前期<a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="实践篇博客">实践篇博客</a>遇到的大量因为内核版本导致的问题，也避免用低版本系统测出不准确数据导致对性能测试和优化的影响。<br>顺便一提，在实践中遇到的与内核版本无关的通用性问题也已提交<a class="link" href="https://github.com/wzshiming/kube-scheduling-perf/pull/17">PR<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>到kube-scheduling-perf仓库～</p>
<table>
<thead>
<tr>
<th>配置项</th>
<th>规格</th>
</tr>
</thead>
<tbody><tr>
<td><strong>操作系统</strong></td>
<td>Ubuntu Linux 5.15.0-143-generic</td>
</tr>
<tr>
<td><strong>CPU</strong></td>
<td>Intel Xeon Gold 6230 @ 2.10GHz, 8核</td>
</tr>
<tr>
<td><strong>内存</strong></td>
<td>15GB (可用13GB)</td>
</tr>
<tr>
<td><strong>存储</strong></td>
<td>79GB (可用21GB)</td>
</tr>
</tbody></table>
<h2 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本"></a>软件版本</h2><table>
<thead>
<tr>
<th>软件</th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Docker</strong></td>
<td>27.5.1</td>
</tr>
<tr>
<td><strong>Kubernetes</strong></td>
<td>1.32.2 (Kind集群)</td>
</tr>
<tr>
<td><strong>kubectl</strong></td>
<td>v1.33.2</td>
</tr>
<tr>
<td><strong>Go</strong></td>
<td>1.24 (Docker容器)</td>
</tr>
</tbody></table>
<h2 id="存储需求"><a href="#存储需求" class="headerlink" title="存储需求"></a>存储需求</h2><table>
<thead>
<tr>
<th>项目</th>
<th>大小</th>
</tr>
</thead>
<tbody><tr>
<td><strong>当前结果目录</strong></td>
<td>15GB</td>
</tr>
<tr>
<td><strong>单个测试结果</strong></td>
<td>1.3GB - 2.7GB（主要占空间的是日志文件）</td>
</tr>
<tr>
<td><strong>建议预留空间</strong></td>
<td>50GB+</td>
</tr>
</tbody></table>
<h1 id="🧠测试结果对比分析"><a href="#🧠测试结果对比分析" class="headerlink" title="🧠测试结果对比分析"></a>🧠测试结果对比分析</h1><h2 id="第一种-Benchmark：10K-Jobs-×-1-Pod"><a href="#第一种-Benchmark：10K-Jobs-×-1-Pod" class="headerlink" title="第一种 Benchmark：10K Jobs × 1 Pod"></a>第一种 Benchmark：10K Jobs × 1 Pod</h2><p><strong>测试参数</strong>：每个Job只有1个Pod，共10K个Job，共10kPod</p>
<h3 id="预期结果（基于视频）"><a href="#预期结果（基于视频）" class="headerlink" title="预期结果（基于视频）"></a>预期结果（基于视频）</h3><ul>
<li>YuniKorn吞吐量比另外两种调度器更高，主要是因为 Kueue 和 Volcano 的 Job 受 K8s Webhook QPS限制</li>
<li>CREATED和SCHEDULED事件之间的差距很小，说明没有调度阶段不为瓶颈、没有排队，此时性能瓶颈为创建阶段</li>
</ul>
<h3 id="实际结果"><a href="#实际结果" class="headerlink" title="实际结果"></a>实际结果</h3><ul>
<li><strong>符合预期</strong>：如下图所示，YuniKorn的吞吐量确实高于其他两种调度器</li>
<li><strong>瓶颈分析</strong>：CREATED和SCHEDULED事件紧密跟随，说明调度阶段不是瓶颈，性能瓶颈确实在创建阶段</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/0-raw/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="图1：本地测试，无GangScheduling要求下，第一种benchmark测试结果"><figcaption>图1：本地测试，无GangScheduling要求下，第一种benchmark测试结果</figcaption></figure></p>
<h2 id="第二种-Benchmark：500-Jobs-×-20-Pods"><a href="#第二种-Benchmark：500-Jobs-×-20-Pods" class="headerlink" title="第二种 Benchmark：500 Jobs × 20 Pods"></a>第二种 Benchmark：500 Jobs × 20 Pods</h2><p><strong>测试参数</strong>：每个Job有20个Pod，共500个Job，共10kPod</p>
<h3 id="预期结果（基于视频）-1"><a href="#预期结果（基于视频）-1" class="headerlink" title="预期结果（基于视频）"></a>预期结果（基于视频）</h3><ul>
<li>Volcano的调度速度慢于另外两种调度器</li>
<li>SCHEDULED明显滞后于CREATED，说明调度速度较慢，此时性能瓶颈为调度（且根据斜率，前期调度速度快、后期逐渐变慢）</li>
<li>CREATED阶段性突变现象（正常情况下CREATED应该匀速增加，这里的现象说明controller会间歇性卡住一会儿）</li>
</ul>
<h3 id="实际结果-1"><a href="#实际结果-1" class="headerlink" title="实际结果"></a>实际结果</h3><ul>
<li><strong>部分符合预期</strong>：Volcano的调度速度确实慢于其他调度器</li>
<li><strong>差异点</strong>：CREATED没有成为瓶颈，始终比SCHEDULED的速度更快，与视频中的预期不符</li>
<li><strong>可能原因</strong>：本地环境的硬件资源限制或软件版本差异影响了测试结果</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/0-raw/b.NoGang-500Job/output/panel-5.png?raw=true" alt="图2：本地测试，无GangScheduling要求下，第二种benchmark测试结果"><figcaption>图2：本地测试，无GangScheduling要求下，第二种benchmark测试结果</figcaption></figure></p>
<h3 id="进一步测试结果"><a href="#进一步测试结果" class="headerlink" title="进一步测试结果"></a>进一步测试结果</h3><p>在 <a class="link" href="https://github.com/hwdef">@hwdef<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 支持下，在 <code>24核 CPU，96 GB 内存</code> 环境下开展测试，发现：是硬件资源限制影响了测试结果。</p>
<ul>
<li><strong>部分符合预期</strong>：Volcano的调度速度确实慢于其他调度器，且 CREATED 成为了瓶颈，确定是硬件资源限制影响了测试结果。</li>
<li><strong>差异点</strong>：资源丰富后，CREATED瓶颈效应存在，但反而由于资源过多，导致瓶颈效应不明显，与视频中的预期有所差异。</li>
<li><strong>其他问题</strong>：缺少 kueue 数据，需要重复测试（确保镜像被正确拉取）或延长 timeout 时间。</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/0-raw/b.NoGang-500Job/output/panel-5-hwdef.png?raw=true" alt="图3：高资源量环境下测试，无GangScheduling要求下，第二种benchmark测试结果"><figcaption>图3：高资源量环境下测试，无GangScheduling要求下，第二种benchmark测试结果</figcaption></figure></p>
<h2 id="第三种-Benchmark：20-Jobs-×-500-Pods"><a href="#第三种-Benchmark：20-Jobs-×-500-Pods" class="headerlink" title="第三种 Benchmark：20 Jobs × 500 Pods"></a>第三种 Benchmark：20 Jobs × 500 Pods</h2><p><strong>测试参数</strong>：每个Job有500Pod，共20个Job，共10kPod</p>
<h3 id="预期结果（基于视频）-2"><a href="#预期结果（基于视频）-2" class="headerlink" title="预期结果（基于视频）"></a>预期结果（基于视频）</h3><ul>
<li>Volcano的调度速度仍然慢于另外两种调度器</li>
<li>SCHEDULED仍然明显滞后于CREATED，说明调度速度较慢，此时性能瓶颈为调度（且根据斜率，前期调度速度比第二种benchmark下更慢、后期逐渐加速）</li>
<li>不存在CREATED阶段性突变现象</li>
</ul>
<h3 id="实际结果-2"><a href="#实际结果-2" class="headerlink" title="实际结果"></a>实际结果</h3><ul>
<li><strong>与预期不符</strong>：反而更接近第二种benchmark的预期，前期CREATED和SCHEDULED线紧贴、后期CREATED出现阶段性突变。但至少验证了 CREATED 确实会成为瓶颈。</li>
<li><strong>可能原因</strong>：<ul>
<li>可能是CREATED成为瓶颈，导致SCHEDULED速度被严重限制</li>
<li>可能是SCHEDULED本来就很慢，反过来导致CREATED没必要提前创建（可能新版本下有其他机制做出该决策）</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/0-raw/c.NoGang-20Job/output/panel-5.png?raw=true" alt="图4：本地测试，无GangScheduling要求下，第三种benchmark测试结果"><figcaption>图4：本地测试，无GangScheduling要求下，第三种benchmark测试结果</figcaption></figure></p>
<h3 id="进一步测试结果-1"><a href="#进一步测试结果-1" class="headerlink" title="进一步测试结果"></a>进一步测试结果</h3><p>在 <a class="link" href="https://github.com/hwdef">@hwdef<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 支持下，在 <code>24核 CPU，96 GB 内存</code> 环境下开展测试，发现：不是硬件资源限制问题。</p>
<ul>
<li>与原环境下结果类似，证明即使提供更多硬件资源也仍然存在该问题。</li>
<li>验证了 CREATED 确实会成为瓶颈，同时可能有 SCHEDULED 对 CREATED 的反向限制。</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/0-raw/c.NoGang-20Job/output/panel-5-hwdef.png?raw=true" alt="图5：高资源量环境下测试，无GangScheduling要求下，第三种benchmark测试结果"><figcaption>图5：高资源量环境下测试，无GangScheduling要求下，第三种benchmark测试结果</figcaption></figure></p>
<h2 id="第四种-Benchmark：1-Job-×-10K-Pods"><a href="#第四种-Benchmark：1-Job-×-10K-Pods" class="headerlink" title="第四种 Benchmark：1 Job × 10K Pods"></a>第四种 Benchmark：1 Job × 10K Pods</h2><p><strong>测试参数</strong>：每个Job有10kPod，共1个Job，共10kPod</p>
<h3 id="预期结果（基于视频）-3"><a href="#预期结果（基于视频）-3" class="headerlink" title="预期结果（基于视频）"></a>预期结果（基于视频）</h3><ul>
<li>现象与第三种benchmark类似</li>
<li>根据斜率，调度速度整体比较平稳</li>
</ul>
<h3 id="实际结果-3"><a href="#实际结果-3" class="headerlink" title="实际结果"></a>实际结果</h3><ul>
<li><strong>与预期不符</strong>：和第三种benchmark类似，CREATED出现阶段性突变。</li>
<li><strong>可能原因</strong>：本地环境的资源限制影响了大规模Pod的创建和调度。</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/0-raw/d.NoGang-1Job/output/panel-5.png?raw=true" alt="图6：本地测试，无GangScheduling要求下，第四种benchmark测试结果"><figcaption>图6：本地测试，无GangScheduling要求下，第四种benchmark测试结果</figcaption></figure></p>
<h3 id="进一步测试结果-2"><a href="#进一步测试结果-2" class="headerlink" title="进一步测试结果"></a>进一步测试结果</h3><p>在 <a class="link" href="https://github.com/hwdef">@hwdef<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 支持下，在 <code>24核 CPU，96 GB 内存</code> 环境下开展测试，发现：不是硬件资源限制问题。</p>
<ul>
<li>与原环境下结果类似，证明即使提供更多硬件资源也仍然存在该问题。</li>
<li>验证了 CREATED 确实会成为瓶颈，同时可能有 SCHEDULED 对 CREATED 的反向限制。（与第三种测试几乎一致）</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/0-raw/d.NoGang-1Job/output/panel-5-hwdef.png?raw=true" alt="图7：高资源量环境下测试，无GangScheduling要求下，第四种benchmark测试结果"><figcaption>图7：高资源量环境下测试，无GangScheduling要求下，第四种benchmark测试结果</figcaption></figure></p>
<h2 id="Gang调度测试"><a href="#Gang调度测试" class="headerlink" title="Gang调度测试"></a>Gang调度测试</h2><h3 id="预期结果（基于视频）-4"><a href="#预期结果（基于视频）-4" class="headerlink" title="预期结果（基于视频）"></a>预期结果（基于视频）</h3><ul>
<li>Volcano的性能都是最佳的</li>
</ul>
<h3 id="实际结果-4"><a href="#实际结果-4" class="headerlink" title="实际结果"></a>实际结果</h3><ul>
<li><strong>与预期不符</strong>：可能由于机器资源有限，大部分情况下集中调度甚至无法正常创建Pod</li>
<li><strong>额外发现</strong>：YuniKorn所创建的Pod数量大于10k，猜测可能是出现bug导致Pod重启（但按理说使用模拟环境不应该有该问题）</li>
</ul>
<h1 id="🔨差异原因分析"><a href="#🔨差异原因分析" class="headerlink" title="🔨差异原因分析"></a>🔨差异原因分析</h1><h2 id="1-硬件资源限制"><a href="#1-硬件资源限制" class="headerlink" title="1. 硬件资源限制"></a>1. 硬件资源限制</h2><p><strong>本地环境限制</strong>：</p>
<ul>
<li>CPU：8核 vs 视频中可能使用更高配置（kube-scheduling-perf仓库推荐 16核）</li>
<li>内存：15GB vs 视频中可能使用更大内存（kube-scheduling-perf仓库推荐 16GB）</li>
</ul>
<p><strong>影响</strong>：硬件资源不足可能导致：</p>
<ul>
<li>Pod创建速度受限</li>
<li>调度器处理能力下降</li>
<li>系统整体性能瓶颈</li>
</ul>
<h2 id="2-软件版本差异"><a href="#2-软件版本差异" class="headerlink" title="2. 软件版本差异"></a>2. 软件版本差异</h2><p><strong>版本对比</strong>：</p>
<ul>
<li>Kubernetes：1.32.2 vs 视频中可能使用不同版本</li>
<li>Docker：27.5.1 vs 视频中可能使用不同版本</li>
<li>调度器版本：可能存在差异</li>
</ul>
<p><strong>影响</strong>：不同版本可能存在：</p>
<ul>
<li>性能优化差异</li>
<li>Bug修复差异</li>
<li>默认配置差异</li>
</ul>
<h1 id="🏥总结与反思"><a href="#🏥总结与反思" class="headerlink" title="🏥总结与反思"></a>🏥总结与反思</h1><h2 id="主要发现"><a href="#主要发现" class="headerlink" title="主要发现"></a>主要发现</h2><ol>
<li><strong>整体趋势一致</strong>：虽然存在差异，但三种调度器的相对性能排名基本符合预期</li>
<li><strong>环境影响显著</strong>：硬件配置、软件版本、网络环境等因素对测试结果有重要影响</li>
<li><strong>资源瓶颈明显</strong>：在资源受限的本地环境中，CREATED事件更容易成为瓶颈</li>
</ol>
<h2 id="后续工作"><a href="#后续工作" class="headerlink" title="后续工作"></a>后续工作</h2><ol>
<li><strong>脚本分析</strong>：进一步浏览 kube-scheduling-perf 脚本所使用的环境、所监控的指标、所使用的监控方式，为后续增加其它指标监控做准备</li>
<li><strong>调度器分析</strong>：进一步分析CREATED阶段性突变的具体原因</li>
</ol>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.youtube.com/watch?v=njT5r3JjIaA&list=PLj6h78yzYM2MP0QhYFK8HOb8UqgbIkLMc&index=226">[2] A Comparative Analysis of Kueue, Volcano, and YuniKorn - Wei Huang, Apple &amp; Shiming Zhang, DaoCloud<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kueue.sigs.k8s.io/">[3] Kueue Documentation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/">[4] Volcano Documentation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://yunikorn.apache.org/">[5] YuniKorn Documentation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度器</tag>
        <tag>K8s</tag>
        <tag>性能测试</tag>
        <tag>Volcano</tag>
        <tag>本地测试</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】Kubernetes Webhook 实战：Kueue 调度器准入控制故障排除与性能优化</title>
    <url>/2025/07/11/k8s/k8s-scheduler-performance-test-webhook/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><blockquote>
<p><strong>📖 文档定位</strong>：本文为 Kueue 调度器 Webhook 机制的<strong>实战故障排除篇</strong>，与 <a href="/2025/07/08/k8s/k8s-webhook/" title="理论介绍文档">理论介绍文档</a> 形成互补。理论文档重点解析 Webhook 的基本概念和工作原理，而本文则专注于解决实际部署和测试过程中遇到的 Webhook 相关问题。</p>
</blockquote>
<p><strong>适用场景</strong>：如果您在部署 Kueue 调度器或进行调度器性能测试时遇到 Webhook 相关的错误，那么本文档将为您提供详细的问题诊断和解决方案。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><h2 id="问题起源"><a href="#问题起源" class="headerlink" title="问题起源"></a>问题起源</h2><p>在 <a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="调度器性能测试调试">调度器性能测试调试</a> 过程中，我们遇到了一个典型的 Webhook 连接问题：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">Internal error occurred: failed calling webhook "mresourceflavor.kb.io": failed to call webhook: </span><br><span class="line">Post "https://kueue-webhook-service.kueue-system.svc:443/mutate-kueue-x-k8s-io-v1beta1-resourceflavor?timeout=10s": </span><br><span class="line">dial tcp 10.96.33.70:443: connect: connection refused</span><br></pre></td></tr></table></figure></div>

<p>这个错误不仅影响了测试的顺利进行，也让我们深入思考了 Webhook 在 Kubernetes 调度器中的重要作用。</p>
<h2 id="为什么需要-Webhook？"><a href="#为什么需要-Webhook？" class="headerlink" title="为什么需要 Webhook？"></a>为什么需要 Webhook？</h2><h3 id="1-准入控制需求"><a href="#1-准入控制需求" class="headerlink" title="1. 准入控制需求"></a>1. 准入控制需求</h3><ul>
<li><strong>资源验证</strong>：确保创建的资源符合集群策略</li>
<li><strong>自动标签</strong>：为工作负载添加必要的元数据</li>
<li><strong>队列管理</strong>：协调工作负载与调度队列的关系</li>
</ul>
<h3 id="2-扩展性要求"><a href="#2-扩展性要求" class="headerlink" title="2. 扩展性要求"></a>2. 扩展性要求</h3><ul>
<li><strong>动态配置</strong>：无需重启 API 服务器即可添加新的验证规则</li>
<li><strong>外部集成</strong>：允许外部系统参与资源管理决策</li>
<li><strong>安全增强</strong>：提供额外的安全验证层</li>
</ul>
<h1 id="🧠Webhook-在-Kueue-中的作用机制"><a href="#🧠Webhook-在-Kueue-中的作用机制" class="headerlink" title="🧠Webhook 在 Kueue 中的作用机制"></a>🧠Webhook 在 Kueue 中的作用机制</h1><h2 id="1-准入控制机制"><a href="#1-准入控制机制" class="headerlink" title="1. 准入控制机制"></a>1. 准入控制机制</h2><p>Kueue 使用 Webhook 实现以下核心功能：</p>
<h3 id="1-1-资源验证"><a href="#1-1-资源验证" class="headerlink" title="1.1 资源验证"></a>1.1 资源验证</h3><ul>
<li><strong>Job 验证</strong>：检查 Kubernetes Job 是否符合 Kueue 管理要求</li>
<li><strong>Pod 验证</strong>：验证 Pod 的资源请求和限制</li>
<li><strong>ResourceFlavor 验证</strong>：确保资源风味配置正确</li>
</ul>
<h3 id="1-2-自动标签管理"><a href="#1-2-自动标签管理" class="headerlink" title="1.2 自动标签管理"></a>1.2 自动标签管理</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 自动添加的标签示例</span></span><br><span class="line"><span class="attr">kueue.x-k8s.io/managed:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">kueue.x-k8s.io/queue-name:</span> <span class="string">"default"</span></span><br></pre></td></tr></table></figure></div>

<h3 id="1-3-队列分配"><a href="#1-3-队列分配" class="headerlink" title="1.3 队列分配"></a>1.3 队列分配</h3><ul>
<li><strong>工作负载分类</strong>：根据标签将工作负载分配到相应队列</li>
<li><strong>资源配额检查</strong>：验证工作负载是否超出队列资源限制</li>
</ul>
<h2 id="2-Webhook-类型"><a href="#2-Webhook-类型" class="headerlink" title="2. Webhook 类型"></a>2. Webhook 类型</h2><h3 id="2-1-Mutating-Webhook（修改性）"><a href="#2-1-Mutating-Webhook（修改性）" class="headerlink" title="2.1 Mutating Webhook（修改性）"></a>2.1 Mutating Webhook（修改性）</h3><ul>
<li><strong>作用</strong>：修改资源内容</li>
<li><strong>时机</strong>：在验证性 Webhook 之前执行</li>
<li><strong>功能</strong>：添加默认标签、注解等</li>
</ul>
<h3 id="2-2-Validating-Webhook（验证性）"><a href="#2-2-Validating-Webhook（验证性）" class="headerlink" title="2.2 Validating Webhook（验证性）"></a>2.2 Validating Webhook（验证性）</h3><ul>
<li><strong>作用</strong>：验证资源是否符合规则</li>
<li><strong>时机</strong>：在资源持久化到 etcd 之前</li>
<li><strong>结果</strong>：允许或拒绝请求</li>
</ul>
<h2 id="3-工作流程详解"><a href="#3-工作流程详解" class="headerlink" title="3. 工作流程详解"></a>3. 工作流程详解</h2><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">用户创建 Job → API 服务器接收请求 → Mutating Webhook → Validating Webhook → 持久化到 etcd</span><br></pre></td></tr></table></figure></div>

<p><strong>具体步骤</strong>：</p>
<ol>
<li><strong>请求接收</strong>：用户提交 Job 创建请求</li>
<li><strong>Webhook 拦截</strong>：API 服务器根据配置拦截请求</li>
<li><strong>修改处理</strong>：Mutating Webhook 添加必要标签</li>
<li><strong>验证处理</strong>：Validating Webhook 检查资源合规性</li>
<li><strong>结果返回</strong>：处理结果返回给 API 服务器</li>
<li><strong>资源创建</strong>：验证通过后，Job 被创建</li>
</ol>
<h1 id="🔨Webhook-配置详解"><a href="#🔨Webhook-配置详解" class="headerlink" title="🔨Webhook 配置详解"></a>🔨Webhook 配置详解</h1><h2 id="1-服务配置"><a href="#1-服务配置" class="headerlink" title="1. 服务配置"></a>1. 服务配置</h2><h3 id="1-1-Webhook-服务定义"><a href="#1-1-Webhook-服务定义" class="headerlink" title="1.1 Webhook 服务定义"></a>1.1 Webhook 服务定义</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kueue-webhook-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kueue-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">9443</span>  <span class="comment"># 指向 webhook 服务器的端口</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">control-plane:</span> <span class="string">controller-manager</span></span><br></pre></td></tr></table></figure></div>

<h3 id="1-2-Webhook-服务器配置"><a href="#1-2-Webhook-服务器配置" class="headerlink" title="1.2 Webhook 服务器配置"></a>1.2 Webhook 服务器配置</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">webhook:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">9443</span>  <span class="comment"># webhook 服务器监听端口</span></span><br><span class="line">  <span class="attr">timeoutSeconds:</span> <span class="number">10</span>  <span class="comment"># 超时时间</span></span><br></pre></td></tr></table></figure></div>

<h2 id="2-Webhook-规则配置"><a href="#2-Webhook-规则配置" class="headerlink" title="2. Webhook 规则配置"></a>2. Webhook 规则配置</h2><h3 id="2-1-Mutating-Webhook-配置"><a href="#2-1-Mutating-Webhook-配置" class="headerlink" title="2.1 Mutating Webhook 配置"></a>2.1 Mutating Webhook 配置</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">admissionregistration.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">MutatingWebhookConfiguration</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kueue-mutating-webhook-configuration</span></span><br><span class="line"><span class="attr">webhooks:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mjob.kb.io</span></span><br><span class="line">  <span class="attr">clientConfig:</span></span><br><span class="line">    <span class="attr">service:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">kueue-webhook-service</span></span><br><span class="line">      <span class="attr">namespace:</span> <span class="string">kueue-system</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/mutate-batch-v1-job</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">"batch"</span>]</span><br><span class="line">    <span class="attr">apiVersions:</span> [<span class="string">"v1"</span>]</span><br><span class="line">    <span class="attr">operations:</span> [<span class="string">"CREATE"</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">"jobs"</span>]</span><br><span class="line">  <span class="attr">failurePolicy:</span> <span class="string">Fail</span></span><br><span class="line">  <span class="attr">timeoutSeconds:</span> <span class="number">10</span></span><br></pre></td></tr></table></figure></div>

<h3 id="2-2-Validating-Webhook-配置"><a href="#2-2-Validating-Webhook-配置" class="headerlink" title="2.2 Validating Webhook 配置"></a>2.2 Validating Webhook 配置</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">admissionregistration.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ValidatingWebhookConfiguration</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kueue-validating-webhook-configuration</span></span><br><span class="line"><span class="attr">webhooks:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">vresourceflavor.kb.io</span></span><br><span class="line">  <span class="attr">clientConfig:</span></span><br><span class="line">    <span class="attr">service:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">kueue-webhook-service</span></span><br><span class="line">      <span class="attr">namespace:</span> <span class="string">kueue-system</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/validate-kueue-x-k8s-io-v1beta1-resourceflavor</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">"kueue.x-k8s.io"</span>]</span><br><span class="line">    <span class="attr">apiVersions:</span> [<span class="string">"v1beta1"</span>]</span><br><span class="line">    <span class="attr">operations:</span> [<span class="string">"CREATE"</span>, <span class="string">"UPDATE"</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">"resourceflavors"</span>]</span><br></pre></td></tr></table></figure></div>

<h2 id="3-证书管理"><a href="#3-证书管理" class="headerlink" title="3. 证书管理"></a>3. 证书管理</h2><h3 id="3-1-TLS-证书配置"><a href="#3-1-TLS-证书配置" class="headerlink" title="3.1 TLS 证书配置"></a>3.1 TLS 证书配置</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 证书存储在 Secret 中</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kueue-webhook-server-cert</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kueue-system</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">kubernetes.io/tls</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">tls.crt:</span> <span class="string">&lt;base64-encoded-cert&gt;</span></span><br><span class="line">  <span class="attr">tls.key:</span> <span class="string">&lt;base64-encoded-key&gt;</span></span><br></pre></td></tr></table></figure></div>

<h3 id="3-2-证书挂载"><a href="#3-2-证书挂载" class="headerlink" title="3.2 证书挂载"></a>3.2 证书挂载</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在 Deployment 中挂载证书</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">webhook-server-cert</span></span><br><span class="line">  <span class="attr">secret:</span></span><br><span class="line">    <span class="attr">secretName:</span> <span class="string">kueue-webhook-server-cert</span></span><br><span class="line"><span class="attr">volumeMounts:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">webhook-server-cert</span></span><br><span class="line">  <span class="attr">mountPath:</span> <span class="string">/tmp/certs</span></span><br><span class="line">  <span class="attr">readOnly:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></div>

<h1 id="🚨常见问题及解决方案"><a href="#🚨常见问题及解决方案" class="headerlink" title="🚨常见问题及解决方案"></a>🚨常见问题及解决方案</h1><h2 id="问题1：Webhook-连接被拒绝"><a href="#问题1：Webhook-连接被拒绝" class="headerlink" title="问题1：Webhook 连接被拒绝"></a>问题1：Webhook 连接被拒绝</h2><h3 id="错误现象"><a href="#错误现象" class="headerlink" title="错误现象"></a>错误现象</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">failed calling webhook "mresourceflavor.kb.io": failed to call webhook: </span><br><span class="line">Post "https://kueue-webhook-service.kueue-system.svc:443/mutate-kueue-x-k8s-io-v1beta1-resourceflavor?timeout=10s": </span><br><span class="line">dial tcp 10.96.33.70:443: connect: connection refused</span><br></pre></td></tr></table></figure></div>

<h3 id="可能原因"><a href="#可能原因" class="headerlink" title="可能原因"></a>可能原因</h3><ol>
<li><strong>Webhook 服务未启动</strong></li>
<li><strong>Webhook Pod 未就绪</strong></li>
<li><strong>证书未正确生成</strong></li>
<li><strong>服务端点未配置</strong></li>
</ol>
<h3 id="诊断步骤"><a href="#诊断步骤" class="headerlink" title="诊断步骤"></a>诊断步骤</h3><h4 id="步骤1：检查-Webhook-Pod-状态"><a href="#步骤1：检查-Webhook-Pod-状态" class="headerlink" title="步骤1：检查 Webhook Pod 状态"></a>步骤1：检查 Webhook Pod 状态</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查 Pod 是否运行</span></span><br><span class="line">kubectl get pods -n kueue-system -l control-plane=controller-manager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Pod 详细信息</span></span><br><span class="line">kubectl describe pod -n kueue-system -l control-plane=controller-manager</span><br></pre></td></tr></table></figure></div>

<h4 id="步骤2：检查-Webhook-服务"><a href="#步骤2：检查-Webhook-服务" class="headerlink" title="步骤2：检查 Webhook 服务"></a>步骤2：检查 Webhook 服务</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查服务是否存在</span></span><br><span class="line">kubectl get service kueue-webhook-service -n kueue-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看服务详细信息</span></span><br><span class="line">kubectl describe service kueue-webhook-service -n kueue-system</span><br></pre></td></tr></table></figure></div>

<h4 id="步骤3：检查服务端点"><a href="#步骤3：检查服务端点" class="headerlink" title="步骤3：检查服务端点"></a>步骤3：检查服务端点</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查端点是否配置</span></span><br><span class="line">kubectl get endpoints kueue-webhook-service -n kueue-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看端点详细信息</span></span><br><span class="line">kubectl describe endpoints kueue-webhook-service -n kueue-system</span><br></pre></td></tr></table></figure></div>

<h4 id="步骤4：检查证书"><a href="#步骤4：检查证书" class="headerlink" title="步骤4：检查证书"></a>步骤4：检查证书</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查证书 Secret 是否存在</span></span><br><span class="line">kubectl get secret kueue-webhook-server-cert -n kueue-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看证书详细信息</span></span><br><span class="line">kubectl describe secret kueue-webhook-server-cert -n kueue-system</span><br></pre></td></tr></table></figure></div>

<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="方案1：等待服务就绪"><a href="#方案1：等待服务就绪" class="headerlink" title="方案1：等待服务就绪"></a>方案1：等待服务就绪</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 等待 Pod 就绪</span></span><br><span class="line">kubectl <span class="built_in">wait</span> --<span class="keyword">for</span>=condition=ready pod -l control-plane=controller-manager -n kueue-system --<span class="built_in">timeout</span>=120s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等待服务端点就绪</span></span><br><span class="line">kubectl <span class="built_in">wait</span> --<span class="keyword">for</span>=condition=ready endpoints kueue-webhook-service -n kueue-system --<span class="built_in">timeout</span>=60s</span><br></pre></td></tr></table></figure></div>

<h4 id="方案2：重新生成证书"><a href="#方案2：重新生成证书" class="headerlink" title="方案2：重新生成证书"></a>方案2：重新生成证书</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除现有证书</span></span><br><span class="line">kubectl delete secret kueue-webhook-server-cert -n kueue-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启 Kueue 控制器</span></span><br><span class="line">kubectl rollout restart deployment kueue-controller-manager -n kueue-system</span><br></pre></td></tr></table></figure></div>

<h4 id="方案3：检查网络连接"><a href="#方案3：检查网络连接" class="headerlink" title="方案3：检查网络连接"></a>方案3：检查网络连接</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 测试服务可访问性</span></span><br><span class="line">kubectl run test-webhook --image=busybox --<span class="built_in">rm</span> -it --restart=Never -- \</span><br><span class="line">  wget -qO- --no-check-certificate https://kueue-webhook-service.kueue-system.svc:443/healthz</span><br></pre></td></tr></table></figure></div>

<h2 id="问题2：Webhook-超时"><a href="#问题2：Webhook-超时" class="headerlink" title="问题2：Webhook 超时"></a>问题2：Webhook 超时</h2><h3 id="错误现象-1"><a href="#错误现象-1" class="headerlink" title="错误现象"></a>错误现象</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">failed calling webhook: timeout=10s</span><br></pre></td></tr></table></figure></div>

<h3 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="方案1：增加超时时间"><a href="#方案1：增加超时时间" class="headerlink" title="方案1：增加超时时间"></a>方案1：增加超时时间</h4><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改 webhook 配置</span></span><br><span class="line"><span class="attr">webhooks:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mjob.kb.io</span></span><br><span class="line">  <span class="attr">timeoutSeconds:</span> <span class="number">30</span>  <span class="comment"># 增加超时时间</span></span><br></pre></td></tr></table></figure></div>

<h4 id="方案2：优化-Webhook-性能"><a href="#方案2：优化-Webhook-性能" class="headerlink" title="方案2：优化 Webhook 性能"></a>方案2：优化 Webhook 性能</h4><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 增加资源限制</span></span><br><span class="line"><span class="attr">resources:</span></span><br><span class="line">  <span class="attr">requests:</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">500m</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">512Mi</span></span><br><span class="line">  <span class="attr">limits:</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">1000m</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">1Gi</span></span><br></pre></td></tr></table></figure></div>

<h4 id="方案3：调整并发处理"><a href="#方案3：调整并发处理" class="headerlink" title="方案3：调整并发处理"></a>方案3：调整并发处理</h4><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 增加并发处理能力</span></span><br><span class="line"><span class="attr">controller:</span></span><br><span class="line">  <span class="attr">groupKindConcurrency:</span></span><br><span class="line">    <span class="attr">Job.batch:</span> <span class="number">100</span></span><br><span class="line">    <span class="attr">Pod:</span> <span class="number">100</span></span><br><span class="line">    <span class="attr">Workload.kueue.x-k8s.io:</span> <span class="number">100</span></span><br></pre></td></tr></table></figure></div>

<h2 id="问题3：证书问题"><a href="#问题3：证书问题" class="headerlink" title="问题3：证书问题"></a>问题3：证书问题</h2><h3 id="错误现象-2"><a href="#错误现象-2" class="headerlink" title="错误现象"></a>错误现象</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">x509: certificate signed by unknown authority</span><br></pre></td></tr></table></figure></div>

<h3 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="方案1：重新生成证书"><a href="#方案1：重新生成证书" class="headerlink" title="方案1：重新生成证书"></a>方案1：重新生成证书</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除现有证书</span></span><br><span class="line">kubectl delete secret kueue-webhook-server-cert -n kueue-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启控制器</span></span><br><span class="line">kubectl rollout restart deployment kueue-controller-manager -n kueue-system</span><br></pre></td></tr></table></figure></div>

<h4 id="方案2：检查证书配置"><a href="#方案2：检查证书配置" class="headerlink" title="方案2：检查证书配置"></a>方案2：检查证书配置</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 验证证书配置</span></span><br><span class="line">kubectl get secret kueue-webhook-server-cert -n kueue-system -o yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查证书内容</span></span><br><span class="line">kubectl get secret kueue-webhook-server-cert -n kueue-system -o jsonpath=<span class="string">'{.data.tls\.crt}'</span> | <span class="built_in">base64</span> -d | openssl x509 -text -noout</span><br></pre></td></tr></table></figure></div>

<h1 id="🔍调试方法"><a href="#🔍调试方法" class="headerlink" title="🔍调试方法"></a>🔍调试方法</h1><h2 id="1-日志分析"><a href="#1-日志分析" class="headerlink" title="1. 日志分析"></a>1. 日志分析</h2><h3 id="查看-Webhook-服务器日志"><a href="#查看-Webhook-服务器日志" class="headerlink" title="查看 Webhook 服务器日志"></a>查看 Webhook 服务器日志</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看 webhook 服务器日志</span></span><br><span class="line">kubectl logs -n kueue-system -l control-plane=controller-manager -c manager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实时跟踪日志</span></span><br><span class="line">kubectl logs -n kueue-system -l control-plane=controller-manager -c manager -f</span><br></pre></td></tr></table></figure></div>

<h3 id="查看-API-服务器日志"><a href="#查看-API-服务器日志" class="headerlink" title="查看 API 服务器日志"></a>查看 API 服务器日志</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看 API 服务器日志</span></span><br><span class="line">kubectl logs -n kube-system kube-apiserver-kind-control-plane</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 API 服务器审计日志</span></span><br><span class="line">kubectl logs -n kube-system kube-apiserver-kind-control-plane | grep webhook</span><br></pre></td></tr></table></figure></div>

<h2 id="2-配置检查"><a href="#2-配置检查" class="headerlink" title="2. 配置检查"></a>2. 配置检查</h2><h3 id="检查-Webhook-配置"><a href="#检查-Webhook-配置" class="headerlink" title="检查 Webhook 配置"></a>检查 Webhook 配置</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看 mutating webhook 配置</span></span><br><span class="line">kubectl get mutatingwebhookconfiguration kueue-mutating-webhook-configuration -o yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 validating webhook 配置</span></span><br><span class="line">kubectl get validatingwebhookconfiguration kueue-validating-webhook-configuration -o yaml</span><br></pre></td></tr></table></figure></div>

<h3 id="检查服务配置"><a href="#检查服务配置" class="headerlink" title="检查服务配置"></a>检查服务配置</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看服务配置</span></span><br><span class="line">kubectl get service kueue-webhook-service -n kueue-system -o yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看端点配置</span></span><br><span class="line">kubectl get endpoints kueue-webhook-service -n kueue-system -o yaml</span><br></pre></td></tr></table></figure></div>

<h2 id="3-网络测试"><a href="#3-网络测试" class="headerlink" title="3. 网络测试"></a>3. 网络测试</h2><h3 id="测试服务连通性"><a href="#测试服务连通性" class="headerlink" title="测试服务连通性"></a>测试服务连通性</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 测试服务可访问性</span></span><br><span class="line">kubectl run test-webhook --image=busybox --<span class="built_in">rm</span> -it --restart=Never -- \</span><br><span class="line">  wget -qO- --no-check-certificate https://kueue-webhook-service.kueue-system.svc:443/healthz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试端口连通性</span></span><br><span class="line">kubectl run test-port --image=busybox --<span class="built_in">rm</span> -it --restart=Never -- \</span><br><span class="line">  nc -zv kueue-webhook-service.kueue-system.svc 443</span><br></pre></td></tr></table></figure></div>

<h1 id="🏥实战总结"><a href="#🏥实战总结" class="headerlink" title="🏥实战总结"></a>🏥实战总结</h1><h2 id="关键要点"><a href="#关键要点" class="headerlink" title="关键要点"></a>关键要点</h2><ol>
<li><strong>Webhook 是 Kueue 的核心组件</strong>：负责准入控制、资源验证和自动标签管理</li>
<li><strong>证书管理至关重要</strong>：TLS 证书是 Webhook 安全通信的基础</li>
<li><strong>服务就绪检查</strong>：确保 Webhook 服务完全就绪是避免连接问题的关键</li>
</ol>
<h2 id="实践经验"><a href="#实践经验" class="headerlink" title="实践经验"></a>实践经验</h2><p>通常可考虑的故障排除流程如下：</p>
<ol>
<li><strong>检查 Pod 状态</strong>：确认 Webhook 服务正在运行</li>
<li><strong>验证服务配置</strong>：检查服务和端点配置</li>
<li><strong>检查证书</strong>：验证 TLS 证书是否正确</li>
<li><strong>测试连通性</strong>：确认网络连接正常</li>
<li><strong>查看日志</strong>：分析错误信息和性能指标</li>
</ol>
<p>希望本文档能够帮助您更好地理解和解决 Kubernetes 集群中的 Webhook 相关问题！</p>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E9%92%A9%E5%AD%90">[1] Webhook - Wikipedia<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/">[2] Kubernetes 中的准入控制 - 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://github.com/volcano-sh/volcano/tree/master/pkg/webhooks">[3] Volcano Webhook Implementation - GitHub<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/cluster-administration/admission-webhooks-good-practices/">[4] Admission Webhook 良好实践 - Kubernetes官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/webhook/">[5] Webhook Mode - Kubernetes官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/">[6] Kubernetes API Server 参数 - 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://juejin.cn/post/7437727364082040871">[7] 什么是Webhook？工作原理？如何实现？缺点？ - 掘金<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://zhuanlan.zhihu.com/p/606844215">[8] 详细介绍一下webhook技术 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://blog.csdn.net/m0_71808387/article/details/140469408">[9] Webhook 是什么？详解其工作原理 - CSDN<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.redhat.com/zh-cn/topics/automation-and-management/shenmeshi-webhook">[10] 什么是 Webhook？ - RedHat<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.cnblogs.com/keep-live/articles/16544143.html">[11] kubernetes的webhook开发 - 博客园<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
        <category>实战</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>Webhook</tag>
        <tag>准入控制</tag>
        <tag>调度器</tag>
        <tag>性能优化</tag>
        <tag>Kueue</tag>
        <tag>故障排除</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</title>
    <url>/2025/06/24/k8s/k8s-scheduler-performance-test/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li>
<li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li>
<li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li>
<li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li>
<li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li>
<li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li>
<li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li>
<li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a>
</li>
</ol>
</blockquote>
<h1 id="kube-scheduling-perf：Kubernetes多调度器性能测试框架全解析"><a href="#kube-scheduling-perf：Kubernetes多调度器性能测试框架全解析" class="headerlink" title="kube-scheduling-perf：Kubernetes多调度器性能测试框架全解析"></a>kube-scheduling-perf：Kubernetes多调度器性能测试框架全解析</h1><h2 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h2><p><code>kube-scheduling-perf</code> 项目为 Kubernetes 社区主流调度器（如 Kueue、Volcano、YuniKorn）提供了统一、自动化的性能测试与对比分析框架。通过自动化脚本和标准化测试流程，用户可在本地快速搭建测试集群，批量运行多种调度器的性能基准测试，并自动收集、汇总测试结果，极大提升了调度器性能评测的效率和可复现性。</p>
<blockquote>
<p><strong>📖 阅读说明</strong>：本文为 kube-scheduling-perf 项目的<strong>理论介绍篇</strong>，重点解析项目的架构设计、自动化流程和核心原理。如果您计划实际部署和使用该工具，强烈建议同时阅读 <a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="实操注意事项说明文档">实操注意事项说明文档</a>，该文档详细记录了在实际环境中可能遇到的各种问题（如网络访问、系统兼容性、权限配置等）及其解决方案。</p>
</blockquote>
<hr>
<h1 id="目录结构与核心组件说明"><a href="#目录结构与核心组件说明" class="headerlink" title="目录结构与核心组件说明"></a>目录结构与核心组件说明</h1><h2 id="clusters-目录"><a href="#clusters-目录" class="headerlink" title="clusters 目录"></a>clusters 目录</h2><ul>
<li><code>clusters/</code> 目录下包含了每个调度器（kueue、volcano、yunikorn）及 overview 的子目录。</li>
<li>每个调度器子目录下都包含一个 <code>Makefile</code> 和 <code>kind.yaml</code>，用于定义该调度器测试集群的启动、销毁、等待等操作。</li>
<li><code>overview/</code> 子目录用于搭建统一的监控与可视化环境（如 Prometheus + Grafana），并负责性能数据的采集与展示。</li>
</ul>
<h2 id="bin-目录"><a href="#bin-目录" class="headerlink" title="bin 目录"></a>bin 目录</h2><ul>
<li><code>bin/</code> 目录用于存放自动编译生成的二进制文件，如 <code>kind</code>（用于创建K8s集群）、<code>test-xxx</code>（各调度器的测试用例可执行文件）。</li>
<li>这些二进制文件由 Makefile 自动生成和调用，用户无需手动干预。</li>
</ul>
<hr>
<h1 id="Makefile-语法与目标说明"><a href="#Makefile-语法与目标说明" class="headerlink" title="Makefile 语法与目标说明"></a>Makefile 语法与目标说明</h1><h2 id="PHONY-说明"><a href="#PHONY-说明" class="headerlink" title=".PHONY 说明"></a>.PHONY 说明</h2><ul>
<li><code>.PHONY</code> 是 Makefile 的一个特殊声明，用于标记”伪目标”。</li>
<li>被 <code>.PHONY</code> 声明的目标不会与同名文件或目录冲突，每次执行 <code>make</code> 时都会被强制执行。</li>
<li>例如：<div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: up</span></span><br><span class="line"><span class="section">up:</span></span><br><span class="line">    <span class="comment"># ...命令...</span></span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h2 id="目标与依赖格式"><a href="#目标与依赖格式" class="headerlink" title="目标与依赖格式"></a>目标与依赖格式</h2><ul>
<li>Makefile 的每个目标格式为：<div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">目标名: 依赖1 依赖2 ...</span></span><br><span class="line">    命令1</span><br><span class="line">    命令2</span><br></pre></td></tr></table></figure></div></li>
<li>冒号后面可以跟依赖目标，表示在执行当前目标前会先执行依赖目标。</li>
<li>命令必须以Tab缩进。</li>
</ul>
<hr>
<h1 id="自动化测试流程详解"><a href="#自动化测试流程详解" class="headerlink" title="自动化测试流程详解"></a>自动化测试流程详解</h1><h2 id="1-make命令的起点：default-目标"><a href="#1-make命令的起点：default-目标" class="headerlink" title="1. make命令的起点：default 目标"></a>1. make命令的起点：default 目标</h2><p>当你在项目根目录下执行 <code>make</code> 时，实际上会触发 <code>Makefile</code> 中的 <code>default</code> 目标。其内容如下：</p>
<div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: default</span></span><br><span class="line"><span class="section">default:</span></span><br><span class="line">	make serial-test \</span><br><span class="line">		RESULT_RECENT_DURATION_SECONDS=250 TEST_TIMEOUT_SECONDS=350 \</span><br><span class="line">		NODES_SIZE=1000 \</span><br><span class="line">		QUEUES_SIZE=1  JOBS_SIZE_PER_QUEUE=10000  PODS_SIZE_PER_JOB=1</span><br><span class="line">	<span class="comment"># ...（省略多组不同参数的serial-test调用）</span></span><br><span class="line">	make serial-test \</span><br><span class="line">		RESULT_RECENT_DURATION_SECONDS=300 TEST_TIMEOUT_SECONDS=400 \</span><br><span class="line">		NODES_SIZE=1000 GANG=true \</span><br><span class="line">		QUEUES_SIZE=1  JOBS_SIZE_PER_QUEUE=1      PODS_SIZE_PER_JOB=10000</span><br></pre></td></tr></table></figure></div>

<ul>
<li>这里依次调用了多次 <code>serial-test</code>，每次传入不同的集群规模、作业数量、Pod数量、是否GANG调度等参数。</li>
<li>这样做的目的是<strong>批量测试不同场景下各调度器的性能</strong>，保证测试的全面性和对比性。</li>
</ul>
<h2 id="2-serial-test-目标的作用"><a href="#2-serial-test-目标的作用" class="headerlink" title="2. serial-test 目标的作用"></a>2. serial-test 目标的作用</h2><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: serial-test</span></span><br><span class="line"><span class="section">serial-test: bin/kind</span></span><br><span class="line">	<span class="variable">$(<span class="built_in">foreach</span> sched,<span class="variable">$(SCHEDULERS)</span>, \</span></span><br><span class="line"><span class="variable">		make prepare-<span class="variable">$(sched)</span>; \</span></span><br><span class="line"><span class="variable">		make start-<span class="variable">$(sched)</span>; \</span></span><br><span class="line"><span class="variable">		make end-<span class="variable">$(sched)</span>; \</span></span><br><span class="line"><span class="variable">	)</span></span><br><span class="line">	make \</span><br><span class="line">		prepare-overview \</span><br><span class="line">		start-overview \</span><br><span class="line">		save-result \</span><br><span class="line">		end-overview</span><br></pre></td></tr></table></figure></div>

<ul>
<li><code>serial-test</code> 首先依赖 <code>bin/kind</code>，确保本地有 kind 工具（用于创建K8s集群）。</li>
<li>然后对 <code>SCHEDULERS</code>（即 Kueue、Volcano、YuniKorn）中的每个调度器，依次执行 <code>prepare-xxx</code>、<code>start-xxx</code>、<code>end-xxx</code> 三个目标。</li>
<li>最后执行 overview 相关目标和结果保存。</li>
</ul>
<h2 id="3-serial-test-的每一步剖析"><a href="#3-serial-test-的每一步剖析" class="headerlink" title="3. serial-test 的每一步剖析"></a>3. serial-test 的每一步剖析</h2><h3 id="3-1-bin-kind"><a href="#3-1-bin-kind" class="headerlink" title="3.1 bin/kind"></a>3.1 bin/kind</h3><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">bin/kind:</span></span><br><span class="line">	<span class="variable">$(GO_IN_DOCKER)</span> go build -o ./bin/kind sigs.k8s.io/kind</span><br></pre></td></tr></table></figure></div>
<ul>
<li>用 Docker 构建 <code>kind</code> 工具的二进制文件，确保后续可以用 kind 创建本地K8s集群。</li>
</ul>
<h3 id="3-2-prepare-xxx、start-xxx、end-xxx"><a href="#3-2-prepare-xxx、start-xxx、end-xxx" class="headerlink" title="3.2 prepare-xxx、start-xxx、end-xxx"></a>3.2 prepare-xxx、start-xxx、end-xxx</h3><p>这些目标通过 <code>define test-scheduler</code> 宏自动生成。以 <code>kueue</code> 为例：</p>
<ul>
<li><code>prepare-kueue</code>：启动集群、等待就绪、初始化测试。</li>
<li><code>start-kueue</code>：重置审计日志，运行批量作业调度测试。</li>
<li><code>end-kueue</code>：销毁测试集群。</li>
</ul>
<p>其它调度器（如 volcano、yunikorn）流程类似。</p>
<h3 id="3-3-overview-相关目标"><a href="#3-3-overview-相关目标" class="headerlink" title="3.3 overview 相关目标"></a>3.3 overview 相关目标</h3><h4 id="prepare-overview"><a href="#prepare-overview" class="headerlink" title="prepare-overview"></a>prepare-overview</h4><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: prepare-overview</span></span><br><span class="line"><span class="section">prepare-overview:</span></span><br><span class="line">	make up-overview</span><br><span class="line">	make wait-overview</span><br></pre></td></tr></table></figure></div>
<ul>
<li>启动 overview 监控集群，并等待其所有服务就绪。</li>
</ul>
<h4 id="start-overview"><a href="#start-overview" class="headerlink" title="start-overview"></a>start-overview</h4><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: start-overview</span></span><br><span class="line"><span class="section">start-overview:</span></span><br><span class="line">	make -C ./clusters/overview start-export</span><br></pre></td></tr></table></figure></div>
<ul>
<li>在 overview 集群中启动数据导出与采集服务（如 patch、kustomize、kubectl create 等）。</li>
</ul>
<h4 id="save-result"><a href="#save-result" class="headerlink" title="save-result"></a>save-result</h4><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: save-result</span></span><br><span class="line"><span class="section">save-result:</span></span><br><span class="line">	sleep <span class="variable">$(RESULT_RECENT_DURATION_SECONDS)</span></span><br><span class="line">	RECENT_DURATION=<span class="string">"<span class="variable">$(RESULT_RECENT_DURATION_SECONDS)</span>second"</span> ./hack/save-result-images.sh</span><br><span class="line">	make down</span><br><span class="line">	<span class="comment"># 归档测试环境变量、日志、输出到 results 目录</span></span><br></pre></td></tr></table></figure></div>
<ul>
<li>等待一段时间，采集最新的监控数据，调用脚本保存结果，并归档到 <code>results/</code> 目录。</li>
</ul>
<h4 id="end-overview"><a href="#end-overview" class="headerlink" title="end-overview"></a>end-overview</h4><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: end-overview</span></span><br><span class="line"><span class="section">end-overview:</span></span><br><span class="line">	make down-overview</span><br></pre></td></tr></table></figure></div>
<ul>
<li>销毁 overview 监控集群，释放资源。</li>
</ul>
<hr>
<h1 id="目标之间的调用关系图"><a href="#目标之间的调用关系图" class="headerlink" title="目标之间的调用关系图"></a>目标之间的调用关系图</h1><pre class="mermaid">graph TD
    A[make] --&gt; B[default]
    B --&gt; C1[serial-test(参数1)]
    B --&gt; C2[serial-test(参数2)]
    B --&gt; Cn[serial-test(参数n)]
    C1 --&gt; D1[prepare-scheduler]
    C1 --&gt; D2[start-scheduler]
    C1 --&gt; D3[end-scheduler]
    C1 --&gt; E[prepare-overview/start-overview/save-result/end-overview]
    D1 --&gt; F1[up-scheduler]
    D1 --&gt; F2[wait-scheduler]
    D1 --&gt; F3[test-init-scheduler]
    D2 --&gt; G1[reset-auditlog-scheduler]
    D2 --&gt; G2[test-batch-job-scheduler]
    D3 --&gt; H[down-scheduler]</pre>

<hr>
<h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><blockquote>
<p><strong>⚠️ 重要提醒</strong>：本文档主要介绍 kube-scheduling-perf 项目的理论架构和自动化流程。在实际运行过程中，由于外网访问限制、系统版本兼容性、用户权限配置等问题，您可能会遇到各种部署和使用障碍。</p>
</blockquote>
<p><strong>实际部署使用指南</strong>：请务必参考 <a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a> 文档，该文档详细记录了：</p>
<ul>
<li><strong>网络访问问题</strong>：国内环境下的镜像加速配置、Go模块代理设置</li>
<li><strong>系统兼容性问题</strong>：内核版本适配、Docker版本要求、Go版本兼容性</li>
<li><strong>权限配置问题</strong>：Docker容器权限、目录所有权、用户权限设置</li>
<li><strong>版本降级方案</strong>：针对老旧系统的版本适配策略</li>
<li><strong>故障排除指南</strong>：常见错误及解决方案</li>
</ul>
<p>该注意事项文档基于实际部署经验总结，能够帮助您快速解决部署过程中的各种技术难题，确保测试工具能够正常运行。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li><strong><code>make</code></strong> 触发 <code>default</code>，批量执行多组参数化的 <code>serial-test</code>。</li>
<li><strong><code>serial-test</code></strong> 依次对每个调度器完成：集群部署→初始化→批量作业测试→集群销毁→结果采集。</li>
<li><strong>overview 相关目标</strong> 负责性能数据的统一采集与可视化。</li>
<li><strong>clusters 目录</strong> 负责各调度器及监控集群的生命周期管理。</li>
<li><strong>bin 目录</strong> 存放自动生成的工具和测试用例二进制文件。</li>
<li><strong>.PHONY</strong> 声明伪目标，保证每次都能正确执行。</li>
</ul>
<p>本项目通过 Makefile 的自动化编排、参数化测试、统一的日志与指标采集、可视化监控等手段，实现了 Kubernetes 多调度器性能对比的”一键化”与标准化。极大降低了测试门槛，提高了效率和可复现性，非常适合调度器开发者、性能分析师和社区贡献者使用与扩展。</p>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://learnku.com/go/wikis/38122">[2] Go 国内加速镜像<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://cloud.tencent.com/developer/article/2020911">[3] 深入理解 Go Modules 的 go.mod 与 go.sum<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度器</tag>
        <tag>K8s</tag>
        <tag>性能测试</tag>
        <tag>Volcano</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】K8s调度器性能对比分析：Kueue vs Volcano vs YuniKorn</title>
    <url>/2025/06/26/k8s/k8s-scheduler-performance-video/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li>
<li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li>
<li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li>
<li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li>
<li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li>
<li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li>
<li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li>
<li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a>
</li>
</ol>
</blockquote>
<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在Kubernetes生态系统中，调度器是集群资源管理的核心组件。随着云原生应用的快速发展，传统的默认调度器已经无法满足大规模、高并发的调度需求。<br>本文整理自Apple工程师Wei Huang与DaoCloud工程师Shiming Zhang在KubeCon上的技术分享<a href="#refer-anchor-1"><sup>[1]</sup></a>，聚焦Kubernetes生态中三大主流批处理调度器（Kueue, Volcano, YuniKorn）的性能对比实验。通过分析测试方法论、关键指标和实际数据，揭示各调度器在不同负载场景下的表现差异。<br>在<a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="上一篇博客">上一篇博客</a>中所介绍的性能测试与监控工具，也就是这次技术分享中的shiming Zhang 及相关成员所设计的，测试监控工具结果也在这次技术分享中有所体现。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><h2 id="背景参数"><a href="#背景参数" class="headerlink" title="背景参数"></a>背景参数</h2><ol>
<li>API QPS 限制是一个重要的参数，而本次测试所涉及的调度器间、该参数存在差异，有可能导致部分测试不公平，因此在此提前说明。</li>
<li>K8s 下，调度器默认使用的 API QPS（<code>--kube-api-qps</code>）限制为 50，而 YuniKorn 为 1000。而前者暂时没找到修改的方法。</li>
<li>除该参数外，在测试中已尽量保持其它参数的一致，尽可能保证了测试的公平性。</li>
</ol>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/2025-KubeCon-A-Comparative-Analysis-1.png" alt="图1：QPS限制参数情况"><figcaption>图1：QPS限制参数情况</figcaption></figure></p>
<h2 id="数据收集方法优化"><a href="#数据收集方法优化" class="headerlink" title="数据收集方法优化"></a>数据收集方法优化</h2><ol>
<li>传统方法使用 Prometheus，会造成很大的误差。<ul>
<li>以前看到过的<a class="link" href="https://cloud.tencent.com/developer/article/2210383">博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>也有类似的观点：<blockquote>
<p>十分不建议在大规模压测时通过 grafana 看板进行调度时间的统计。因为调度器暴露的调度时间指标是通过 histogram 直方图的方式，而 histogram 是假定位于每个 bucket 的样本在该 bucket 内满足均匀分布。当压测进行时，短时间大量创建 Pod，必定有部分 Pod 的调度时长达到分钟级别，此时其所属的 bucket 范围更广，均匀分布的条件就越不可能成立，从 metrics 这统计的调度时间会产生很大的误差(<a class="link" href="https://hulining.gitbook.io/prometheus/practices/histograms#errors-of-quantile-estimation)%E3%80%82">https://hulining.gitbook.io/prometheus/practices/histograms#errors-of-quantile-estimation)。<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</blockquote>
</li>
</ul>
</li>
<li>本方法基于 audit-exporter，从 kube-apiserver 中收集信息并记录在 audit.log 来准确地记录具体性能。</li>
</ol>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/2025-KubeCon-A-Comparative-Analysis-2.png" alt="图2：传统数据收集方法示意图"><figcaption>图2：传统数据收集方法示意图</figcaption></figure></p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/2025-KubeCon-A-Comparative-Analysis-3.png" alt="图3：数据收集方法优化示意图"><figcaption>图3：数据收集方法优化示意图</figcaption></figure></p>
<h1 id="🧠环境说明"><a href="#🧠环境说明" class="headerlink" title="🧠环境说明"></a>🧠环境说明</h1><h2 id="测试软件环境"><a href="#测试软件环境" class="headerlink" title="测试软件环境"></a>测试软件环境</h2><p>本次性能测试软件版本如下图：</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/2025-KubeCon-A-Comparative-Analysis-4.png" alt="图4：性能测试中的软件版本"><figcaption>图4：性能测试中的软件版本</figcaption></figure></p>
<h2 id="测试参数配置"><a href="#测试参数配置" class="headerlink" title="测试参数配置"></a>测试参数配置</h2><p>本次测试benchmark如下图，在10k总Pod量下，分别在启用/不启用Gang Scheduling的情况下（个人理解，即分别在更偏向在线服务/离线作业特征的场景下），调整Job数量和每Job的Pod数量。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/2025-KubeCon-A-Comparative-Analysis-5.png" alt="图5：性能测试中的参数配置"><figcaption>图5：性能测试中的参数配置</figcaption></figure></p>
<p>注意：在测试中没有使用很多Queue，因为发现Queue的数量对测试结果影响不大。</p>
<h1 id="🔨结果"><a href="#🔨结果" class="headerlink" title="🔨结果"></a>🔨结果</h1><p>对于不要求Gang调度的benchmark，Volcano表现较差；对于要求Gang调度的benchmark，Volcano的性能都是最佳的。</p>
<p>我们对于不要求Gang调度的四种benchmark结果进行具体介绍。其中第二种测试中的现象很有意思。<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/2025-KubeCon-A-Comparative-Analysis-6.png" alt="图6：无GangScheduling要求下，第一种benchmark测试结果"><figcaption>图6：无GangScheduling要求下，第一种benchmark测试结果</figcaption></figure></p>
<ol>
<li>第一种benchmark下，每个Job只有1个Pod，共10K个Job，共10kPod。有以下现象：<ul>
<li>YuniKorn吞吐量比另外两种调度器更高，主要是因为 Kueue 和 Volcano 有额外 Job 管理功能，而 YuniKorn 不提供 Job 管理功能。</li>
<li>CREATED和SCHEDULED事件之间的差距很小，说明没有调度阶段不为瓶颈、没有排队，此时性能瓶颈为创建阶段。</li>
</ul>
</li>
</ol>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/2025-KubeCon-A-Comparative-Analysis-7.png" alt="图7：无GangScheduling要求下，第二种benchmark测试结果"><figcaption>图7：无GangScheduling要求下，第二种benchmark测试结果</figcaption></figure></p>
<ol>
<li>第二种benchmark下，每个Job有20个Pod，共500个Job，共10kPod。有以下现象：<ul>
<li>Volcano的调度速度慢于另外两种调度器；</li>
<li>SCHEDULED明显滞后于CREATED，说明调度速度较慢，此时性能瓶颈为调度（且根据斜率，前期调度速度快、后期逐渐变慢）；</li>
<li>CREATED阶段性突变现象（正常情况下CREATED应该匀速增加，这里的现象说明controller会间歇性卡住一会儿）。<ul>
<li>可能的原因是Volcano会分批处理Job，在视频中的用词是“create pod in Batch”，当一批Job处理完后才会继续处理下一批Job。</li>
<li>此外，还有一个可能的影响因素是 Volcano 需要更多的webhook来创建Pod，而受限于webhook QPS（如前文所述），所以出现排队阻塞和卡顿。前期阻塞情况比后期更严重，可能是因为后期部分webhook可以复用。</li>
<li>后续还需验证该猜想。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/2025-KubeCon-A-Comparative-Analysis-8.png" alt="图8：无GangScheduling要求下，第三种benchmark测试结果"><figcaption>图8：无GangScheduling要求下，第三种benchmark测试结果</figcaption></figure><br>3. 第三种benchmark下，每个Job有500Pod，共20个Job，共10kPod。有以下现象：</p>
<ul>
<li>Volcano的调度速度仍然慢于另外两种调度器；</li>
<li>SCHEDULED仍然明显滞后于CREATED，说明调度速度较慢，此时性能瓶颈为调度（且根据斜率，前期调度速度比第二种benchmark下更慢、后期逐渐加速）；</li>
<li>不存在CREATED阶段性突变现象。<ul>
<li>和第二种benchmark的区别是Job只有20个，说明Volcano分批处理Job的粒度应该在[20,500]区间内（根据第二、三种benchmark的Job数量推断）。</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/2025-KubeCon-A-Comparative-Analysis-9.png" alt="图9：无GangScheduling要求下，第四种benchmark测试结果"><figcaption>图9：无GangScheduling要求下，第四种benchmark测试结果</figcaption></figure><br>4. 第四种benchmark下，每个Job有10kPod，共1个Job，共10kPod。</p>
<ul>
<li><p>现象与第三种benchmark类似；根据斜率，调度速度整体比较平稳。</p>
</li>
<li><p>四种情况下 Volcano 的总调度时间基本与 Job 数量成正比，说明其性能瓶颈主要由 Job 导致。</p>
</li>
</ul>
<h1 id="🏥疑问及解答"><a href="#🏥疑问及解答" class="headerlink" title="🏥疑问及解答"></a>🏥疑问及解答</h1><ol>
<li><p>K8s参数中的<code>--kube-api-qps</code>是什么意思？</p>
<ul>
<li><strong>总结</strong>：<code>--kube-api-qps</code>是Kubernetes调度器向API服务器发送请求的速率限制参数，控制调度器每秒可以向kube-apiserver发送的最大请求数量。</li>
<li><strong>参数含义</strong>：QPS（Queries Per Second）表示每秒查询次数，默认值为50，意味着调度器每秒最多可以向API服务器发送50个请求。这个限制包括所有类型的API请求，如获取节点信息、创建Pod、更新Pod状态等。</li>
<li><strong>原因说明</strong>：设置QPS限制是为了防止调度器过度占用API服务器资源，避免API服务器过载。在大规模集群中，如果调度器不受限制地向API服务器发送请求，可能会导致API服务器响应变慢或崩溃。YuniKorn设置为1000是因为它针对高吞吐量场景进行了优化，而Kueue和Volcano使用默认值50，在大量Job创建时容易达到限制。</li>
</ul>
</li>
<li><p>视频中图表的含义是什么？</p>
<ul>
<li>纵轴是事件数量，横轴是测试过程时间点。</li>
<li>斜率表示吞吐量（每秒事件数量），斜率越大说明速度越快、效率越高。</li>
</ul>
</li>
<li><p>图中Created、Scheduled 代表着什么？</p>
<ul>
<li><strong>总结</strong>：Created事件表示Pod被成功创建并提交到API服务器的时间点，Scheduled事件表示Pod被调度器成功调度到某个节点的时间点。两者之间的时间差反映了调度延迟。</li>
<li><strong>事件含义</strong>：<ul>
<li><strong>CREATED事件</strong>：当Job Controller成功创建Pod并提交到kube-apiserver时触发，表示Pod已进入待调度队列。</li>
<li><strong>SCHEDULED事件</strong>：当调度器完成Pod的节点选择并成功绑定到节点时触发，表示Pod已获得运行位置。</li>
</ul>
</li>
<li><strong>原因说明</strong>：在正常情况下，CREATED和SCHEDULED事件应该紧密跟随，时间差很小。如果SCHEDULED明显滞后于CREATED，说明调度器处理能力不足，存在调度瓶颈。如果两者差距很小但整体斜率较低，说明瓶颈在Pod创建阶段而非调度阶段。</li>
</ul>
</li>
<li><p>视频中频繁提到的 webhook 是什么？webhook QPS是什么？为什么关注这个点？</p>
<ul>
<li><strong>总结</strong>：Webhook是Kubernetes的准入控制器机制，用于在资源创建/更新时进行验证和修改。Webhook QPS限制影响调度器创建Pod的速度，可能成为性能瓶颈。</li>
<li><strong>含义</strong>：<ul>
<li><strong>Webhook</strong>：Kubernetes准入控制器的一种实现方式，当API服务器接收到资源请求时，会调用配置的webhook服务进行验证、修改或拒绝操作。调度器（如Volcano、Kueue）通常使用webhook来实现自定义的调度逻辑，如PodGroup验证、资源配额检查等。</li>
<li><strong>Webhook QPS</strong>：API服务器向webhook服务发送请求的速率限制，默认通常为50 QPS，与<code>--kube-api-qps</code>类似。</li>
</ul>
</li>
<li><strong>原因说明</strong>：调度器需要通过webhook来验证和创建Pod，当大量Job同时提交时，webhook QPS限制会导致请求排队等待，从而影响整体调度性能。Volcano需要更多的webhook调用（如PodGroup验证、资源分配等），因此更容易受到webhook QPS限制的影响，出现阶段性阻塞现象。</li>
</ul>
</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="📝参考文献"><a href="#📝参考文献" class="headerlink" title="📝参考文献"></a>📝参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.youtube.com/watch?v=njT5r3JjIaA&list=PLj6h78yzYM2MP0QhYFK8HOb8UqgbIkLMc&index=226">[1] A Comparative Analysis of Kueue, Volcano, and YuniKorn - Wei Huang, Apple &amp; Shiming Zhang, DaoCloud<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kueue.sigs.k8s.io/">[2] Kueue Documentation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/">[3] Volcano Documentation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://yunikorn.apache.org/">[4] YuniKorn Documentation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/">[5] kubelet 参数文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://cloud.tencent.com/developer/article/2210383">[6] 大规模集群仿真模拟与调度器压测方法<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[7] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度器</tag>
        <tag>K8s</tag>
        <tag>性能测试</tag>
        <tag>Volcano</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano 数据收集方法深度解析与Prometheus Histogram误差问题</title>
    <url>/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li>
<li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li>
<li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li>
<li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li>
<li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li>
<li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li>
<li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li>
<li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li>
<li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li>
<li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li>
<li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li>
<li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li>
<li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li>
<li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a>
</li>
</ol>
</blockquote>
<p>在前期的文章中，我提到了<a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="调度器性能对比分析">调度器性能对比分析</a>中一个重要论断：传统方法使用Prometheus会造成很大误差，而audit-exporter方法能够准确记录性能。当时我误以为这种差异源于数据处理阶段的Prometheus histogram统计方法，但深入分析<a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="指标采集链路">指标采集链路</a>后发现，<strong>两种方法的核心差异实际上在数据收集阶段，而非数据处理阶段</strong>。</p>
<p>本文旨在澄清这一技术细节，并深入探讨Prometheus histogram的误差机制与替代方案。</p>
<hr>
<h1 id="🎯-问题澄清：数据收集-vs-数据处理"><a href="#🎯-问题澄清：数据收集-vs-数据处理" class="headerlink" title="🎯 问题澄清：数据收集 vs 数据处理"></a>🎯 问题澄清：数据收集 vs 数据处理</h1><h2 id="1-传统Prometheus方法-vs-Audit-Exporter方法"><a href="#1-传统Prometheus方法-vs-Audit-Exporter方法" class="headerlink" title="1. 传统Prometheus方法 vs Audit-Exporter方法"></a>1. 传统Prometheus方法 vs Audit-Exporter方法</h2><h3 id="传统Prometheus方法的数据收集路径"><a href="#传统Prometheus方法的数据收集路径" class="headerlink" title="传统Prometheus方法的数据收集路径"></a>传统Prometheus方法的数据收集路径</h3><p>传统的Kubernetes调度器性能监控依赖调度器自身暴露的Prometheus指标：</p>
<pre class="mermaid">graph LR
    A[调度器内部逻辑] --&gt; B[调度器暴露metrics端点]
    B --&gt; C[Prometheus定期抓取]
    C --&gt; D[存储到TSDB]
    D --&gt; E[Grafana查询展示]</pre>

<p><strong>核心特点</strong>：</p>
<ul>
<li><strong>数据源</strong>：调度器进程内部的instrumentation代码</li>
<li><strong>时间精度</strong>：受限于调度器代码的埋点位置和精度</li>
<li><strong>数据完整性</strong>：可能遗漏调度过程中的某些阶段</li>
<li><strong>系统开销</strong>：对调度器性能有直接影响</li>
</ul>
<h3 id="Audit-Exporter方法的数据收集路径"><a href="#Audit-Exporter方法的数据收集路径" class="headerlink" title="Audit-Exporter方法的数据收集路径"></a>Audit-Exporter方法的数据收集路径</h3><p>而audit-exporter方法从kube-apiserver的审计日志中提取性能数据：</p>
<pre class="mermaid">graph LR
    A[调度器向APIServer发起请求] --&gt; B[APIServer记录审计日志]
    B --&gt; C[audit-exporter解析日志]
    C --&gt; D[转换为Prometheus指标]
    D --&gt; E[Prometheus抓取存储]
    E --&gt; F[Grafana查询展示]</pre>

<p><strong>核心特点</strong>：</p>
<ul>
<li><strong>数据源</strong>：kube-apiserver的完整请求审计记录</li>
<li><strong>时间精度</strong>：基于APIServer的高精度时间戳</li>
<li><strong>数据完整性</strong>：涵盖从请求到响应的完整生命周期</li>
<li><strong>系统开销</strong>：不影响调度器性能，仅增加APIServer审计开销</li>
</ul>
<h2 id="2-本质差异分析"><a href="#2-本质差异分析" class="headerlink" title="2. 本质差异分析"></a>2. 本质差异分析</h2><h3 id="✅-数据收集阶段的差异（核心）"><a href="#✅-数据收集阶段的差异（核心）" class="headerlink" title="✅ 数据收集阶段的差异（核心）"></a>✅ 数据收集阶段的差异（核心）</h3><p><strong>传统方法的局限性</strong>：</p>
<ol>
<li><strong>可控能力差</strong>：调度器内部的metric埋点可能无法覆盖所有关键路径，受制于代码中指标记录调用的位置和频率  </li>
<li><strong>潜在性能影响</strong>：在高负载下，调度器本身指标统计可能会影响调度性能</li>
</ol>
<p><strong>Audit-exporter方法的优势</strong>：</p>
<ol>
<li><strong>可控能力强</strong>：可以自定义捕获数据，例如本项目能监控每个API请求的完整生命周期（RequestReceived → ResponseComplete），且因为基于外部 APIServer，所以所有组件（调度器、控制器等）的请求都被统一记录</li>
<li><strong>无性能影响</strong>：基于外部 APIServer，低侵入性，不影响被监控组件的性能</li>
</ol>
<p>具体来说，通过audit日志能够精确记录关键事件：</p>
<div class="code-container" data-rel="Json"><figure class="iseeu highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">  <span class="attr">"verb"</span><span class="punctuation">:</span> <span class="string">"create"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"objectRef"</span><span class="punctuation">:</span> <span class="punctuation">{</span><span class="attr">"resource"</span><span class="punctuation">:</span> <span class="string">"pods"</span><span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"stage"</span><span class="punctuation">:</span> <span class="string">"ResponseComplete"</span><span class="punctuation">,</span> </span><br><span class="line">  <span class="attr">"stageTimestamp"</span><span class="punctuation">:</span> <span class="string">"2025-01-27T10:30:45.123456Z"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"requestReceivedTimestamp"</span><span class="punctuation">:</span> <span class="string">"2025-01-27T10:30:45.098123Z"</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></table></figure></div>

<p>通过解析这些事件，可以计算出精确的 <strong>Pod创建延迟</strong>、 <strong>调度延迟</strong> 等数据。</p>
<h3 id="❌-数据处理阶段的相似性"><a href="#❌-数据处理阶段的相似性" class="headerlink" title="❌ 数据处理阶段的相似性"></a>❌ 数据处理阶段的相似性</h3><p><strong>重要澄清</strong>：两种方法在数据处理阶段实际上是相同的！（之前我的博客中，知道数据处理方法中 histogram 会存在误差，但现在才发现这种误差两种方法都会有）</p>
<p>无论是传统方法还是audit-exporter方法，最终都会：</p>
<ol>
<li>将原始数据转换为Prometheus histogram指标</li>
<li>使用相同的bucket配置和histogram_quantile()函数</li>
<li>面临相同的线性插值误差问题</li>
</ol>
<p>因此，<strong>Prometheus histogram的误差问题在两种方法中都存在</strong>，差异并非来自数据处理阶段。</p>
<hr>
<h1 id="📊-Prometheus-Histogram误差深度解析"><a href="#📊-Prometheus-Histogram误差深度解析" class="headerlink" title="📊 Prometheus Histogram误差深度解析"></a>📊 Prometheus Histogram误差深度解析</h1><h2 id="1-Histogram工作原理"><a href="#1-Histogram工作原理" class="headerlink" title="1. Histogram工作原理"></a>1. Histogram工作原理</h2><p>Prometheus histogram通过预定义的bucket边界来统计数据分布：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 示例：调度延迟histogram配置</span></span><br><span class="line">latencyHistogram := prometheus.NewHistogram(prometheus.HistogramOpts{</span><br><span class="line">    Name: <span class="string">"scheduler_latency_seconds"</span>,</span><br><span class="line">    Buckets: []<span class="type">float64</span>{<span class="number">0.01</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">10</span>}, <span class="comment">// bucket边界</span></span><br><span class="line">})</span><br></pre></td></tr></table></figure></div>

<p>当收集到延迟数据时，每个观测值会被分配到相应的bucket中：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">观测值: 0.3秒</span><br><span class="line">↓</span><br><span class="line">累计到bucket: le="0.5", le="1", le="5", le="10", le="+Inf"</span><br></pre></td></tr></table></figure></div>

<p>其中 le 指 less，即 bucket 记录“小于 x 的数字有多少个”。</p>
<h2 id="2-线性插值误差机制"><a href="#2-线性插值误差机制" class="headerlink" title="2. 线性插值误差机制"></a>2. 线性插值误差机制</h2><h3 id="均匀分布假设的问题"><a href="#均匀分布假设的问题" class="headerlink" title="均匀分布假设的问题"></a>均匀分布假设的问题</h3><p>Prometheus使用<code>histogram_quantile()</code>函数计算百分位数时，<strong>假设每个bucket内的数据均匀分布</strong>：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Prometheus源码中的线性插值逻辑（简化）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">linearInterpolation</span><span class="params">(bucketStart, bucketEnd <span class="type">float64</span>, rank, count <span class="type">float64</span>)</span></span> <span class="type">float64</span> {</span><br><span class="line">    <span class="keyword">return</span> bucketStart + (bucketEnd-bucketStart)*rank/count</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>例子</strong>：假设我们有bucket配置<code>[0.1, 0.5, 1.0]</code>，观测到以下数据：</p>
<table>
<thead>
<tr>
<th>Bucket范围</th>
<th>累计计数</th>
<th>实际分布</th>
</tr>
</thead>
<tbody><tr>
<td>(0, 0.1]</td>
<td>10</td>
<td>均匀分布</td>
</tr>
<tr>
<td>(0.1, 0.5]</td>
<td>90</td>
<td><strong>集中在0.12秒附近</strong></td>
</tr>
<tr>
<td>(0.5, 1.0]</td>
<td>100</td>
<td>均匀分布</td>
</tr>
</tbody></table>
<p>计算P90（第90个样本）：</p>
<ul>
<li><strong>Prometheus假设</strong>：P90在(0.1, 0.5]区间内均匀分布，计算得P90 ≈ 0.5秒</li>
<li><strong>实际情况</strong>：如果80个样本都集中在0.12秒附近，真实P90 ≈ 0.12秒</li>
<li><strong>结论</strong>：存在非常大的误差（尤其当桶边界非线性时，目前看大多数情况下桶边界都是指数级增长，具体原因可能是大部分数据都非均匀分布，数据范围太大时线性分布粒度过粗）</li>
</ul>
<h2 id="3-Bucket配置的关键影响"><a href="#3-Bucket配置的关键影响" class="headerlink" title="3. Bucket配置的关键影响"></a>3. Bucket配置的关键影响</h2><h3 id="默认Bucket的问题"><a href="#默认Bucket的问题" class="headerlink" title="默认Bucket的问题"></a>默认Bucket的问题</h3><p>不同Prometheus客户端库的默认bucket配置：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Go客户端默认bucket</span></span><br><span class="line">prometheus.DefBuckets = []<span class="type">float64</span>{</span><br><span class="line">    <span class="number">.005</span>, <span class="number">.01</span>, <span class="number">.025</span>, <span class="number">.05</span>, <span class="number">.1</span>, <span class="number">.25</span>, <span class="number">.5</span>, <span class="number">1</span>, <span class="number">2.5</span>, <span class="number">5</span>, <span class="number">10</span>,</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// Python客户端默认bucket  </span></span><br><span class="line">DEFAULT_BUCKETS = (</span><br><span class="line">    <span class="number">.005</span>, <span class="number">.01</span>, <span class="number">.025</span>, <span class="number">.05</span>, <span class="number">.075</span>, <span class="number">.1</span>, <span class="number">.25</span>, <span class="number">.5</span>, <span class="number">.75</span>, </span><br><span class="line">    <span class="number">1.0</span>, <span class="number">2.5</span>, <span class="number">5.0</span>, <span class="number">7.5</span>, <span class="number">10.0</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div>

<p>这些默认配置的问题：</p>
<ol>
<li><strong>覆盖范围过广</strong>：从5ms到10s，对特定应用场景分辨率不足</li>
<li><strong>分布不均</strong>：低延迟区间密集，高延迟区间稀疏</li>
</ol>
<h3 id="可能的备选Bucket策略"><a href="#可能的备选Bucket策略" class="headerlink" title="可能的备选Bucket策略"></a>可能的备选Bucket策略</h3><p><strong>1. 基于SLO设计</strong>：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 假设SLO为P95 &lt; 500ms, P99 &lt; 1s</span></span><br><span class="line">sloBuckets := []<span class="type">float64</span>{</span><br><span class="line">    <span class="number">0.050</span>, <span class="number">0.100</span>, <span class="number">0.200</span>, <span class="number">0.350</span>, <span class="comment">// P95周围密集采样</span></span><br><span class="line">    <span class="number">0.500</span>, <span class="number">0.650</span>, <span class="number">0.800</span>, <span class="number">0.950</span>, <span class="comment">// P99周围密集采样  </span></span><br><span class="line">    <span class="number">1.000</span>, <span class="number">2.000</span>, <span class="number">5.000</span>,        <span class="comment">// 异常情况覆盖</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>2. 对数分布</strong>：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 指数增长，适合跨多个数量级的指标</span></span><br><span class="line">logBuckets := []<span class="type">float64</span>{</span><br><span class="line">    <span class="number">0.001</span>, <span class="number">0.002</span>, <span class="number">0.005</span>, <span class="number">0.01</span>, <span class="number">0.02</span>, <span class="number">0.05</span>, </span><br><span class="line">    <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>,</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>3. 动态调整</strong>：某些高级方案支持根据实际数据分布动态调整bucket（VictoriaMetrics似乎有这个功能）</p>
<hr>
<h1 id="🔧-Histogram替代方案与优化"><a href="#🔧-Histogram替代方案与优化" class="headerlink" title="🔧 Histogram替代方案与优化"></a>🔧 Histogram替代方案与优化</h1><h2 id="1-Summary指标"><a href="#1-Summary指标" class="headerlink" title="1. Summary指标"></a>1. Summary指标</h2><p>Prometheus提供了Summary类型作为histogram的替代：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line">summary := prometheus.NewSummary(prometheus.SummaryOpts{</span><br><span class="line">    Name: <span class="string">"latency_seconds"</span>,</span><br><span class="line">    Objectives: <span class="keyword">map</span>[<span class="type">float64</span>]<span class="type">float64</span>{</span><br><span class="line">        <span class="number">0.5</span>: <span class="number">0.05</span>,  <span class="comment">// P50误差±5%</span></span><br><span class="line">        <span class="number">0.9</span>: <span class="number">0.01</span>,  <span class="comment">// P90误差±1% </span></span><br><span class="line">        <span class="number">0.99</span>: <span class="number">0.001</span>, <span class="comment">// P99误差±0.1%</span></span><br><span class="line">    },</span><br><span class="line">})</span><br></pre></td></tr></table></figure></div>

<p><strong>优势</strong>：</p>
<ul>
<li>客户端精确计算百分位数，无插值误差</li>
<li>内存占用相对固定</li>
<li>查询性能好</li>
</ul>
<p><strong>劣势</strong>：</p>
<ul>
<li><strong>无法聚合</strong>：不能跨实例计算全局百分位数</li>
<li><strong>预定义百分位</strong>：无法在查询时动态计算其他百分位数</li>
<li><strong>客户端开销</strong>：需要维护滑动窗口和排序</li>
</ul>
<hr>
<h1 id="🔚-总结"><a href="#🔚-总结" class="headerlink" title="🔚 总结"></a>🔚 总结</h1><p>通过本文的深入分析，我们可以得出以下关键结论：</p>
<h2 id="核心澄清"><a href="#核心澄清" class="headerlink" title="核心澄清"></a>核心澄清</h2><ol>
<li><p><strong>数据收集vs数据处理</strong>：audit-exporter方法与传统Prometheus方法的主要差异在于<strong>数据收集阶段</strong>（数据源和精度），而非数据处理阶段（histogram计算）。</p>
</li>
<li><p><strong>Histogram误差本质</strong>：Prometheus histogram的误差源于bucket内均匀分布假设与实际数据分布的差异，这在两种方法中都存在。默认bucket配置可能不匹配实际应用的延迟分布，需要根据SLO定制。</p>
</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="📝参考文献"><a href="#📝参考文献" class="headerlink" title="📝参考文献"></a>📝参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://cloud.tencent.com/developer/article/2210383">[1] 大规模集群仿真模拟与调度器压测方法<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://hulining.gitbook.io/prometheus/practices/histograms#errors-of-quantile-estimation">[2] Prometheus中文文档 - Histogram and Summary<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>%E3%80%82)</p>
<p><a class="link" href="https://mp.weixin.qq.com/s/5Y_pCPIJcRpIlqhdtb3XBw">[3] 蓝胖子编程梦 - prometheus描点原理<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.cnblogs.com/hobbybear/p/17531488.html">[4] 蓝胖子编程梦 - prometheus Histogram 统计原理<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[5] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://github.com/wzshiming/kube-apiserver-audit-exporter">[6] Github - kube-apiserver-audit-exporter<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> </p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>K8s</tag>
        <tag>性能测试</tag>
        <tag>监控</tag>
        <tag>Volcano</tag>
        <tag>Histogram</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano 自定义镜像与二次压测</title>
    <url>/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li>
<li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li>
<li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li>
<li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li>
<li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li>
<li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li>
<li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li>
<li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li>
<li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li>
<li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li>
<li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li>
<li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li>
<li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li>
<li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a>
</li>
</ol>
</blockquote>
<p>（在未来）优化时，在调度器源码中加入 <strong>新算法</strong> 后，我们最关心的就是：</p>
<blockquote>
<p><em>「我改的逻辑到底是否提升了吞吐量？」</em></p>
</blockquote>
<p>本篇将手把手演示 <strong>本地构建自定义 Volcano Scheduler 镜像 → 替换到 Kind 集群 → 重跑 Benchmark</strong> 的全流程，帮助大家 <strong>快速验证改动效果</strong>。</p>
<hr>
<h1 id="1️⃣-Fork-amp-修改源码"><a href="#1️⃣-Fork-amp-修改源码" class="headerlink" title="1️⃣ Fork & 修改源码"></a>1️⃣ Fork &amp; 修改源码</h1><ol>
<li>Fork <a class="link" href="https://github.com/volcano-sh/volcano">Volcano<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 仓库；</li>
<li>切分支 <code>feat/my-algorithm</code>；</li>
<li>在 <code>pkg/scheduler/plugins/</code> 新增/修改调度逻辑；</li>
<li>本地单元测试通过后，进入构建阶段。</li>
</ol>
<blockquote>
<p><strong>示例改动</strong>：在 <code>allocate.go</code> 打印每次 <code>selectBestNode</code> 结果。</p>
</blockquote>
<hr>
<h1 id="2️⃣-本地构建镜像-amp-推送-Registry"><a href="#2️⃣-本地构建镜像-amp-推送-Registry" class="headerlink" title="2️⃣ 本地构建镜像 & 推送 Registry"></a>2️⃣ 本地构建镜像 &amp; 推送 Registry</h1><p>项目脚本已自带 <strong>本地 5000 端口 Registry</strong>，无需额外安装。关键脚本：</p>
<div class="code-container" data-rel="Sh"><figure class="iseeu highlight sh"><figcaption><span>hack/local-registry-with-load-images.sh:17:33</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create local registry container if not running</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="string">"<span class="subst">$(docker inspect -f '{{.State.Running}}' <span class="string">"<span class="variable">${reg_name}</span>"</span> 2&gt;/dev/null || true)</span>"</span> != <span class="string">'true'</span> ]]; <span class="keyword">then</span></span><br><span class="line">  target_image=<span class="string">"docker.io/library/registry:2.8.3"</span></span><br><span class="line">  <span class="keyword">if</span> [[ <span class="variable">${IMAGE_PREFIX}</span> != <span class="string">""</span> ]] &amp;&amp; ! docker image inspect <span class="string">"<span class="variable">${target_image}</span>"</span> &amp;&gt;/dev/null; <span class="keyword">then</span></span><br><span class="line">    docker pull <span class="string">"<span class="variable">${IMAGE_PREFIX}</span><span class="variable">${target_image}</span>"</span></span><br><span class="line">    docker tag <span class="string">"<span class="variable">${IMAGE_PREFIX}</span><span class="variable">${target_image}</span>"</span> <span class="string">"<span class="variable">${target_image}</span>"</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line">  docker run \</span><br><span class="line">    -d \</span><br><span class="line">    --restart=always \</span><br><span class="line">    -p <span class="string">"127.0.0.1:<span class="variable">${reg_port}</span>:5000"</span> \</span><br><span class="line">    --network bridge \</span><br><span class="line">    --name <span class="string">"<span class="variable">${reg_name}</span>"</span> \</span><br><span class="line">    -v <span class="string">"<span class="variable">${ROOT_DIR}</span>/registry-data:/var/lib/registry"</span> \</span><br><span class="line">    <span class="string">"<span class="variable">${target_image}</span>"</span> || :</span><br><span class="line">  <span class="built_in">sleep</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></div>

<p>构建 &amp; 推送命令：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 假设当前位于 volcano 仓库根目录</span></span><br><span class="line"><span class="built_in">export</span> TAG=dev</span><br><span class="line">make -C build scheduler-image \</span><br><span class="line">  IMAGE_REPO=kind-registry:5000/volcano-scheduler \</span><br><span class="line">  IMAGE_TAG=<span class="variable">${TAG}</span></span><br><span class="line"></span><br><span class="line">docker push kind-registry:5000/volcano-scheduler:<span class="variable">${TAG}</span></span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>若在国内环境，可通过 <code>IMAGE_PREFIX</code> 拉取基础镜像，详见上文 Metrics 篇。</p>
</blockquote>
<p>Mermaid 流程一览：</p>
<pre class="mermaid">graph TD;
  A[源码改动] --&gt; B("Docker build")
  B --&gt; C("本地镜像 kind-registry:5000")
  C --&gt; D("kustomize build → kubectl apply")
  D --&gt; E("Kind 集群调度性能测试")</pre>

<hr>
<h1 id="3️⃣-替换-Deployment-中的镜像"><a href="#3️⃣-替换-Deployment-中的镜像" class="headerlink" title="3️⃣ 替换 Deployment 中的镜像"></a>3️⃣ 替换 Deployment 中的镜像</h1><p>调度器 Deployment 位于：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><figcaption><span>schedulers/volcano/volcano-scheduler/deployment.yaml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">kind-registry:5000/docker.io/volcanosh/vc-scheduler:v1.11.0</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">volcano-scheduler</span></span><br></pre></td></tr></table></figure></div>

<p>只需把 <code>image:</code> 行替换为新镜像：</p>
<div class="code-container" data-rel="Diff"><figure class="iseeu highlight diff"><table><tr><td class="code"><pre><span class="line"><span class="deletion">- image: kind-registry:5000/docker.io/volcanosh/vc-scheduler:v1.11.0</span></span><br><span class="line"><span class="addition">+ image: kind-registry:5000/volcano-scheduler:dev</span></span><br></pre></td></tr></table></figure></div>

<hr>
<h1 id="4️⃣-重新压测-amp-对比指标"><a href="#4️⃣-重新压测-amp-对比指标" class="headerlink" title="4️⃣ 重新压测 & 对比指标"></a>4️⃣ 重新压测 &amp; 对比指标</h1><ol>
<li><strong>启动集群 &amp; 压测</strong></li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">make prepare-volcano start-volcano \</span><br><span class="line">  IMAGE_PREFIX= \</span><br><span class="line">  NODES_SIZE=1000 QUEUES_SIZE=1 JOBS_SIZE_PER_QUEUE=500 PODS_SIZE_PER_JOB=20</span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li><strong>结束测试 &amp; 保存面板</strong></li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">make end-volcano</span><br></pre></td></tr></table></figure></div>

<ol start="3">
<li><strong>查看结果目录</strong>（假设时间戳 <code>1690300000</code>）：</li>
</ol>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">results/</span><br><span class="line">  └── 1690300000/</span><br><span class="line">      ├── audit.log</span><br><span class="line">      ├── metrics.json</span><br><span class="line">      └── panels/</span><br><span class="line">          ├── panel-1.png   # CREATED 曲线</span><br><span class="line">          ├── panel-2.png   # SCHEDULED 曲线</span><br><span class="line">          └── panel-3.png   # RUNNING 曲线</span><br></pre></td></tr></table></figure></div>



<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>


<p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.youtube.com/watch?v=njT5r3JjIaA&list=PLj6h78yzYM2MP0QhYFK8HOb8UqgbIkLMc&index=226">[2] A Comparative Analysis of Kueue, Volcano, and YuniKorn - Wei Huang, Apple &amp; Shiming Zhang, DaoCloud<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/audit/">[3] Kubernetes官方文档 - 审计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Policy">[4] Kubernetes官方文档 - 审计Policy配置参考<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>K8s</tag>
        <tag>性能测试</tag>
        <tag>Volcano</tag>
        <tag>镜像定制</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</title>
    <url>/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li>
<li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li>
<li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li>
<li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li>
<li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li>
<li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li>
<li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li>
<li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li>
<li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li>
<li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li>
<li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li>
<li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li>
<li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li>
<li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a>
</li>
</ol>
</blockquote>
<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="上一篇博客">上一篇博客</a>中，我们分析了本地环境下的调度器性能测试结果，发现了一些有趣的现象：在某些测试场景下，CREATED事件会出现阶段性突变，而SCHEDULED事件则相对平稳。这种现象可能与调度器的enqueue机制有关。</p>
<p>本文详细介绍了如何禁用Volcano调度器的enqueue功能，通过对比分析来验证我们的猜测：<strong>enqueue可能会提前判断资源是否充足，从而在资源不足时限制Pod的创建，进而影响调度性能</strong>。</p>
<p>通过禁用enqueue功能，我们可以观察调度器在资源分配阶段的纯粹性能表现，为调度器性能优化提供重要参考。</p>
<h1 id="🧠Volcano调度器enqueue功能简介"><a href="#🧠Volcano调度器enqueue功能简介" class="headerlink" title="🧠Volcano调度器enqueue功能简介"></a>🧠Volcano调度器enqueue功能简介</h1><h2 id="什么是enqueue？"><a href="#什么是enqueue？" class="headerlink" title="什么是enqueue？"></a>什么是enqueue？</h2><p><strong>enqueue</strong>是Volcano调度器调度流程中的一个重要阶段，主要负责：</p>
<ol>
<li><strong>作业入队管理</strong>：将提交的Job添加到调度队列中</li>
<li><strong>优先级排序</strong>：根据Job的优先级、提交时间等因素进行排序</li>
<li><strong>资源预检查</strong>：提前判断集群资源是否满足Job需求</li>
<li><strong>队列容量控制</strong>：管理队列的容量限制和准入控制</li>
</ol>
<h2 id="enqueue对调度性能的影响"><a href="#enqueue对调度性能的影响" class="headerlink" title="enqueue对调度性能的影响"></a>enqueue对调度性能的影响</h2><p>基于<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="前期测试结果">前期测试结果</a>的分析，我们猜测enqueue可能会：</p>
<ul>
<li><strong>提前资源判断</strong>：在Pod创建前就判断资源是否充足</li>
<li><strong>限制Pod创建</strong>：当资源不足时，限制新Pod的创建速度</li>
<li><strong>影响CREATED事件</strong>：导致CREATED事件出现阶段性突变</li>
<li><strong>调度性能瓶颈</strong>：在某些场景下成为整体性能的瓶颈</li>
</ul>
<h2 id="Volcano调度器的完整调度流程"><a href="#Volcano调度器的完整调度流程" class="headerlink" title="Volcano调度器的完整调度流程"></a>Volcano调度器的完整调度流程</h2><pre class="mermaid">graph LR
    A[Job提交] --&gt; B[enqueue]
    B --&gt; C[allocate]
    C --&gt; D[backfill]
    D --&gt; E[reclaim]
    E --&gt; F[preempt]
    
    B1[enqueue阶段] --&gt; B2[队列管理]
    B1 --&gt; B3[优先级排序]
    B1 --&gt; B4[资源预检查]
    
    C1[allocate阶段] --&gt; C2[资源分配]
    C1 --&gt; C3[节点选择]
    C1 --&gt; C4[Pod绑定]</pre>

<h1 id="🔧如何禁用Volcano的enqueue功能"><a href="#🔧如何禁用Volcano的enqueue功能" class="headerlink" title="🔧如何禁用Volcano的enqueue功能"></a>🔧如何禁用Volcano的enqueue功能</h1><h2 id="1-修改调度器配置文件"><a href="#1-修改调度器配置文件" class="headerlink" title="1. 修改调度器配置文件"></a>1. 修改调度器配置文件</h2><h3 id="1-1-修改主配置文件"><a href="#1-1-修改主配置文件" class="headerlink" title="1.1 修改主配置文件"></a>1.1 修改主配置文件</h3><p>编辑 <code>schedulers/volcano/scheduler.conf</code> 文件：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 原始配置</span></span><br><span class="line">actions: <span class="string">"enqueue, allocate, backfill"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改为（移除enqueue）</span></span><br><span class="line">actions: <span class="string">"allocate, backfill"</span></span><br></pre></td></tr></table></figure></div>

<h3 id="1-2-修改测试配置文件"><a href="#1-2-修改测试配置文件" class="headerlink" title="1.2 修改测试配置文件"></a>1.2 修改测试配置文件</h3><p>编辑 <code>test/volcano/init.yaml</code> 文件：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 原始配置</span></span><br><span class="line"><span class="attr">actions:</span> <span class="string">"enqueue, allocate,#<span class="template-variable">{{ if .preemption }}</span> preempt,#<span class="template-variable">{{ end }}</span> backfill, reclaim"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改为（移除enqueue）</span></span><br><span class="line"><span class="attr">actions:</span> <span class="string">"allocate,#<span class="template-variable">{{ if .preemption }}</span> preempt,#<span class="template-variable">{{ end }}</span> backfill, reclaim"</span></span><br></pre></td></tr></table></figure></div>


<h2 id="2-重新部署Volcano调度器"><a href="#2-重新部署Volcano调度器" class="headerlink" title="2. 重新部署Volcano调度器"></a>2. 重新部署Volcano调度器</h2><p>修改配置后，需要重新部署调度器：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 重新构建和部署</span></span><br><span class="line">make up-volcano</span><br></pre></td></tr></table></figure></div>

<h1 id="🚀如何手动配置测试环境"><a href="#🚀如何手动配置测试环境" class="headerlink" title="🚀如何手动配置测试环境"></a>🚀如何手动配置测试环境</h1><h2 id="1-启动Volcano测试环境"><a href="#1-启动Volcano测试环境" class="headerlink" title="1. 启动Volcano测试环境"></a>1. 启动Volcano测试环境</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启动完整的Volcano测试环境</span></span><br><span class="line">make prepare-volcano</span><br></pre></td></tr></table></figure></div>

<p>这个命令会依次执行：</p>
<ul>
<li><code>make up-volcano</code>：创建Kind集群并部署Volcano</li>
<li><code>make wait-volcano</code>：等待所有服务就绪</li>
<li><code>make test-init-volcano</code>：初始化测试环境，创建虚拟节点</li>
</ul>
<h2 id="2-验证环境状态"><a href="#2-验证环境状态" class="headerlink" title="2. 验证环境状态"></a>2. 验证环境状态</h2><h3 id="2-1-检查集群状态"><a href="#2-1-检查集群状态" class="headerlink" title="2.1 检查集群状态"></a>2.1 检查集群状态</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get nodes -o wide</span><br></pre></td></tr></table></figure></div>

<p>应该看到：</p>
<ul>
<li><code>volcano-control-plane</code>：控制平面节点</li>
<li><code>node-0</code>、<code>node-1</code>等：虚拟KWOK节点</li>
</ul>
<h3 id="2-2-检查Volcano服务状态"><a href="#2-2-检查Volcano服务状态" class="headerlink" title="2.2 检查Volcano服务状态"></a>2.2 检查Volcano服务状态</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get pods -n volcano-system</span><br></pre></td></tr></table></figure></div>

<p>确保所有Pod都处于Running状态。</p>
<h3 id="2-3-检查虚拟节点标签"><a href="#2-3-检查虚拟节点标签" class="headerlink" title="2.3 检查虚拟节点标签"></a>2.3 检查虚拟节点标签</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get nodes --show-labels | grep node-</span><br></pre></td></tr></table></figure></div>

<p>确保虚拟节点有正确的标签：<code>type=kwok</code></p>
<h1 id="🔍如何验证enqueue是否被成功禁用"><a href="#🔍如何验证enqueue是否被成功禁用" class="headerlink" title="🔍如何验证enqueue是否被成功禁用"></a>🔍如何验证enqueue是否被成功禁用</h1><h2 id="1-检查ConfigMap配置"><a href="#1-检查ConfigMap配置" class="headerlink" title="1. 检查ConfigMap配置"></a>1. 检查ConfigMap配置</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get configmap -n volcano-system volcano-scheduler-configmap -o yaml</span><br></pre></td></tr></table></figure></div>

<p><strong>期望结果</strong>：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">volcano-scheduler.conf:</span> <span class="string">"actions: \"allocate, backfill, reclaim\"\n..."</span></span><br></pre></td></tr></table></figure></div>

<p><strong>关键点</strong>：配置中应该没有<code>enqueue</code>，只有<code>allocate, backfill, reclaim</code>。</p>
<h2 id="2-检查调度器启动日志"><a href="#2-检查调度器启动日志" class="headerlink" title="2. 检查调度器启动日志"></a>2. 检查调度器启动日志</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl logs -n volcano-system deployment/volcano-scheduler --since=1h | grep <span class="string">"Successfully loaded"</span></span><br></pre></td></tr></table></figure></div>

<p><strong>期望结果</strong>：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">Successfully loaded Scheduler conf, actions: [allocate backfill reclaim]</span><br></pre></td></tr></table></figure></div>

<p><strong>关键点</strong>：日志中应该显示<code>actions: [allocate backfill reclaim]</code>，没有enqueue。</p>
<h2 id="3-检查实时调度日志"><a href="#3-检查实时调度日志" class="headerlink" title="3. 检查实时调度日志"></a>3. 检查实时调度日志</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl logs -n volcano-system deployment/volcano-scheduler -f | grep -E <span class="string">"(enqueue|allocate|backfill)"</span></span><br></pre></td></tr></table></figure></div>

<p><strong>期望结果</strong>：应该只看到<code>allocate</code>和<code>backfill</code>相关的日志，没有<code>enqueue</code>相关的日志。</p>
<h1 id="🧪如何执行性能测试"><a href="#🧪如何执行性能测试" class="headerlink" title="🧪如何执行性能测试"></a>🧪如何执行性能测试</h1><h2 id="1-运行批处理作业测试"><a href="#1-运行批处理作业测试" class="headerlink" title="1. 运行批处理作业测试"></a>1. 运行批处理作业测试</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用小规模参数进行测试</span></span><br><span class="line">make start-volcano QUEUES_SIZE=1 JOBS_SIZE_PER_QUEUE=20 PODS_SIZE_PER_JOB=500</span><br></pre></td></tr></table></figure></div>

<p><strong>参数说明</strong>：</p>
<ul>
<li><code>QUEUES_SIZE=1</code>：创建1个队列</li>
<li><code>JOBS_SIZE_PER_QUEUE=20</code>：每个队列20个Job</li>
<li><code>PODS_SIZE_PER_JOB=500</code>：每个Job包含500个Pod</li>
<li><strong>总计</strong>：20个Job × 500个Pod = 10,000个Pod</li>
</ul>
<h2 id="2-测试执行过程"><a href="#2-测试执行过程" class="headerlink" title="2. 测试执行过程"></a>2. 测试执行过程</h2><p>测试程序会：</p>
<ol>
<li><strong>创建队列</strong>：<code>test-queue-long-term-research-0</code></li>
<li><strong>创建Job</strong>：20个Volcano Job</li>
<li><strong>创建Pod</strong>：每个Job创建500个Pod</li>
<li><strong>执行调度</strong>：Volcano调度器分配资源</li>
<li><strong>收集结果</strong>：记录CREATED和SCHEDULED事件</li>
</ol>
<h2 id="3-监控测试进度"><a href="#3-监控测试进度" class="headerlink" title="3. 监控测试进度"></a>3. 监控测试进度</h2><h3 id="3-1-查看Job状态"><a href="#3-1-查看Job状态" class="headerlink" title="3.1 查看Job状态"></a>3.1 查看Job状态</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看Volcano Job（注意：不是标准Kubernetes Job）</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get vcjob -A</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者使用完整API</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get jobs.batch.volcano.sh -A</span><br></pre></td></tr></table></figure></div>

<h3 id="3-2-查看Pod状态"><a href="#3-2-查看Pod状态" class="headerlink" title="3.2 查看Pod状态"></a>3.2 查看Pod状态</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看所有Pod</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get pods -A | grep volcano-job</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看特定Job的Pod</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get pods -l job-name=volcano-job-long-term-research-0-1</span><br></pre></td></tr></table></figure></div>

<h3 id="3-3-查看调度器日志"><a href="#3-3-查看调度器日志" class="headerlink" title="3.3 查看调度器日志"></a>3.3 查看调度器日志</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 实时监控调度过程</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl logs -n volcano-system deployment/volcano-scheduler -f | grep -E <span class="string">"(Binding|allocate|task)"</span></span><br></pre></td></tr></table></figure></div>

<h1 id="📊如何验证测试是否正常执行"><a href="#📊如何验证测试是否正常执行" class="headerlink" title="📊如何验证测试是否正常执行"></a>📊如何验证测试是否正常执行</h1><h2 id="1-检查测试结果"><a href="#1-检查测试结果" class="headerlink" title="1. 检查测试结果"></a>1. 检查测试结果</h2><h3 id="1-1-查看测试程序输出"><a href="#1-1-查看测试程序输出" class="headerlink" title="1.1 查看测试程序输出"></a>1.1 查看测试程序输出</h3><p>测试完成后，应该看到类似输出：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">=== RUN   TestBatchJob</span><br><span class="line">--- PASS: TestBatchJob (40.05s)</span><br><span class="line">PASS</span><br></pre></td></tr></table></figure></div>

<h3 id="1-2-检查Job和Pod状态"><a href="#1-2-检查Job和Pod状态" class="headerlink" title="1.2 检查Job和Pod状态"></a>1.2 检查Job和Pod状态</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查Job状态</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get vcjob -o wide</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查Pod状态分布</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get pods -A | grep volcano-job | awk <span class="string">'{print $3}'</span> | <span class="built_in">sort</span> | <span class="built_in">uniq</span> -c</span><br></pre></td></tr></table></figure></div>

<p><strong>期望结果</strong>：</p>
<ul>
<li>大部分Pod应该处于<code>Completed</code>状态</li>
<li>少量Pod可能处于<code>Running</code>或<code>Pending</code>状态</li>
<li>没有Pod处于<code>Failed</code>状态</li>
</ul>
<h2 id="2-验证调度行为"><a href="#2-验证调度行为" class="headerlink" title="2. 验证调度行为"></a>2. 验证调度行为</h2><h3 id="2-1-检查Pod调度位置"><a href="#2-1-检查Pod调度位置" class="headerlink" title="2.1 检查Pod调度位置"></a>2.1 检查Pod调度位置</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看Pod被调度到哪些节点</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl get pods -A -o wide | grep volcano-job | awk <span class="string">'{print $1, $2, $8}'</span></span><br></pre></td></tr></table></figure></div>

<p><strong>期望结果</strong>：Pod应该被调度到虚拟节点（如<code>node-0</code>），而不是控制平面节点。</p>
<h3 id="2-2-检查资源分配"><a href="#2-2-检查资源分配" class="headerlink" title="2.2 检查资源分配"></a>2.2 检查资源分配</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看节点资源使用情况</span></span><br><span class="line">KUBECONFIG=./clusters/volcano/kubeconfig.yaml kubectl describe node node-0</span><br></pre></td></tr></table></figure></div>

<h2 id="3-分析调度性能"><a href="#3-分析调度性能" class="headerlink" title="3. 分析调度性能"></a>3. 分析调度性能</h2><h3 id="3-1-对比enqueue启用-禁用的差异"><a href="#3-1-对比enqueue启用-禁用的差异" class="headerlink" title="3.1 对比enqueue启用/禁用的差异"></a>3.1 对比enqueue启用/禁用的差异</h3><p><strong>启用enqueue时</strong>：</p>
<ul>
<li>CREATED事件可能出现阶段性突变</li>
<li>SCHEDULED事件相对平稳</li>
<li>整体调度时间较长</li>
</ul>
<p><strong>禁用enqueue后</strong>：</p>
<ul>
<li>CREATED事件应该更加平稳</li>
<li>SCHEDULED事件可能成为瓶颈</li>
<li>整体调度时间可能缩短</li>
</ul>
<h3 id="3-2-关键指标对比"><a href="#3-2-关键指标对比" class="headerlink" title="3.2 关键指标对比"></a>3.2 关键指标对比</h3><table>
<thead>
<tr>
<th>指标</th>
<th>启用enqueue</th>
<th>禁用enqueue</th>
<th>差异分析</th>
</tr>
</thead>
<tbody><tr>
<td>CREATED事件曲线</td>
<td>阶段性突变</td>
<td>相对平稳</td>
<td>enqueue的资源预检查影响</td>
</tr>
<tr>
<td>SCHEDULED事件曲线</td>
<td>相对平稳</td>
<td>可能成为瓶颈</td>
<td>直接进入资源分配阶段</td>
</tr>
<tr>
<td>整体调度时间</td>
<td>较长</td>
<td>可能较短</td>
<td>跳过队列管理阶段</td>
</tr>
<tr>
<td>资源利用率</td>
<td>较高</td>
<td>可能较低</td>
<td>缺乏资源预优化</td>
</tr>
</tbody></table>
<h1 id="🧹如何清理测试环境"><a href="#🧹如何清理测试环境" class="headerlink" title="🧹如何清理测试环境"></a>🧹如何清理测试环境</h1><h2 id="1-停止测试"><a href="#1-停止测试" class="headerlink" title="1. 停止测试"></a>1. 停止测试</h2><p>如果测试还在运行，可以按<code>Ctrl+C</code>停止。</p>
<h2 id="2-清理测试环境"><a href="#2-清理测试环境" class="headerlink" title="2. 清理测试环境"></a>2. 清理测试环境</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 清理Volcano测试环境</span></span><br><span class="line">make down-volcano</span><br></pre></td></tr></table></figure></div>

<p>这个命令会：</p>
<ul>
<li>删除所有测试Pod和Job</li>
<li>销毁Kind集群</li>
<li>清理相关资源</li>
</ul>
<h2 id="3-验证清理结果"><a href="#3-验证清理结果" class="headerlink" title="3. 验证清理结果"></a>3. 验证清理结果</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查集群是否已销毁</span></span><br><span class="line">docker ps | grep volcano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查相关目录是否清理</span></span><br><span class="line"><span class="built_in">ls</span> -la clusters/volcano/</span><br></pre></td></tr></table></figure></div>

<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/actions/">[2] Volcano Documentation - Scheduler Actions Enqueue<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://github.com/volcano-sh/volcano/blob/master/docs/user-guide/how_to_configure_scheduler.md">[3] Volcano GitHub - How to Configure Scheduler<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a href="!--swig%EF%BF%BC39--">[4] <a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></a></p>
<p><a href="!--swig%EF%BF%BC41--">[5] <a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></a> </p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度器</tag>
        <tag>K8s</tag>
        <tag>性能测试</tag>
        <tag>Volcano</tag>
        <tag>enqueue</tag>
        <tag>调度优化</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</title>
    <url>/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li>
<li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li>
<li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li>
<li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li>
<li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li>
<li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li>
<li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li>
<li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li>
<li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li>
<li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li>
<li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li>
<li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li>
<li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li>
<li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a>
</li>
</ol>
</blockquote>
<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地环境测试结果与视频对比分析">本地环境测试结果与视频对比分析</a>中，我们发现本地测试结果与KubeCon技术分享视频中的结果存在显著差异。虽然整体趋势基本一致，但在某些测试场景下，本地测试的CREATED事件曲线、SCHEDULED事件表现与视频预期不符。</p>
<p>为了深入分析这些差异的原因，我们提出了五种可能影响实验效果的猜想，并依次进行了系统性的实验验证。本文总结了这些猜想的验证过程、实验结果和最终结论，为Volcano调度器的性能优化提供了重要参考。</p>
<h1 id="🔍问题背景回顾"><a href="#🔍问题背景回顾" class="headerlink" title="🔍问题背景回顾"></a>🔍问题背景回顾</h1><h2 id="1-本地测试与视频结果差异"><a href="#1-本地测试与视频结果差异" class="headerlink" title="1. 本地测试与视频结果差异"></a>1. 本地测试与视频结果差异</h2><p>根据<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="前期分析">前期分析</a>，我们发现了以下主要差异：</p>
<table>
<thead>
<tr>
<th>测试场景</th>
<th>视频预期</th>
<th>本地实际</th>
<th>差异程度</th>
</tr>
</thead>
<tbody><tr>
<td><strong>10K Jobs × 1 Pod</strong></td>
<td>CREATED阶段瓶颈严重</td>
<td>✅ 符合预期</td>
<td>基本一致</td>
</tr>
<tr>
<td><strong>500 Jobs × 20 Pods</strong></td>
<td>CREATED阶段性突变</td>
<td>⚠️ 部分符合</td>
<td>中等差异</td>
</tr>
<tr>
<td><strong>20 Jobs × 500 Pods</strong></td>
<td>调度速度平稳</td>
<td>❌ 出现突变</td>
<td>显著差异</td>
</tr>
<tr>
<td><strong>1 Job × 10K Pods</strong></td>
<td>调度速度平稳</td>
<td>❌ 出现突变</td>
<td>显著差异</td>
</tr>
</tbody></table>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/2025-KubeCon-A-Comparative-Analysis-5.png" alt="图1：性能测试中的参数配置"><figcaption>图1：性能测试中的参数配置</figcaption></figure></p>
<h2 id="2-差异现象分析"><a href="#2-差异现象分析" class="headerlink" title="2. 差异现象分析"></a>2. 差异现象分析</h2><p>这些差异主要表现为：</p>
<ol>
<li><strong>CREATED事件异常</strong>：在benchmark3和benchmark4中，CREATED事件出现阶段性突变，与视频中的平稳增长不符</li>
<li><strong>Pod创建数量不足</strong>：在某些测试中，实际创建的Pod数量远少于预期的10,000个</li>
<li><strong>调度性能瓶颈</strong>：调度器性能表现与预期存在较大差距</li>
</ol>
<h1 id="🧪五种猜想及其验证实验"><a href="#🧪五种猜想及其验证实验" class="headerlink" title="🧪五种猜想及其验证实验"></a>🧪五种猜想及其验证实验</h1><h2 id="猜想1：enqueue功能可能是性能瓶颈"><a href="#猜想1：enqueue功能可能是性能瓶颈" class="headerlink" title="猜想1：enqueue功能可能是性能瓶颈"></a>猜想1：enqueue功能可能是性能瓶颈</h2><h3 id="1-1-猜想依据"><a href="#1-1-猜想依据" class="headerlink" title="1.1 猜想依据"></a>1.1 猜想依据</h3><p>基于<a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="视频分析">视频分析</a>，我们猜测enqueue阶段可能会：</p>
<ul>
<li><strong>提前判断资源</strong>：在Pod创建前就判断资源是否充足</li>
<li><strong>限制Pod创建</strong>：当资源不足时，限制新Pod的创建速度</li>
<li><strong>影响CREATED事件</strong>：导致CREATED事件出现阶段性突变</li>
</ul>
<h3 id="1-2-实验设计"><a href="#1-2-实验设计" class="headerlink" title="1.2 实验设计"></a>1.2 实验设计</h3><p>我们通过<a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="禁用enqueue功能">禁用enqueue功能</a>来验证这一猜想：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改调度器配置，移除enqueue阶段</span></span><br><span class="line">actions: <span class="string">"allocate, backfill, reclaim"</span>  <span class="comment"># 原始：actions: "enqueue, allocate, backfill"</span></span><br></pre></td></tr></table></figure></div>

<h3 id="1-3-实验结果"><a href="#1-3-实验结果" class="headerlink" title="1.3 实验结果"></a>1.3 实验结果</h3><h4 id="第一种-Benchmark：10K-Jobs-×-1-Pod"><a href="#第一种-Benchmark：10K-Jobs-×-1-Pod" class="headerlink" title="第一种 Benchmark：10K Jobs × 1 Pod"></a>第一种 Benchmark：10K Jobs × 1 Pod</h4><p><strong>测试参数</strong>：每个Job只有1个Pod，共10K个Job，共10kPod</p>
<p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果几乎一致。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/1-no-enqueue/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="图2：对于猜想1，第一种benchmark测试结果"><figcaption>图2：对于猜想1，第一种benchmark测试结果</figcaption></figure></p>
<h4 id="第二种-Benchmark：500-Jobs-×-20-Pods"><a href="#第二种-Benchmark：500-Jobs-×-20-Pods" class="headerlink" title="第二种 Benchmark：500 Jobs × 20 Pods"></a>第二种 Benchmark：500 Jobs × 20 Pods</h4><p><strong>测试参数</strong>：每个Job有20个Pod，共500个Job，共10kPod</p>
<p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果几乎一致。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/1-no-enqueue/b.NoGang-500Job-no/output/panel-5.png?raw=true" alt="图3：对于猜想1，第二种benchmark测试结果"><figcaption>图3：对于猜想1，第二种benchmark测试结果</figcaption></figure></p>
<h4 id="第三种-Benchmark：20-Jobs-×-500-Pods"><a href="#第三种-Benchmark：20-Jobs-×-500-Pods" class="headerlink" title="第三种 Benchmark：20 Jobs × 500 Pods"></a>第三种 Benchmark：20 Jobs × 500 Pods</h4><p><strong>测试参数</strong>：每个Job有500Pod，共20个Job，共10kPod</p>
<p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果几乎一致，仍然存在“仅创建1000Pod”的bug。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/1-no-enqueue/c.NoGang-20Job-no/output/panel-5.png?raw=true" alt="图4：对于猜想1，第三种benchmark测试结果"><figcaption>图4：对于猜想1，第三种benchmark测试结果</figcaption></figure></p>
<h4 id="第四种-Benchmark：1-Job-×-10K-Pods"><a href="#第四种-Benchmark：1-Job-×-10K-Pods" class="headerlink" title="第四种 Benchmark：1 Job × 10K Pods"></a>第四种 Benchmark：1 Job × 10K Pods</h4><p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果几乎一致。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/1-no-enqueue/c.NoGang-20Job-no/output/panel-5.png?raw=true" alt="图5：对于猜想1，第四种benchmark测试结果"><figcaption>图5：对于猜想1，第四种benchmark测试结果</figcaption></figure></p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p><strong>实验结论</strong>：enqueue阶段不是性能瓶颈</p>
<p><strong>关键发现</strong>：</p>
<ul>
<li>禁用enqueue后，测试结果与前期本地测试结果基本一致</li>
<li>CREATED事件仍然出现阶段性突变</li>
<li>调度性能没有显著改善</li>
</ul>
<p><strong>分析说明</strong>：enqueue主要负责任务入队和优先级排序，对Pod创建和调度的直接影响有限。CREATED事件的异常现象可能源于其他因素。</p>
<h2 id="猜想2：webhook超时可能导致性能测试异常"><a href="#猜想2：webhook超时可能导致性能测试异常" class="headerlink" title="猜想2：webhook超时可能导致性能测试异常"></a>猜想2：webhook超时可能导致性能测试异常</h2><h3 id="2-1-猜想依据"><a href="#2-1-猜想依据" class="headerlink" title="2.1 猜想依据"></a>2.1 猜想依据</h3><p>在<a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="问题排查过程">问题排查过程</a>中，我们发现了严重的webhook超时问题：</p>
<ul>
<li><strong>Pod创建失败率</strong>：98.7%的Pod创建请求因超时而失败</li>
<li><strong>超时配置</strong>：webhook超时时间设置为10秒</li>
<li><strong>日志证据</strong>：4.9GB的审计日志记录了大量超时错误</li>
</ul>
<h3 id="2-2-实验设计"><a href="#2-2-实验设计" class="headerlink" title="2.2 实验设计"></a>2.2 实验设计</h3><p>我们通过修改webhook超时时间从10秒增加到30秒来验证这一猜想：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 批量修改所有webhook配置文件的超时时间</span></span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-*.yaml</span><br></pre></td></tr></table></figure></div>

<h3 id="2-3-实验结果"><a href="#2-3-实验结果" class="headerlink" title="2.3 实验结果"></a>2.3 实验结果</h3><h4 id="第一种-Benchmark：10K-Jobs-×-1-Pod-1"><a href="#第一种-Benchmark：10K-Jobs-×-1-Pod-1" class="headerlink" title="第一种 Benchmark：10K Jobs × 1 Pod"></a>第一种 Benchmark：10K Jobs × 1 Pod</h4><p><strong>测试参数</strong>：每个Job只有1个Pod，共10K个Job，共10kPod</p>
<p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果几乎一致。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/2-long-webhook-timeout/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="图6：对于猜想2，第一种benchmark测试结果"><figcaption>图6：对于猜想2，第一种benchmark测试结果</figcaption></figure></p>
<h4 id="第二种-Benchmark：500-Jobs-×-20-Pods-1"><a href="#第二种-Benchmark：500-Jobs-×-20-Pods-1" class="headerlink" title="第二种 Benchmark：500 Jobs × 20 Pods"></a>第二种 Benchmark：500 Jobs × 20 Pods</h4><p><strong>测试参数</strong>：每个Job有20个Pod，共500个Job，共10kPod</p>
<p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果几乎一致。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/2-long-webhook-timeout/b.NoGang-500Job-no/output/panel-5.png?raw=true" alt="图7：对于猜想2，第二种benchmark测试结果"><figcaption>图7：对于猜想2，第二种benchmark测试结果</figcaption></figure></p>
<h4 id="第三种-Benchmark：20-Jobs-×-500-Pods-1"><a href="#第三种-Benchmark：20-Jobs-×-500-Pods-1" class="headerlink" title="第三种 Benchmark：20 Jobs × 500 Pods"></a>第三种 Benchmark：20 Jobs × 500 Pods</h4><p><strong>测试参数</strong>：每个Job有500Pod，共20个Job，共10kPod</p>
<p><strong>实际结果</strong>：<strong>✅有显著变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果完全不同，结果恢复为符合预期的正常状态“创建Pod数量达10000”。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/2-long-webhook-timeout/c.NoGang-20Job-no/output/panel-5.png?raw=true" alt="图8：对于猜想2，第三种benchmark测试结果"><figcaption>图8：对于猜想2，第三种benchmark测试结果</figcaption></figure></p>
<h4 id="第四种-Benchmark：1-Job-×-10K-Pods-1"><a href="#第四种-Benchmark：1-Job-×-10K-Pods-1" class="headerlink" title="第四种 Benchmark：1 Job × 10K Pods"></a>第四种 Benchmark：1 Job × 10K Pods</h4><p><strong>实际结果</strong>：<strong>✅有显著变化</strong>。如下图所示，与<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试">本地测试</a>时的结果完全不同，结果恢复为符合预期的正常状态“创建Pod数量达10000”。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/2-long-webhook-timeout/d.NoGang-1Job-no/output/panel-5.png?raw=true" alt="图9：对于猜想2，第四种benchmark测试结果"><figcaption>图9：对于猜想2，第四种benchmark测试结果</figcaption></figure></p>
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p><strong>实验结论</strong>：webhook超时确实是导致性能测试异常的主要原因</p>
<p><strong>关键发现</strong>：</p>
<ul>
<li><strong>benchmark3和benchmark4</strong>：从”创建Pod数量不到1000”恢复为正常状态”创建Pod数量达10000”</li>
<li><strong>性能恢复</strong>：Pod创建成功率从1.3%提升到接近100%</li>
<li><strong>测试稳定性</strong>：大规模Pod创建测试能够正常完成</li>
</ul>
<p><strong>分析说明</strong>：webhook超时时间过短（10秒）无法处理大量并发Pod创建请求，导致请求堆积和失败。将超时时间延长到30秒后，系统能够正常处理高并发负载。这也为我们指出了在大规模下需要注意的配置问题。</p>
<h2 id="猜想3：Volcano版本较低可能导致性能测试结果异常"><a href="#猜想3：Volcano版本较低可能导致性能测试结果异常" class="headerlink" title="猜想3：Volcano版本较低可能导致性能测试结果异常"></a>猜想3：Volcano版本较低可能导致性能测试结果异常</h2><h3 id="3-1-猜想依据"><a href="#3-1-猜想依据" class="headerlink" title="3.1 猜想依据"></a>3.1 猜想依据</h3><p>基于版本差异可能带来的影响，我们猜测：</p>
<ul>
<li><strong>性能优化差异</strong>：新版本可能包含重要的性能优化</li>
<li><strong>算法改进差异</strong>：调度算法可能在新版本中有显著改进</li>
<li><strong>配置默认值差异</strong>：新版本的默认配置可能更适合大规模测试</li>
</ul>
<h3 id="3-2-实验设计"><a href="#3-2-实验设计" class="headerlink" title="3.2 实验设计"></a>3.2 实验设计</h3><p>我们通过将Volcano版本从v1.11.0升级到v1.12.0-alpha.0来验证这一猜想：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 批量替换版本号</span></span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/*/deployment.yaml</span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/*/job.yaml</span><br></pre></td></tr></table></figure></div>

<h3 id="3-3-实验结果"><a href="#3-3-实验结果" class="headerlink" title="3.3 实验结果"></a>3.3 实验结果</h3><h4 id="第一种-Benchmark：10K-Jobs-×-1-Pod-2"><a href="#第一种-Benchmark：10K-Jobs-×-1-Pod-2" class="headerlink" title="第一种 Benchmark：10K Jobs × 1 Pod"></a>第一种 Benchmark：10K Jobs × 1 Pod</h4><p><strong>测试参数</strong>：每个Job只有1个Pod，共10K个Job，共10kPod</p>
<p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与验证猜想2时的结果几乎一致。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="图10：对于猜想3，第一种benchmark测试结果"><figcaption>图10：对于猜想3，第一种benchmark测试结果</figcaption></figure></p>
<h4 id="第二种-Benchmark：500-Jobs-×-20-Pods-2"><a href="#第二种-Benchmark：500-Jobs-×-20-Pods-2" class="headerlink" title="第二种 Benchmark：500 Jobs × 20 Pods"></a>第二种 Benchmark：500 Jobs × 20 Pods</h4><p><strong>测试参数</strong>：每个Job有20个Pod，共500个Job，共10kPod</p>
<p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与验证猜想2时的结果几乎一致。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/b.NoGang-500Job-no/output/panel-5.png?raw=true" alt="图11：对于猜想3，第二种benchmark测试结果"><figcaption>图11：对于猜想3，第二种benchmark测试结果</figcaption></figure></p>
<h4 id="第三种-Benchmark：20-Jobs-×-500-Pods-2"><a href="#第三种-Benchmark：20-Jobs-×-500-Pods-2" class="headerlink" title="第三种 Benchmark：20 Jobs × 500 Pods"></a>第三种 Benchmark：20 Jobs × 500 Pods</h4><p><strong>测试参数</strong>：每个Job有500Pod，共20个Job，共10kPod</p>
<p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与验证猜想2时的结果几乎一致。但CREATE速度似乎更快了些（也有可能只是随机波动）。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/c.NoGang-20Job-no/output/panel-5.png?raw=true" alt="图12：对于猜想3，第三种benchmark测试结果"><figcaption>图12：对于猜想3，第三种benchmark测试结果</figcaption></figure></p>
<h4 id="第四种-Benchmark：1-Job-×-10K-Pods-2"><a href="#第四种-Benchmark：1-Job-×-10K-Pods-2" class="headerlink" title="第四种 Benchmark：1 Job × 10K Pods"></a>第四种 Benchmark：1 Job × 10K Pods</h4><p><strong>实际结果</strong>：<strong>无明显变化</strong>。如下图所示，与验证猜想2时的结果几乎一致。但CREATE速度似乎更快了些（也有可能只是随机波动）。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/d.NoGang-1Job-no/output/panel-5.png?raw=true" alt="图13：对于猜想3，第四种benchmark测试结果"><figcaption>图13：对于猜想3，第四种benchmark测试结果</figcaption></figure></p>
<h4 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h4><p><strong>实验结论</strong>：Volcano版本不是导致性能测试结果差异的主要原因</p>
<p><strong>关键发现</strong>：</p>
<ul>
<li>升级到v1.12.0-alpha.0后，测试结果与前期本地测试结果基本一致</li>
<li>CREATED事件的异常现象仍然存在</li>
<li>调度性能没有显著改善</li>
</ul>
<p><strong>分析说明</strong>：虽然版本升级可能带来一些改进，但核心的性能瓶颈问题仍然存在。这表明性能差异主要源于配置和架构层面的问题，而非版本本身。</p>
<h2 id="猜想4：webhook处理可能是性能瓶颈"><a href="#猜想4：webhook处理可能是性能瓶颈" class="headerlink" title="猜想4：webhook处理可能是性能瓶颈"></a>猜想4：webhook处理可能是性能瓶颈</h2><h3 id="4-1-猜想依据"><a href="#4-1-猜想依据" class="headerlink" title="4.1 猜想依据"></a>4.1 猜想依据</h3><p>基于webhook系统的复杂性，我们猜测webhook处理本身可能成为性能瓶颈：</p>
<ul>
<li><strong>多次判断开销</strong>：每个Pod创建请求需要经过多个webhook验证</li>
<li><strong>TLS证书验证</strong>：每次webhook调用都需要进行TLS验证</li>
<li><strong>网络延迟</strong>：webhook服务调用可能引入额外的网络延迟</li>
</ul>
<h3 id="4-2-实验设计"><a href="#4-2-实验设计" class="headerlink" title="4.2 实验设计"></a>4.2 实验设计</h3><p>我们通过<a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="完全禁用webhook功能">完全禁用webhook功能</a>来验证这一猜想：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除所有webhook配置，保留admission服务</span></span><br><span class="line">make disable-volcano-webhooks</span><br></pre></td></tr></table></figure></div>

<h3 id="4-3-实验结果"><a href="#4-3-实验结果" class="headerlink" title="4.3 实验结果"></a>4.3 实验结果</h3><h4 id="第一种-Benchmark：10K-Jobs-×-1-Pod-3"><a href="#第一种-Benchmark：10K-Jobs-×-1-Pod-3" class="headerlink" title="第一种 Benchmark：10K Jobs × 1 Pod"></a>第一种 Benchmark：10K Jobs × 1 Pod</h4><p><strong>测试参数</strong>：每个Job只有1个Pod，共10K个Job，共10kPod</p>
<p><strong>实际结果</strong>：<strong>✅性能明显上升</strong>。如下两图对比所示，整体斜率比前期测试结果更大，说明CREATED和SCHEDULE的速度更快。</p>
<p>优化前：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="图10：对于猜想3，第一种benchmark测试结果"><figcaption>图10：对于猜想3，第一种benchmark测试结果</figcaption></figure></p>
<p>优化后：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="图14：对于猜想4，第一种benchmark测试结果"><figcaption>图14：对于猜想4，第一种benchmark测试结果</figcaption></figure></p>
<h4 id="第二种-Benchmark：500-Jobs-×-20-Pods-3"><a href="#第二种-Benchmark：500-Jobs-×-20-Pods-3" class="headerlink" title="第二种 Benchmark：500 Jobs × 20 Pods"></a>第二种 Benchmark：500 Jobs × 20 Pods</h4><p><strong>测试参数</strong>：每个Job有20个Pod，共500个Job，共10kPod</p>
<p><strong>实际结果</strong>：<strong>✅性能略有上升</strong>。如下两图对比所示，CREATE斜率比前期测试结果更大（甚至好几段近乎直线上升），说明CREATED的速度显著上升；但与此同时需要注意的是，<strong>CREATE仍然存在阶梯状</strong>突变，证明CREATE瓶颈仍然需要通过其他方式解决。</p>
<p>优化前：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/b.NoGang-500Job-no/output/panel-5.png?raw=true" alt="图11：对于猜想3，第二种benchmark测试结果"><figcaption>图11：对于猜想3，第二种benchmark测试结果</figcaption></figure></p>
<p>优化后：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/b.NoGang-500Job-no/output/panel-5.png?raw=true" alt="图15：对于猜想4，第二种benchmark测试结果"><figcaption>图15：对于猜想4，第二种benchmark测试结果</figcaption></figure></p>
<h4 id="第三种-Benchmark：20-Jobs-×-500-Pods-3"><a href="#第三种-Benchmark：20-Jobs-×-500-Pods-3" class="headerlink" title="第三种 Benchmark：20 Jobs × 500 Pods"></a>第三种 Benchmark：20 Jobs × 500 Pods</h4><p><strong>测试参数</strong>：每个Job有500Pod，共20个Job，共10kPod</p>
<p><strong>✅性能明显上升</strong>。如下两图对比所示，整体斜率比前期测试结果更大，说明CREATED和SCHEDULE的速度更快。同时也注意到，即便如此也还是比另外两种调度器更慢些，意味着SCHEDULE部分调度性能本身也还有优化空间。</p>
<p>优化前：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/c.NoGang-20Job-no/output/panel-5.png?raw=true" alt="图12：对于猜想3，第三种benchmark测试结果"><figcaption>图12：对于猜想3，第三种benchmark测试结果</figcaption></figure></p>
<p>优化后：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/c.NoGang-20Job-no/output/panel-5.png?raw=true" alt="图16：对于猜想4，第三种benchmark测试结果"><figcaption>图16：对于猜想4，第三种benchmark测试结果</figcaption></figure></p>
<h4 id="第四种-Benchmark：1-Job-×-10K-Pods-3"><a href="#第四种-Benchmark：1-Job-×-10K-Pods-3" class="headerlink" title="第四种 Benchmark：1 Job × 10K Pods"></a>第四种 Benchmark：1 Job × 10K Pods</h4><p><strong>✅性能明显上升</strong>。如下两图对比所示，整体斜率比前期测试结果更大，说明CREATED和SCHEDULE的速度更快。同时和benchmark3一样，也注意到，即便如此也还是比另外两种调度器更慢些，意味着SCHEDULE部分调度性能本身也还有优化空间。</p>
<p>优化前：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/3-update-volcano-version-1.12.0-alpha.0/d.NoGang-1Job-no/output/panel-5.png?raw=true" alt="图13：对于猜想3，第四种benchmark测试结果"><figcaption>图13：对于猜想3，第四种benchmark测试结果</figcaption></figure></p>
<p>优化后：<br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/d.NoGang-1Job-no/output/panel-5.png?raw=true" alt="图17：对于猜想4，第四种benchmark测试结果"><figcaption>图17：对于猜想4，第四种benchmark测试结果</figcaption></figure></p>
<h4 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h4><p><strong>实验结论</strong>：webhook处理确实是重要的性能瓶颈</p>
<p><strong>关键发现</strong>：禁用webhook后，性能获得较大提升，Pod创建/调度速度显著加快，调度器整体性能表现改善</p>
<p><strong>分析说明</strong>：webhook系统虽然提供了重要的验证和修改功能，但在大规模Pod创建场景下，其处理开销成为了性能瓶颈。禁用webhook后，系统能够更直接地处理Pod创建请求，从而提升整体性能。</p>
<h2 id="猜想5：Volcano批处理机制可能导致CREATED阶段瓶颈"><a href="#猜想5：Volcano批处理机制可能导致CREATED阶段瓶颈" class="headerlink" title="猜想5：Volcano批处理机制可能导致CREATED阶段瓶颈"></a>猜想5：Volcano批处理机制可能导致CREATED阶段瓶颈</h2><h3 id="5-1-猜想依据"><a href="#5-1-猜想依据" class="headerlink" title="5.1 猜想依据"></a>5.1 猜想依据</h3><p>基于<a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="视频分析">视频分析</a>，我们注意到在benchmark1和benchmark2下，CREATED阶段成为性能瓶颈。视频中提到Volcano会”create pod in Batch”，即分批处理Job，当一批Job处理完后才会继续处理下一批Job。</p>
<p>这种批处理机制可能导致：</p>
<ul>
<li><strong>CREATED事件阶段性突变</strong>：批处理完成后，下一批Job的Pod创建会出现集中爆发</li>
<li><strong>资源浪费</strong>：批处理期间资源可能被闲置，且批处理完成后资源竞争激烈</li>
</ul>
<h3 id="5-2-实验验证"><a href="#5-2-实验验证" class="headerlink" title="5.2 实验验证"></a>5.2 实验验证</h3><p>虽然我们没有针对这一猜想进行专门的测试，但从前面所有实验结果都能证明这一点（尤其是benchmark1和benchmark2）：</p>
<ol>
<li><strong>enqueue实验</strong>：禁用enqueue后，CREATED事件仍然出现阶段性突变，说明问题不在enqueue阶段</li>
<li><strong>webhook超时实验</strong>：修复超时问题后，Pod创建数量恢复正常，但CREATED的阶段性特征仍然存在</li>
<li><strong>版本升级实验</strong>：升级到v1.12.0-alpha.0后，CREATED事件的异常现象仍然存在</li>
<li><strong>webhook禁用实验</strong>：即使禁用webhook，在Job数量较多时仍然存在Pod创建瓶颈</li>
</ol>
<p>这些实验结果的一致性表明，CREATED阶段的瓶颈问题源于更深层的架构设计，即Volcano的批处理机制。</p>
<h3 id="5-3-实验结论"><a href="#5-3-实验结论" class="headerlink" title="5.3 实验结论"></a>5.3 实验结论</h3><p><strong>实验结论</strong>：Volcano的批处理机制确实是CREATED阶段性能瓶颈的根本原因</p>
<p><strong>关键发现</strong>：</p>
<ul>
<li>批处理机制导致Pod创建出现阶段性突变</li>
<li>这种瓶颈无法通过调整配置参数完全解决</li>
<li>需要从架构层面进行优化</li>
</ul>
<p><strong>分析说明</strong>：Volcano的批处理设计虽然在某些场景下有利于资源管理和调度优化，但在大规模、高并发的Pod创建场景下，这种同步批处理机制成为了性能瓶颈。系统需要等待当前批次完成才能开始下一批次的处理，无法实现真正的并行流水线。</p>
<h1 id="📊实验结果综合分析"><a href="#📊实验结果综合分析" class="headerlink" title="📊实验结果综合分析"></a>📊实验结果综合分析</h1><table>
<thead>
<tr>
<th>猜想</th>
<th>验证方法</th>
<th>实验结果</th>
<th>结论</th>
</tr>
</thead>
<tbody><tr>
<td><strong>enqueue功能瓶颈</strong></td>
<td>禁用enqueue阶段</td>
<td>性能无显著改善</td>
<td>❌ 不是主要瓶颈</td>
</tr>
<tr>
<td><strong>webhook超时问题</strong></td>
<td>延长超时时间</td>
<td>Pod创建恢复正常</td>
<td>✅ 是重要瓶颈</td>
</tr>
<tr>
<td><strong>版本差异影响</strong></td>
<td>升级到v1.12.0-alpha.0</td>
<td>性能无显著改善</td>
<td>❌ 不是主要瓶颈</td>
</tr>
<tr>
<td><strong>webhook处理瓶颈</strong></td>
<td>完全禁用webhook</td>
<td>性能大幅提升</td>
<td>✅ 是主要瓶颈</td>
</tr>
<tr>
<td><strong>批处理机制瓶颈</strong></td>
<td>综合分析所有实验结果</td>
<td>CREATED阶段性突变“卡顿”问题持续存在</td>
<td>✅ 是根本瓶颈</td>
</tr>
</tbody></table>
<h1 id="🚀未来方向"><a href="#🚀未来方向" class="headerlink" title="🚀未来方向"></a>🚀未来方向</h1><h2 id="1-短期优化方案"><a href="#1-短期优化方案" class="headerlink" title="1. 短期优化方案"></a>1. 短期优化方案</h2><h3 id="1-1-调整webhook超时时间"><a href="#1-1-调整webhook超时时间" class="headerlink" title="1.1 调整webhook超时时间"></a>1.1 调整webhook超时时间</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将webhook超时时间从10秒增加到30秒</span></span><br><span class="line"><span class="attr">timeoutSeconds:</span> <span class="number">30</span>  <span class="comment"># 原始：timeoutSeconds: 10</span></span><br></pre></td></tr></table></figure></div>

<p><strong>适用场景</strong>：需要保持webhook功能完整性的生产环境<br><strong>优化效果</strong>：解决超时导致的测试异常问题</p>
<h3 id="1-2-优化webhook资源配置"><a href="#1-2-优化webhook资源配置" class="headerlink" title="1.2 优化webhook资源配置"></a>1.2 优化webhook资源配置</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 增加webhook服务的资源限制</span></span><br><span class="line"><span class="attr">resources:</span></span><br><span class="line">  <span class="attr">requests:</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">"512Mi"</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">"500m"</span></span><br><span class="line">  <span class="attr">limits:</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">"1Gi"</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">"1000m"</span></span><br></pre></td></tr></table></figure></div>

<p><strong>适用场景</strong>：资源受限但需要webhook功能的环境<br><strong>优化效果</strong>：提升webhook处理能力</p>
<h2 id="2-长期优化方向"><a href="#2-长期优化方向" class="headerlink" title="2. 长期优化方向"></a>2. 长期优化方向</h2><h3 id="2-1-替代webhook的验证机制"><a href="#2-1-替代webhook的验证机制" class="headerlink" title="2.1 替代webhook的验证机制"></a>2.1 替代webhook的验证机制</h3><p>基于<a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="我们的实验发现">我们的实验发现</a>，未来可以考虑：</p>
<ol>
<li><strong>加强Controller校验</strong>：将必要的校验功能转移到 Volcano Controller Manager（例如空指针判断等），为简单场景下禁用 webhook 做支撑</li>
<li><strong>使用CRD规则校验</strong>：或使用通用表达式语言（CEL）来实现K8s准入校验规则，验证CRD的值（使用 K8s v1.29 [stabe] x-kubernetes-validations 扩展），实现利用 Kubernetes CRD 的验证功能替代部分 validating webhook</li>
</ol>
<h3 id="2-2-优化CREATED批处理阻塞瓶颈“卡顿”问题"><a href="#2-2-优化CREATED批处理阻塞瓶颈“卡顿”问题" class="headerlink" title="2.2 优化CREATED批处理阻塞瓶颈“卡顿”问题"></a>2.2 优化CREATED批处理阻塞瓶颈“卡顿”问题</h3><p>基于第五个猜想的验证结果，针对Volcano批处理机制的根本性瓶颈，未来可以考虑：</p>
<ol>
<li><strong>动态批次调整</strong>：根据系统负载动态调整批次大小，避免资源闲置和突发负载</li>
<li><strong>异步批处理</strong>：将同步批处理改为异步处理，不阻塞下一批Job的Pod创建</li>
<li><strong>流水线优化</strong>：设计真正的流水线机制，实现Pod创建、验证、调度的并行处理</li>
</ol>
<!-- ### 2.3 异步处理机制

设计异步的Pod验证和修改机制：

1. **异步验证**：Pod创建后异步进行验证，不阻塞创建流程
2. **批量处理**：将多个验证请求批量处理，提高效率
3. **缓存机制**：缓存验证结果，减少重复计算
-->

<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a href="!--swig%EF%BF%BC37--">[2] <a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></a></p>
<p><a href="!--swig%EF%BF%BC39--">[3] <a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></a></p>
<p><a href="!--swig%EF%BF%BC41--">[4] <a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></a></p>
<p><a href="!--swig%EF%BF%BC43--">[5] <a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></a></p>
<p><a href="!--swig%EF%BF%BC45--">[6] <a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></a></p>
<p><a href="!--swig%EF%BF%BC47--">[7] <a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/">[8] Kubernetes 文档 - Admission Controllers 准入控制 <i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/blog/2022/09/23/crd-validation-rules-beta/">[9] Kubernetes 文档 - Kubernetes 1.25: CustomResourceDefinition Validation Rules Graduate to Beta<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions">[10] Kubernetes 文档 - 使用 CustomResourceDefinition 扩展 Kubernetes API<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#validation">[11] Kubernetes 文档 - CRD Validation 合法性检查<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#validation-rules">[12] Kubernetes 文档 - CRD Validation Rules 合法性检查规则<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#validation-rules">[13] Kubernetes 文档 - CRD Validation Rules 合法性检查规则（K8s v1.29 [stabe]）<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/validating-admission-policy/">[14] Kubernetes 文档 - 验证准入策略（ValidatingAdmissionPolicy）（K8s v1.30 [stable]）<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://liangyuanpeng.com/post/k8s-admissionregistration-with-cel/">[15] 用cel表达式来实现k8s准入校验<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度器</tag>
        <tag>K8s</tag>
        <tag>性能测试</tag>
        <tag>Volcano</tag>
        <tag>性能瓶颈</tag>
        <tag>实验验证</tag>
        <tag>系统优化</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano 指标采集与可视化</title>
    <url>/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li>
<li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li>
<li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li>
<li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li>
<li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li>
<li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li>
<li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li>
<li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li>
<li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li>
<li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li>
<li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li>
<li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li>
<li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li>
<li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a>
</li>
</ol>
</blockquote>
<p>上一篇我们从 <strong>Makefile → Kind → 测试代码</strong> 串起了一次最小性能测试的全链路。本篇将回答另一个常见问题：</p>
<blockquote>
<p><em>「<code>TestBatchJob</code> 跑完后，Grafana 面板上的 CREATED / SCHEDULED / RUNNING 曲线是怎么来的？」</em></p>
</blockquote>
<p>下图给出了核心组件与数据流，阅读完本文，希望能够帮你快速实现：</p>
<ol>
<li>理解 审计日志 → Exporter → Prometheus+Grafana → 截图归档 的端到端链路；</li>
<li>自定义审计策略 &amp; 面板查询 &amp; 截图归档。</li>
</ol>
<pre class="mermaid">graph LR;
  subgraph Control-Plane 审计日志
    APIServer["Kube-APIServer(开启审计)"] --&gt;|/var/log/kubernetes/kube-apiserver-audit.log| NodeDisk[(control-plane 节点磁盘)]
  end

  NodeDisk --&gt; Exporter["Audit-Exporter(Deployment)"]
  Exporter --&gt;|/metrics| Prometheus((Prometheus))
  Prometheus --&gt; Grafana[(Grafana Dashboard)]
  Grafana --&gt; Script[save-result-images.sh]</pre>

<hr>
<h1 id="1️⃣-审计日志：audit-policy-yaml-决定记录什么"><a href="#1️⃣-审计日志：audit-policy-yaml-决定记录什么" class="headerlink" title="1️⃣ 审计日志：audit-policy.yaml 决定记录什么"></a>1️⃣ 审计日志：audit-policy.yaml 决定<strong>记录什么</strong></h1><p>对应前文流程图中的 <code>Control-Plane 审计日志</code> 部分，在 Kubernetes 中，每个请求在不同执行阶段都会生成审计事件；这些审计事件会根据特定策略被预处理并写入后端。<a href="#refer-anchor-1"><sup>[3]</sup></a></p>
<p>在此过程中，Kubernetes 审计子系统需要一份 <em>Policy</em> 文件来声明规则（指明需记录的事件范围）。而本项目根目录的 <code>audit-policy.yaml</code> 中就声明了一套规则，重点拦截了衡量调度器吞吐量的关键对象 <strong>Pod / Job 的 CRUD</strong>：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><figcaption><span>audit-policy.yaml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Policy</span></span><br><span class="line"><span class="attr">omitManagedFields:</span> <span class="literal">True</span></span><br><span class="line"><span class="attr">omitStages:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">RequestReceived</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">ResponseStarted</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">level:</span> <span class="string">RequestResponse</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">""</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">pods/binding</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">pods/status</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">batch</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">jobs</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">jobs/status</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">batch.volcano.sh</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">jobs</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">jobs/status</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">create</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">patch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">update</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">delete</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li><code>omitStages</code> 指明每个请求可无须记录相关的阶段（stage）。Kubernetes 中已定义的阶段有：<ul>
<li><code>RequestReceived</code> - 此阶段对应审计处理器接收到请求后， 并且在委托给其余处理器之前生成的事件。</li>
<li><code>ResponseStarted</code> - 在响应消息的头部发送后，响应消息体发送前生成的事件。 只有长时间运行的请求（例如 watch）才会生成这个阶段。</li>
<li><code>ResponseComplete</code> - 当响应消息体完成并且没有更多数据需要传输的时候。</li>
<li><code>Panic</code> - 当 panic 发生时生成。</li>
</ul>
</li>
<li><code>level: RequestResponse</code> 既保留请求头，也包含响应体，方便后续解析出 <strong>Result 及耗时</strong>。<ul>
<li><code>verbs</code> 指明此规则所适用的操作（verb）列表。将 CREATE / PATCH / UPDATE / DELETE 四类操作一次性覆盖；</li>
<li><code>resources</code> 指明此规则所适用的资源类别列表，包含 <code>batch</code>、<code>batch.volcano.sh/jobs</code> 等 CRD，兼顾不同调度器对象。字段 <code>group</code> 给出包含资源的 API 组的名称，空字符串代表 core API 组。</li>
</ul>
</li>
<li><code>level: Metadata</code> 则仅记录请求的元数据（请求的用户、时间戳、资源、动词等等）， 但是不记录请求或者响应的消息体。<ul>
<li><code>resources</code> 为空列表意味着适用于 API 组中的所有资源类别。</li>
</ul>
</li>
</ul>
<p>通常情况下，可以使用 <code>--audit-policy-file</code> 标志将包含策略的文件传递给 <code>kube-apiserver</code>。</p>
<!-- 在本项目中，...。 -->

<h2 id="▶️-FAQ：策略细节常见疑问"><a href="#▶️-FAQ：策略细节常见疑问" class="headerlink" title="▶️ FAQ：策略细节常见疑问"></a>▶️ FAQ：策略细节常见疑问</h2><blockquote>
<p>💡 以下内容专门回应在阅读源码时最常见的 3 个疑惑。</p>
</blockquote>
<p><strong>① <code>level: Metadata</code> 与 <code>level: RequestResponse</code> 有何区别？为何都要保留？</strong></p>
<ul>
<li>作用域不同：<ul>
<li><code>RequestResponse</code> 规则<strong>只</strong>匹配我们关心的调度相关资源（<code>pods</code> / <code>jobs</code> / <code>jobs.batch.volcano.sh</code> 等），并且显式列举了 <code>verbs</code>=<code>create|patch|update|delete</code>。它会把 <strong>请求头 + 响应体</strong> 全量落盘，方便后续 Exporter 解析出 <strong>Result (Success/Failure) 与延迟直方图</strong>。</li>
<li><code>Metadata</code> 规则的 <code>resources: []</code> 表示「兜底规则」——凡是不在前一条命中列表内的 <strong>任何</strong> 资源，统一只记录元数据（谁、何时、做了什么），<strong>不包含请求/响应体</strong>。这样既能保留审计合规性，又避免为海量无关对象写大文件。</li>
</ul>
</li>
<li>优先级：Kubernetes 会按照 YAML 中的 <strong>先后顺序</strong> 匹配规则，一旦命中即停止继续匹配。因此本项目先写精确匹配、再写兜底规则，二者不会冲突。</li>
<li>同时编写两条规则的目的：<strong>平衡指标精度与日志体积</strong>。<code>RequestResponse</code> 为核心对象提供高粒度延迟直方图与成功率计算；<code>Metadata</code> 兜底满足审计留痕合规，又避免为成百上千个与调度无关的对象写入冗余响应体，从而显著降低磁盘占用与解析成本。</li>
</ul>
<p><strong>② 为什么 <code>omitStages</code> 要排除 <code>RequestReceived</code> 和 <code>ResponseStarted</code>？最终会记录哪些 Stage？</strong></p>
<ul>
<li>背景：一次 API 请求最多可生成四个 Stage 事件（<code>RequestReceived</code> ➡ <code>ResponseStarted</code> ➡ <code>ResponseComplete</code> ➡ <code>Panic</code>）。其中 <code>RequestReceived</code> 与 <code>ResponseStarted</code> <em>体量大且价值有限</em>：<ul>
<li><code>RequestReceived</code> 只表明「请求到达了 APIServer」，但拿不到任何时长信息；</li>
<li><code>ResponseStarted</code> 仅对 <strong>长连接 watch</strong> 场景才会生成，对我们的批量 CRUD 测试用例几乎恒为空；</li>
</ul>
</li>
<li>因此在策略里把这两阶段排除，既减少日志体积，也避免 Exporter 做无意义解析。</li>
<li>与规则无冲突：<code>omitStages</code> 作用于 <strong>全局</strong>，告诉 APIServer 在生成审计事件时忽略指定阶段；后面的 <code>rules</code> 只决定「对哪些请求生成事件以及生成到什么 level」。二者工作维度不同，不会互相覆盖。</li>
<li>在本项目的批量 Job / Pod 测试中，最终实际落盘的 Stage 主要是：<ul>
<li><code>ResponseComplete</code> — 绝大多数正常请求；</li>
<li><code>Panic</code> — 只有当 APIServer panic 才会出现（理论上极少）。</li>
</ul>
</li>
<li>如何拿到「创建 / 调度 / 运行」等关键时间点？Exporter 仅需关注 <code>stage="ResponseComplete"</code> 的事件：<ul>
<li><strong>创建时间</strong>：匹配 <code>verb=create</code> 且 <code>resource=pods|jobs</code> 的完成时间戳；</li>
<li><strong>调度时间</strong>：匹配 <code>resource=pods/binding</code> 的完成时间戳（kube-scheduler 向 APIServer 发起 bind 请求）；</li>
<li><strong>运行时间</strong>：匹配 <code>resource=pods/status</code>、<code>verb=update</code> 且 <code>status.phase=Running</code> 的完成时间戳；<br>Exporter 在内存中以同名 Pod UID 关联多条事件，计算时间差即可，无需 <code>RequestReceived/Started</code> 阶段即可还原完整链路。</li>
<li><strong><code>Panic</code> 含义</strong>：当 APIServer 在处理请求过程中发生运行时崩溃并捕获到 panic 时才会生成，用于事后问题排查，正常测试流程极罕见。</li>
</ul>
</li>
</ul>
<p><strong>③ <code>audit-policy.yaml</code> 是如何交给 Kind 中的 kube-apiserver 的？</strong></p>
<ul>
<li>每个调度器对应的 Kind 集群（位于 <code>clusters/&lt;scheduler&gt;/kind.yaml</code>）都做了如下三种操作：<ol>
<li><code>extraMounts</code> 把根目录下的 <code>audit-policy.yaml</code> <strong>挂载</strong>到控制平面节点的 <code>/etc/kubernetes/policies/audit-policy.yaml</code>；</li>
<li><code>apiServer.extraVolumes</code> 定义名为 <code>audit-policies</code> 的 HostPath 卷，并将其挂载到同一路径，确保文件在 Pod 内可读；</li>
<li><code>apiServer.extraArgs</code> 增加<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">audit-policy-file:</span> <span class="string">/etc/kubernetes/policies/audit-policy.yaml</span></span><br><span class="line"><span class="attr">audit-log-path:</span> <span class="string">/var/log/kubernetes/kube-apiserver-audit.&lt;scheduler&gt;.log</span></span><br><span class="line"><span class="attr">audit-log-maxsize:</span> <span class="string">"10240"</span></span><br></pre></td></tr></table></figure></div>
这样 APIServer 一启动就按照我们自定义的策略把审计事件写入宿主机 <code>/var/log/kubernetes/</code>，后续再被 Exporter Tail。</li>
</ol>
</li>
</ul>
<hr>
<h1 id="2️⃣-Exporter：kube-apiserver-audit-exporter-把日志变成指标"><a href="#2️⃣-Exporter：kube-apiserver-audit-exporter-把日志变成指标" class="headerlink" title="2️⃣ Exporter：kube-apiserver-audit-exporter 把日志变成指标"></a>2️⃣ Exporter：kube-apiserver-audit-exporter 把日志变成指标</h1><p>前文 Policy 决定了「记录什么」，Exporter 则决定了「怎么提炼指标」。<br>部署清单位于：<code>base/kube-apiserver-audit-exporter/kube-apiserver-audit-exporter/deployment.yaml</code></p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><figcaption><span>base/kube-apiserver-audit-exporter/kube-apiserver-audit-exporter/deployment.yaml:24:41</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--audit-log-path</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/var/log/kubernetes/kube-apiserver-audit.log</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">kind-registry:5000/ghcr.io/wzshiming/kube-apiserver-audit-exporter/kube-apiserver-audit-exporter:v0.0.25</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">exporter</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">100Mi</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/var/log/kubernetes</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">audit-logs</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure></div>

<p>关键参数说明：</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>含义</th>
<th>示例值</th>
</tr>
</thead>
<tbody><tr>
<td><code>--audit-log-path</code></td>
<td>审计日志所在宿主机路径</td>
<td><code>/var/log/kubernetes/kube-apiserver-audit.log</code></td>
</tr>
<tr>
<td><code>image</code></td>
<td>可独立升级的 Exporter 镜像</td>
<td><code>…/kube-apiserver-audit-exporter:v0.0.25</code></td>
</tr>
<tr>
<td>VolumeMount</td>
<td>将宿主机日志目录挂载进 Pod</td>
<td><code>mountPath: /var/log/kubernetes</code></td>
</tr>
</tbody></table>
<h2 id="📌-组件何时被部署？——-Makefile-触发点"><a href="#📌-组件何时被部署？——-Makefile-触发点" class="headerlink" title="📌 组件何时被部署？—— Makefile 触发点"></a>📌 组件何时被部署？—— Makefile 触发点</h2><p>在本仓库最常用的入口 <code>make default</code> 会连续执行多轮 <strong>serial-test</strong>。理解一次 <em>serial-test</em> 的执行序列即可明白监控组件的真实部署时机：</p>
<table>
<thead>
<tr>
<th>步骤</th>
<th>触发目标</th>
<th>关键动作</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><code>prepare-&lt;scheduler&gt;</code></td>
<td><code>make up-&lt;scheduler&gt;</code> 创建 <strong>单个调度器集群</strong>，但此时 <em>没有</em> 监控栈</td>
</tr>
<tr>
<td>2</td>
<td><code>start-&lt;scheduler&gt;</code></td>
<td>运行性能测试 (<code>TestBatchJob</code> 等) 并 <strong>写入 audit-log</strong></td>
</tr>
<tr>
<td>3</td>
<td><code>end-&lt;scheduler&gt;</code></td>
<td><code>make down-&lt;scheduler&gt;</code> 销毁该集群，<strong>日志仍留在宿主机</strong> <code>/var/log/kubernetes/</code></td>
</tr>
<tr>
<td>⬇(循环)</td>
<td>(依次换下一个调度器)</td>
<td>…</td>
</tr>
<tr>
<td>4</td>
<td><code>prepare-overview</code></td>
<td><code>make up-overview</code> 创建 <strong>独立的 overview 集群</strong></td>
</tr>
<tr>
<td>5</td>
<td><code>start-overview</code></td>
<td><code>clusters/overview/Makefile:start-export</code> 部署 Exporter + PromStack，并把 <em>所有</em> <code>kube-apiserver-audit.*.log</code> HostPath 挂载到 Pod</td>
</tr>
<tr>
<td>6</td>
<td><code>save-result</code></td>
<td>睡 <code>$(RESULT_RECENT_DURATION_SECONDS)</code> 秒等待指标就绪→执行 <code>hack/save-result-images.sh</code> 截图</td>
</tr>
<tr>
<td>7</td>
<td><code>end-overview</code></td>
<td>销毁 overview 集群，聚合循环结束</td>
</tr>
</tbody></table>
<blockquote>
<p>也就是说：<strong>Export­er 和 Prometheus 直到 <em>所有</em> 调度器测试跑完后才被一次性拉起</strong>，随后一次性重放/解析先前留下的多份 audit-log。</p>
</blockquote>
<p>Exporter 会 tail 文件并实时解析，输出如下两类 Prometheus 指标（简化）：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line"># HELP kube_audit_event_total Total number of audit events</span><br><span class="line"># TYPE kube_audit_event_total counter</span><br><span class="line">kube_audit_event_total{verb="create",resource="pods",status="Success"}  1280</span><br><span class="line"></span><br><span class="line"># HELP kube_audit_event_latency_seconds Histogram of audit event latency</span><br><span class="line"># TYPE kube_audit_event_latency_seconds histogram</span><br><span class="line">kube_audit_event_latency_seconds_bucket{resource="pods",le="0.1"} 240</span><br></pre></td></tr></table></figure></div>

<p>其中 <code>status="Success"</code> 字段让我们能够在 Grafana 中分别绘制 <strong>CREATED / SCHEDULED / RUNNING</strong> 三条曲线。</p>
<h2 id="🔍-内部实现：Exporter-如何-tail-解析？"><a href="#🔍-内部实现：Exporter-如何-tail-解析？" class="headerlink" title="🔍 内部实现：Exporter 如何 tail + 解析？"></a>🔍 内部实现：Exporter 如何 tail + 解析？</h2><p>该部分比较复杂，涉及另一个项目。简单理解后，将该部分分为以下三步：</p>
<ul>
<li><strong>跟踪文件</strong>：Exporter 使用 Go 语言实现，入口位于 &lt;base/kube-apiserver-audit-exporter&gt;，源仓库位于<a class="link" href="https://github.com/wzshiming/kube-apiserver-audit-exporter">https://github.com/wzshiming/kube-apiserver-audit-exporter<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>。其核心依赖 <code>tail</code>（或 OS <code>inotify</code>）持续读取宿主机 <code>/var/log/kubernetes/…audit.log</code>；</li>
<li><strong>JSON 解析</strong>：每行审计日志都是合法 JSON，Exporter 利用 <code>encoding/json</code> 反序列化为 <code>auditinternal.Event</code> 结构体，随后按 <code>verb / resource / stage / status</code> 维度进行 <code>map</code> 聚合；</li>
<li><strong>指标暴露</strong>：聚合结果通过 <code>prometheus/client_golang</code> 转为 <code>counter</code> 与 <code>histogram</code> 两类 <code>kube_audit_*</code> 指标；</li>
</ul>
<p>若要<strong>增加更多指标</strong>（如自定义 label、增加 <code>summary</code> 等）：</p>
<ul>
<li><strong>定位代码</strong>：仓库中路径 <code>exporter/metrics.go</code> 下可见：以apiRequests(api_requests_total)、podSchedulingLatency(pod_scheduling_latency_seconds)为例<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Metric definitions</span></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">  registry = prometheus.NewRegistry()</span><br><span class="line"></span><br><span class="line">  apiRequests = prometheus.NewCounterVec(prometheus.CounterOpts{</span><br><span class="line">    Name: <span class="string">"api_requests_total"</span>,</span><br><span class="line">    Help: <span class="string">"Total number of API requests to the scheduler"</span>,</span><br><span class="line">  }, []<span class="type">string</span>{<span class="string">"cluster"</span>, <span class="string">"namespace"</span>, <span class="string">"user"</span>, <span class="string">"verb"</span>, <span class="string">"resource"</span>, <span class="string">"code"</span>})</span><br><span class="line">  <span class="comment">// 核心为：apiRequests = prometheus.NewCounterVec(...)</span></span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  podSchedulingLatency = prometheus.NewHistogramVec(prometheus.HistogramOpts{</span><br><span class="line">    Name:    <span class="string">"pod_scheduling_latency_seconds"</span>,</span><br><span class="line">    Help:    <span class="string">"Duration from pod creation to scheduled on node in seconds"</span>,</span><br><span class="line">    Buckets: prometheus.ExponentialBuckets(<span class="number">0.001</span>, <span class="number">2</span>, <span class="number">20</span>),</span><br><span class="line">  }, []<span class="type">string</span>{<span class="string">"cluster"</span>, <span class="string">"namespace"</span>, <span class="string">"user"</span>})</span><br><span class="line">  <span class="comment">// 核心为：batchJobCompleteLatency = prometheus.NewCounterVec(...)</span></span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> {</span><br><span class="line">  registry.MustRegister(</span><br><span class="line">    apiRequests,</span><br><span class="line">    podSchedulingLatency,</span><br><span class="line">    ...</span><br><span class="line">  )</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// updateMetrics processes audit event and updates metrics</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Exporter)</span></span> updateMetrics(clusterLabel <span class="type">string</span>, event auditv1.Event) {</span><br><span class="line">  <span class="comment">// ... 根据需求，自定义规则将  verb/resource 填充指标 ...</span></span><br><span class="line">  <span class="keyword">if</span> event.Stage == auditv1.StageResponseComplete {</span><br><span class="line">    labels := []<span class="type">string</span>{</span><br><span class="line">      clusterLabel,</span><br><span class="line">      ns,</span><br><span class="line">      extractUserAgent(event.UserAgent),</span><br><span class="line">      event.Verb,</span><br><span class="line">      extractResourceName(event),</span><br><span class="line">      strconv.Itoa(<span class="type">int</span>(event.ResponseStatus.Code)),</span><br><span class="line">  }</span><br><span class="line">  apiRequests.WithLabelValues(labels...).Inc()</span><br><span class="line">  <span class="comment">// 核心为：apiRequests.WithLabelValues(labels...).Inc()</span></span><br><span class="line"> }</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> event.ObjectRef != <span class="literal">nil</span> {</span><br><span class="line">    <span class="keyword">switch</span> event.ObjectRef.Resource {</span><br><span class="line">    <span class="keyword">case</span> <span class="string">"pods"</span>:</span><br><span class="line">      <span class="keyword">if</span> event.ObjectRef.Subresource == <span class="string">"binding"</span> &amp;&amp; event.Verb == <span class="string">"create"</span> {</span><br><span class="line">        target := buildTarget(event.ObjectRef)</span><br><span class="line">        createTime, exists := p.podCreationTimes[target]</span><br><span class="line">        <span class="keyword">if</span> !exists {</span><br><span class="line">          <span class="comment">// Kueue's audit events may create pod/binding events before pod creation events</span></span><br><span class="line">          user := extractUserAgent(event.UserAgent)</span><br><span class="line">          podSchedulingLatency.WithLabelValues(</span><br><span class="line">            clusterLabel,</span><br><span class="line">            ns,</span><br><span class="line">            user,</span><br><span class="line">          ).Observe(<span class="number">0</span>)</span><br><span class="line">        <span class="comment">// 核心为：podSchedulingLatency.WithLabelValues(...).Observe()</span></span><br><span class="line">          p.podCreationTimes[target] = <span class="literal">nil</span></span><br><span class="line">          <span class="keyword">return</span></span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> createTime == <span class="literal">nil</span> {</span><br><span class="line">          <span class="keyword">return</span></span><br><span class="line">        }</span><br><span class="line">        latency := event.StageTimestamp.Sub(*createTime).Seconds()</span><br><span class="line"></span><br><span class="line">        user := extractUserAgent(event.UserAgent)</span><br><span class="line">        podSchedulingLatency.WithLabelValues(</span><br><span class="line">          clusterLabel,</span><br><span class="line">          ns,</span><br><span class="line">          user,</span><br><span class="line">        ).Observe(latency)</span><br><span class="line">      <span class="comment">// 核心为：podSchedulingLatency.WithLabelValues(...).Observe()</span></span><br><span class="line">        p.podCreationTimes[target] = <span class="literal">nil</span></span><br><span class="line"></span><br><span class="line">      }</span><br><span class="line">      ...</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div></li>
<li><strong>扩展步骤</strong>：<ol>
<li>复制：复制上述变量块，替换 <code>Name</code> 为 <code>kube_audit_pod_latency_seconds</code>（示例），同时调整 <code>Buckets</code>、<code>Help</code> 等参数；</li>
<li>修改：在 <code>updateMetrics</code> 中增加条件：<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> evt.ObjectRef.Resource == <span class="string">"pods"</span> {</span><br><span class="line">    podLatency.WithLabelValues(evt.Verb, evt.Stage).Observe(cost)</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div></li>
<li>注册：确保在 <code>init()</code> 或 <code>NewCollector()</code> 中 <code>registry.MustRegister(podLatency)</code>；</li>
<li>换镜像：<code>docker build -t &lt;registry&gt;/audit-exporter:dev . &amp;&amp; docker push …</code>，然后在 <code>base/kube-apiserver-audit-exporter/.../deployment.yaml</code> 更新 <code>image</code> 并 <code>kubectl apply -k</code>。</li>
</ol>
</li>
</ul>
<blockquote>
<p>完整示例可参考项目 <code>exporter/metrics.go</code> <a class="link" href="https://github.com/wzshiming/kube-apiserver-audit-exporter/blob/master/exporter/metrics.go">源码<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>。</p>
</blockquote>
<hr>
<h1 id="3️⃣-Prometheus-抓取：Kustomize-一条龙"><a href="#3️⃣-Prometheus-抓取：Kustomize-一条龙" class="headerlink" title="3️⃣ Prometheus 抓取：Kustomize 一条龙"></a>3️⃣ Prometheus 抓取：Kustomize 一条龙</h1><p><code>base/kube-prometheus-stack</code> 目录通过 Kustomize 把 Exporter、Prometheus Operator 与多个 ServiceMonitor 组合在一起，无需额外手动配置抓取目标。</p>
<ul>
<li>Prometheus 会自动发现 Exporter 的 <code>metrics</code> 端口；</li>
<li>Grafana 面板 JSON <code>audit-exporter.json</code> 已预置在同目录，标签切片（Scheduler 类型、Namespace、Verb）均可动态选择。</li>
</ul>
<blockquote>
<p>若要自定义阈值或颜色，只需 <code>kubectl edit cm grafana-dashboards</code> 后刷新浏览器即可即时生效。</p>
</blockquote>
<p>其中用到了 Kustomize 工具，较为复杂，在此仅简单介绍。</p>
<h2 id="✨-Kustomize-简介"><a href="#✨-Kustomize-简介" class="headerlink" title="✨ Kustomize 简介"></a>✨ Kustomize 简介</h2><p>Kustomize 是 Kubernetes 官方提供的 <strong>原生资源定制工具</strong>，核心理念是“声明式 Patch 与组合”。相比 <code>helm</code>，它无需模板语言，也不引入额外 CRD：</p>
<ul>
<li><strong>基础资源</strong>（Base）：每个目录下的 <code>kustomization.yaml</code> 列出若干 <code>resources</code>，可按文件或目录引用；</li>
<li><strong>叠加层</strong>（Overlay）：上层可以通过 <code>patches</code>, <code>images</code>, <code>replicas</code> 等声明式字段覆写或追加配置；</li>
<li><strong>生成器</strong>：<code>configMapGenerator</code>, <code>secretGenerator</code> 快速为应用生成引用。</li>
</ul>
<p>在本项目中：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">base/kube-prometheus-stack/           # 监控基础组件 Base</span><br><span class="line">  ├── crd/                            # CRD 资源</span><br><span class="line">  ├── grafana/                        # Dashboard JSON 及账号</span><br><span class="line">  ├── ...</span><br><span class="line">  └── kustomization.yaml              # 声明所有组件</span><br></pre></td></tr></table></figure></div>

<p><code>clusters/overview/Makefile</code> 里的 <code>kubectl kustomize &lt;dir&gt; | hack/local-registry-with-load-images.sh</code> 两步做了：</p>
<ol>
<li><code>kubectl kustomize</code> → <strong>渲染</strong>：把以上 Base + Patch 解析成纯 YAML 清单；</li>
<li><code>local-registry-with-load-images.sh</code> → <strong>镜像处理</strong>：重写鏡像地址到本地 Kind Registry 并预先 <code>docker pull</code>；</li>
<li><code>kubectl create -k</code> → <strong>应用</strong>：批量创建 Exporter、Prometheus Operator、Alertmanager、ServiceMonitor 等所有资源，一次到位。</li>
</ol>
<p>因此我们才能“一键 make”拿到完整的监控栈。</p>
<hr>
<h1 id="4️⃣-截图归档：save-result-images-sh-归档面板截图"><a href="#4️⃣-截图归档：save-result-images-sh-归档面板截图" class="headerlink" title="4️⃣ 截图归档：save-result-images.sh 归档面板截图"></a>4️⃣ 截图归档：save-result-images.sh 归档面板截图</h1><p>运行 <code>make save-result</code> 后，<code>hack/save-result-images.sh</code> 会在本地循环调用 Grafana <code>render</code> API，按面板 ID 生成 <code>output/panel-*.png</code>：</p>
<div class="code-container" data-rel="Sh"><figure class="iseeu highlight sh"><figcaption><span>hack/save-result-images.sh</span></figcaption><table><tr><td class="code"><pre><span class="line">RECENT_DURATION=<span class="variable">${RECENT_DURATION:-5min}</span></span><br><span class="line"></span><br><span class="line">FROM=$(<span class="built_in">date</span> -u -Iseconds -d <span class="string">"- <span class="variable">${RECENT_DURATION}</span>"</span> | sed <span class="string">'s/+00:00/.000Z/'</span>)</span><br><span class="line">TO=$(<span class="built_in">date</span> -u -Iseconds | sed <span class="string">'s/+00:00/.000Z/'</span>)</span><br><span class="line"></span><br><span class="line">OUTPUT=<span class="string">"<span class="variable">${ROOT_DIR}</span>/output"</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="string">"<span class="variable">${OUTPUT}</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> {1..8}; <span class="keyword">do</span></span><br><span class="line">  wget -O <span class="string">"<span class="variable">${OUTPUT}</span>/panel-<span class="variable">${i}</span>.png"</span> <span class="string">"http://127.0.0.1:8080/grafana/render/d-solo/perf?var-rate_interval=5s&amp;orgId=1&amp;from=<span class="variable">${FROM}</span>&amp;to=<span class="variable">${TO}</span>&amp;timezone=browser&amp;var-datasource=prometheus&amp;var-resource=\$__all&amp;var-user=\$__all&amp;var-verb=create&amp;var-verb=delete&amp;var-verb=patch&amp;var-verb=update&amp;var-namespace=default&amp;var-cluster=\$__all&amp;refresh=5s&amp;theme=dark&amp;panelId=panel-<span class="variable">${i}</span>&amp;__feature.dashboardSceneSolo&amp;width=900&amp;height=500&amp;scale=10"</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li><code>RECENT_DURATION</code> 环境变量控制 <em>截图时间窗口</em>（默认 5 分钟）；</li>
<li><code>FROM/TO</code> 时间戳使用 ISO-8601 UTC 毫秒格式，避免时区混淆；</li>
<li><code>panelId</code> 与面板 JSON 中的 <code>id</code> 一一对应，可根据需要扩展。</li>
</ul>
<p>示例输出目录结构：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">output/</span><br><span class="line">  ├── panel-1.png   # CREATED 速率</span><br><span class="line">  ├── panel-2.png   # SCHEDULED 速率</span><br><span class="line">  ├── panel-3.png   # RUNNING 速率</span><br><span class="line">  └── …</span><br></pre></td></tr></table></figure></div>

<h2 id="⏱️-为什么三套调度器曲线对齐到同一起始时间？"><a href="#⏱️-为什么三套调度器曲线对齐到同一起始时间？" class="headerlink" title="⏱️ 为什么三套调度器曲线对齐到同一起始时间？"></a>⏱️ 为什么三套调度器曲线对齐到同一起始时间？</h2><p>在 <em>serial-test</em> 模式下，Exporter 直到第 4 步才启动，<strong>它会从头开始顺序扫描所有 audit-log</strong>。Prometheus 采集时将「第一次 scrape 该指标的时刻」视为样本时间戳，而不是事件发生时间。因此：</p>
<ul>
<li>当 Exporter 第一次读取 <em>三份</em> 日志文件时（约 <strong>T0</strong>），所有指标都会带上 <strong>T0</strong> 的统一时间戳；</li>
<li>读取完第一份文件后继续第二、第三份——对于 Prometheus 来说也仍是 “T0~T0+Δ” 的时间窗口；</li>
</ul>
<p>结果就是：Grafana 图上三条曲线似乎“同一时刻起跑”。它们并非并发，而是 <strong>日志回放造成的时间折叠</strong> —— 先跑的调度器其实更早完成，但其事件被延后才被采集。</p>
<p>如果希望曲线按真实事件时间展开，可以：</p>
<ol>
<li>修改 Exporter，让它把 <code>evt.StageTimestamp</code> 用作 Prometheus <code>histogram</code> 的 <code>ObserveWithTimestamp</code>；</li>
<li>或者在测试流程中提前启动 overview 集群，使 Exporter 按实时模式持续采集。</li>
</ol>
<p>如果想<strong>亲眼查看 audit-log</strong>，有两种方法：</p>
<ol>
<li><strong>直接读宿主机文件</strong>（Kind 节点实际上是 Docker 容器）：<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> kueue-control-plane \</span><br><span class="line">  <span class="built_in">cat</span> /var/log/kubernetes/kube-apiserver-audit.kueue.log | <span class="built_in">head</span></span><br></pre></td></tr></table></figure></div>
三个文件名称分别为 <code>kube-apiserver-audit.{kueue|volcano|yunikorn}.log</code>。</li>
<li><strong>查看 Exporter 容器日志</strong>（overview 集群）：<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl -n monitoring logs deploy/kube-apiserver-audit-exporter | <span class="built_in">head</span></span><br></pre></td></tr></table></figure></div>
启动时它会打印 <code>starting from offset=0 file=...</code>，表明正在从头重放。</li>
</ol>
<blockquote>
<p>日志文件很大，可用 <code>grep '"verb":"create"'</code> 等命令过滤感兴趣事件，字段含义详见 Kubernetes 官方审计文档。</p>
</blockquote>
<h2 id="📊-Panel-一览速查表"><a href="#📊-Panel-一览速查表" class="headerlink" title="📊 Panel 一览速查表"></a>📊 Panel 一览速查表</h2><table>
<thead>
<tr>
<th>面板 ID</th>
<th>Grafana 标题</th>
<th>输出文件</th>
<th>主要查询</th>
<th>典型用途</th>
</tr>
</thead>
<tbody><tr>
<td>panel-1</td>
<td>Pod Scheduling Latency Group By UserAgent</td>
<td>panel-1.png</td>
<td><code>histogram_quantile(0.99, pod_scheduling_latency_seconds_bucket)</code> 等分位线</td>
<td>调度延迟长尾监控</td>
</tr>
<tr>
<td>panel-2</td>
<td>Total API Calls Group By (UserAgent, Verb, Resource)</td>
<td>panel-2.png</td>
<td><code>api_requests_total</code> 累积</td>
<td>全维度 API 调用计数</td>
</tr>
<tr>
<td>panel-3</td>
<td>API Calls Rate Group By (UserAgent, Verb, Resource)</td>
<td>panel-3.png</td>
<td><code>rate(api_requests_total[$rate_interval])</code></td>
<td>API 吞吐趋势（含资源/动词维度）</td>
</tr>
<tr>
<td>panel-4</td>
<td>BatchJob Completion Latency Group By UserAgent</td>
<td>panel-4.png</td>
<td><code>histogram_quantile(... batchjob_completion_latency_seconds_bucket)</code></td>
<td>关注 Job 完成延迟</td>
</tr>
<tr>
<td>panel-5</td>
<td>Total Pod Scheduled Group By UserAgent</td>
<td>panel-5.png</td>
<td><code>sum(pod_scheduling_latency_seconds_count)</code> vs <code>sum(api_requests_total{verb="create",resource="pods"})</code></td>
<td>对比已调度与已创建 Pod 总量</td>
</tr>
<tr>
<td>panel-6</td>
<td>Total BatchJob Completed Group By UserAgent</td>
<td>panel-6.png</td>
<td><code>sum(batchjob_completion_latency_seconds_count)</code></td>
<td>Job 完成总量统计</td>
</tr>
<tr>
<td>panel-7</td>
<td>Total API Calls Group By UserAgent</td>
<td>panel-7.png</td>
<td><code>sum(api_requests_total) by (cluster,user)</code></td>
<td>按 UserAgent 维度累计 API 调用</td>
</tr>
<tr>
<td>panel-8</td>
<td>API Calls Rate Group By UserAgent</td>
<td>panel-8.png</td>
<td><code>rate(api_requests_total[$rate_interval])</code></td>
<td>按 UserAgent 维度 API 吞吐</td>
</tr>
</tbody></table>
<blockquote>
<p>以上所有查询皆可在 <code>base/kube-prometheus-stack/audit-exporter.json</code> 中找到对应 <code>panel.id</code> 的 <code>expr</code> 字段。</p>
</blockquote>
<h3 id="🏷️-CREATED-SCHEDULED-指标与-Panel-5-解读"><a href="#🏷️-CREATED-SCHEDULED-指标与-Panel-5-解读" class="headerlink" title="🏷️ CREATED / SCHEDULED 指标与 Panel-5 解读"></a>🏷️ CREATED / SCHEDULED 指标与 Panel-5 解读</h3><p>Grafana 的 <strong>panel-5.png</strong>（<code>Total Pod Scheduled Group By UserAgent</code>）同时叠加了 <em>累计已调度</em> 与 <em>累计已创建</em> 两条时间序列，用来快速判断“调度器吞吐量是否跟得上工作负载产生速度”。</p>
<p>两条序列的 PromQL 如下：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 已调度总量（Series-A）</span><br><span class="line">sum(pod_scheduling_latency_seconds_count{cluster=~"$cluster",namespace=~"$namespace",user=~"$user"}) by (cluster,user)</span><br><span class="line"></span><br><span class="line"># 已创建总量（Series-B）</span><br><span class="line">sum(api_requests_total{cluster=~"$cluster",namespace=~"$namespace",user=~"$user",resource="pods",verb="create"}) by (cluster,user)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>💡 <strong>资源类型</strong></p>
<ul>
<li>两条序列均针对 <strong>Pod</strong> 资源：<ul>
<li><strong>Series-B（CREATED）</strong> 捕获 <code>verb=create, resource=pods</code> 的审计事件；</li>
<li><strong>Series-A（SCHEDULED）</strong> 统计 <code>pod_scheduling_latency_seconds_count</code> 直方图计数，同样基于 Pod UID 聚合。</li>
</ul>
</li>
<li>Volcano 中的 <strong>PodGroup</strong> 仅在 <em>Gang</em> 场景下辅助调度，不会出现在上述指标中，因其创建频次远低于 Pod，且非调度器吞吐主瓶颈。</li>
</ul>
</blockquote>
<h3 id="ℹ️-为什么-Panel-5-采用-pod-scheduling-latency-seconds-count？可以改用-api-requests-total-吗？"><a href="#ℹ️-为什么-Panel-5-采用-pod-scheduling-latency-seconds-count？可以改用-api-requests-total-吗？" class="headerlink" title="ℹ️ 为什么 Panel-5 采用 pod_scheduling_latency_seconds_count？可以改用 api_requests_total 吗？"></a>ℹ️ 为什么 Panel-5 采用 <code>pod_scheduling_latency_seconds_count</code>？可以改用 <code>api_requests_total</code> 吗？</h3><ol>
<li><strong>数据源差异</strong><ul>
<li><code>api_requests_total{verb="create",resource="pods/binding"}</code> 也能反映调度动作，但 <strong>Exporter 默认并未将 <code>pods/binding</code> 事件打入此 Counter</strong>，而是交由 <code>pod_scheduling_latency_seconds</code> Histogram 统一处理（具体实现可见本文“<a href="#-%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0exporter-%E5%A6%82%E4%BD%95-tail--%E8%A7%A3%E6%9E%90">🔍 内部实现：Exporter 如何 tail + 解析？</a>”章节代码示例），以便同时统计累积延迟。</li>
<li>Histogram 自带 <code>_count</code> 系列，天然表示 <strong>成功调度次数</strong>；其 Bucket 仍能计算 P99 等延迟 —— 一举两得。</li>
</ul>
</li>
<li><strong>统计精度</strong><ul>
<li>Exporter 对同一 Pod 仅在 <strong>首次绑定成功</strong> 时 <code>Observe</code> 一次，所以 <code>_count</code> 与实际调度 Pod 数量一一对应，不会多计。</li>
<li>若直接使用 <code>api_requests_total</code> 方案，需要确保：<ol>
<li>Exporter 也把 <code>pods/binding</code> 计入 Counter；</li>
<li>Retry 或失败重试场景会导致多计，需要额外 <code>status="Success"</code> 过滤。</li>
</ol>
</li>
</ul>
</li>
<li><strong>替代方案</strong><ul>
<li>若你更习惯 Counter，可在 <code>metrics.go</code> 中追加：<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line">podBindRequests := prometheus.NewCounterVec(... name=<span class="string">"pod_bind_requests_total"</span> ...)</span><br><span class="line"><span class="comment">// 在 event.ObjectRef.Subresource=="binding" 时 Inc()</span></span><br></pre></td></tr></table></figure></div></li>
<li>然后在 Dashboard 将 Panel-5 的 Series-A 改为 <code>sum(pod_bind_requests_total)</code>。</li>
</ul>
</li>
</ol>
<p>⚖️ <strong>结论</strong>：默认 <code>_count</code> 与 Counter 效果一致且无需新指标，<strong>不会导致调度数量误差</strong>；若需要可根据上述方法自定义。</p>
<hr>
<h1 id="5️⃣-本地验证：三步走"><a href="#5️⃣-本地验证：三步走" class="headerlink" title="5️⃣ 本地验证：三步走"></a>5️⃣ 本地验证：三步走</h1><ol>
<li><strong>最小规模跑一次</strong></li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">make prepare-volcano start-volcano end-volcano \</span><br><span class="line">    NODES_SIZE=1 JOBS_SIZE_PER_QUEUE=1 PODS_SIZE_PER_JOB=1</span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li><strong>打开 Grafana</strong></li>
</ol>
<p>浏览器访问 <a class="link" href="http://127.0.0.1:8080/grafana">http://127.0.0.1:8080/grafana<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>，Dashboards → <code>perf</code>，即可看到实时曲线。</p>
<ol start="3">
<li><strong>查看截图</strong></li>
</ol>
<p>测试结束后，<code>output/</code> 将出现自动截好的图片，确认时间轴与曲线一致。</p>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>


<p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.youtube.com/watch?v=njT5r3JjIaA&list=PLj6h78yzYM2MP0QhYFK8HOb8UqgbIkLMc&index=226">[2] A Comparative Analysis of Kueue, Volcano, and YuniKorn - Wei Huang, Apple &amp; Shiming Zhang, DaoCloud<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/audit/">[3] Kubernetes官方文档 - 审计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Policy">[4] Kubernetes官方文档 - 审计Policy配置参考<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>K8s</tag>
        <tag>性能测试</tag>
        <tag>监控</tag>
        <tag>Volcano</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano 测试流程拆解</title>
    <url>/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li>
<li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li>
<li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li>
<li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li>
<li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li>
<li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li>
<li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li>
<li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li>
<li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li>
<li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li>
<li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li>
<li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li>
<li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li>
<li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a>
</li>
</ol>
</blockquote>
<p>本文将以 Volcano 为代表，解析<a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">kube-scheduler-performance<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>工具一次 <strong>调度器性能测试</strong> 从集群启动到结果归档的完整链路，搞清楚 <strong>每个步骤调用了哪些文件、各自作用是什么</strong>，为后续指标剖析与实验扩展打下基础。</p>
<p>阅读完本文，希望能够帮你快速实现：</p>
<ol>
<li>复现最小规模的 Volcano 性能测试；</li>
<li>在源码中快速定位某一步骤的入口脚本 / YAML。</li>
</ol>
<hr>
<h1 id="1️⃣-执行链路总览"><a href="#1️⃣-执行链路总览" class="headerlink" title="1️⃣ 执行链路总览"></a>1️⃣ 执行链路总览</h1><p>执行一次最小测试的命令非常简单：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">make prepare-volcano start-volcano end-volcano \</span><br><span class="line">    NODES_SIZE=1 JOBS_SIZE_PER_QUEUE=1 PODS_SIZE_PER_JOB=1</span><br></pre></td></tr></table></figure></div>
<p>这背后却触发了 <strong>≥ 10</strong> 个 Makefile 目标与 <strong>30+</strong> 个 YAML / Shell / Go 文件。整体时序如图所示（流程简化，仅保留关键节点）：</p>
<pre class="mermaid">graph TD;
    A[prepare-volcano] --&gt; B[up-volcano];
    B --&gt; C[kind 创建测试集群];
    C --&gt; D[wait-volcano];
    D --&gt; E[test-init-volcano];
    A -.-&gt;|完成后调用| F[start-volcano];
    F --&gt; G[reset-auditlog-volcano];
    G --&gt; H[test-batch-job-volcano];
    F -.-&gt; |完成后调用| I[end-volcano];
    I --&gt; J[down-volcano];</pre>

<blockquote>
<p>Tips: <code>prepare-volcano → start-volcano → end-volcano</code> 由根 Makefile 的 <code>define test-scheduler</code> 宏在编译期自动展开。</p>
</blockquote>
<h2 id="宏展开示例：Volcano"><a href="#宏展开示例：Volcano" class="headerlink" title="宏展开示例：Volcano"></a>宏展开示例：Volcano</h2><p><code>define test-scheduler</code> 是一个带占位符 <code>$(1)</code> 的宏，最后通过 <code>$(foreach sched,$(SCHEDULERS),$(eval $(call test-scheduler,$(sched))))</code> 对 <em>kueue / volcano / yunikorn</em> 进行循环替换。下面以 <strong>Volcano</strong> 为例简要对比“模板”与“实例”——</p>
<p><strong>模板片段（截自 Makefile:110:140）</strong></p>
<div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">define</span> test-scheduler</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: prepare-$(1)</span></span><br><span class="line"><span class="section">prepare-$(1):</span></span><br><span class="line">	make up-$(1)</span><br><span class="line">	make wait-$(1)</span><br><span class="line">	make test-init-$(1)</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: start-$(1)</span></span><br><span class="line"><span class="section">start-$(1):</span></span><br><span class="line">	make reset-auditlog-$(1)</span><br><span class="line">	make test-batch-job-$(1)</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: end-$(1)</span></span><br><span class="line"><span class="section">end-$(1):</span></span><br><span class="line">	make down-$(1)</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: up-$(1)</span></span><br><span class="line"><span class="section">up-$(1):</span></span><br><span class="line">	make -C ./clusters/$(1) up</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: down-$(1)</span></span><br><span class="line"><span class="section">down-$(1):</span></span><br><span class="line">	-make -C ./clusters/$(1) down</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: wait-$(1)</span></span><br><span class="line"><span class="section">wait-$(1):</span></span><br><span class="line">	make -C ./clusters/$(1) wait</span><br><span class="line"></span><br><span class="line"><span class="section">bin/test-$(1): $(shell find ./test/utils ./test/$(1) -type f)</span></span><br><span class="line">	<span class="variable">$(GO_IN_DOCKER)</span> go test -c -o ./bin/test-$(1) ./test/$(1)</span><br></pre></td></tr></table></figure></div>
<p><strong>展开后（自动生成）的部分规则</strong></p>
<div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: prepare-volcano</span></span><br><span class="line"><span class="section">prepare-volcano:</span></span><br><span class="line">	make up-volcano</span><br><span class="line">	make wait-volcano</span><br><span class="line">	make test-init-volcano</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: start-volcano</span></span><br><span class="line"><span class="section">start-volcano:</span></span><br><span class="line">	make reset-auditlog-volcano</span><br><span class="line">	make test-batch-job-volcano</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: end-volcano</span></span><br><span class="line"><span class="section">end-volcano:</span></span><br><span class="line">	make down-volcano</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure></div>
<p>借助这种“写一次、生成三份”的做法，大幅减少了针对不同调度器写重复 Make 目标的工作量。</p>
<hr>
<h1 id="2️⃣-关键-Makefile-目标拆解"><a href="#2️⃣-关键-Makefile-目标拆解" class="headerlink" title="2️⃣ 关键 Makefile 目标拆解"></a>2️⃣ 关键 Makefile 目标拆解</h1><table>
<thead>
<tr>
<th>目标</th>
<th>所在文件</th>
<th>主要命令</th>
<th>职责说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>prepare-volcano</code></td>
<td>根 <code>Makefile</code></td>
<td><code>make up-volcano</code> <code>make wait-volcano</code> <code>make test-init-volcano</code></td>
<td>集群启动 + 基础就绪检查 + 预热测试二进制</td>
</tr>
<tr>
<td><code>up-volcano</code></td>
<td><code>clusters/volcano/Makefile</code></td>
<td><code>kind create cluster</code> &amp; 部署 Volcano</td>
<td>创建 Kind 集群并应用 Volcano 相关 Kustomize 资源</td>
</tr>
<tr>
<td><code>wait-volcano</code></td>
<td>同上</td>
<td><code>kubectl wait --for=condition=Ready</code></td>
<td>等待所有 Pod Ready，含 controller / scheduler</td>
</tr>
<tr>
<td><code>test-init-volcano</code></td>
<td>根 <code>Makefile</code></td>
<td>运行 <code>bin/test-volcano -run ^TestInit</code></td>
<td>生成初始队列、扩容节点</td>
</tr>
<tr>
<td><code>start-volcano</code></td>
<td>根 <code>Makefile</code></td>
<td><code>make reset-auditlog-volcano</code> <code>make test-batch-job-volcano</code></td>
<td>清空上一轮 audit 日志 &amp; 正式发压</td>
</tr>
<tr>
<td><code>reset-auditlog-volcano</code></td>
<td><code>clusters/volcano/Makefile</code></td>
<td><code>kubectl delete</code> audit-log ConfigMap</td>
<td>置空历史日志，保证数据窗口准确</td>
</tr>
<tr>
<td><code>test-batch-job-volcano</code></td>
<td>根 <code>Makefile</code></td>
<td><code>bin/test-volcano -run ^TestBatchJob</code></td>
<td>按参数批量提交 Job / Pod 并记录时间线</td>
</tr>
<tr>
<td><code>end-volcano</code></td>
<td>根 <code>Makefile</code></td>
<td><code>make down-volcano</code></td>
<td>销毁 Kind 集群，释放资源</td>
</tr>
</tbody></table>
<hr>
<h1 id="3️⃣-clusters-volcano-目录速览"><a href="#3️⃣-clusters-volcano-目录速览" class="headerlink" title="3️⃣ clusters/volcano 目录速览"></a>3️⃣ clusters/volcano 目录速览</h1><ul>
<li><code>kind.yaml</code>：集群版本、节点数量、containerd 本地镜像仓库挂载；</li>
<li><code>deployment.yaml</code>：Volcano Controller 与 Scheduler 部署模板；</li>
<li><code>kustomization.yaml</code>：声明所有资源并支持 <code>image</code> 覆盖；</li>
<li><code>service.yaml</code>：暴露 Volcano webhook / metrics（如需）。</li>
</ul>
<p>这些文件通过 <code>kustomize build</code> 管道被 <code>up-volcano</code> 目标应用到 Kind 集群中。</p>
<hr>
<h1 id="4️⃣-test-volcano-测试代码剖析"><a href="#4️⃣-test-volcano-测试代码剖析" class="headerlink" title="4️⃣ test/volcano 测试代码剖析"></a>4️⃣ test/volcano 测试代码剖析</h1><p>核心 Go 测试位于 <code>test/volcano/</code> 目录，包含两个主要测试函数和一套完整的 Provider 实现。<strong>整体思路</strong>：通过 Go 语言编写测试用例，调用 Kubernetes API 在真实集群中创建资源，模拟大规模批量调度场景。</p>
<h2 id="TestInit-和-TestBatchJob-流程"><a href="#TestInit-和-TestBatchJob-流程" class="headerlink" title="TestInit 和 TestBatchJob 流程"></a>TestInit 和 TestBatchJob 流程</h2><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><figcaption><span>test/volcano/batch_job_test.go</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestInit</span><span class="params">(t *testing.T)</span></span> {</span><br><span class="line">	err := provider.AddNodes(t.Context())</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">		t.Fatal(err)</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	err = provider.InitCase(t.Context())</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">		t.Fatal(err)</span><br><span class="line">	}</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestBatchJob</span><span class="params">(t *testing.T)</span></span> {</span><br><span class="line">	err := provider.AddJobs(t.Context())</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">		t.Fatal(err)</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	err = utils.WaitDeployment(t.Context(), utils.Resources)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">		t.Fatal(err)</span><br><span class="line">	}</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>核心逻辑</strong>：</p>
<ul>
<li><code>TestInit</code>：<strong>集群预热阶段</strong>，创建假节点（通过 KWOK）和配置 Volcano 队列层级</li>
<li><code>TestBatchJob</code>：<strong>正式压测阶段</strong>，批量提交 Job 并等待调度完成</li>
</ul>
<p>两个测试函数通过 **全局变量 <code>provider</code>**（VolcanoProvider 实例）共享状态，测试参数从环境变量或 Makefile 传入。</p>
<h2 id="参数传递机制解析"><a href="#参数传递机制解析" class="headerlink" title="参数传递机制解析"></a>参数传递机制解析</h2><p>测试参数的传递遵循 <strong>Makefile → 环境变量 → Go Flag → Provider 实例</strong> 的四级链路：</p>
<h3 id="1-Makefile-参数定义"><a href="#1-Makefile-参数定义" class="headerlink" title="1. Makefile 参数定义"></a>1. Makefile 参数定义</h3><div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><figcaption><span>Makefile</span></figcaption><table><tr><td class="code"><pre><span class="line">CPU_PER_NODE ?= 128</span><br><span class="line">MEMORY_PER_NODE ?= 1024Gi</span><br><span class="line">NODES_SIZE ?= 1</span><br><span class="line"></span><br><span class="line">QUEUES_SIZE ?= 1</span><br><span class="line">JOBS_SIZE_PER_QUEUE ?= 1</span><br><span class="line">PODS_SIZE_PER_JOB ?= 1</span><br><span class="line"></span><br><span class="line">CPU_REQUEST_PER_POD ?= 1</span><br><span class="line">MEMORY_REQUEST_PER_POD ?= 1Gi</span><br><span class="line"></span><br><span class="line">GANG ?= false</span><br><span class="line">PREEMPTION ?= false</span><br></pre></td></tr></table></figure></div>

<h3 id="2-环境变量注入"><a href="#2-环境变量注入" class="headerlink" title="2. 环境变量注入"></a>2. 环境变量注入</h3><p>当执行 <code>make test-batch-job-volcano</code> 时，Makefile 会将上述变量作为环境变量传递给测试进程：</p>
<div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><figcaption><span>Makefile</span></figcaption><table><tr><td class="code"><pre><span class="line">TEST_ENVS = \</span><br><span class="line">    NODES_SIZE=<span class="variable">$(NODES_SIZE)</span> \</span><br><span class="line">    CPU_PER_NODE=<span class="variable">$(CPU_PER_NODE)</span> \</span><br><span class="line">    MEMORY_PER_NODE=<span class="variable">$(MEMORY_PER_NODE)</span> \</span><br><span class="line">    QUEUES_SIZE=<span class="variable">$(QUEUES_SIZE)</span> \</span><br><span class="line">    JOBS_SIZE_PER_QUEUE=<span class="variable">$(JOBS_SIZE_PER_QUEUE)</span> \</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></div>

<h3 id="3-Go-Flag-解析"><a href="#3-Go-Flag-解析" class="headerlink" title="3. Go Flag 解析"></a>3. Go Flag 解析</h3><p><code>test/volcano/main_test.go</code> 中，<code>provider.AddFlags()</code> 调用 <code>test/utils/option.go</code> 的标准 flag 库：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><figcaption><span>test/utils/option.go</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(o *Options)</span></span> AddFlags() {</span><br><span class="line">    flag.StringVar(&amp;o.CpuPerNode, <span class="string">"cpu-per-node"</span>, getEnv(<span class="string">"CPU_PER_NODE"</span>, <span class="string">"32"</span>), <span class="string">"CPU resources per node"</span>)</span><br><span class="line">    flag.StringVar(&amp;o.MemoryPerNode, <span class="string">"memory-per-node"</span>, getEnv(<span class="string">"MEMORY_PER_NODE"</span>, <span class="string">"256Gi"</span>), <span class="string">"Memory resources per node"</span>)</span><br><span class="line">    flag.IntVar(&amp;o.NodeSize, <span class="string">"nodes-size"</span>, getEnvInt(<span class="string">"NODES_SIZE"</span>, <span class="number">1</span>), <span class="string">"Number of nodes to create"</span>)</span><br><span class="line">    </span><br><span class="line">    flag.IntVar(&amp;o.QueueSize, <span class="string">"queues-size"</span>, getEnvInt(<span class="string">"QUEUES_SIZE"</span>, <span class="number">1</span>), <span class="string">"Number of queues to create"</span>)</span><br><span class="line">    flag.IntVar(&amp;o.JobsSizePerQueue, <span class="string">"jobs-size-per-queue"</span>, getEnvInt(<span class="string">"JOBS_SIZE_PER_QUEUE"</span>, <span class="number">1</span>), <span class="string">"Number of jobs per queue"</span>)</span><br><span class="line">    flag.IntVar(&amp;o.PodsSizePerJob, <span class="string">"pods-size-per-job"</span>, getEnvInt(<span class="string">"PODS_SIZE_PER_JOB"</span>, <span class="number">1</span>), <span class="string">"Number of pods per job"</span>)</span><br><span class="line">    </span><br><span class="line">    flag.BoolVar(&amp;o.Gang, <span class="string">"gang"</span>, getEnvBool(<span class="string">"GANG"</span>, <span class="literal">false</span>), <span class="string">"Enable gang scheduling"</span>)</span><br><span class="line">    flag.BoolVar(&amp;o.Preemption, <span class="string">"preemption"</span>, getEnvBool(<span class="string">"PREEMPTION"</span>, <span class="literal">false</span>), <span class="string">"Enable preemption"</span>)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getEnv</span><span class="params">(key, fallback <span class="type">string</span>)</span></span> <span class="type">string</span> {</span><br><span class="line">    <span class="keyword">if</span> value, exists := os.LookupEnv(key); exists {</span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> fallback</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="4-优先级覆盖机制"><a href="#4-优先级覆盖机制" class="headerlink" title="4. 优先级覆盖机制"></a>4. 优先级覆盖机制</h3><p>参数读取有明确的优先级：<strong>命令行参数 &gt; 环境变量 &gt; 默认值</strong></p>
<p>例如：</p>
<ul>
<li><code>make test-batch-job-volcano NODES_SIZE=100</code>：通过 Makefile 变量传递</li>
<li><code>NODES_SIZE=200 ./bin/test-volcano</code>：直接设置环境变量</li>
<li><code>./bin/test-volcano -nodes-size=300</code>：命令行参数（最高优先级）</li>
</ul>
<p>因此，当我们在前面代码中看到 <code>p.CpuPerNode</code>、<code>p.NodeSize</code> 等字段时，它们的值最终来源于这套参数传递链路，确保了测试规模可以通过 Makefile 灵活调控。</p>
<h2 id="VolcanoProvider-核心实现"><a href="#VolcanoProvider-核心实现" class="headerlink" title="VolcanoProvider 核心实现"></a>VolcanoProvider 核心实现</h2><h3 id="1-AddNodes：批量创建假节点"><a href="#1-AddNodes：批量创建假节点" class="headerlink" title="1. AddNodes：批量创建假节点"></a>1. AddNodes：批量创建假节点</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><figcaption><span>test/volcano/provider_test.go</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *VolcanoProvider)</span></span> AddNodes(ctx context.Context) <span class="type">error</span> {</span><br><span class="line">	builder := utils.NewNodeBuilder().</span><br><span class="line">		WithFastReady().</span><br><span class="line">		WithCPU(p.CpuPerNode).</span><br><span class="line">		WithMemory(p.MemoryPerNode)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="keyword">range</span> p.NodeSize {</span><br><span class="line">		err := utils.Resources.Create(ctx,</span><br><span class="line">			builder.</span><br><span class="line">				WithName(fmt.Sprintf(<span class="string">"node-%d"</span>, i)).</span><br><span class="line">				Build(),</span><br><span class="line">		)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">			<span class="keyword">return</span> err</span><br><span class="line">		}</span><br><span class="line">	}</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>解析</strong>：通过 <code>utils.NewNodeBuilder()</code> 构造器模式批量生成 Node 对象。关键点：</p>
<ul>
<li><code>WithFastReady()</code>：设置节点状态为 Ready，跳过真实硬件检测</li>
<li><code>WithCPU(p.CpuPerNode)</code>：每个节点的 CPU 容量（如 “128”）</li>
<li><code>WithMemory(p.MemoryPerNode)</code>：每个节点的内存容量（如 “1024Gi”）</li>
</ul>
<h3 id="2-InitCase：配置-Volcano-调度器"><a href="#2-InitCase：配置-Volcano-调度器" class="headerlink" title="2. InitCase：配置 Volcano 调度器"></a>2. InitCase：配置 Volcano 调度器</h3><p><strong>关键代码片段</strong>：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><figcaption><span>test/volcano/provider_test.go</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *VolcanoProvider)</span></span> InitCase(ctx context.Context) <span class="type">error</span> {</span><br><span class="line">	<span class="comment">// 1. 解析资源配额</span></span><br><span class="line">	cpuPerQueue, err := resource.ParseQuantity(p.CpuPerQueue)</span><br><span class="line">	memoryPerQueue, err := resource.ParseQuantity(p.MemoryPerQueue)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 2. 计算层级资源限制</span></span><br><span class="line">	<span class="keyword">if</span> p.CpuLendingLimit != <span class="string">""</span> {</span><br><span class="line">		cpuLendingLimit, err := resource.ParseQuantity(p.CpuLendingLimit)</span><br><span class="line">		hierarchy = <span class="literal">true</span></span><br><span class="line">		cpuCapabilityTotal = utils.TimesQuantity(cpuPerQueue, p.QueueSize+p.ImpactingQueuesSize+p.CriticalQueuesSize).String()</span><br><span class="line">		cpuCapability = cpuPerQueue.String()</span><br><span class="line">		cpuPerQueue.Sub(cpuLendingLimit)  <span class="comment">// deserved = capability - lending</span></span><br><span class="line">		cpuDeserved = cpuPerQueue.String()</span><br><span class="line">	}</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 3. 更新 root Queue 配置</span></span><br><span class="line">	obj := &amp;unstructured.Unstructured{}</span><br><span class="line">	obj.SetName(<span class="string">"root"</span>)</span><br><span class="line">	obj.SetAPIVersion(<span class="string">"scheduling.volcano.sh/v1beta1"</span>)</span><br><span class="line">	obj.SetKind(<span class="string">"Queue"</span>)</span><br><span class="line">	err = utils.Resources.Patch(ctx, obj, k8s.Patch{</span><br><span class="line">		PatchType: types.MergePatchType,</span><br><span class="line">		Data: []<span class="type">byte</span>(fmt.Sprintf(<span class="string">`{"spec":{"capability":{"cpu": %q, "memory": %q}}}`</span>, cpuCapabilityTotal, memoryCapabilityTotal)),</span><br><span class="line">	})</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 4. 重启 Volcano Scheduler 使配置生效</span></span><br><span class="line">	err = utils.RestartDeployment(ctx, utils.Resources, <span class="string">"volcano-scheduler"</span>, <span class="string">"volcano-system"</span>)</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>核心逻辑解析</strong>：</p>
<ol>
<li><strong>资源计算</strong>：根据队列数量计算总容量（<code>cpuCapabilityTotal</code>）和单队列配额（<code>cpuCapability</code>）</li>
<li><strong>层级调度</strong>：如果设置了 <code>CpuLendingLimit</code>，启用 <code>hierarchy=true</code>，计算 <code>deserved</code>（保证资源）和 <code>capability</code>（借用上限）</li>
<li><strong>动态配置</strong>：通过 <code>unstructured.Unstructured</code> 直接操作 CRD，避免导入 Volcano 依赖</li>
<li><strong>热重启</strong>：更新 ConfigMap 后重启 Scheduler Pod，确保新配置生效</li>
</ol>
<h3 id="3-AddJobs：分批提交作业"><a href="#3-AddJobs：分批提交作业" class="headerlink" title="3. AddJobs：分批提交作业"></a>3. AddJobs：分批提交作业</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><figcaption><span>test/volcano/provider_test.go</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *VolcanoProvider)</span></span> AddJobs(ctx context.Context) <span class="type">error</span> {</span><br><span class="line">	steps := []<span class="keyword">struct</span> {</span><br><span class="line">		queueSize    <span class="type">int</span></span><br><span class="line">		jobsPerQueue <span class="type">int</span></span><br><span class="line">		podsPerJob   <span class="type">int</span></span><br><span class="line">		priority     <span class="type">string</span></span><br><span class="line">		duration     <span class="type">string</span></span><br><span class="line">		delay        time.Duration</span><br><span class="line">	}{</span><br><span class="line">		{p.QueueSize, p.JobsSizePerQueue, p.PodsSizePerJob, <span class="string">"long-term-research"</span>, p.PodDuration, <span class="number">0</span>},</span><br><span class="line">		{p.ImpactingQueuesSize, p.ImpactingJobsSizePerQueue, p.ImpactingPodsSizePerJob, <span class="string">"business-impacting"</span>, p.ImpactingPodDuration, <span class="number">5</span> * time.Second},</span><br><span class="line">		{p.CriticalQueuesSize, p.CriticalJobsSizePerQueue, p.CriticalPodsSizePerJob, <span class="string">"human-critical"</span>, p.CriticalPodDuration, <span class="number">5</span> * time.Second},</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> _, step := <span class="keyword">range</span> steps {</span><br><span class="line">		<span class="keyword">if</span> step.delay &gt; <span class="number">0</span> {</span><br><span class="line">			time.Sleep(step.delay)  <span class="comment">// 模拟业务场景：优先级作业延迟到达</span></span><br><span class="line">		}</span><br><span class="line">		<span class="keyword">for</span> i := <span class="keyword">range</span> step.queueSize {</span><br><span class="line">			<span class="keyword">for</span> <span class="keyword">range</span> step.jobsPerQueue {</span><br><span class="line">				err := p.addSingleJobs(ctx, step.podsPerJob, i, step.priority, step.duration)</span><br><span class="line">				<span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">					<span class="keyword">return</span> err</span><br><span class="line">				}</span><br><span class="line">			}</span><br><span class="line">		}</span><br><span class="line">	}</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>策略解析</strong>：通过 <strong>三阶段提交</strong> 模拟真实多租户场景：</p>
<ol>
<li><strong>第一波</strong>：<code>long-term-research</code> 队列，立即提交（delay=0）</li>
<li><strong>第二波</strong>：<code>business-impacting</code> 队列，5秒后提交（模拟业务高峰）</li>
<li><strong>第三波</strong>：<code>human-critical</code> 队列，再5秒后提交（模拟紧急任务）</li>
</ol>
<p>每个阶段都有独立的 <strong>queueSize × jobsPerQueue × podsPerJob</strong> 三维参数，可灵活调整压测规模。</p>
<h2 id="Volcano-Job-模板解析"><a href="#Volcano-Job-模板解析" class="headerlink" title="Volcano Job 模板解析"></a>Volcano Job 模板解析</h2><p>使用的是 Volcano CRD <code>batch.volcano.sh/v1alpha1/Job</code>，关键字段：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><figcaption><span>test/volcano/batch_job.yaml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch.volcano.sh/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">volcano-job-#{{</span> <span class="string">.name</span> <span class="string">}}-#{{</span> <span class="string">.index</span> <span class="string">}}</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment">#{{ if .gang }}</span></span><br><span class="line">  <span class="attr">minAvailable:</span> <span class="comment">#{{ .size }}</span></span><br><span class="line">  <span class="comment">#{{ else }}</span></span><br><span class="line">  <span class="attr">minAvailable:</span> <span class="number">1</span></span><br><span class="line">  <span class="comment">#{{ end }}</span></span><br><span class="line">  <span class="attr">schedulerName:</span> <span class="string">volcano</span></span><br><span class="line">  <span class="attr">queue:</span> <span class="comment">#{{ .queue }}</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">replicas:</span> <span class="comment">#{{ .size }}</span></span><br><span class="line">    <span class="attr">template:</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sleep</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">hello-world</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="comment">#{{ .cpuRequestPerPod }}</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="comment">#{{ .memoryRequestPerPod }}</span></span><br><span class="line">        <span class="attr">nodeSelector:</span></span><br><span class="line">          <span class="attr">"type":</span> <span class="string">kwok</span></span><br></pre></td></tr></table></figure></div>

<p><strong>模板机制解析</strong>：</p>
<ul>
<li><strong>模板语法</strong>：<code>#{{ .variable }}</code> 由 <code>utils.YamlWithArgs()</code> 在运行时替换</li>
<li><strong>Gang 调度</strong>：<code>minAvailable: #{{ .size }}</code> 要求所有 Pod 同时就绪，模拟 MPI/AI 训练场景</li>
<li><strong>资源隔离</strong>：<code>queue: #{{ .queue }}</code> 指定队列，<code>schedulerName: volcano</code> 确保由 Volcano 调度</li>
<li><strong>假负载</strong>：<code>nodeSelector: "type": kwok</code> 强制调度到假节点，<code>image: hello-world</code> 秒级启动</li>
</ul>
<p><strong>实际执行过程</strong>：<code>addSingleJobs()</code> 调用 <code>utils.YamlWithArgs()</code> 将参数注入模板，再通过 <code>decoder.DecodeEach()</code> 解析 YAML 并调用 Kubernetes API 创建 Job。</p>
<hr>
<p><strong>技术要点总结</strong>：整个测试框架通过 <code>sigs.k8s.io/e2e-framework</code> 与真实 API Server 通信，产生的所有 API 调用都会被 audit-policy.yaml 记录，为后续指标分析提供数据源。</p>
<hr>
<h1 id="5️⃣-hack-脚本的幕后协同"><a href="#5️⃣-hack-脚本的幕后协同" class="headerlink" title="5️⃣ hack 脚本的幕后协同"></a>5️⃣ hack 脚本的幕后协同</h1><table>
<thead>
<tr>
<th>脚本</th>
<th>触发时机</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td><code>hack/kind-with-local-registry.sh</code></td>
<td><code>up-volcano</code> 前</td>
<td>启动本地 5001 registry + 注入 containerd 配置（**在每个 Kind 节点的 <code>/etc/containerd/certs.d/</code> 写入 <code>hosts.toml</code>**，指向本地仓库），实现“边拉边推、本地秒级拉取”</td>
</tr>
<tr>
<td><code>hack/local-registry-with-load-images.sh</code></td>
<td><code>up-volcano</code> 期间</td>
<td>将远端镜像拉取后重新打 tag 推到本地 registry，Kind 节点下载极快</td>
</tr>
<tr>
<td><code>hack/replace-qps.sh</code></td>
<td><em>可选</em></td>
<td>修改 APIServer QPS，<strong>一键替换所有带 <code># &lt;--QPS</code> 注释的 YAML 中的数值</strong>，从而把 <code>--kube-api-qps</code> 或 webhook QPS 提到 1000+，缓解 API Server 限流</td>
</tr>
<tr>
<td><code>hack/save-result-images.sh</code></td>
<td>测试结束后</td>
<td>调用 Grafana API 截图面板，写入 <code>output/</code> 归档</td>
</tr>
</tbody></table>
<h2 id="containerd-配置注入示例"><a href="#containerd-配置注入示例" class="headerlink" title="containerd 配置注入示例"></a>containerd 配置注入示例</h2><p><code>hack/kind-with-local-registry.sh</code> 的核心逻辑：</p>
<div class="code-container" data-rel="Sh"><figure class="iseeu highlight sh"><figcaption><span>hack/kind-with-local-registry.sh</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create kind cluster with containerd registry configuration</span></span><br><span class="line">kind create cluster --config <span class="string">"<span class="variable">${KIND_CONFIG:-}</span>"</span> --name <span class="string">"<span class="variable">${KIND_CLUSTER_NAME:-kind}</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure containerd registry hosts on all nodes</span></span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> $(kind get nodes); <span class="keyword">do</span></span><br><span class="line">  docker <span class="built_in">exec</span> <span class="string">"<span class="variable">${node}</span>"</span> <span class="built_in">mkdir</span> -p <span class="string">"<span class="variable">${registry_dir}</span>"</span></span><br><span class="line">  docker <span class="built_in">exec</span> -i <span class="string">"<span class="variable">${node}</span>"</span> <span class="built_in">tee</span> <span class="string">"<span class="variable">${registry_dir}</span>/hosts.toml"</span> &gt;/dev/null &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">[host."http://${in_cluster_registry}"]</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></div>

<p><strong>核心原理</strong>：脚本为每个 Kind 节点在 <code>/etc/containerd/certs.d/kind-registry:5000/hosts.toml</code> 写入配置，告诉 containerd 优先从本地 registry 拉取镜像，实现离线加速。</p>
<h4 id="修改-APIServer-QPS-示例"><a href="#修改-APIServer-QPS-示例" class="headerlink" title="修改 APIServer QPS 示例"></a>修改 APIServer QPS 示例</h4><p>当测试遇到 API Server QPS 瓶颈时，可以手动调用脚本，批量调整：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 把所有标记为 "# &lt;--QPS" 的数值统一改为 2000</span></span><br><span class="line">hack/replace-qps.sh 2000</span><br></pre></td></tr></table></figure></div>

<p>脚本核心逻辑：</p>
<div class="code-container" data-rel="Sh"><figure class="iseeu highlight sh"><figcaption><span>hack/replace-qps.sh</span></figcaption><table><tr><td class="code"><pre><span class="line">find . \</span><br><span class="line">    -iname <span class="string">"*.yaml"</span> \</span><br><span class="line">    -not \( -path ./vendor/\* -o -path ./tmp/\* \) \</span><br><span class="line">    -<span class="built_in">type</span> f \</span><br><span class="line">    -<span class="built_in">exec</span> sed -i <span class="string">'s|\([0-9]\+\)\(.\+\)# &lt;--QPS|'</span><span class="variable">${QPS}</span><span class="string">'\2# &lt;--QPS|g'</span> {} +</span><br></pre></td></tr></table></figure></div>

<p><strong>工作原理</strong>：遍历项目内所有 <code>.yaml</code> 文件，将包含 <code># &lt;--QPS</code> 标记行的数字替换为指定值。项目中共有 12 个文件、20+ 处配置受影响，包括调度器组件的 <code>--kube-api-qps</code>/<code>--kube-api-burst</code> 和 Kind 集群的 <code>kube-api-qps</code> 参数。</p>
<hr>
<h1 id="6️⃣-结语"><a href="#6️⃣-结语" class="headerlink" title="6️⃣ 结语"></a>6️⃣ 结语</h1><p>至此，我们已经串起了 <strong>Volcano 性能测试的最小可运行链路</strong>，并定位了关键 Makefile 目标与 YAML / Go 源码。下一篇将深入 <strong>指标采集与可视化</strong>，详解 audit-exporter 如何把 <code>CREATED / SCHEDULED / RUNNING</code> 三条曲线绘制到同一张 Grafana 面板。</p>
<blockquote>
<p>📌 <strong>实践练习</strong>：如果感兴趣，可以尝试把 <code>JOBS_SIZE_PER_QUEUE</code> 改为 2，再次运行测试，观察 <code>logs/</code> 与 <code>results/</code> 目录下是否出现新的时间戳文件夹，并查看面板截图差异。 </p>
</blockquote>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>


<p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.youtube.com/watch?v=njT5r3JjIaA&list=PLj6h78yzYM2MP0QhYFK8HOb8UqgbIkLMc&index=226">[2] A Comparative Analysis of Kueue, Volcano, and YuniKorn - Wei Huang, Apple &amp; Shiming Zhang, DaoCloud<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度器</tag>
        <tag>K8s</tag>
        <tag>性能测试</tag>
        <tag>Volcano</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano版本修改与性能测试优化</title>
    <url>/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li>
<li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li>
<li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li>
<li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li>
<li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li>
<li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li>
<li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li>
<li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li>
<li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li>
<li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li>
<li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li>
<li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li>
<li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li>
<li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a>
</li>
</ol>
</blockquote>
<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地环境测试结果与视频对比分析">本地环境测试结果与视频对比分析</a>中，我们发现本地测试结果与KubeCon技术分享视频中的结果存在显著差异。虽然整体趋势基本一致，但在某些测试场景下，本地测试的CREATED事件曲线、SCHEDULED事件表现与视频预期不符。</p>
<p>通过深入分析，我们猜测这些差异可能源于<strong>Volcano调度器版本不同</strong>。视频中使用的可能是较新的版本（如1.12.0-alpha.0），而本地环境使用的是较旧版本（v1.11.0）。本文详细介绍了如何查看当前测试所用的Volcano版本，如何自动化升级到目标版本，以及如何验证版本升级的效果。</p>
<h1 id="🔍问题回顾与分析"><a href="#🔍问题回顾与分析" class="headerlink" title="🔍问题回顾与分析"></a>🔍问题回顾与分析</h1><h2 id="1-本地测试与视频结果差异"><a href="#1-本地测试与视频结果差异" class="headerlink" title="1. 本地测试与视频结果差异"></a>1. 本地测试与视频结果差异</h2><h3 id="1-1-差异现象总结"><a href="#1-1-差异现象总结" class="headerlink" title="1.1 差异现象总结"></a>1.1 差异现象总结</h3><p>根据<a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="本地测试结果">本地测试结果</a>，我们发现了以下主要差异：</p>
<table>
<thead>
<tr>
<th>测试场景</th>
<th>视频预期</th>
<th>本地实际</th>
<th>差异分析</th>
</tr>
</thead>
<tbody><tr>
<td><strong>10K Jobs × 1 Pod</strong></td>
<td>YuniKorn吞吐量最高</td>
<td>✅ 符合预期</td>
<td>基本一致</td>
</tr>
<tr>
<td><strong>500 Jobs × 20 Pods</strong></td>
<td>CREATED阶段性突变</td>
<td>⚠️ 部分符合</td>
<td>可能版本差异</td>
</tr>
<tr>
<td><strong>20 Jobs × 500 Pods</strong></td>
<td>CREATED成为瓶颈</td>
<td>❌ 出现突变</td>
<td>瓶颈效应不明显</td>
</tr>
<tr>
<td><strong>1 Job × 10K Pods</strong></td>
<td>调度速度平稳</td>
<td>❌ 出现突变</td>
<td>版本兼容性问题</td>
</tr>
</tbody></table>
<h3 id="1-2-差异原因猜测"><a href="#1-2-差异原因猜测" class="headerlink" title="1.2 差异原因猜测"></a>1.2 差异原因猜测</h3><p>基于测试结果分析，我们猜测差异可能源于：</p>
<ol>
<li><strong>调度器版本差异</strong>：本地使用v1.11.0，视频可能使用更新版本</li>
<li><strong>性能优化差异</strong>：新版本可能包含重要的性能优化</li>
<li><strong>算法改进差异</strong>：调度算法可能在新版本中有显著改进</li>
<li><strong>配置默认值差异</strong>：新版本的默认配置可能更适合大规模测试</li>
</ol>
<h1 id="🔍如何查看测试所用的Volcano版本"><a href="#🔍如何查看测试所用的Volcano版本" class="headerlink" title="🔍如何查看测试所用的Volcano版本"></a>🔍如何查看测试所用的Volcano版本</h1><h2 id="1-查看部署文件中的版本信息"><a href="#1-查看部署文件中的版本信息" class="headerlink" title="1. 查看部署文件中的版本信息"></a>1. 查看部署文件中的版本信息</h2><h3 id="1-1-直接查看配置文件"><a href="#1-1-直接查看配置文件" class="headerlink" title="1.1 直接查看配置文件"></a>1.1 直接查看配置文件</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看admission webhook manager版本</span></span><br><span class="line">grep <span class="string">"image:"</span> schedulers/volcano/volcano-admission/deployment.yaml | grep volcano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看scheduler版本</span></span><br><span class="line">grep <span class="string">"image:"</span> schedulers/volcano/volcano-scheduler/deployment.yaml | grep volcano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看controller manager版本</span></span><br><span class="line">grep <span class="string">"image:"</span> schedulers/volcano/volcano-controller/deployment.yaml | grep volcano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看初始化job版本</span></span><br><span class="line">grep <span class="string">"image:"</span> schedulers/volcano/volcano-admission-init/job.yaml | grep volcano</span><br></pre></td></tr></table></figure></div>

<h3 id="1-2-批量查看所有版本"><a href="#1-2-批量查看所有版本" class="headerlink" title="1.2 批量查看所有版本"></a>1.2 批量查看所有版本</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 一次性查看所有Volcano组件版本</span></span><br><span class="line">grep -r <span class="string">"image:"</span> schedulers/volcano/ | grep volcano | grep -E <span class="string">"v[0-9]+\.[0-9]+\.[0-9]+"</span></span><br></pre></td></tr></table></figure></div>

<p><strong>输出示例</strong>：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">schedulers/volcano/volcano-admission/deployment.yaml:        image: kind-registry:5000/docker.io/volcanosh/vc-webhook-manager:v1.11.0</span><br><span class="line">schedulers/volcano/volcano-admission-init/job.yaml:        image: kind-registry:5000/docker.io/volcanosh/vc-webhook-manager:v1.11.0</span><br><span class="line">schedulers/volcano/volcano-scheduler/deployment.yaml:        image: kind-registry:5000/docker.io/volcanosh/vc-scheduler:v1.11.0</span><br><span class="line">schedulers/volcano/volcano-controller/deployment.yaml:        image: kind-registry:5000/docker.io/volcanosh/vc-controller-manager:v1.11.0</span><br></pre></td></tr></table></figure></div>

<h2 id="2-查看运行中的集群版本"><a href="#2-查看运行中的集群版本" class="headerlink" title="2. 查看运行中的集群版本"></a>2. 查看运行中的集群版本</h2><h3 id="2-1-检查已部署的Pod版本"><a href="#2-1-检查已部署的Pod版本" class="headerlink" title="2.1 检查已部署的Pod版本"></a>2.1 检查已部署的Pod版本</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置kubeconfig</span></span><br><span class="line"><span class="built_in">export</span> KUBECONFIG=./clusters/volcano/kubeconfig.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看运行中的Pod镜像版本</span></span><br><span class="line">kubectl get pods -n volcano-system -o jsonpath=<span class="string">'{range .items[*]}{.metadata.name}{"\t"}{.spec.containers[*].image}{"\n"}{end}'</span></span><br></pre></td></tr></table></figure></div>

<h3 id="2-2-查看ConfigMap中的配置"><a href="#2-2-查看ConfigMap中的配置" class="headerlink" title="2.2 查看ConfigMap中的配置"></a>2.2 查看ConfigMap中的配置</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看调度器配置</span></span><br><span class="line">kubectl get configmap -n volcano-system volcano-scheduler-configmap -o yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看admission webhook配置</span></span><br><span class="line">kubectl get validatingwebhookconfigurations -o yaml | grep -A 5 -B 5 volcano</span><br></pre></td></tr></table></figure></div>

<h2 id="3-版本信息汇总"><a href="#3-版本信息汇总" class="headerlink" title="3. 版本信息汇总"></a>3. 版本信息汇总</h2><p>通过上述方法，我们确认了当前环境使用的Volcano版本：</p>
<table>
<thead>
<tr>
<th>组件</th>
<th>当前版本</th>
<th>镜像名称</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Webhook Manager</strong></td>
<td>v1.11.0</td>
<td><code>volcanosh/vc-webhook-manager:v1.11.0</code></td>
</tr>
<tr>
<td><strong>Scheduler</strong></td>
<td>v1.11.0</td>
<td><code>volcanosh/vc-scheduler:v1.11.0</code></td>
</tr>
<tr>
<td><strong>Controller Manager</strong></td>
<td>v1.11.0</td>
<td><code>volcanosh/vc-controller-manager:v1.11.0</code></td>
</tr>
</tbody></table>
<h1 id="🚀如何自动化升级Volcano版本"><a href="#🚀如何自动化升级Volcano版本" class="headerlink" title="🚀如何自动化升级Volcano版本"></a>🚀如何自动化升级Volcano版本</h1><h2 id="1-目标版本选择"><a href="#1-目标版本选择" class="headerlink" title="1. 目标版本选择"></a>1. 目标版本选择</h2><p>我们选择升级到<code>v1.12.0-alpha.0</code>，原因主要是KubeCon视频中说明使用了该版本。推测新版本中可能包含性能改进、旧版本中可能存在部分bug被修复，甚至调度算法可能也有所更新。</p>
<h2 id="2-版本升级脚本"><a href="#2-版本升级脚本" class="headerlink" title="2. 版本升级脚本"></a>2. 版本升级脚本</h2><h3 id="2-1-批量替换版本"><a href="#2-1-批量替换版本" class="headerlink" title="2.1 批量替换版本"></a>2.1 批量替换版本</h3><p>如果不想使用脚本，也可以手动执行：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 备份原文件</span></span><br><span class="line"><span class="built_in">cp</span> -r schedulers/volcano schedulers/volcano.backup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量替换版本</span></span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/*/deployment.yaml</span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/*/job.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证修改结果</span></span><br><span class="line">grep -r <span class="string">"image:"</span> schedulers/volcano/ | grep volcano | grep -E <span class="string">"v[0-9]+\.[0-9]+\.[0-9]+"</span></span><br></pre></td></tr></table></figure></div>

<h3 id="3-2-逐个文件修改"><a href="#3-2-逐个文件修改" class="headerlink" title="3.2 逐个文件修改"></a>3.2 逐个文件修改</h3><p>也可以逐个文件进行修改：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改admission webhook</span></span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/volcano-admission/deployment.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改scheduler</span></span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/volcano-scheduler/deployment.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改controller</span></span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/volcano-controller/deployment.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改初始化job</span></span><br><span class="line">sed -i <span class="string">'s/v1\.11\.0/v1.12.0-alpha.0/g'</span> schedulers/volcano/volcano-admission-init/job.yaml</span><br></pre></td></tr></table></figure></div>

<h1 id="✅验证版本升级效果"><a href="#✅验证版本升级效果" class="headerlink" title="✅验证版本升级效果"></a>✅验证版本升级效果</h1><h2 id="1-配置文件验证"><a href="#1-配置文件验证" class="headerlink" title="1. 配置文件验证"></a>1. 配置文件验证</h2><h3 id="1-1-检查版本是否已更新"><a href="#1-1-检查版本是否已更新" class="headerlink" title="1.1 检查版本是否已更新"></a>1.1 检查版本是否已更新</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 验证所有文件是否已更新</span></span><br><span class="line">grep -r <span class="string">"image:"</span> schedulers/volcano/ | grep volcano | grep -E <span class="string">"v[0-9]+\.[0-9]+\.[0-9]+"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 期望输出：所有文件都显示 v1.12.0-alpha.0</span></span><br></pre></td></tr></table></figure></div>

<h3 id="1-2-检查文件完整性"><a href="#1-2-检查文件完整性" class="headerlink" title="1.2 检查文件完整性"></a>1.2 检查文件完整性</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查是否有遗漏的文件</span></span><br><span class="line">find schedulers/volcano/ -name <span class="string">"*.yaml"</span> -<span class="built_in">exec</span> grep -l <span class="string">"v1\.11\.0"</span> {} \;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果没有输出，说明所有文件都已更新</span></span><br></pre></td></tr></table></figure></div>

<h2 id="2-部署验证"><a href="#2-部署验证" class="headerlink" title="2. 部署验证"></a>2. 部署验证</h2><h3 id="2-1-重新部署Volcano"><a href="#2-1-重新部署Volcano" class="headerlink" title="2.1 重新部署Volcano"></a>2.1 重新部署Volcano</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 清理旧环境</span></span><br><span class="line">make down-volcano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新部署</span></span><br><span class="line">make up-volcano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等待服务就绪</span></span><br><span class="line">make wait-volcano</span><br></pre></td></tr></table></figure></div>

<h3 id="2-2-验证Pod镜像版本"><a href="#2-2-验证Pod镜像版本" class="headerlink" title="2.2 验证Pod镜像版本"></a>2.2 验证Pod镜像版本</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置kubeconfig</span></span><br><span class="line"><span class="built_in">export</span> KUBECONFIG=./clusters/volcano/kubeconfig.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查Pod是否使用新版本镜像</span></span><br><span class="line">kubectl get pods -n volcano-system -o jsonpath=<span class="string">'{range .items[*]}{.metadata.name}{"\t"}{.spec.containers[*].image}{"\n"}{end}'</span> | grep volcano</span><br></pre></td></tr></table></figure></div>

<p><strong>期望输出</strong>：所有Pod都应该显示<code>v1.12.0-alpha.0</code>版本</p>
<h3 id="2-3-检查服务状态"><a href="#2-3-检查服务状态" class="headerlink" title="2.3 检查服务状态"></a>2.3 检查服务状态</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查所有Pod状态</span></span><br><span class="line">kubectl get pods -n volcano-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查服务日志</span></span><br><span class="line">kubectl logs -n volcano-system deployment/volcano-scheduler --since=1m</span><br><span class="line">kubectl logs -n volcano-system deployment/volcano-controller-manager --since=1m</span><br></pre></td></tr></table></figure></div>

<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://github.com/volcano-sh/volcano/releases">[2] Volcano GitHub - Releases<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a href="!--swig%EF%BF%BC29--">[3] <a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></a></p>
<p><a href="!--swig%EF%BF%BC31--">[4] <a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></a></p>
<p><a href="!--swig%EF%BF%BC33--">[5] <a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></a> </p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>调度器</tag>
        <tag>性能优化</tag>
        <tag>K8s</tag>
        <tag>性能测试</tag>
        <tag>Volcano</tag>
        <tag>版本升级</tag>
        <tag>自动化脚本</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</title>
    <url>/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li>
<li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li>
<li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li>
<li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li>
<li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li>
<li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li>
<li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li>
<li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li>
<li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li>
<li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li>
<li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li>
<li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li>
<li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li>
<li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a>
</li>
</ol>
</blockquote>
<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="上一篇博客">上一篇博客</a>中，我们介绍了如何禁用Volcano调度器的enqueue功能。然而，在实际测试过程中，我们发现了一个更严重的问题：<strong>Pod创建数量始终少于10000，仅达到1000左右</strong>，这严重影响了测试结果的准确性。</p>
<p>本文详细记录了问题排查的完整过程，从发现异常现象到分析4.9GB的审计日志，最终定位到Webhook超时是导致Pod创建失败的根本原因。通过修改Webhook超时时间，我们成功解决了这个问题。</p>
<h1 id="🚨问题现象描述"><a href="#🚨问题现象描述" class="headerlink" title="🚨问题现象描述"></a>🚨问题现象描述</h1><h2 id="测试环境配置"><a href="#测试环境配置" class="headerlink" title="测试环境配置"></a>测试环境配置</h2><p>我们使用以下参数进行测试：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">make serial-test \</span><br><span class="line">    RESULT_RECENT_DURATION_SECONDS=60 TEST_TIMEOUT_SECONDS=160 \</span><br><span class="line">    NODES_SIZE=1000 \</span><br><span class="line">    QUEUES_SIZE=1  JOBS_SIZE_PER_QUEUE=20     PODS_SIZE_PER_JOB=500</span><br><span class="line"></span><br><span class="line">make serial-test \</span><br><span class="line">    RESULT_RECENT_DURATION_SECONDS=90 TEST_TIMEOUT_SECONDS=190 \</span><br><span class="line">    NODES_SIZE=1000 \</span><br><span class="line">    QUEUES_SIZE=1 JOBS_SIZE_PER_QUEUE=1 PODS_SIZE_PER_JOB=10000</span><br></pre></td></tr></table></figure></div>

<p><strong>预期结果</strong>：应该创建10,000个Pod<br><strong>实际结果</strong>：仅创建了不到1,000个Pod，成功率不到10%</p>
<h1 id="🔍问题排查过程"><a href="#🔍问题排查过程" class="headerlink" title="🔍问题排查过程"></a>🔍问题排查过程</h1><h2 id="1-初步分析"><a href="#1-初步分析" class="headerlink" title="1. 初步分析"></a>1. 初步分析</h2><p>首先，我们检查了测试环境的基本状态：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查Pod数量</span></span><br><span class="line">kubectl get pods -A | grep volcano-job | <span class="built_in">wc</span> -l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查Job状态</span></span><br><span class="line">kubectl get vcjob -A</span><br></pre></td></tr></table></figure></div>

<p>发现确实只有少量Pod被创建，大部分Pod创建请求似乎失败了。</p>
<h2 id="2-日志文件分析"><a href="#2-日志文件分析" class="headerlink" title="2. 日志文件分析"></a>2. 日志文件分析</h2><h3 id="2-1-日志文件大小"><a href="#2-1-日志文件大小" class="headerlink" title="2.1 日志文件大小"></a>2.1 日志文件大小</h3><p>测试完成后，我们发现审计日志文件异常巨大：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ls</span> -lh results/1755448387/logs/kube-apiserver-audit.volcano.log</span><br><span class="line"><span class="comment"># 输出：-rw-rw-rw- 1 root root 4.9G  8月 18 00:22 kube-apiserver-audit.volcano.log</span></span><br></pre></td></tr></table></figure></div>

<p><strong>4.9GB的日志文件</strong>表明系统产生了大量的审计记录，远大于其它测试的审计记录，猜测这意味着存在大量失败的操作。</p>
<h3 id="2-2-高效日志分析方法"><a href="#2-2-高效日志分析方法" class="headerlink" title="2.2 高效日志分析方法"></a>2.2 高效日志分析方法</h3><p>由于日志文件过大，我们采用了高效的分析方法：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 统计错误数量</span></span><br><span class="line">grep -c <span class="string">"context deadline exceeded"</span> kube-apiserver-audit.volcano.log</span><br><span class="line"><span class="comment"># 输出：520120</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计Webhook调用数量</span></span><br><span class="line">grep -c <span class="string">"validatepod.volcano.sh"</span> kube-apiserver-audit.volcano.log</span><br><span class="line"><span class="comment"># 输出：515531</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计Pod创建成功/失败数量</span></span><br><span class="line">grep -c <span class="string">"ResponseComplete.*pods.*create.*Success"</span> kube-apiserver-audit.volcano.log</span><br><span class="line"><span class="comment"># 输出：712</span></span><br><span class="line">grep -c <span class="string">"ResponseComplete.*pods.*create.*Failure"</span> kube-apiserver-audit.volcano.log</span><br><span class="line"><span class="comment"># 输出：520518</span></span><br></pre></td></tr></table></figure></div>

<h2 id="3-根本原因定位"><a href="#3-根本原因定位" class="headerlink" title="3. 根本原因定位"></a>3. 根本原因定位</h2><h3 id="3-1-错误模式分析"><a href="#3-1-错误模式分析" class="headerlink" title="3.1 错误模式分析"></a>3.1 错误模式分析</h3><p>通过分析日志中的错误信息，我们发现了统一的错误模式：</p>
<div class="code-container" data-rel="Json"><figure class="iseeu highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">  <span class="attr">"status"</span><span class="punctuation">:</span> <span class="string">"Failure"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"message"</span><span class="punctuation">:</span> <span class="string">"Internal error occurred: failed calling webhook \"validatepod.volcano.sh\": failed to call webhook: Post \"https://volcano-admission-service.volcano-system.svc:443/pods/validate?timeout=10s\": context deadline exceeded"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"reason"</span><span class="punctuation">:</span> <span class="string">"InternalError"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"code"</span><span class="punctuation">:</span> <span class="number">500</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></table></figure></div>

<p><strong>关键信息</strong>：</p>
<ul>
<li><strong>错误类型</strong>：Webhook调用超时</li>
<li><strong>超时时间</strong>：10秒</li>
<li><strong>影响范围</strong>：98.7%的Pod创建请求失败</li>
</ul>
<h3 id="3-2-统计数据汇总"><a href="#3-2-统计数据汇总" class="headerlink" title="3.2 统计数据汇总"></a>3.2 统计数据汇总</h3><table>
<thead>
<tr>
<th>指标</th>
<th>数量</th>
<th>占比</th>
</tr>
</thead>
<tbody><tr>
<td><strong>总Pod创建请求</strong></td>
<td>526,767</td>
<td>100%</td>
</tr>
<tr>
<td><strong>成功创建</strong></td>
<td>712</td>
<td>0.13%</td>
</tr>
<tr>
<td><strong>失败创建</strong></td>
<td>520,518</td>
<td>98.7%</td>
</tr>
<tr>
<td><strong>Webhook超时错误</strong></td>
<td>520,120</td>
<td>98.7%</td>
</tr>
</tbody></table>
<h2 id="4-问题根因分析"><a href="#4-问题根因分析" class="headerlink" title="4. 问题根因分析"></a>4. 问题根因分析</h2><h3 id="4-1-Webhook超时机制"><a href="#4-1-Webhook超时机制" class="headerlink" title="4.1 Webhook超时机制"></a>4.1 Webhook超时机制</h3><p>Volcano使用admission webhook来验证和修改Pod创建请求：</p>
<ol>
<li><p><strong>Pod创建流程</strong>：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubectl create pod → API Server → Admission Webhook → Volcano Controller → Pod创建</span><br></pre></td></tr></table></figure></div>
</li>
<li><p><strong>超时配置</strong>：</p>
<ul>
<li>当前配置：<code>timeoutSeconds: 10</code></li>
<li>问题：10秒内无法处理大量并发Pod创建请求</li>
</ul>
</li>
</ol>
<h3 id="4-2-性能瓶颈分析"><a href="#4-2-性能瓶颈分析" class="headerlink" title="4.2 性能瓶颈分析"></a>4.2 性能瓶颈分析</h3><p>当设置<code>PODS_SIZE_PER_JOB=10000</code>时：</p>
<ol>
<li><strong>并发压力</strong>：系统需要同时处理10,000个Pod创建请求</li>
<li><strong>Webhook负载</strong>：每个请求都需要经过admission webhook验证</li>
<li><strong>超时触发</strong>：大量请求堆积导致处理时间超过10秒</li>
<li><strong>失败连锁</strong>：超时失败导致Pod创建失败，影响整体测试结果</li>
</ol>
<h1 id="🔧问题修复方案"><a href="#🔧问题修复方案" class="headerlink" title="🔧问题修复方案"></a>🔧问题修复方案</h1><h2 id="1-修改Webhook超时时间"><a href="#1-修改Webhook超时时间" class="headerlink" title="1. 修改Webhook超时时间"></a>1. 修改Webhook超时时间</h2><h3 id="1-1-手动修改方法"><a href="#1-1-手动修改方法" class="headerlink" title="1.1 手动修改方法"></a>1.1 手动修改方法</h3><p>我们需要将所有webhook配置文件的超时时间从10秒增加到30秒：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查找所有webhook配置文件</span></span><br><span class="line">find schedulers/volcano/ -name <span class="string">"*webhook*.yaml"</span> -<span class="built_in">exec</span> grep -l <span class="string">"timeoutSeconds: 10"</span> {} \;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量修改超时时间</span></span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-*.yaml</span><br></pre></td></tr></table></figure></div>

<p><strong>重要说明</strong>：Kubernetes对webhook超时时间有严格限制，必须在1到30秒之间。我们最初尝试设置为60秒，但在部署时遇到了验证错误。</p>
<h2 id="1-3-Kubernetes超时时间限制"><a href="#1-3-Kubernetes超时时间限制" class="headerlink" title="1.3 Kubernetes超时时间限制"></a>1.3 Kubernetes超时时间限制</h2><p>在修复过程中，我们发现了一个重要的Kubernetes限制：</p>
<p>当我们尝试将webhook超时时间设置为60秒时，在部署过程中遇到了以下错误：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">Error from server (Invalid): error when creating <span class="string">"../../schedulers/volcano"</span>: </span><br><span class="line">MutatingWebhookConfiguration.admissionregistration.k8s.io <span class="string">"volcano-admission-service-jobs-mutate"</span> </span><br><span class="line">is invalid: webhooks[0].timeoutSeconds: Invalid value: 60: </span><br><span class="line">the <span class="built_in">timeout</span> value must be between 1 and 30 seconds</span><br></pre></td></tr></table></figure></div>

<p>这个错误表明：</p>
<ul>
<li><strong>Kubernetes限制</strong>：webhook超时时间必须在1到30秒之间</li>
<li><strong>我们之前的设置</strong>：60秒超出了允许范围</li>
<li><strong>影响范围</strong>：所有7个webhook配置文件都无法部署</li>
</ul>
<h3 id="1-2-修改的文件列表"><a href="#1-2-修改的文件列表" class="headerlink" title="1.2 修改的文件列表"></a>1.2 修改的文件列表</h3><p>需要修改的7个webhook配置文件：</p>
<ol>
<li><code>admission-service-jobs-validate_validatingwebhookconfiguration.yaml</code></li>
<li><code>admission-service-queues-mutate_mutatingwebhookconfiguration.yaml</code></li>
<li><code>admission-service-jobs-mutate_mutatingwebhookconfiguration.yaml</code></li>
<li><code>admission-service-podgroups-mutate_mutatingwebhookconfiguration.yaml</code></li>
<li><code>admission-service-pods-mutate_mutatingwebhookconfiguration.yaml</code></li>
<li><code>admission-service-queues-validate_validatingwebhookconfiguration.yaml</code></li>
<li><code>admission-service-pods-validate_validatingwebhookconfiguration.yaml</code></li>
</ol>
<h2 id="2-修复实现"><a href="#2-修复实现" class="headerlink" title="2. 修复实现"></a>2. 修复实现</h2><p>为了修改配置，可以按照以下步骤进行：</p>
<h3 id="步骤1：备份原配置文件"><a href="#步骤1：备份原配置文件" class="headerlink" title="步骤1：备份原配置文件"></a>步骤1：备份原配置文件</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建备份目录</span></span><br><span class="line"><span class="built_in">mkdir</span> -p schedulers/volcano/backup-$(<span class="built_in">date</span> +%Y%m%d-%H%M%S)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 备份所有webhook配置文件</span></span><br><span class="line"><span class="built_in">cp</span> schedulers/volcano/admission-service-*.yaml schedulers/volcano/backup-$(<span class="built_in">date</span> +%Y%m%d-%H%M%S)/</span><br></pre></td></tr></table></figure></div>

<h3 id="步骤2：查找需要修改的文件"><a href="#步骤2：查找需要修改的文件" class="headerlink" title="步骤2：查找需要修改的文件"></a>步骤2：查找需要修改的文件</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查找所有包含timeoutSeconds的文件</span></span><br><span class="line">find schedulers/volcano/ -name <span class="string">"*webhook*.yaml"</span> -<span class="built_in">exec</span> grep -l <span class="string">"timeoutSeconds:"</span> {} \;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看当前超时设置</span></span><br><span class="line">grep -r <span class="string">"timeoutSeconds:"</span> schedulers/volcano/ | grep -E <span class="string">"[0-9]+"</span></span><br></pre></td></tr></table></figure></div>

<h3 id="步骤3：逐个修改文件"><a href="#步骤3：逐个修改文件" class="headerlink" title="步骤3：逐个修改文件"></a>步骤3：逐个修改文件</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改validating webhook配置文件</span></span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-jobs-validate_validatingwebhookconfiguration.yaml</span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-pods-validate_validatingwebhookconfiguration.yaml</span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-queues-validate_validatingwebhookconfiguration.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改mutating webhook配置文件</span></span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-jobs-mutate_mutatingwebhookconfiguration.yaml</span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-podgroups-mutate_mutatingwebhookconfiguration.yaml</span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-pods-mutate_mutatingwebhookconfiguration.yaml</span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-queues-mutate_mutatingwebhookconfiguration.yaml</span><br></pre></td></tr></table></figure></div>

<h3 id="步骤4：批量修改（推荐）"><a href="#步骤4：批量修改（推荐）" class="headerlink" title="步骤4：批量修改（推荐）"></a>步骤4：批量修改（推荐）</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 一次性修改所有文件</span></span><br><span class="line">sed -i <span class="string">'s/timeoutSeconds: 10/timeoutSeconds: 30/g'</span> schedulers/volcano/admission-service-*.yaml</span><br></pre></td></tr></table></figure></div>

<h2 id="3-验证修复效果"><a href="#3-验证修复效果" class="headerlink" title="3. 验证修复效果"></a>3. 验证修复效果</h2><h3 id="3-1-检查配置修改"><a href="#3-1-检查配置修改" class="headerlink" title="3.1 检查配置修改"></a>3.1 检查配置修改</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查是否所有文件都已修改</span></span><br><span class="line">grep -r <span class="string">"timeoutSeconds:"</span> schedulers/volcano/ | grep -E <span class="string">"[0-9]+"</span></span><br><span class="line"><span class="comment"># 期望输出：所有文件都显示 timeoutSeconds: 30</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 确认没有遗漏的文件</span></span><br><span class="line">find schedulers/volcano/ -name <span class="string">"*webhook*.yaml"</span> -<span class="built_in">exec</span> grep -l <span class="string">"timeoutSeconds: 10"</span> {} \;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果上述命令有输出，说明还有文件未修改</span></span><br></pre></td></tr></table></figure></div>

<h3 id="3-2-重新部署测试"><a href="#3-2-重新部署测试" class="headerlink" title="3.2 重新部署测试"></a>3.2 重新部署测试</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 重新部署Volcano</span></span><br><span class="line">make up-volcano</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新运行测试</span></span><br><span class="line">make serial-test \</span><br><span class="line">    RESULT_RECENT_DURATION_SECONDS=90 TEST_TIMEOUT_SECONDS=190 \</span><br><span class="line">    NODES_SIZE=1000 \</span><br><span class="line">    QUEUES_SIZE=1 JOBS_SIZE_PER_QUEUE=1 PODS_SIZE_PER_JOB=10000</span><br></pre></td></tr></table></figure></div>

<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/architecture/">[2] Volcano 文档 - 架构<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/">[3] Kubernetes 文档 - Admission Controllers 准入控制 <i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a href="!--swig%EF%BF%BC30--">[4] <a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></a></p>
<p><a href="!--swig%EF%BF%BC32--">[5] <a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></a> </p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Webhook</tag>
        <tag>调度器</tag>
        <tag>K8s</tag>
        <tag>性能测试</tag>
        <tag>Volcano</tag>
        <tag>问题排查</tag>
        <tag>超时修复</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</title>
    <url>/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 监控与性能测试》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></li>
<li><a href="/2025/07/01/k8s/k8s-scheduler-performance-test-debug/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf 实操注意事项说明</a></li>
<li><a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></li>
<li><a href="/2025/07/23/k8s/k8s-scheduler-performance-test-local/" title="云原生批调度实战：本地环境测试结果与视频对比分析">云原生批调度实战：本地环境测试结果与视频对比分析</a></li>
<li><a href="/2025/07/27/k8s/k8s-scheduler-performance-volcano-process/" title="监控与测试环境解析：测试流程拆解篇">监控与测试环境解析：测试流程拆解篇</a></li>
<li><a href="/2025/08/07/k8s/k8s-scheduler-performance-volcano-metrics/" title="监控与测试环境解析：指标采集与可视化篇">监控与测试环境解析：指标采集与可视化篇</a></li>
<li><a href="/2025/09/09/k8s/k8s-scheduler-performance-go-analysis/" title="监控与测试环境解析：Go 项目解析与并发编程实践">监控与测试环境解析：Go 项目解析与并发编程实践</a></li>
<li><a href="/2025/08/08/k8s/k8s-scheduler-performance-volcano-custom/" title="监控与测试环境解析：自定义镜像性能回归测试">监控与测试环境解析：自定义镜像性能回归测试</a></li>
<li><a href="/2025/08/10/k8s/k8s-scheduler-performance-volcano-analysis/" title="监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题">监控与测试环境解析：数据收集方法深度解析与Prometheus Histogram误差问题</a></li>
<li><a href="/2025/08/17/k8s/k8s-scheduler-performance-volcano-enqueue/" title="云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试">云原生批调度实战：Volcano调度器enqueue功能禁用与性能测试</a></li>
<li><a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></li>
<li><a href="/2025/08/20/k8s/k8s-scheduler-performance-volcano-version/" title="云原生批调度实战：Volcano版本修改与性能测试优化">云原生批调度实战：Volcano版本修改与性能测试优化</a></li>
<li><a href="/2025/08/22/k8s/k8s-scheduler-performance-volcano-webhook-disable/" title="云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析">云原生批调度实战：Volcano Webhook禁用与性能瓶颈分析</a></li>
<li><a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结">云原生批调度实战：Volcano性能瓶颈猜想验证与实验总结</a>
</li>
</ol>
</blockquote>
<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="上一篇博客">上一篇博客</a>中，我们通过修改webhook超时时间解决了Pod创建数量不足的问题。然而，在实际测试过程中，我们发现webhook本身可能成为性能瓶颈，特别是在大规模Job提交的场景下。</p>
<p>本文详细介绍了如何通过修改<code>kube-scheduling-perf</code>的Makefile来完全禁用Volcano的webhook功能，分析了webhook对调度性能的影响，并探讨了未来通过CRD替代webhook的可能性。通过实验发现，即使禁用webhook，在Job数量较多时仍然存在Pod创建瓶颈，这为后续的调度器优化提供了重要参考。</p>
<h1 id="🖼️背景需求分析"><a href="#🖼️背景需求分析" class="headerlink" title="🖼️背景需求分析"></a>🖼️背景需求分析</h1><h2 id="1-Webhook性能瓶颈问题"><a href="#1-Webhook性能瓶颈问题" class="headerlink" title="1. Webhook性能瓶颈问题"></a>1. Webhook性能瓶颈问题</h2><h3 id="1-1-多次判断的性能开销"><a href="#1-1-多次判断的性能开销" class="headerlink" title="1.1 多次判断的性能开销"></a>1.1 多次判断的性能开销</h3><p>Volcano的webhook系统包含多个组件，每个Pod创建请求都需要经过：</p>
<ol>
<li><strong>Mutating Webhook</strong>：修改Pod配置（如添加<code>maxRetry</code>、<code>minAvailable</code>等字段）</li>
<li><strong>Validating Webhook</strong>：验证Pod配置的合法性</li>
<li><strong>Admission Service</strong>：处理webhook请求的服务</li>
<li><strong>TLS证书验证</strong>：确保webhook调用的安全性</li>
</ol>
<p>在<a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="之前的测试">之前的测试</a>中，我们发现webhook超时成为了Pod创建失败的主要原因，98.7%的请求因超时而失败。</p>
<h3 id="1-2-替代方案的可能性"><a href="#1-2-替代方案的可能性" class="headerlink" title="1.2 替代方案的可能性"></a>1.2 替代方案的可能性</h3><p>考虑到现代Kubernetes版本的发展趋势，webhook的某些功能可以通过以下方式替代：</p>
<ol>
<li><strong>加强Controller校验</strong>：将必要的校验功能转移到 Volcano Controller Manager（例如空指针判断等），为简单场景下禁用 webhook 做支撑</li>
<li><strong>使用CRD规则校验</strong>：或使用通用表达式语言（CEL）来实现K8s准入校验规则，验证CRD的值（使用 K8s v1.29 [stabe] x-kubernetes-validations 扩展），实现利用 Kubernetes CRD 的验证功能替代部分 Validating Webhook</li>
<li><strong>预配置模板</strong>：通过提前配置Job模板，减少运行时的修改需求</li>
</ol>
<h3 id="1-3-性能测试需求"><a href="#1-3-性能测试需求" class="headerlink" title="1.3 性能测试需求"></a>1.3 性能测试需求</h3><p>为了准确评估webhook对调度性能的影响，我们需要：</p>
<ul>
<li><strong>基准测试</strong>：在有webhook的情况下进行性能测试</li>
<li><strong>对比测试</strong>：在禁用webhook的情况下进行相同的性能测试</li>
<li><strong>瓶颈分析</strong>：识别webhook是否是真正的性能瓶颈</li>
</ul>
<h1 id="🔧方案设计与实现"><a href="#🔧方案设计与实现" class="headerlink" title="🔧方案设计与实现"></a>🔧方案设计与实现</h1><h2 id="1-整体设计思路"><a href="#1-整体设计思路" class="headerlink" title="1. 整体设计思路"></a>1. 整体设计思路</h2><h3 id="1-1-保留核心组件"><a href="#1-1-保留核心组件" class="headerlink" title="1.1 保留核心组件"></a>1.1 保留核心组件</h3><p>我们采用<strong>选择性禁用</strong>的策略，只删除webhook配置，保留其他重要组件：</p>
<ul>
<li>✅ <strong>保留</strong>：<code>volcano-admission</code> deployment、<code>volcano-admission-service</code>、<code>volcano-admission-init</code> job</li>
<li>❌ <strong>删除</strong>：所有<code>MutatingWebhookConfiguration</code>和<code>ValidatingWebhookConfiguration</code></li>
</ul>
<h3 id="1-2-实现方式"><a href="#1-2-实现方式" class="headerlink" title="1.2 实现方式"></a>1.2 实现方式</h3><p>通过修改<code>./clusters/volcano/Makefile</code>，在Volcano部署完成后自动删除webhook配置：</p>
<div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: disable-volcano-webhooks</span></span><br><span class="line"><span class="section">disable-volcano-webhooks:</span></span><br><span class="line">	<span class="comment"># 只删除webhook配置，保留admission服务和初始化组件</span></span><br><span class="line">	<span class="comment"># 删除所有MutatingWebhookConfiguration</span></span><br><span class="line">	-KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl delete mutatingwebhookconfiguration volcano-admission-service-jobs-mutate</span><br><span class="line">	-KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl delete mutatingwebhookconfiguration volcano-admission-service-podgroups-mutate</span><br><span class="line">	-KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl delete mutatingwebhookconfiguration volcano-admission-service-pods-mutate</span><br><span class="line">	-KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl delete mutatingwebhookconfiguration volcano-admission-service-queues-mutate</span><br><span class="line">	<span class="comment"># 删除所有ValidatingWebhookConfiguration</span></span><br><span class="line">	-KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl delete validatingwebhookconfiguration volcano-admission-service-jobs-validate</span><br><span class="line">	-KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl delete validatingwebhookconfiguration volcano-admission-service-pods-validate</span><br><span class="line">	-KUBECONFIG=<span class="variable">$(KUBECONFIG)</span> kubectl delete validatingwebhookconfiguration volcano-admission-service-queues-validate</span><br><span class="line">	@echo <span class="string">"Volcano webhook configurations have been disabled, but admission service and init components are preserved"</span></span><br></pre></td></tr></table></figure></div>

<h2 id="2-具体实现步骤"><a href="#2-具体实现步骤" class="headerlink" title="2. 具体实现步骤"></a>2. 具体实现步骤</h2><h3 id="2-1-修改Makefile"><a href="#2-1-修改Makefile" class="headerlink" title="2.1 修改Makefile"></a>2.1 修改Makefile</h3><p>在<code>clusters/volcano/Makefile</code>中，我们添加了多个webhook控制选项：</p>
<div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 完全禁用webhook</span></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: disable-volcano-webhooks</span></span><br><span class="line"><span class="section">disable-volcano-webhooks:</span></span><br><span class="line">	<span class="comment"># 删除所有webhook配置</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 只禁用mutating webhook</span></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: disable-volcano-mutating-webhooks</span></span><br><span class="line"><span class="section">disable-volcano-mutating-webhooks:</span></span><br><span class="line">	<span class="comment"># 只删除MutatingWebhookConfiguration</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 只禁用validating webhook</span></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: disable-volcano-validating-webhooks</span></span><br><span class="line"><span class="section">disable-volcano-validating-webhooks:</span></span><br><span class="line">	<span class="comment"># 只删除ValidatingWebhookConfiguration</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新启用webhook</span></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: enable-volcano-webhooks</span></span><br><span class="line"><span class="section">enable-volcano-webhooks:</span></span><br><span class="line">	<span class="comment"># 重新创建所有webhook配置</span></span><br></pre></td></tr></table></figure></div>

<h3 id="2-2-集成到部署流程"><a href="#2-2-集成到部署流程" class="headerlink" title="2.2 集成到部署流程"></a>2.2 集成到部署流程</h3><p>在<code>up</code>目标中集成webhook禁用：</p>
<div class="code-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: up</span></span><br><span class="line"><span class="section">up: \</span></span><br><span class="line">	create-cluster</span><br><span class="line">	make wait</span><br><span class="line">	make -j 2 \</span><br><span class="line">		create-kwok \</span><br><span class="line">		create-volcano</span><br><span class="line">	make disable-volcano-webhooks  <span class="comment"># 自动禁用webhook</span></span><br><span class="line">	make limit-built-controller-manager</span><br><span class="line">	make uncordon</span><br></pre></td></tr></table></figure></div>

<h2 id="3-技术细节说明"><a href="#3-技术细节说明" class="headerlink" title="3. 技术细节说明"></a>3. 技术细节说明</h2><h3 id="3-1-Webhook配置类型"><a href="#3-1-Webhook配置类型" class="headerlink" title="3.1 Webhook配置类型"></a>3.1 Webhook配置类型</h3><p>我们禁用的webhook配置包括：</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>配置名称</th>
<th>功能描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Mutating</strong></td>
<td><code>volcano-admission-service-jobs-mutate</code></td>
<td>修改Job配置，添加<code>maxRetry</code>等字段</td>
</tr>
<tr>
<td><strong>Mutating</strong></td>
<td><code>volcano-admission-service-podgroups-mutate</code></td>
<td>修改PodGroup配置</td>
</tr>
<tr>
<td><strong>Mutating</strong></td>
<td><code>volcano-admission-service-pods-mutate</code></td>
<td>修改Pod配置</td>
</tr>
<tr>
<td><strong>Mutating</strong></td>
<td><code>volcano-admission-service-queues-mutate</code></td>
<td>修改Queue配置</td>
</tr>
<tr>
<td><strong>Validating</strong></td>
<td><code>volcano-admission-service-jobs-validate</code></td>
<td>验证Job配置合法性</td>
</tr>
<tr>
<td><strong>Validating</strong></td>
<td><code>volcano-admission-service-pods-validate</code></td>
<td>验证Pod配置合法性</td>
</tr>
<tr>
<td><strong>Validating</strong></td>
<td><code>volcano-admission-service-queues-validate</code></td>
<td>验证Queue配置合法性</td>
</tr>
</tbody></table>
<h3 id="3-2-保留组件的原因"><a href="#3-2-保留组件的原因" class="headerlink" title="3.2 保留组件的原因"></a>3.2 保留组件的原因</h3><p>我们选择保留以下组件的原因：</p>
<ol>
<li><strong><code>volcano-admission</code> deployment</strong>：保持服务架构完整性，避免其他组件依赖问题</li>
<li>**<code>volcano-admission-service</code>**：维持网络服务，避免服务发现失败</li>
<li><strong><code>volcano-admission-init</code> job</strong>：继续生成TLS证书，确保系统安全性</li>
</ol>
<h1 id="🚀未来展望与优化方向"><a href="#🚀未来展望与优化方向" class="headerlink" title="🚀未来展望与优化方向"></a>🚀未来展望与优化方向</h1><h2 id="1-CRD替代Webhook的可能性"><a href="#1-CRD替代Webhook的可能性" class="headerlink" title="1. CRD替代Webhook的可能性"></a>1. CRD替代Webhook的可能性</h2><h3 id="1-1-Kubernetes版本演进"><a href="#1-1-Kubernetes版本演进" class="headerlink" title="1.1 Kubernetes版本演进"></a>1.1 Kubernetes版本演进</h3><p>从Kubernetes 1.16开始，CRD支持更强大的验证和默认值设置：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">validation:</span></span><br><span class="line">    <span class="attr">openAPIV3Schema:</span></span><br><span class="line">      <span class="comment"># 可以定义复杂的验证规则</span></span><br><span class="line">  <span class="attr">defaulting:</span></span><br><span class="line">    <span class="comment"># 可以设置默认值</span></span><br></pre></td></tr></table></figure></div>

<h3 id="1-2-替代方案设计"><a href="#1-2-替代方案设计" class="headerlink" title="1.2 替代方案设计"></a>1.2 替代方案设计</h3><p>未来可以考虑通过以下方式替代webhook：</p>
<ol>
<li><strong>CRD验证规则</strong>：在Job CRD中定义验证规则，替代validating webhook</li>
<li><strong>默认值设置</strong>：通过CRD的defaulting功能，替代mutating webhook</li>
<li><strong>准入策略</strong>：使用Pod Security Standards等内置策略</li>
</ol>
<h3 id="1-3-实现路径"><a href="#1-3-实现路径" class="headerlink" title="1.3 实现路径"></a>1.3 实现路径</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 示例：通过CRD实现Job验证</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">jobs.batch.volcano.sh</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">validation:</span></span><br><span class="line">    <span class="attr">openAPIV3Schema:</span></span><br><span class="line">      <span class="attr">properties:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">properties:</span></span><br><span class="line">            <span class="attr">maxRetry:</span></span><br><span class="line">              <span class="attr">type:</span> <span class="string">integer</span></span><br><span class="line">              <span class="attr">minimum:</span> <span class="number">1</span></span><br><span class="line">              <span class="attr">maximum:</span> <span class="number">10</span></span><br><span class="line">            <span class="attr">minAvailable:</span></span><br><span class="line">              <span class="attr">type:</span> <span class="string">integer</span></span><br><span class="line">              <span class="attr">minimum:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">defaulting:</span></span><br><span class="line">    <span class="attr">openAPIV3Schema:</span></span><br><span class="line">      <span class="attr">properties:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">properties:</span></span><br><span class="line">            <span class="attr">maxRetry:</span></span><br><span class="line">              <span class="attr">default:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure></div>

<h2 id="2-Controller调度逻辑优化"><a href="#2-Controller调度逻辑优化" class="headerlink" title="2. Controller调度逻辑优化"></a>2. Controller调度逻辑优化</h2><p>基于测试结果，我们发现前期确定的优化点仍然存在。具体而言：</p>
<ol>
<li><strong>实验结果发现</strong>：即使禁用了webhook，在Job数量很多时仍然存在<a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="前期测试">前期测试</a>中提到的Pod CREATE 瓶颈。</li>
<li><strong>可能原因</strong>：Volcano会分批处理Job并CREATE Pod，当Job数量多时CREATE速度比SCHEDULE速度慢而成为瓶颈。</li>
<li><strong>后续思路</strong>：可以通过检查和修改controller的调度逻辑来进行优化。</li>
</ol>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://github.com/wzshiming/kube-scheduling-perf">[1] Github - kube-scheduling-perf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a href="!--swig%EF%BF%BC23--">[2] <a href="/2025/08/18/k8s/k8s-scheduler-performance-volcano-webhook-debug/" title="云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复">云原生批调度实战：Volcano Pod创建数量不足问题排查与Webhook超时修复</a></a></p>
<p><a href="!--swig%EF%BF%BC25--">[3] <a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="云原生批调度实战：调度器测试监控结果">云原生批调度实战：调度器测试监控结果</a></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/architecture/">[4] Volcano 文档 - 架构<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/blog/2022/09/23/crd-validation-rules-beta/">[5] Kubernetes 文档 - Kubernetes 1.25: CustomResourceDefinition Validation Rules Graduate to Beta<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions">[6] Kubernetes 文档 - 使用 CustomResourceDefinition 扩展 Kubernetes API<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#validation">[7] Kubernetes 文档 - CRD Validation 合法性检查<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#validation-rules">[8] Kubernetes 文档 - CRD Validation Rules 合法性检查规则<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#validation-rules">[9] Kubernetes 文档 - CRD Validation Rules 合法性检查规则（K8s v1.29 [stabe]）<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/validating-admission-policy/">[10] Kubernetes 文档 - 验证准入策略（ValidatingAdmissionPolicy）（K8s v1.30 [stable]）<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://liangyuanpeng.com/post/k8s-admissionregistration-with-cel/">[11] 用cel表达式来实现k8s准入校验<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a href="!--swig%EF%BF%BC27--">[12] <a href="/2025/06/24/k8s/k8s-scheduler-performance-test/" title="云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf">云原生批调度实战：调度器测试与监控工具 kube-scheduling-perf</a></a> </p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Webhook</tag>
        <tag>调度器</tag>
        <tag>性能优化</tag>
        <tag>K8s</tag>
        <tag>性能测试</tag>
        <tag>Volcano</tag>
        <tag>CRD</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano 深度解析（一）：批处理背景需求与Volcano特点</title>
    <url>/2025/05/26/k8s/k8s-volcano-1/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 深度解析》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/05/26/k8s/k8s-volcano-1/" title="云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点">云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点</a></li>
<li><a href="/2025/05/27/k8s/k8s-volcano-2/" title="云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态">云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态</a></li>
<li><a href="/2025/06/22/k8s/k8s-volcano-install/" title="云原生批调度实战：Volcano 安装与初试">云原生批调度实战：Volcano 安装与初试</a></li>
<li><a href="/2025/08/25/k8s/k8s-volcano-core-flow/" title="云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计">云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计</a></li>
<li><a href="/2025/08/26/k8s/k8s-volcano-create-analysis/" title="云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析">云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析</a></li>
<li><a href="/2025/09/04/k8s/k8s-volcano-create-schedule-contention-analysis/" title="云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验">云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验</a>
</li>
</ol>
</blockquote>
<h1 id="🖼️-背景与需求"><a href="#🖼️-背景与需求" class="headerlink" title="🖼️ 背景与需求"></a>🖼️ 背景与需求</h1><p>在云原生浪潮下，越来越多的大数据和人工智能框架需要在 Kubernetes（K8s）上运行高性能计算（HPC）应用程序，这对调度系统提出了前所未有的挑战。本文将梳理批处理的发展脉络、核心需求及 Volcano 的定位。</p>
<h2 id="1-批处理的演进与挑战"><a href="#1-批处理的演进与挑战" class="headerlink" title="1. 批处理的演进与挑战"></a>1. 批处理的演进与挑战</h2><ul>
<li><p><strong>发展历程</strong>：</p>
<ul>
<li>1990s：以 OpenMPI + Slurm 为代表的 HPC 应用，强调高性能、资源密集型计算。</li>
<li>2006 年后：Spark + Hadoop 推动大数据批处理，数据量激增，调度需求复杂化。</li>
<li>2016 年后：TensorFlow 等 AI 框架在 K8s 上运行，云原生成为新趋势。</li>
<li>多技术生态并存，资源管理和调度愈发复杂，急需统一的批处理调度方案。</li>
</ul>
</li>
<li><p><strong>关键概念</strong>：</p>
<ul>
<li>（1）”离线批处理”与”在线实时处理”构成两座大山：<a href="#refer-anchor-1"><sup>[8]</sup></a><ul>
<li><strong>批处理</strong>：无需人工交互，输入数据预先设定。</li>
<li><strong>实时处理</strong>：需要用户交互输入。</li>
</ul>
</li>
<li>（2）”离线批处理”的典型代表为”高性能计算”（HPC）、”大数据”、”AI 工作负载（训练）”。<a href="#refer-anchor-1"><sup>[2,3]</sup></a><ul>
<li><strong>批处理（Batch Processing）</strong> 是一种计算模式，将任务分组后定时运行，HPC 是批处理的典型应用场景之一。</li>
<li><strong>HPC</strong> 强调利用强大算力处理复杂任务，批处理是其常用的调度和执行方式。</li>
<li><strong>组成</strong>：HPC 包括高性能的硬件（网络、存储、计算节点）和以批处理为主的软件组织方式。<a href="#refer-anchor-1"><sup>[7]</sup></a></li>
</ul>
</li>
<li>（3）HPC 中典型框架：MPI<a href="#refer-anchor-1"><sup>[9]</sup></a><ul>
<li>MPI（Message Passing Interface）：<ul>
<li>用于多个节点之间高效数据交换，在高性能计算中有广泛应用。</li>
<li>是一种抽象的消息传递接口模型，有多种具体实现。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://www.altoros.com/blog/wp-content/uploads/2022/07/Volcano-batching-progression-Kubernetes-KubeCon-2022-CNCF-1024x576.png" alt="Workload trends throughout the years"><figcaption>Workload trends throughout the years</figcaption></figure></p>
<center>多年来的工作负载变化趋势(图源<sup>[2,3]</sup>)</center>

<h2 id="2-为什么-K8s-需要批处理调度系统？"><a href="#2-为什么-K8s-需要批处理调度系统？" class="headerlink" title="2. 为什么 K8s 需要批处理调度系统？"></a>2. 为什么 K8s 需要批处理调度系统？</h2><p>Kubernetes 原生调度器主要面向在线服务和微服务场景，对于批处理作业的支持有限，难以满足以下需求：</p>
<ul>
<li>A. 作业管理 —— <strong>All or Nothing 作业需求支持</strong>：<ul>
<li><strong>A1 - 作业需求感知</strong>：K8s 仅支持 Pod 级调度，不了解上层应用程序/作业；缺乏精细的生命周期管理，缺乏任务依赖性和作业依赖性感知。<a href="#refer-anchor-1"><sup>[2,3]</sup></a></li>
<li><strong>A2 - All or Nothing</strong>：批处理作业（如 TensorFlow、MPI）需所有任务同时启动，否则易死锁、资源浪费或失败，影响整体吞吐。<a href="#refer-anchor-1"><sup>[1,10]</sup></a><ul>
<li>以Spark作业为例，driver（ApplicationMaster，负责分解任务+申请资源） 和 executor（负责执行具体任务） 需协同启动，否则可能出现不同作业的 driver 占满资源，executor 无法启动，导致死锁。<a href="#refer-anchor-1"><sup>[5]</sup></a></li>
</ul>
</li>
</ul>
</li>
<li>B. 租户管理 —— <strong>多租户资源共享</strong>：<ul>
<li><strong>B1 - 租户感知</strong>：没有租户概念、无法用于管理多个租户资源配额、已使用资源等信息。<a href="#refer-anchor-1"><sup>[5]</sup></a><ul>
<li>仅有用于认证的Authentication，无法用于资源管理。</li>
</ul>
</li>
<li><strong>B2 - 租户共享</strong>：多个租户共用资源池，需根据供需关系动态分配，低谷互补、高峰公平，避免资源浪费和阻塞。<a href="#refer-anchor-1"><sup>[2,3]</sup></a><ul>
<li><strong>由于各租户资源利用情况波动，存在资源利用低谷期和高峰期。</strong>低谷期需要互补（闲置资源拿去给有需要的人用）避免浪费、高峰期需要竞争（确保每个人能拿到应得的资源量）保证公平性。</li>
<li><strong>K8s 仅靠 namespace ，超过配额的请求会被拒绝。</strong>这种资源配置方式僵化，难以实现动态公平分配，易造成资源浪费。缺乏作业、租户、命名空间之间的资源共享机制支持（弹性调度、资源借用、资源抢占）。</li>
</ul>
</li>
</ul>
</li>
<li>C. 调度功能 —— <strong>高吞吐的多种调度算法</strong>：<ul>
<li><strong>C1 - 高吞吐性能需求</strong>：需以提升整体作业吞吐量为目标，原生 K8s 调度策略简单低效。<a href="#refer-anchor-1"><sup>[2,3]</sup></a></li>
<li><strong>C2 - 复杂调度功能（作业）</strong>：缺乏基于作业的调度，例如作业排序job ordering、作业优先级job priority、作业抢占job preemption、作业公平分享job fair-share、作业预留job reservation、任务拓扑感知调度task-topology。<a href="#refer-anchor-1"><sup>[2,3]</sup></a></li>
<li><strong>C3 - 复杂调度功能（资源）</strong>：缺乏足够的高级调度算法，例如异构资源感知、CPU拓扑、IO感知、回填Backfill。<a href="#refer-anchor-1"><sup>[2,3]</sup></a></li>
</ul>
</li>
<li>D. 工程实践 —— <strong>与计算框架无缝对接</strong>：支持主流任务型计算框架。<a href="#refer-anchor-1"><sup>[2,3]</sup></a><ul>
<li>对主流计算框架（如MPI、Tensorflow、Mxnet、Pytorch）的支持不足。</li>
<li>对每个框架对应不同的operator间协调不足，导致部署和运维复杂。</li>
</ul>
</li>
</ul>
<h2 id="3-Volcano-简介"><a href="#3-Volcano-简介" class="headerlink" title="3. Volcano 简介"></a>3. Volcano 简介</h2><ul>
<li><strong>原生K8s调度器</strong>：主要针对在线服务设计，采用”先到先得”的调度策略。面向具有资源需求大、运行时间长、依赖关系复杂等特点的批处理作业，原生调度器力不从心，无法满足复杂的调度需求。</li>
<li><strong>Volcano</strong>：基于 K8s 的通用批处理调度系统，专为云原生架构下的 HPC 场景设计。提供了作业管理、队列管理、资源预留等高级特性，特别适合 AI 训练、大数据处理等场景。</li>
</ul>
<ol>
<li><p>项目背景：<a href="#refer-anchor-1"><sup>[2,3]</sup></a></p>
<ul>
<li>2019 年 3 月创建，6 月由华为云开源并贡献给 CNCF</li>
<li>2020 年 4 月成为 CNCF 沙箱项目</li>
<li>2022 年 4 月升级为 CNCF 孵化项目</li>
</ul>
</li>
<li><p>社区活跃度：<a href="#refer-anchor-1"><sup>[2,3,11-13]</sup></a></p>
<ul>
<li>GitHub 星数超过 4.6k</li>
<li>有超过 350 位贡献者</li>
<li>有稳定的版本更新，2025/02/07已更新至v1.11.0</li>
<li>已实现 50+ 落地案例，主要用户包括：腾讯、亚马逊、荷兰ING银行、百度、小红书、滴滴、360、爱奇艺、中科类脑、鹏程实验室、Curise、理想汽车、云知声、喜马拉雅、唯品会、希望组、BOSS直聘等</li>
<li>有活跃的 Slack 社区和邮件列表</li>
</ul>
</li>
</ol>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://www.altoros.com/blog/wp-content/uploads/2022/07/Volcano-overview-Kubernetes-KubeCon-2022-CNCF-1024x576.png" alt="Overview of Volcano"><figcaption>Overview of Volcano</figcaption></figure></p>
<center>Volcano 概览(图源<sup>[2,3]</sup>)</center>

<h2 id="4-Volcano-核心特性"><a href="#4-Volcano-核心特性" class="headerlink" title="4. Volcano 核心特性"></a>4. Volcano 核心特性</h2><p>针对上述需求，Volcano提供了几种典型功能。<a href="#refer-anchor-1"><sup>[1-4]</sup></a></p>
<ul>
<li><strong>A. 作业管理</strong>：多种Pod模板，生命周期/错误管理。<ul>
<li><strong>Job、PodGroup等模板</strong>：应对作业感知需求。使用 Volcano Job 提供统一作业接口，支持作业内多个任务依赖性感知和管理，支持细粒度的作业生命周期管理。</li>
<li><strong>Gang调度</strong>：应对All or Nothing需求。Job和PodGroup将一组关联的pod当成一个group，从而在pod的概念之上又封装了一层。通过配置minAvailable（最小pod运行数）和replicas（最大pod运行数），实现了对整体group的调度，要么至少minAvailable个pod都成功，要么都失败。</li>
</ul>
</li>
<li><strong>B. 租户管理</strong>：使用队列（Queue）管理多租户资源情况，使用配额（Quota）控制租户可用资源量。<ul>
<li><strong>队列抽象</strong>：应对租户感知需求。通过集群集对象-队列（Queue），与用户user/命名空间namespace解耦，用于配置每个用户应有的资源量/资源比例，从而支持在“多租户”或资源池之间共享资源。</li>
<li><strong>队列调度</strong>：应对多租户共享-充分利用需求。队列广泛用于共享弹性工作负载和批处理工作负载的资源。特别是，队列可用于<ul>
<li>在租户或资源池之间共享资源。感知资源需求和资源闲置情况，为突发高需求的作业分配闲置资源。</li>
<li>为不同租户或资源池提供不同的调度策略或算法，例如先进先出（FIFO）、公平共享（fair share）、优先级（priority）、SLA。</li>
</ul>
</li>
<li><strong>公平调度</strong>：应对多租户共享-公平利用需求。批处理工作负载要求在一段时间内公平分配资源，而不是在某个特定时间点。<ul>
<li>例如，一个用户（或一个特定队列）在某段时间内为运行一个大型作业占用了集群总资源的一半（超过应得的资源量）是可以接受的，但如果这种情况一直持续（可能是作业完成后的几个小时），则该用户（或队列）应受到惩罚，例如使其能够拿到的资源更少。</li>
</ul>
</li>
</ul>
</li>
<li><strong>C. 调度功能</strong><ul>
<li>Cache组件+调度插件+调度状态优化：应对高吞吐、复杂功能需求。<ul>
<li><strong>Cache组件</strong>：缓存集群中的节点和 pod 信息，并根据信息更新作业（PodGroup）和任务（pod）之间的关系，避免反复与 API Server 交互导致的低效。</li>
<li><strong>调度插件</strong>：支持多种调度策略，如：Gang-Scheduling、Job priority、Job queue、Job order、Preemption、backfill、Job Fair-share、Namespace fair-share、Task-topology、IO-Awareness、Resource reservation、SLA、GPU sharing、NUMA-Awareness、HDRF、Hierarchy Queue、Co-location、Elastic scheduling、TDM、Proportional scheduling。<a href="#refer-anchor-1"><sup>[3]</sup></a></li>
<li><strong>调度状态优化</strong>：增加了多个 pod 状态，以便对不同问题分而治之（个人猜测便于多线程流水线处理），提高上述场景中的调度性能。</li>
</ul>
</li>
<li>抢占&amp;回收（Preemption &amp; Reclaim）：应对多租户共享需求。在低谷期，可以先使用别人的空闲资源；当重回高峰期时，资源所有者将回收reclaim资源。<ul>
<li>Reclaim回收操作用于在队列之间平衡资源，Preemption抢占操作用于在作业之间平衡资源。</li>
</ul>
</li>
<li>预留&amp;回填（Reservation &amp; Backfill）：应对多租户公平需求。<ul>
<li>避免大任务饿死starve：当将一个需要大量资源的大规模任务提交给Kubernetes时，如果管道中有很多小任务，则这个大任务可能会因当前调度策略或算法的原因而饥饿或最终被杀死。为了避免饥饿，应该有条件地为任务预留Reservation资源，例如通过设置超时时间。</li>
<li>充分利用：进一步地，当资源被预留时，它们可能会闲置或未被使用。为了提高资源利用率，调度器会有条件地将小任务填充Backfill到这些预留的资源中。</li>
<li>预留和回填都是根据插件返回的结果触发的。Volcano调度器提供了API，供开发者或用户确定哪些任务被预留或回填。</li>
</ul>
</li>
</ul>
</li>
<li><strong>D. 工程实践</strong><ul>
<li>Job/PodGroup + K8s计算框架manager组件：对作业抽象，无缝对接计算框架。使用 Volcano Job 提供统一作业接口，适用于 mpi、pytorch、tensorflow、mxnet 等大多数批处理作业，支持多种可扩展的作业插件（Env、Svc、Ssh、Tensorflow）。</li>
</ul>
</li>
</ul>
<h2 id="x1f9e0-疑问"><a href="#x1f9e0-疑问" class="headerlink" title="🧠疑问"></a><span class="emoji" alias="brain" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png?v8">🧠</span>疑问</h2><ol>
<li>Volcano的Cache机制理论上可以大大加速调度，但根据Godel测试仍然效率较低，也许这是一个需要重点测试性能的地方。</li>
<li>Volcano的多种Pod状态机制理论上可以使用多线程加速调度，但不确定实际是否使用了相关功能，也需要重点测试。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.cncf.io/blog/2021/02/26/volcano-collision-between-containers-and-batch-computing/">[1] CNCF - Volcano: Collision between containers and batch computing<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.altoros.com/blog/volcano-scheduling-300000-pods-in-production-daily/">[2] Altoros - Volcano: Scheduling 300,000 Kubernetes Pods in Production Daily<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://static.sched.com/hosted_files/kccnceu2022/bd/KubeCon_EU_2022_Volcano_Intro-v2.0.pdf">[3] KubeCon + CloudNativeCon Europe 2022 - Intro &amp; Deep dive，Volcano: A Cloud Native Batch System<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/actions/">[4] Volcano - Scheduler Actions<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="http://www.fanyilun.me/2022/06/02/YARN%E5%92%8CK8s%E8%B0%83%E5%BA%A6Spark%E4%BD%9C%E4%B8%9A%E7%9A%84%E5%AF%B9%E6%AF%94/">[5] 阿里云范佚伦 - YARN/K8s调度Spark作业的对比<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://zhuanlan.zhihu.com/p/694390153?share_code=DHgU3jGrptl0&utm_psn=1909311368072508289">[6] 知乎 - 太可研究所 - 漫谈大数据中的资源管理<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://cloud.google.com/discover/what-is-high-performance-computing?hl=zh-CN">[7] Google Cloud - 什么是高性能计算？<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://zh.wikipedia.org/wiki/%E6%89%B9%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1">[8] 维基百科 - 批处理任务<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://scale-py.godaai.org/ch-mpi/mpi-intro.html">[9] Python 数据科学加速 - MPI 简介<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://izsk.me/2021/03/15/Kubernetes-kubebatch-knows/">[10] Z.S.K.’s Record - Kube-batch学习(批调度器初识一)<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://github.com/volcano-sh/volcano">[11] GitHub - Volcano 仓库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/">[12] Volcano - Volcano介绍<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/blog/volcano-community-co-construction-program/">[13] Volcano - Volcano 社区共建计划<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>调度</tag>
        <tag>Volcano</tag>
        <tag>批处理</tag>
        <tag>HPC</tag>
        <tag>云原生</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano 深度解析（二）：Volcano调度流程与调度状态</title>
    <url>/2025/05/27/k8s/k8s-volcano-2/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 深度解析》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/05/26/k8s/k8s-volcano-1/" title="云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点">云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点</a></li>
<li><a href="/2025/05/27/k8s/k8s-volcano-2/" title="云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态">云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态</a></li>
<li><a href="/2025/06/22/k8s/k8s-volcano-install/" title="云原生批调度实战：Volcano 安装与初试">云原生批调度实战：Volcano 安装与初试</a></li>
<li><a href="/2025/08/25/k8s/k8s-volcano-core-flow/" title="云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计">云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计</a></li>
<li><a href="/2025/08/26/k8s/k8s-volcano-create-analysis/" title="云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析">云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析</a></li>
<li><a href="/2025/09/04/k8s/k8s-volcano-create-schedule-contention-analysis/" title="云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验">云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验</a>
</li>
</ol>
</blockquote>
<h1 id="💡-简介"><a href="#💡-简介" class="headerlink" title="💡 简介"></a>💡 简介</h1><p>前一篇文章总结了 Volcano 作为专为云原生架构下 HPC 场景设计的批处理调度系统，需要解决批处理作业的”作业管理”、”租户管理”、”调度功能”、”工程实践”方面的独特需求。因此，Volcano 在调度方面设计了一系列解决方案。本文将聚焦于 Volcano 的调度流程与调度状态。</p>
<h1 id="🖼️-Volcano-调度流程概览"><a href="#🖼️-Volcano-调度流程概览" class="headerlink" title="🖼️ Volcano 调度流程概览"></a>🖼️ Volcano 调度流程概览</h1><p>Volcano 通过一系列组件实现批处理作业的高效调度，主要流程如下：</p>
<ol>
<li><strong>缓存（Cache）</strong>：缓存集群节点和 Pod 信息，维护作业（PodGroup）与任务（Pod）之间的关系。缓存不仅提供集群快照，还为调度程序和 kube-apiserver 之间的交互提供接口（如绑定）。</li>
<li><strong>周期性调度</strong>：调度器基于集群快照周期性调度作业，每个周期创建会话对象（Session），存储调度所需数据。为了确保分布式系统的信息一致性，Volcano 调度器总是根据某个时间点的集群快照来调度作业，并在每个调度周期内做出一致的决定。</li>
<li><strong>调度周期操作——会话开启（OpenSession）</strong>：每个调度周期依次执行如下核心操作（actions）。此外，在 OpenSession 中，用户可以注册用户定义的插件，如 Gang 和 DRF，为操作提供算法。<ul>
<li><strong>Enqueue（入队）</strong>：筛选资源满足条件的作业进入待调度队列，确保只有资源充足时才创建 Pod。</li>
<li><strong>Allocate（分配）</strong>：为待调度 Pod 分配节点，包含作业排序、节点预选与优选。</li>
<li><strong>Preempt（抢占）</strong>：处理高优先级作业对低优先级作业的资源抢占，支持队列内和作业内的抢占。</li>
<li><strong>Reclaim（回收）</strong>：跨队列资源回收，高优先级队列可回收低优先级队列的资源，提升整体资源利用率。</li>
<li><strong>Backfill（回填）</strong>：为 BestEffort 类型 Pod（无明确资源申请）寻找调度位置，提高资源利用率。</li>
<li><strong>插件机制</strong>：各 action 可通过插件自定义算法，如 DRF 插件实现作业排序和资源分配。</li>
</ul>
</li>
<li><strong>会话关闭（CloseSession）</strong>：清理调度周期中间数据，准备下一个调度周期。</li>
</ol>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://www.cncf.io/wp-content/uploads/2022/07/image4-16.png" alt="Volcano调度流程"><figcaption>Volcano调度流程</figcaption></figure></p>
<p>对于一个调度周期内的各个操作（actions），我们作以下展开叙述：</p>
<ol>
<li><strong>Enqueue入队操作</strong>：筛选符合要求的作业进入待调度队列。<ul>
<li><strong>简介</strong>：这种机制确保了Pod只会在资源满足的情况下被创建，是调度器配置中必不可少的action。<ul>
<li>当一个Job下的最小资源申请量不能得到满足时，即使为Job下的Pod执行调度动作，Pod也会因为gang约束没有达到而无法进行调度。</li>
<li>只有当集群资源满足作业声明的最小资源需求时，Enqueue action才允许该作业入队，使得PodGroup的状态由Pending状态转换为Inqueue状态。</li>
<li>这个状态转换是Pod创建的前提，只有PodGroup进入Inqueue状态后，volcano-controller才会为该PodGroup创建Pod。</li>
</ul>
</li>
<li><strong>场景</strong>：在AI/MPI/HPC这样的集群资源可能不足的高负荷的场景下，Enqueue action能够防止集群下有大量不能调度的pod，提高了调度器的性能。</li>
<li><strong>注意</strong>：enqueue action和preempt/reclaim action是互相冲突的，如果同时配置了enqueue action和preempt/reclaim action，且enqueue action判断作业无法入队，有可能导致无法生成Pending状态的Pod，从而无法触发preempt/reclaim action。</li>
</ul>
</li>
<li><strong>Allocate 分配操作</strong>：调度流程中的正常分配步骤，用于处理在待调度Pod列表中具有资源申请量的Pod调度。<ul>
<li><strong>简介</strong>：包括作业的predicate和prioritize。（由于这些操作是通过插件实现的，因此用户可以重新定义自己的分配操作，例如 firmament，一种基于图的调度算法）<ol>
<li>根据作业顺序（JobOrderFn）对作业进行排序；</li>
<li>使用根据节点规则（predicateFn）预选，过滤掉不能分配作业的node；</li>
<li>根据节点顺序（NodeOrderFn）对节点进行排序，检查节点上的资源，并为处于作业就绪状态的作业选择最合适的节点。</li>
</ol>
</li>
<li><strong>场景</strong>：在集群混合业务场景中，Allocate的预选部分能够将特定的业务（AI、大数据、HPC、科学计算）按照所在namespace快速筛选、分类，对特定的业务进行快速、集中的调度。在Tensorflow、MPI等复杂计算场景中，单个作业中会有多个任务，Allocate action会遍历job下的多个task分配优选，为每个task找到最合适的node。</li>
<li><strong>注意</strong>：Allocate action遵循commit机制，当一个Pod的调度请求得到满足后，最终并不一定会为该Pod执行绑定动作，这一步骤还取决于Pod所在Job的gang约束是否得到满足。只有Pod所在Job的gang约束得到满足，Pod才可以被调度，否则，Pod不能够被调度。</li>
</ul>
</li>
<li><strong>Preempt抢占操作</strong>：调度流程中的抢占步骤，用于处理高优先级调度问题。<ul>
<li><strong>简介</strong>：Preempt用于同一个Queue中job之间的抢占，或同一Job下Task之间的抢占。</li>
<li><strong>场景</strong>：【官方文档中未解释跨Queue如何发生抢占】<ul>
<li><strong>Queue内job抢占</strong>：一个公司中多个部门共用一个集群，每个部门可以映射成一个Queue，不同部门之间的资源不能互相抢占，这种机制能够很好的保证部门资源的隔离性；同一个部门/Queue内部可以枪战。</li>
<li><strong>Job内task抢占</strong>：同一Job下通常可以有多个task，例如复杂的AI应用场景中，tensorflow-job内部需要设置一个ps和多个worker，Preempt action就支持这种场景下多个worker之间的抢占。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Reclaim回收操作</strong>：调度流程中的跨队列资源回收步骤。<ul>
<li><strong>简介</strong>：与Preempt不同，Reclaim专门处理不同Queue之间的资源回收。当某个Queue中的作业需要资源且该Queue未超用时，可以从其他可回收队列中回收资源。</li>
<li><strong>场景</strong>：<ul>
<li>跨队列资源回收：在多部门共用集群的场景下，当高优先级部门（如在线业务部门）的Queue资源不足时，可以从其他可回收的部门Queue（如离线计算部门）回收资源。例如，在线业务Queue可以从离线业务Queue回收资源，但离线业务Queue之间不能互相回收资源。</li>
<li>资源利用率优化：通过跨队列资源回收机制，集群可以在保证高优先级业务SLA的同时，提高整体资源利用率。当高优先级Queue作业较少时，低优先级Queue队列可以使用闲置资源；当高优先级Queue资源不足时，可以从低优先级Queue回收资源，确保关键业务的资源需求。</li>
</ul>
</li>
<li><strong>注意</strong>：<ol>
<li>Reclaim在执行时会检查多个条件：目标Queue是否可回收（Reclaimable）、任务是否可被回收（Preemptable）、资源回收后是否满足作业运行需求等，从而确保资源回收的合理性。</li>
<li>要使Queue中的作业可以被其他Queue回收资源，需要在Queue的spec中将reclaimable字段设置为true。</li>
</ol>
</li>
</ul>
</li>
<li><strong>Backfill回填操作</strong>：调度流程中处理BestEffort Pod（即没有指定资源申请量的Pod）的调度步骤。【和前面分析的Reservation&amp;Backfill似乎不是一个意思？】<ul>
<li><strong>简介</strong>：与Allocate action类似，Backfill也会遍历所有节点寻找合适的调度位置，主要区别在于它处理的是没有明确资源申请量的Pod。</li>
<li><strong>场景</strong>：在集群中，除了需要明确资源申请的工作负载外，还存在一些对资源需求不明确的工作负载。这些工作负载通常以BestEffort的方式运行，Backfill action负责为这类 Pod寻找合适的调度位置。</li>
</ul>
</li>
<li><strong>插件</strong>定义了actions所需的算法。<ul>
<li>例如，DRF 插件提供了 JobOrderFn 函数，用于根据主导资源对作业进行排序。JobOrderFn 函数根据 DRF 计算每个作业的份额值，份额值越小，说明分配给作业的资源越少，资源将优先分配给该作业。</li>
<li>DRF 插件还提供了 EventHandler 函数。在作业获得资源分配allocate或抢占资源preempt后，调度程序会指示 DRF 插件更新作业共享值。</li>
</ul>
</li>
</ol>
<h1 id="🔨-Volcano-调度状态"><a href="#🔨-Volcano-调度状态" class="headerlink" title="🔨 Volcano 调度状态"></a>🔨 Volcano 调度状态</h1><p>Volcano 增加了多种 Pod 状态以提升调度性能，主要状态如下：</p>
<ul>
<li><strong>Pending</strong>：Pod 创建后等待调度。</li>
<li><strong>Allocated</strong>：资源已分配但未绑定，调度周期内有效。</li>
<li><strong>Pipelined</strong>：分配到即将释放的资源，调度周期内有效。</li>
<li><strong>Binding</strong>：调度决定已提交，等待 kube-apiserver 确认。</li>
<li><strong>Bound</strong>：kube-apiserver 确认后，Pod 进入 Bound 状态。</li>
<li><strong>Releasing</strong>：Pod 等待删除。</li>
<li><strong>Running/Failed/Succeeded/Unknown</strong>：与 K8s 原生一致。</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://www.cncf.io/wp-content/uploads/2022/07/image2-28.png" alt="Volcano调度状态"><figcaption>Volcano调度状态</figcaption></figure></p>
<p>具体而言：</p>
<ol>
<li><strong>Pending 挂起</strong>：Pod 创建后，会处于待调度状态，等待调度。其目的是为这些待调度 pod 找到最佳目的地。</li>
<li><strong>Allocated 已分配</strong>：当闲置资源已分配给 pod，但未向 kube-apiserver 发送调度决定时，pod 处于 Allocated 状态。<ul>
<li>Allocated 状态仅在调度周期内存在，用于记录 pod 和资源分配信息。</li>
<li>当作业满足启动条件（如 minMember）时，调度程序会向 kube-apiserver 提交调度决定。</li>
<li>如果在当前调度周期内无法提交调度决定，pod 状态将回滚到Pending。</li>
</ul>
</li>
<li><strong>Piplined管道化</strong>：此状态与 Allocated 类似。不同之处在于，在此状态下分配给 pod 的资源是其他 pod 正在释放release的资源。<ul>
<li>此状态在调度周期内使用，不会更新到 kube-apiserver，从而减少了 kube-apiserver 的通信和 QPS。</li>
</ul>
</li>
<li><strong>Binding 绑定</strong>：当作业满足启动条件时，调度程序会向 kube-apiserver 提交调度决定。在 kube-apiserver 返回最终状态之前，pod 仍处于Binding状态。该状态也存储在调度程序的缓存中，并在整个调度周期内有效。</li>
<li><strong>Bound 绑定</strong>：作业调度决定经 kube-apiserver 确认后，pod 将变为Bound状态。</li>
<li><strong>Releasing 释放</strong>：当 pod 等待删除时，它处于释放状态。</li>
<li><strong>Running运行中、Failed失败、Succeeded成功和Unknown未知</strong>：与当前设计相比没有变化。</li>
</ol>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><ol>
<li>官方文档中未解释跨Queue如何发生抢占，后续还需继续查看代码。</li>
<li>官方文档中的Backfill阶段，和上一篇文章分析的Reservation&amp;Backfill似乎不是一个意思，后续还需继续查看具体实践中的操作细节。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.cncf.io/blog/2021/02/26/volcano-collision-between-containers-and-batch-computing/">[1] CNCF - Volcano: Collision between containers and batch computing<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://izsk.me/2021/03/15/Kubernetes-kubebatch-knows/">[2] Z.S.K.’s Record - Kube-batch学习(批调度器初识一)<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://izsk.me/2021/03/21/Kubernetes-kubebatch-theory/">[3] Z.S.K.’s Record - Kube-batch学习(queue及podgroup)<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://izsk.me/2021/03/27/Kubernetes-kubebatch-actions-plugins/">[4] Z.S.K.’s Record - Kube-batch学习(核心模块)<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://izsk.me/2023/11/12/volcano-key-resources/">[5] Z.S.K.’s Record - volcano如何应对大规模任务系列之volcano关键对象<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://izsk.me/2024/05/31/volcano-actions-plugins/">[6] Z.S.K.’s Record - volcano如何应对大规模任务系列之volcano插件系统<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://github.com/volcano-sh/volcano">[7] GitHub - Volcano 仓库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/actions/">[8] Volcano - Scheduler Actions<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>调度</tag>
        <tag>Volcano</tag>
        <tag>批处理</tag>
        <tag>HPC</tag>
        <tag>云原生</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano 深度解析（三）：核心流程解析与架构设计</title>
    <url>/2025/08/25/k8s/k8s-volcano-core-flow/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 深度解析》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/05/26/k8s/k8s-volcano-1/" title="云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点">云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点</a></li>
<li><a href="/2025/05/27/k8s/k8s-volcano-2/" title="云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态">云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态</a></li>
<li><a href="/2025/06/22/k8s/k8s-volcano-install/" title="云原生批调度实战：Volcano 安装与初试">云原生批调度实战：Volcano 安装与初试</a></li>
<li><a href="/2025/08/25/k8s/k8s-volcano-core-flow/" title="云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计">云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计</a></li>
<li><a href="/2025/08/26/k8s/k8s-volcano-create-analysis/" title="云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析">云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析</a></li>
<li><a href="/2025/09/04/k8s/k8s-volcano-create-schedule-contention-analysis/" title="云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验">云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验</a>
</li>
</ol>
</blockquote>
<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="调度器性能对比分析">调度器性能对比分析</a>中，我们发现Volcano在大规模Job创建时存在性能瓶颈，特别是与Webhook相关的限制。为了深入理解这一现象并提供有效的优化方案，我们需要从代码层面深入分析Volcano的核心流程。</p>
<p>本文将从Volcano的整体架构出发，详细解析从Job创建到Pod调度的完整流程，通过代码分析揭示Volcano如何实现高效的批处理调度，以及与原生Kubernetes调度器的关键差异。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>在性能测试中，我们发现Volcano在以下场景下存在性能瓶颈：</p>
<ol>
<li><strong>大规模Job创建</strong>：同时创建大量Job时，会出现阶段性阻塞</li>
<li><strong>Webhook QPS限制</strong>：Webhook的QPS限制可能影响Job创建速度</li>
<li><strong>批量处理机制</strong>：可能存在批量处理策略，按批创建，导致创建成为瓶颈</li>
</ol>
<p>为了理解这些问题的根本原因，我们需要深入分析Volcano的核心流程。在这篇博客中，我们对代码进行初步分析，从Job创建到Pod调度的完整流程开始，初步了解各组件的作用和交互关系。</p>
<h1 id="🏗️Volcano整体架构概览"><a href="#🏗️Volcano整体架构概览" class="headerlink" title="🏗️Volcano整体架构概览"></a>🏗️Volcano整体架构概览</h1><h2 id="核心组件架构"><a href="#核心组件架构" class="headerlink" title="核心组件架构"></a>核心组件架构</h2><p>Volcano作为Kubernetes的批处理调度系统，主要由以下几个核心组件组成：</p>
<pre class="mermaid">graph TB
    A[用户] --&gt; B[kube-apiserver]
    B --&gt; C[Volcano Controller Manager]
    B --&gt; D[Volcano Scheduler]
    B --&gt; E[Volcano Webhook Manager]
    
    C --&gt; F[Job Controller]
    C --&gt; G[PodGroup Controller]
    C --&gt; H[Queue Controller]
    
    D --&gt; I[Cache]
    D --&gt; J[Actions]
    D --&gt; K[Plugins]
    
    E --&gt; L[Admission Webhooks]
    E --&gt; M[Validating Webhooks]
    E --&gt; N[Mutating Webhooks]
    
    F --&gt; O[Pod Creation]
    G --&gt; P[PodGroup Management]
    H --&gt; Q[Queue Management]
    
    I --&gt; R[Node Cache]
    I --&gt; S[Pod Cache]
    I --&gt; T[Job Cache]
    
    J --&gt; U[Enqueue]
    J --&gt; V[Allocate]
    J --&gt; W[Preempt]
    J --&gt; X[Reclaim]
    J --&gt; Y[Backfill]</pre>

<h2 id="组件职责分析"><a href="#组件职责分析" class="headerlink" title="组件职责分析"></a>组件职责分析</h2><h3 id="1-Controller-Manager"><a href="#1-Controller-Manager" class="headerlink" title="1. Controller Manager"></a>1. Controller Manager</h3><ul>
<li><strong>Job Controller</strong>：管理Volcano Job的生命周期</li>
<li><strong>PodGroup Controller</strong>：管理PodGroup的创建和状态</li>
<li><strong>Queue Controller</strong>：管理队列资源和配额</li>
</ul>
<h3 id="2-Scheduler"><a href="#2-Scheduler" class="headerlink" title="2. Scheduler"></a>2. Scheduler</h3><ul>
<li><strong>Cache</strong>：维护集群状态快照</li>
<li><strong>Actions</strong>：执行调度操作（入队、分配、抢占等）</li>
<li><strong>Plugins</strong>：提供调度算法和策略</li>
</ul>
<h3 id="3-Webhook-Manager"><a href="#3-Webhook-Manager" class="headerlink" title="3. Webhook Manager"></a>3. Webhook Manager</h3><ul>
<li><strong>Admission Webhooks</strong>：准入控制</li>
<li><strong>Validating Webhooks</strong>：验证资源</li>
<li><strong>Mutating Webhooks</strong>：修改资源</li>
</ul>
<h1 id="🔄Job创建到Pod调度的完整流程"><a href="#🔄Job创建到Pod调度的完整流程" class="headerlink" title="🔄Job创建到Pod调度的完整流程"></a>🔄Job创建到Pod调度的完整流程</h1><h2 id="流程概览"><a href="#流程概览" class="headerlink" title="流程概览"></a>流程概览</h2><pre class="mermaid">sequenceDiagram
    participant User as 用户
    participant API as kube-apiserver
    participant Webhook as Webhook Manager
    participant Controller as Controller Manager
    participant Scheduler as Volcano Scheduler
    participant Cache as Scheduler Cache
    
    User-&gt;&gt;API: 创建Volcano Job
    API-&gt;&gt;Webhook: 调用准入Webhook
    Webhook-&gt;&gt;API: 验证/修改Job
    API-&gt;&gt;Controller: 触发Job Controller
    Controller-&gt;&gt;API: 创建PodGroup
    API-&gt;&gt;Webhook: 调用PodGroup Webhook
    Webhook-&gt;&gt;API: 验证PodGroup
    Controller-&gt;&gt;API: 创建Pod
    API-&gt;&gt;Webhook: 调用Pod Webhook
    Webhook-&gt;&gt;API: 验证Pod
    API-&gt;&gt;Scheduler: 触发调度
    Scheduler-&gt;&gt;Cache: 获取集群快照
    Scheduler-&gt;&gt;Scheduler: 执行调度算法
    Scheduler-&gt;&gt;API: 绑定Pod到节点</pre>

<h2 id="详细流程分析"><a href="#详细流程分析" class="headerlink" title="详细流程分析"></a>详细流程分析</h2><h3 id="阶段1：Job创建与验证"><a href="#阶段1：Job创建与验证" class="headerlink" title="阶段1：Job创建与验证"></a>阶段1：Job创建与验证</h3><h4 id="1-1-用户提交Job"><a href="#1-1-用户提交Job" class="headerlink" title="1.1 用户提交Job"></a>1.1 用户提交Job</h4><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch.volcano.sh/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-job</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">minAvailable:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">schedulerName:</span> <span class="string">volcano</span></span><br><span class="line">  <span class="attr">queue:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">task-1</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">container-1</span></span><br><span class="line">              <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">              <span class="attr">command:</span> [<span class="string">"sleep"</span>, <span class="string">"100"</span>]</span><br></pre></td></tr></table></figure></div>

<h4 id="1-2-Webhook验证"><a href="#1-2-Webhook验证" class="headerlink" title="1.2 Webhook验证"></a>1.2 Webhook验证</h4><p>当用户提交Job时，kube-apiserver会调用Volcano的Webhook进行验证。AdmitJobs函数通过HTTP路由系统被kube-apiserver调用，而不是直接的函数调用：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/webhooks/admission/jobs/validate/admit_job.go</span></span><br><span class="line"><span class="keyword">var</span> service = &amp;router.AdmissionService{</span><br><span class="line">    Path: <span class="string">"/jobs/validate"</span>,</span><br><span class="line">    Func: AdmitJobs,  <span class="comment">// 注册到HTTP路由</span></span><br><span class="line">    ValidatingConfig: &amp;whv1.ValidatingWebhookConfiguration{...},</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">AdmitJobs</span><span class="params">(ar admissionv1.AdmissionReview)</span></span> *admissionv1.AdmissionResponse {</span><br><span class="line">    <span class="keyword">switch</span> ar.Request.Operation {</span><br><span class="line">    <span class="keyword">case</span> admissionv1.Create:</span><br><span class="line">        msg = validateJobCreate(job, &amp;reviewResponse)</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>实际验证内容</strong>：根据代码分析，<code>validateJobCreate</code>函数主要验证：</p>
<ul>
<li><strong>基础参数校验</strong>：minAvailable、maxRetry、replicas等参数范围</li>
<li><strong>任务模板验证</strong>：Pod模板的合法性和K8s资源规范</li>
<li><strong>MPI依赖检查</strong>：验证master/worker任务配置</li>
<li><strong>任务间依赖</strong>：检查依赖关系是否形成有向无环图(DAG)</li>
<li><strong>队列状态验证</strong>：检查Queue是否存在、状态是否为Open、是否为叶子队列</li>
<li><strong>插件配置验证</strong>：验证Job插件是否存在</li>
</ul>
<p><strong>调用机制</strong>：Webhook通过以下机制被调用：</p>
<ol>
<li>webhook-manager启动时注册HTTP路由 (<code>http.HandleFunc(service.Path, service.Handler)</code>)</li>
<li>kube-apiserver根据ValidatingWebhookConfiguration向Volcano发送HTTP POST请求</li>
<li>请求路径为 <code>/jobs/validate</code>，由router.Serve处理并调用AdmitJobs函数</li>
</ol>
<h4 id="1-3-Job-Controller处理"><a href="#1-3-Job-Controller处理" class="headerlink" title="1.3 Job Controller处理"></a>1.3 Job Controller处理</h4><p>Job Controller监听到Job创建事件后，开始处理：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(jc *jobcontroller)</span></span> syncJob(job *vcbatch.Job) <span class="type">error</span> {</span><br><span class="line">    <span class="comment">// 1. 创建PodGroup</span></span><br><span class="line">    <span class="comment">// 2. 创建Pod</span></span><br><span class="line">    <span class="comment">// 3. 更新Job状态</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="阶段2：PodGroup创建"><a href="#阶段2：PodGroup创建" class="headerlink" title="阶段2：PodGroup创建"></a>阶段2：PodGroup创建</h3><h4 id="2-1-PodGroup的作用"><a href="#2-1-PodGroup的作用" class="headerlink" title="2.1 PodGroup的作用"></a>2.1 PodGroup的作用</h4><p>PodGroup是Volcano的核心概念，用于实现Gang调度：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(jc *jobcontroller)</span></span> createPodGroup(job *vcbatch.Job) <span class="type">error</span> {</span><br><span class="line">    podGroup := &amp;vcscheduling.PodGroup{</span><br><span class="line">        ObjectMeta: metav1.ObjectMeta{</span><br><span class="line">            Name:      job.Name,</span><br><span class="line">            Namespace: job.Namespace,</span><br><span class="line">        },</span><br><span class="line">        Spec: vcscheduling.PodGroupSpec{</span><br><span class="line">            MinMember: job.Spec.MinAvailable,</span><br><span class="line">            Queue:     job.Spec.Queue,</span><br><span class="line">        },</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> jc.vcClient.SchedulingV1beta1().PodGroups(job.Namespace).Create(podGroup)</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h4 id="2-2-PodGroup状态管理"><a href="#2-2-PodGroup状态管理" class="headerlink" title="2.2 PodGroup状态管理"></a>2.2 PodGroup状态管理</h4><p>PodGroup的状态转换：</p>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Pending
    Pending --&gt; Inqueue
    Inqueue --&gt; Running
    Running --&gt; Completed
    Running --&gt; Failed
    Completed --&gt; [*]
    Failed --&gt; [*]</pre>

<h3 id="阶段3：Pod创建"><a href="#阶段3：Pod创建" class="headerlink" title="阶段3：Pod创建"></a>阶段3：Pod创建</h3><h4 id="3-1-批量Pod创建"><a href="#3-1-批量Pod创建" class="headerlink" title="3.1 批量Pod创建"></a>3.1 批量Pod创建</h4><p>Job Controller会根据Job配置创建多个Pod：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller.go</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="type">int</span>(ts.Replicas); i++ {</span><br><span class="line">    podName := fmt.Sprintf(jobhelpers.PodNameFmt, job.Name, name, i)</span><br><span class="line">    <span class="keyword">if</span> _, found := pods[podName]; !found {</span><br><span class="line">        newPod := createJobPod(job, tc, ts.TopologyPolicy, i, jobForwarding)</span><br><span class="line">        <span class="comment">// 收集待创建的 Pod，并登记到 WaitGroup</span></span><br><span class="line">        podToCreateEachTask = <span class="built_in">append</span>(podToCreateEachTask, newPod)</span><br><span class="line">        waitCreationGroup.Add(<span class="number">1</span>)</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
<p>随后使用 goroutine + WaitGroup 并发向 API Server 创建 Pod：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller.go</span></span><br><span class="line"><span class="keyword">for</span> _, pod := <span class="keyword">range</span> podToCreateEachTask {</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(pod *v1.Pod)</span></span> {</span><br><span class="line">        <span class="keyword">defer</span> waitCreationGroup.Done()</span><br><span class="line">        _, err := kubeClient.CoreV1().Pods(pod.Namespace).Create(ctx, pod, metav1.CreateOptions{})</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &amp;&amp; !apierrors.IsAlreadyExists(err) {</span><br><span class="line">            <span class="comment">// 错误处理略</span></span><br><span class="line">        }</span><br><span class="line">    }(pod)</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h4 id="3-2-Pod-模板展开"><a href="#3-2-Pod-模板展开" class="headerlink" title="3.2 Pod 模板展开"></a>3.2 Pod 模板展开</h4><p>单个 Pod 的构造细节在 <code>createJobPod</code>（<code>pkg/controllers/job/job_controller_util.go</code>）：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller_util.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">createJobPod</span><span class="params">(job *batch.Job, template *v1.PodTemplateSpec,</span></span></span><br><span class="line"><span class="params"><span class="function">    topologyPolicy batch.NumaPolicy, ix <span class="type">int</span>, jobForwarding <span class="type">bool</span>)</span></span> *v1.Pod {</span><br><span class="line"></span><br><span class="line">    pod := &amp;v1.Pod{</span><br><span class="line">        ObjectMeta: metav1.ObjectMeta{</span><br><span class="line">            Name:      jobhelpers.MakePodName(job.Name, template.Name, ix),</span><br><span class="line">            Namespace: job.Namespace,</span><br><span class="line">            OwnerReferences: []metav1.OwnerReference{</span><br><span class="line">                *metav1.NewControllerRef(job, helpers.JobKind),</span><br><span class="line">            },</span><br><span class="line">        },</span><br><span class="line">        Spec: template.Spec,</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 省略 SchedulerName、Volume 等附加字段填充</span></span><br><span class="line">    <span class="keyword">return</span> pod</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="阶段4：调度处理"><a href="#阶段4：调度处理" class="headerlink" title="阶段4：调度处理"></a>阶段4：调度处理</h3><h4 id="4-1-调度器触发"><a href="#4-1-调度器触发" class="headerlink" title="4.1 调度器触发"></a>4.1 调度器触发</h4><p>当Pod创建后，调度器开始工作：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/scheduler/framework/session.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ssn *Session)</span></span> Open() {</span><br><span class="line">    <span class="comment">// 1. 获取集群快照</span></span><br><span class="line">    <span class="comment">// 2. 执行调度Actions</span></span><br><span class="line">    <span class="comment">// 3. 更新调度结果</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h4 id="4-2-调度Actions执行"><a href="#4-2-调度Actions执行" class="headerlink" title="4.2 调度Actions执行"></a>4.2 调度Actions执行</h4><p>调度器按顺序执行Actions：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/scheduler/actions/allocate/allocate.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(alloc *Action)</span></span> Execute(ssn *framework.Session) {</span><br><span class="line">    <span class="comment">// 1. Enqueue: 将Job加入调度队列</span></span><br><span class="line">    <span class="comment">// 2. Allocate: 为Pod分配节点</span></span><br><span class="line">    <span class="comment">// 3. Preempt: 处理抢占</span></span><br><span class="line">    <span class="comment">// 4. Reclaim: 处理资源回收</span></span><br><span class="line">    <span class="comment">// 5. Backfill: 处理回填</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h4 id="4-3-节点选择算法"><a href="#4-3-节点选择算法" class="headerlink" title="4.3 节点选择算法"></a>4.3 节点选择算法</h4><p>调度器使用多种算法选择最优节点：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/scheduler/plugins/predicates/predicates.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *predicatePlugin)</span></span> OnNodeAdd(node *v1.Node) {</span><br><span class="line">    <span class="comment">// 节点预选：过滤不满足条件的节点</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *predicatePlugin)</span></span> OnNodeUpdate(oldNode, newNode *v1.Node) {</span><br><span class="line">    <span class="comment">// 节点优选：为节点打分</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h1 id="🔍关键组件深度解析"><a href="#🔍关键组件深度解析" class="headerlink" title="🔍关键组件深度解析"></a>🔍关键组件深度解析</h1><h2 id="Controller-Manager组件"><a href="#Controller-Manager组件" class="headerlink" title="Controller Manager组件"></a>Controller Manager组件</h2><h3 id="Job-Controller"><a href="#Job-Controller" class="headerlink" title="Job Controller"></a>Job Controller</h3><p>Job Controller是Volcano的核心控制器，负责管理Job的生命周期：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller.go</span></span><br><span class="line"><span class="keyword">type</span> jobcontroller <span class="keyword">struct</span> {</span><br><span class="line">    vcClient    vcclientset.Interface</span><br><span class="line">    kubeClient  kubernetes.Interface</span><br><span class="line">    jobInformer vcinformer.JobInformer</span><br><span class="line">    podInformer corev1informer.PodInformer</span><br><span class="line">    <span class="comment">// ... 其他字段</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(jc *jobcontroller)</span></span> syncJob(job *vcbatch.Job) <span class="type">error</span> {</span><br><span class="line">    <span class="comment">// 1. 检查Job状态</span></span><br><span class="line">    <span class="comment">// 2. 创建/更新PodGroup</span></span><br><span class="line">    <span class="comment">// 3. 创建/更新Pod</span></span><br><span class="line">    <span class="comment">// 4. 更新Job状态</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="PodGroup-Controller"><a href="#PodGroup-Controller" class="headerlink" title="PodGroup Controller"></a>PodGroup Controller</h3><p>PodGroup Controller管理PodGroup的状态转换：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/podgroup/podgroup_controller.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(pgc *podgroupcontroller)</span></span> syncPodGroup(pg *vcscheduling.PodGroup) <span class="type">error</span> {</span><br><span class="line">    <span class="comment">// 1. 检查PodGroup状态</span></span><br><span class="line">    <span class="comment">// 2. 计算满足条件的Pod数量</span></span><br><span class="line">    <span class="comment">// 3. 更新PodGroup状态</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h2 id="Scheduler组件"><a href="#Scheduler组件" class="headerlink" title="Scheduler组件"></a>Scheduler组件</h2><h3 id="Cache机制"><a href="#Cache机制" class="headerlink" title="Cache机制"></a>Cache机制</h3><p>调度器的Cache维护集群状态快照：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/scheduler/cache/cache.go</span></span><br><span class="line"><span class="keyword">type</span> Cache <span class="keyword">struct</span> {</span><br><span class="line">    nodes <span class="keyword">map</span>[<span class="type">string</span>]*api.NodeInfo</span><br><span class="line">    jobs  <span class="keyword">map</span>[api.JobID]*api.JobInfo</span><br><span class="line">    pods  <span class="keyword">map</span>[<span class="type">string</span>]*api.PodInfo</span><br><span class="line">    <span class="comment">// ... 其他字段</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cache)</span></span> Snapshot() *api.ClusterInfo {</span><br><span class="line">    <span class="comment">// 创建集群快照</span></span><br><span class="line">    <span class="keyword">return</span> &amp;api.ClusterInfo{</span><br><span class="line">        Nodes: c.nodes,</span><br><span class="line">        Jobs:  c.jobs,</span><br><span class="line">        <span class="comment">// ... 其他信息</span></span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="Actions机制"><a href="#Actions机制" class="headerlink" title="Actions机制"></a>Actions机制</h3><p>Actions定义了调度器的核心操作：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/scheduler/actions/allocate/allocate.go</span></span><br><span class="line"><span class="keyword">type</span> Action <span class="keyword">struct</span> {</span><br><span class="line">    <span class="comment">// Action实现</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(alloc *Action)</span></span> Execute(ssn *framework.Session) {</span><br><span class="line">    <span class="comment">// 1. Enqueue: 入队操作</span></span><br><span class="line">    <span class="comment">// 2. Allocate: 分配操作</span></span><br><span class="line">    <span class="comment">// 3. Preempt: 抢占操作</span></span><br><span class="line">    <span class="comment">// 4. Reclaim: 回收操作</span></span><br><span class="line">    <span class="comment">// 5. Backfill: 回填操作</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h2 id="Webhook-Manager组件"><a href="#Webhook-Manager组件" class="headerlink" title="Webhook Manager组件"></a>Webhook Manager组件</h2><h3 id="Admission-Webhooks"><a href="#Admission-Webhooks" class="headerlink" title="Admission Webhooks"></a>Admission Webhooks</h3><p>准入控制器处理资源创建和修改：</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/webhooks/admission/job/admit.go</span></span><br><span class="line"><span class="keyword">type</span> jobAdmit <span class="keyword">struct</span> {</span><br><span class="line">    <span class="comment">// Webhook实现</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(job *jobAdmit)</span></span> Admit(ar *admissionv1.AdmissionReview) *admissionv1.AdmissionResponse {</span><br><span class="line">    <span class="comment">// 1. 解析请求</span></span><br><span class="line">    <span class="comment">// 2. 验证资源</span></span><br><span class="line">    <span class="comment">// 3. 返回结果</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://github.com/volcano-sh/volcano">[1] Volcano GitHub 仓库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/">[2] Volcano 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/kube-scheduler/">[3] Kubernetes 调度器设计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/architecture/">[4] Volcano 架构设计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/">[5] Kubernetes Webhook 机制<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/actions/">[6] Volcano 调度器 Actions<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/architecture/controller/">[7] Kubernetes 控制器<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/schduler_introduction/">[8] Volcano 调度器<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>调度器</tag>
        <tag>Volcano</tag>
        <tag>批处理</tag>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano 深度解析（四）：CREATE 阶段瓶颈追踪与优化思考</title>
    <url>/2025/08/26/k8s/k8s-volcano-create-analysis/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 深度解析》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/05/26/k8s/k8s-volcano-1/" title="云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点">云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点</a></li>
<li><a href="/2025/05/27/k8s/k8s-volcano-2/" title="云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态">云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态</a></li>
<li><a href="/2025/06/22/k8s/k8s-volcano-install/" title="云原生批调度实战：Volcano 安装与初试">云原生批调度实战：Volcano 安装与初试</a></li>
<li><a href="/2025/08/25/k8s/k8s-volcano-core-flow/" title="云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计">云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计</a></li>
<li><a href="/2025/08/26/k8s/k8s-volcano-create-analysis/" title="云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析">云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析</a></li>
<li><a href="/2025/09/04/k8s/k8s-volcano-create-schedule-contention-analysis/" title="云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验">云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验</a>
</li>
</ol>
</blockquote>
<p>本文承接《Volcano 深度解析（三）：核心流程解析与架构设计》，聚焦 <strong>CREATED 阶段</strong> 的性能瓶颈。实验环境及测试方法延续前文，不再赘述。</p>
<h1 id="0️⃣-背景回顾"><a href="#0️⃣-背景回顾" class="headerlink" title="0️⃣ 背景回顾"></a>0️⃣ 背景回顾</h1><p>在 <a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="Webhook 禁用实验">Webhook 禁用实验</a> 中，我们已确认：即使禁用 Webhook，<strong>CREATED 曲线仍呈阶梯式“突增 / 突停”</strong>。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="CREATED 阶梯示例 Benchmark-1：10K Jobs × 1 Pod"><figcaption>CREATED 阶梯示例 Benchmark-1：10K Jobs × 1 Pod</figcaption></figure><br><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/Freshwlnd/image/refs/heads/blog/kube-scheduling-perf-image/4-disable-webhook/b.NoGang-500Job-no/output/panel-5.png" alt="CREATED 阶梯示例 Benchmark-2：500 Jobs × 20 Pods"><figcaption>CREATED 阶梯示例 Benchmark-2：500 Jobs × 20 Pods</figcaption></figure></p>
<p>本文尝试回答两个问题：</p>
<ol>
<li>阶梯为何产生？</li>
<li>有哪些“调得动”的参数能够缓解？</li>
</ol>
<h1 id="1️⃣-实验现象重现"><a href="#1️⃣-实验现象重现" class="headerlink" title="1️⃣ 实验现象重现"></a>1️⃣ 实验现象重现</h1><table>
<thead>
<tr>
<th>Benchmark</th>
<th>Job×Pod</th>
<th>现象</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>benchmark-1</td>
<td>10K×1</td>
<td>CREATE 与 SCHEDULE 几乎重叠，整体速度四组中最慢</td>
<td><strong>CREATE = 主要瓶颈</strong></td>
</tr>
<tr>
<td>benchmark-2</td>
<td>500×20</td>
<td>阶梯最清晰，阶段性出现 CREATE 阻塞 → SCHEDULE 停顿</td>
<td>CREATE &amp; SCHEDULE 交替受阻</td>
</tr>
<tr>
<td>benchmark-3</td>
<td>20×500</td>
<td>CREATE 有阶梯但速度明显快于 SCHEDULE</td>
<td>SCHEDULE 成瓶颈</td>
</tr>
<tr>
<td>benchmark-4</td>
<td>1×10K</td>
<td>同上，CREATE 不是主瓶颈</td>
<td></td>
</tr>
</tbody></table>
<p><strong>猜想</strong>：JobController 对 Pod 的“批量同步创建”导致单批全部结束前无法进入下一批，从而表现为突停；批量完成后瞬时放量，表现为突增。</p>
<h1 id="2️⃣-代码走读：JobController-批量创建逻辑"><a href="#2️⃣-代码走读：JobController-批量创建逻辑" class="headerlink" title="2️⃣ 代码走读：JobController 批量创建逻辑"></a>2️⃣ 代码走读：JobController 批量创建逻辑</h1><h2 id="2-1-Worker-协程来源"><a href="#2-1-Worker-协程来源" class="headerlink" title="2.1 Worker 协程来源"></a>2.1 Worker 协程来源</h2><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// cmd/controller-manager/app/server.go:134-139</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">startControllers</span><span class="params">(config *rest.Config, opt *options.ServerOption)</span></span> <span class="function"><span class="keyword">func</span><span class="params">(ctx context.Context)</span></span> {</span><br><span class="line">    ...</span><br><span class="line">    controllerOpt.WorkerNum = opt.WorkerThreads</span><br><span class="line">    ...</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><code>--worker-threads</code> 默认为 <strong>50</strong>（不指定则使用该值），决定 JobController 并发消费 <strong>Job 请求</strong> 的 goroutine 数。</p>
<blockquote>
<p>⚠️ <strong>注意</strong>：这里的协程只决定 <em>Job</em> 并行数，跟 <em>Pod</em> 并行数并非一回事。</p>
</blockquote>
<h2 id="2-2-哈希分片与队列"><a href="#2-2-哈希分片与队列" class="headerlink" title="2.2 哈希分片与队列"></a>2.2 哈希分片与队列</h2><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller.go:318-333</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *jobcontroller)</span></span> belongsToThisRoutine(key <span class="type">string</span>, count <span class="type">uint32</span>) <span class="type">bool</span> {</span><br><span class="line">    val := cc.genHash(key)</span><br><span class="line">    <span class="keyword">return</span> val % cc.workers == count</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *jobcontroller)</span></span> getWorkerQueue(key <span class="type">string</span>) workqueue.TypedRateLimitingInterface[any] {</span><br><span class="line">	val := cc.genHash(key)</span><br><span class="line">	queue := cc.queueList[val%cc.workers]</span><br><span class="line">	<span class="keyword">return</span> queue</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// genHash 源码</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *jobcontroller)</span></span> genHash(key <span class="type">string</span>) <span class="type">uint32</span> {</span><br><span class="line">    hashVal := fnv.New32() <span class="comment">// FNV-1a 非加密散列</span></span><br><span class="line">    hashVal.Write([]<span class="type">byte</span>(key))</span><br><span class="line">    <span class="keyword">return</span> hashVal.Sum32()</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p>FNV（Fowler–Noll–Vo）是一种速度快、冲突率低的非加密散列函数，它在 Volcano 中承担 <strong>一致分片</strong> 的角色：</p>
<ol>
<li><strong>单 Job 串行化</strong>：保证相同的 JobKey 永远路由到同一 worker，避免多协程并发修改同一 Job 状态导致的竞态（如版本冲突、重复创建 Pod 等）。</li>
<li><strong>负载均衡</strong>：不同 Job 均匀散落到 <code>workers</code> 个队列，提升并行度。</li>
</ol>
<blockquote>
<p>❓ 如果不保证“同一Job → 同一协程”？</p>
<ul>
<li>多协程可能同时进入同一 Job 的状态机，导致 <strong>Status 冲突</strong>（ResourceVersion 不匹配重试、乐观锁失败）。</li>
<li>重复创建 Pod / PodGroup，产生 <strong>资源泄漏</strong> 与 <strong>Gang 调度失败</strong>。</li>
<li>如不使用该机制，则需要加全局锁或精细乐观重试，得不偿失。</li>
</ul>
</blockquote>
<h2 id="3️⃣-CREATE-批量创建流程"><a href="#3️⃣-CREATE-批量创建流程" class="headerlink" title="3️⃣ CREATE 批量创建流程"></a>3️⃣ CREATE 批量创建流程</h2><h3 id="PodGroup-创建"><a href="#PodGroup-创建" class="headerlink" title="PodGroup 创建"></a>PodGroup 创建</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller_actions.go:190-214</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *jobcontroller)</span></span> createOrUpdatePodGroup(job *batch.Job) <span class="type">error</span> {</span><br><span class="line">    ...</span><br><span class="line">    pg := &amp;scheduling.PodGroup{ ... }</span><br><span class="line">    vcClient.SchedulingV1beta1().PodGroups(...).Create(..., pg, ...)</span><br><span class="line">    ...</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p>一次 API 调用即可完成，且一个 Job 只建一个 PodGroup；创建本身比较简单（仅是逻辑单元），可能不是主要瓶颈：</p>
<ul>
<li>PodGroup 本质是一个 CRD 对象（仅几十字节的 Spec &amp; Metadata，见<code>pkg/controllers/job/job_controller_actions.go</code>定义部分），创建过程只是 kube-apiserver → etcd 的一次写操作。</li>
<li>不涉及调度决策、节点通信或资源计算；成功后即可返回，无后续长耗时流程。</li>
</ul>
<p>但需注意：若 <code>MinMember</code> 设置过大或 Queue 资源不足，调度器在 <strong>后续阶段</strong> 仍可能因 PodGroup 不满足条件而阻塞 Job 启动，这属于调度环节而非 CREATE 环节。</p>
<h3 id="Pod-创建"><a href="#Pod-创建" class="headerlink" title="Pod 创建"></a>Pod 创建</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller_actions.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *jobcontroller)</span></span> syncJob(jobInfo *apis.JobInfo, updateStatus state.UpdateStatusFn) <span class="type">error</span> {</span><br><span class="line">    ...</span><br><span class="line">    waitCreationGroup := sync.WaitGroup{}</span><br><span class="line">    ...</span><br><span class="line">	<span class="keyword">var</span> podToCreateEachTask []*v1.Pod</span><br><span class="line">	<span class="keyword">for</span> _, ts := <span class="keyword">range</span> job.Spec.Tasks {</span><br><span class="line">        <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="type">int</span>(ts.Replicas); i++ {           <span class="comment">// 收集待建 Pod</span></span><br><span class="line">            ...</span><br><span class="line">            newPod := createJobPod(job, tc, ts.TopologyPolicy, i, jobForwarding)</span><br><span class="line">            ...</span><br><span class="line">            podToCreateEachTask = <span class="built_in">append</span>(podToCreateEachTask, newPod)</span><br><span class="line">            waitCreationGroup.Add(<span class="number">1</span>)</span><br><span class="line">            ...</span><br><span class="line">        }</span><br><span class="line">        podToCreate[ts.Name] = podToCreateEachTask</span><br><span class="line">    }</span><br><span class="line">    ...</span><br><span class="line">	<span class="keyword">for</span> taskName, podToCreateEachTask := <span class="keyword">range</span> podToCreate {</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(taskName <span class="type">string</span>, podToCreateEachTask []*v1.Pod)</span></span> {</span><br><span class="line">            ...</span><br><span class="line">            <span class="keyword">for</span> _, pod := <span class="keyword">range</span> podToCreateEachTask {</span><br><span class="line">                <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(pod *v1.Pod)</span></span> {</span><br><span class="line">                    <span class="keyword">defer</span> waitCreationGroup.Done()</span><br><span class="line">                    kubeClient.CoreV1().Pods(...).Create(...)</span><br><span class="line">                }(pod)</span><br><span class="line">            }</span><br><span class="line">            ...</span><br><span class="line">        }(taskName, podToCreateEachTask)</span><br><span class="line">    }</span><br><span class="line">    ...</span><br><span class="line">    waitCreationGroup.Wait()  <span class="comment">// ⬅ 阻塞：一批全部完成前不返回</span></span><br><span class="line">    ...</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p><strong>观察</strong>：每个 Job 中的所有 Pod 都必须在同一批完成，<code>Wait()</code> 阻塞期间该 worker 协程无法服务其他 Job，形成“突停”。</p>
</blockquote>
<p>与上述PodGroup有所差异，由于Pod是K8s原生对象，涉及到的字段极多且复杂，既需要默认填充大量字段、也需要花更多时间写入etcd，因此更容易成为瓶颈。</p>
<h2 id="4️⃣-CREATE-阶段可能的瓶颈链路"><a href="#4️⃣-CREATE-阶段可能的瓶颈链路" class="headerlink" title="4️⃣  CREATE 阶段可能的瓶颈链路"></a>4️⃣  CREATE 阶段可能的瓶颈链路</h2><ol>
<li><strong>ControllerManager – PodGroup 创建</strong>：单请求，理论影响小；仅在 CRD 校验或 etcd 压力大时显现。</li>
<li><strong>ControllerManager – Pod 创建并发</strong>：瞬时并发高且字段复杂，容易受 kube-apiserver QPS/TPS 限流影响。</li>
<li><strong>kube-apiserver – etcd 写入</strong>：大批量对象持久化；etcd IOPS 饱和时延长请求时长。</li>
<li><strong>网络 / TLS 握手</strong>：每 Pod 一次 HTTPS；高并发下握手耗时占比提升。</li>
<li><strong>Webhook</strong>（若开启）：Mutating/Validating 延时或超时。</li>
<li><strong>Worker 协程饱和</strong>：<code>--worker-threads</code> 阈值被占满后，新 Job 无法 dequeue，外部观察即“突停”。</li>
</ol>
<blockquote>
<p>在四组 Benchmark 中，总 Pod 数一致（10K），但 <strong>Job 数量越多，Worker 越容易饱和</strong>，因此出现瓶颈的并非 “单 Job 内 Pod 数” 而是 “Cluster 同时活跃的 Job 数”。</p>
</blockquote>
<h2 id="5️⃣-关键对象关系"><a href="#5️⃣-关键对象关系" class="headerlink" title="5️⃣ 关键对象关系"></a>5️⃣ 关键对象关系</h2><table>
<thead>
<tr>
<th>对象</th>
<th>层级</th>
<th>作用</th>
<th>与其他对象关系</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Job</strong></td>
<td>Volcano CRD</td>
<td>用户提交的批处理作业</td>
<td>一个 Job <strong>拥有</strong> 1 PodGroup &amp; N Tasks</td>
</tr>
<tr>
<td><strong>PodGroup</strong></td>
<td>Volcano CRD</td>
<td>Gang 调度边界，决定最小可运行成员数</td>
<td>Job 创建时同步生成；Scheduler 以 PG 维度做满足性判断</td>
</tr>
<tr>
<td><strong>Task</strong></td>
<td>Job 内部元素</td>
<td>Job 的逻辑分片，可用不同镜像/参数</td>
<td>Task <strong>生成</strong> 多个 Pod(Replicas)</td>
</tr>
<tr>
<td><strong>Pod</strong></td>
<td>K8s 原生</td>
<td>实际运行单元</td>
<td>由 Task 模板实例化，归属同一 PodGroup</td>
</tr>
</tbody></table>
<blockquote>
<p>PodGroup ≠ Task：个人理解前者是 Job 的化身，后者是 Job 内的子对象。<br>层级关系为：1 Job（PodGroup） → n Task → n*m Pod。</p>
</blockquote>
<h2 id="6️⃣-相关参数与理论影响"><a href="#6️⃣-相关参数与理论影响" class="headerlink" title="6️⃣ 相关参数与理论影响"></a>6️⃣ 相关参数与理论影响</h2><table>
<thead>
<tr>
<th>参数</th>
<th>默认</th>
<th>预期影响</th>
<th>实测结论</th>
</tr>
</thead>
<tbody><tr>
<td><code>--worker-threads</code></td>
<td>50</td>
<td>决定可同时被处理的 Job 数</td>
<td>✅ 提高可缩短突停时长，但系统整体压力增大</td>
</tr>
<tr>
<td><code>task.replicas</code></td>
<td>用户输入</td>
<td>决定单 Job 内批量大小</td>
<td>⚠️ 非根因；更改只影响单 batch 时长</td>
</tr>
<tr>
<td>新增参数</td>
<td>N/A</td>
<td>控制每次并发 Pod 数（而非局限于一个 Job 内的 Pod 数）</td>
<td>🚧 需进一步设计</td>
</tr>
</tbody></table>
<blockquote>
<p>结论：</p>
<ul>
<li><strong>Job 数</strong> → Worker 饱和度 → 是否突停。</li>
<li><strong>Replica 数</strong> → 单 worker 持续时间 → 阶梯宽度。</li>
</ul>
</blockquote>
<h2 id="7️⃣-优化方向"><a href="#7️⃣-优化方向" class="headerlink" title="7️⃣ 优化方向"></a>7️⃣ 优化方向</h2><table>
<thead>
<tr>
<th>方向</th>
<th>复杂度</th>
<th>收益</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>智能调整 <code>--worker-threads</code></td>
<td>低</td>
<td>高</td>
<td>观察到出现瓶颈（或观察到 replicas 普遍较小）时，自动提高并行协程数，削弱同步阻塞</td>
</tr>
<tr>
<td>引入新参数，或调整协程Wait阻塞逻辑</td>
<td>中</td>
<td>高</td>
<td>分片提交 Pods（支持跨Job并行），削弱同步阻塞</td>
</tr>
</tbody></table>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://github.com/volcano-sh/volcano">[1] Volcano GitHub 仓库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/">[2] Volcano 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/kube-scheduler/">[3] Kubernetes 调度器设计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/architecture/">[4] Volcano 架构设计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/">[5] Kubernetes Webhook 机制<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/actions/">[6] Volcano 调度器 Actions<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/architecture/controller/">[7] Kubernetes 控制器<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/schduler_introduction/">[8] Volcano 调度器<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>调度器</tag>
        <tag>性能优化</tag>
        <tag>Volcano</tag>
        <tag>批处理</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano 深度解析（五）：CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验</title>
    <url>/2025/09/04/k8s/k8s-volcano-create-schedule-contention-analysis/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 深度解析》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/05/26/k8s/k8s-volcano-1/" title="云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点">云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点</a></li>
<li><a href="/2025/05/27/k8s/k8s-volcano-2/" title="云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态">云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态</a></li>
<li><a href="/2025/06/22/k8s/k8s-volcano-install/" title="云原生批调度实战：Volcano 安装与初试">云原生批调度实战：Volcano 安装与初试</a></li>
<li><a href="/2025/08/25/k8s/k8s-volcano-core-flow/" title="云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计">云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计</a></li>
<li><a href="/2025/08/26/k8s/k8s-volcano-create-analysis/" title="云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析">云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析</a></li>
<li><a href="/2025/09/04/k8s/k8s-volcano-create-schedule-contention-analysis/" title="云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验">云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验</a>
</li>
</ol>
</blockquote>
<p>本文承接《CREATE 阶段瓶颈追踪与优化思考》，基于大量实验数据和源码深度分析，重新梳理 <strong>CREATE/SCHEDULE 卡顿现象</strong> 的根本原因。上篇博客中我们推测协程数不足是导致卡顿的主要原因，但实验结果却呈现了一些反直觉的现象，本文将结合源码分析给出更准确的解释。</p>
<h1 id="0️⃣-引言"><a href="#0️⃣-引言" class="headerlink" title="0️⃣ 引言"></a>0️⃣ 引言</h1><p>在上一篇博客 <a href="/2025/08/26/k8s/k8s-volcano-create-analysis/" title="CREATE 阶段瓶颈追踪">CREATE 阶段瓶颈追踪</a> 中，我们通过代码分析推测，Controller 的 worker 协程数不足可能是导致 <code>CREATE</code>/<code>SCHEDULE</code> 阶段出现卡顿（表现为“突增、突停”）现象的原因。然而，后续大量的性能测试揭示了一些反直觉的现象，挑战了这一初步结论。</p>
<ul>
<li><strong>协程数增加并不总是提升性能</strong>：在某些配置下，增加协程数反而会降低性能</li>
</ul>
<p>这些现象促使我们重新审视问题的根本原因。<br>本次，我们将结合最新的实验结果以及对 Volcano 源码的进一步分析，重新梳理 <code>CREATE</code>/<code>SCHEDULE</code> 卡顿现象的深层原因，并探讨其背后的 K8s API-Server 争用机制。</p>
<h1 id="1️⃣-背景回顾"><a href="#1️⃣-背景回顾" class="headerlink" title="1️⃣ 背景回顾"></a>1️⃣ 背景回顾</h1><h2 id="1-1-卡顿现象描述"><a href="#1-1-卡顿现象描述" class="headerlink" title="1.1 卡顿现象描述"></a>1.1 卡顿现象描述</h2><p>根据前期测试（无论是 KubeCon 的分享还是我们本地的复现），我们发现 Volcano 在处理大量 Pod 的 <code>CREATE</code> 和 <code>SCHEDULE</code> 过程中，性能曲线并非平滑上升，而是会出现卡顿现象，具体体现为：</p>
<ul>
<li><strong>“完成 <code>CREATE</code> 的 Pod 数量”</strong> 和 <strong>“完成 <code>SCHEDULE</code> 的 Pod 数量”</strong> 指标各自出现持续增长一段时间后突停一段时间</li>
<li>然后再持续增长一段时间后又突停一段时间，循环往复</li>
</ul>
<p><figure class="image-caption"><img src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/b.NoGang-500Job-no/output/panel-5.png?raw=true" alt="CREATE/SCHEDULE 卡顿现象示意图1"><figcaption>CREATE/SCHEDULE 卡顿现象示意图1</figcaption></figure></p>
<p><figure class="image-caption"><img src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/5-more-worker-threads/only-volcano/worker_threads_100/3.NoGang-2KJob/output/panel-5.png?raw=true" alt="CREATE/SCHEDULE 卡顿现象示意图2"><figcaption>CREATE/SCHEDULE 卡顿现象示意图2</figcaption></figure></p>
<p>这种现象引起了我们的担忧：这些停顿的平台期是否意味着时间的浪费？如果我们能消除这些停顿，把这些时间段用起来，是不是我们就能够达到更高的效率呢？</p>
<h2 id="1-2-测试环境说明"><a href="#1-2-测试环境说明" class="headerlink" title="1.2 测试环境说明"></a>1.2 测试环境说明</h2><p>前期我们保持 Node 数量和 Pod 数量不变，调整 Job 数量（以及对应的每 Job 内 Pod 数量）进行测试。测试配置如下：</p>
<table>
<thead>
<tr>
<th>Benchmark</th>
<th>Job×Pod</th>
<th>总 Pod 数</th>
<th>现象特征</th>
</tr>
</thead>
<tbody><tr>
<td>benchmark-1</td>
<td>10K×1</td>
<td>10,000</td>
<td><code>CREATE</code> 与 <code>SCHEDULE</code> 几乎重叠，整体速度最慢</td>
</tr>
<tr>
<td>benchmark-2</td>
<td>500×20</td>
<td>10,000</td>
<td>阶梯最清晰，<code>CREATE</code>/<code>SCHEDULE</code> 交替性卡顿</td>
</tr>
<tr>
<td>benchmark-3</td>
<td>200×50</td>
<td>10,000</td>
<td><code>CREATE</code> 有阶梯但速度明显快于 <code>SCHEDULE</code></td>
</tr>
<tr>
<td>benchmark-4</td>
<td>20×500</td>
<td>10,000</td>
<td><code>CREATE</code> 有阶梯，且与 <code>SCHEDULE</code> 有交点</td>
</tr>
<tr>
<td>benchmark-5</td>
<td>1×10K</td>
<td>10,000</td>
<td><code>CREATE</code> 快速完成，<code>SCHEDULE</code> 成为瓶颈</td>
</tr>
</tbody></table>
<h1 id="2️⃣-现象观察：三个层次的卡顿模式"><a href="#2️⃣-现象观察：三个层次的卡顿模式" class="headerlink" title="2️⃣ 现象观察：三个层次的卡顿模式"></a>2️⃣ 现象观察：三个层次的卡顿模式</h1><p>仔细观察后，我们发现卡顿现象随 Job 数量有三个层次：</p>
<h2 id="2-1-不卡顿：Job-数量少，每-Job-内-Pod-数量多"><a href="#2-1-不卡顿：Job-数量少，每-Job-内-Pod-数量多" class="headerlink" title="2.1 不卡顿：Job 数量少，每 Job 内 Pod 数量多"></a>2.1 不卡顿：Job 数量少，每 Job 内 Pod 数量多</h2><p><strong>典型场景</strong>：benchmark-4（20×500）、benchmark-5（1×10K）</p>
<p><strong>现象特征</strong>：</p>
<ul>
<li><code>CREATE</code> 快速完成，<code>SCHEDULE</code> 慢慢完成</li>
<li>两条曲线基本平滑，无明显卡顿</li>
<li><code>CREATE</code> 始终比 <code>SCHEDULE</code> 更快</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/c.NoGang-20Job-no/output/panel-5.png?raw=true" alt="不卡顿现象示例"><figcaption>不卡顿现象示例</figcaption></figure></p>
<h2 id="2-2-卡顿但互不影响：Job-数量较多，每-Job-内-Pod-数量较少"><a href="#2-2-卡顿但互不影响：Job-数量较多，每-Job-内-Pod-数量较少" class="headerlink" title="2.2 卡顿但互不影响：Job 数量较多，每 Job 内 Pod 数量较少"></a>2.2 卡顿但互不影响：Job 数量较多，每 Job 内 Pod 数量较少</h2><p><strong>典型场景</strong>：benchmark-3（200×50）</p>
<p><strong>现象特征</strong>：</p>
<ul>
<li><code>CREATE</code>/<code>SCHEDULE</code> 交替性卡顿</li>
<li><code>CREATE</code> 始终比 <code>SCHEDULE</code> 更快，两条曲线没有交点</li>
<li>卡顿期间，另一条曲线仍在工作</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/e.NoGang-200Job/output/panel-5.png?raw=true" alt="卡顿但互不影响示例"><figcaption>卡顿但互不影响示例</figcaption></figure></p>
<h2 id="2-3-卡顿且相互影响：Job-数量极多，每-Job-内-Pod-数量极少"><a href="#2-3-卡顿且相互影响：Job-数量极多，每-Job-内-Pod-数量极少" class="headerlink" title="2.3 卡顿且相互影响：Job 数量极多，每 Job 内 Pod 数量极少"></a>2.3 卡顿且相互影响：Job 数量极多，每 Job 内 Pod 数量极少</h2><p><strong>典型场景</strong>：benchmark-2（500×20）、benchmark-1（10K×1）</p>
<p><strong>现象特征</strong>：</p>
<ul>
<li><code>CREATE</code>/<code>SCHEDULE</code> 交替性卡顿</li>
<li><code>CREATE</code> 有时会阻塞 <code>SCHEDULE</code>，两条曲线存在交点</li>
<li>整体性能最差</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/b.NoGang-500Job-no/output/panel-5.png?raw=true" alt="卡顿且相互影响示例1"><figcaption>卡顿且相互影响示例1</figcaption></figure></p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/4-disable-webhook/a.NoGang-10KJob/output/panel-5.png?raw=true" alt="卡顿且相互影响示例2"><figcaption>卡顿且相互影响示例2</figcaption></figure></p>
<h2 id="2-4-关键发现：CREATE-和-SCHEDULE-不会同时卡顿"><a href="#2-4-关键发现：CREATE-和-SCHEDULE-不会同时卡顿" class="headerlink" title="2.4 关键发现：CREATE 和 SCHEDULE 不会同时卡顿"></a>2.4 关键发现：CREATE 和 SCHEDULE 不会同时卡顿</h2><p>仔细观察后，我们发现了一个非常有意思且关键的现象：<code>CREATE</code> 和 <code>SCHEDULE</code> <strong>不会同时出现卡顿</strong>（即从图中看不会同时斜率为 0，而斜率代表着每秒完成对应操作的 Pod 数量）。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/5-more-worker-threads/only-volcano/worker_threads_100/3.NoGang-2KJob/output/panel-5.png?raw=true" alt="CREATE 和 SCHEDULE 不会同时卡顿示意图1：完成 CREATE 和 SCHEDULE 的 Pod 总数数量图"><figcaption>CREATE 和 SCHEDULE 不会同时卡顿示意图1：完成 CREATE 和 SCHEDULE 的 Pod 总数数量图</figcaption></figure></p>
<p>对照事件趋势图也会发现，<code>CREATE</code>（图中红色虚线）和<code>SCHEDULE</code>（图中亮绿色实线）的波峰和波谷恰恰好重合。</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/5-more-worker-threads/only-volcano/worker_threads_100/3.NoGang-2KJob/output/panel-11.png?raw=true" alt="CREATE 和 SCHEDULE 不会同时卡顿示意图2：完成 CREATE 和 SCHEDULE 的 Pod 每秒吞吐图"><figcaption>CREATE 和 SCHEDULE 不会同时卡顿示意图2：完成 CREATE 和 SCHEDULE 的 Pod 每秒吞吐图</figcaption></figure></p>
<p>即使是在上述第 3 种层次下，两条曲线的交点也是一交即分。这也就意味着，<code>CREATE</code> 和 <code>SCHEDULE</code> 两种操作始终是在工作的，但是似乎存在一种严重的“争用”，导致某些时候只有一类操作能够顺利进行。</p>
<h2 id="2-5-Api-Server-日志分析"><a href="#2-5-Api-Server-日志分析" class="headerlink" title="2.5 Api-Server 日志分析"></a>2.5 Api-Server 日志分析</h2><p>进一步仔细排查后发现，<code>kube-apiserver</code> 日志中出现大量（超过 3000 次）<code>409 Conflict</code> 错误。<br>典型错误日志如下：<br>    <div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">事件类型: default_vc-controller-manager/v0.0.0 (linux/amd64) kubernetes/$Format_create_pods</span><br><span class="line">发生次数: 1575</span><br><span class="line">事件特征:</span><br><span class="line">    namespace: default</span><br><span class="line">    userAgent: vc-controller-manager/v0.0.0 (linux/amd64) kubernetes/$Format</span><br><span class="line">    verb: create</span><br><span class="line">    resource: pods</span><br><span class="line">    code: 409</span><br><span class="line">    reason: AlreadyExists</span><br><span class="line"></span><br><span class="line">------------------------------</span><br><span class="line"></span><br><span class="line">事件类型: default_vc-controller-manager/v0.0.0 (linux/amd64) kubernetes/$Format_update_jobs/status</span><br><span class="line">发生次数: 705</span><br><span class="line">事件特征:</span><br><span class="line">    namespace: default</span><br><span class="line">    userAgent: vc-controller-manager/v0.0.0 (linux/amd64) kubernetes/$Format</span><br><span class="line">    verb: update</span><br><span class="line">    resource: jobs/status</span><br><span class="line">    code: 409</span><br><span class="line">    reason: Conflict</span><br><span class="line"></span><br><span class="line">------------------------------</span><br><span class="line"></span><br><span class="line">事件类型: default_vc-controller-manager/v0.0.0 (linux/amd64) kubernetes/$Format_create_podgroups</span><br><span class="line">发生次数: 623</span><br><span class="line">事件特征:</span><br><span class="line">    namespace: default</span><br><span class="line">    userAgent: vc-controller-manager/v0.0.0 (linux/amd64) kubernetes/$Format</span><br><span class="line">    verb: create</span><br><span class="line">    resource: podgroups</span><br><span class="line">    code: 409</span><br><span class="line">    reason: AlreadyExists</span><br><span class="line"></span><br><span class="line">------------------------------</span><br><span class="line"></span><br><span class="line">事件类型: default_vc-scheduler/v0.0.0 (linux/amd64) kubernetes/$Format_update_podgroups</span><br><span class="line">发生次数: 477</span><br><span class="line">事件特征:</span><br><span class="line">    namespace: default</span><br><span class="line">    userAgent: vc-scheduler/v0.0.0 (linux/amd64) kubernetes/$Format</span><br><span class="line">    verb: update</span><br><span class="line">    resource: podgroups</span><br><span class="line">    code: 409</span><br><span class="line">    reason: Conflict</span><br><span class="line"></span><br><span class="line">------------------------------</span><br><span class="line"></span><br></pre></td></tr></table></figure></div></p>
<h1 id="3️⃣-原因分析：API-Server-请求排队争用"><a href="#3️⃣-原因分析：API-Server-请求排队争用" class="headerlink" title="3️⃣ 原因分析：API-Server 请求排队争用"></a>3️⃣ 原因分析：API-Server 请求排队争用</h1><h2 id="3-1-初步分析：CREATE-和-SCHEDULE-的独立性"><a href="#3-1-初步分析：CREATE-和-SCHEDULE-的独立性" class="headerlink" title="3.1 初步分析：CREATE 和 SCHEDULE 的独立性"></a>3.1 初步分析：<code>CREATE</code> 和 <code>SCHEDULE</code> 的独立性</h2><p>根据上述关键现象，我们猜测造成“卡顿”的原因很可能是 <code>CREATE</code> 和 <code>SCHEDULE</code> 两种操作之间的“争用”。</p>
<p>然而，经过对 Volcano 源码的仔细分析，我们发现 <code>CREATE</code> 功能属于 Controller 组件，而 <code>SCHEDULE</code> 功能属于 Scheduler 组件，两者在代码层面并没有直接的调用、依赖或其它影响关系。</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller_actions.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *jobcontroller)</span></span> syncJob(jobInfo *apis.JobInfo, updateStatus state.UpdateStatusFn) <span class="type">error</span> {</span><br><span class="line">    <span class="comment">// Controller 负责 Pod 创建</span></span><br><span class="line">    <span class="keyword">for</span> _, pod := <span class="keyword">range</span> podToCreateEachTask {</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(pod *v1.Pod)</span></span> {</span><br><span class="line">            <span class="keyword">defer</span> waitCreationGroup.Done()</span><br><span class="line">            newPod, err := cc.kubeClient.CoreV1().Pods(pod.Namespace).Create(context.TODO(), pod, metav1.CreateOptions{})</span><br><span class="line">            <span class="comment">// ...</span></span><br><span class="line">        }(pod)</span><br><span class="line">    }</span><br><span class="line">    waitCreationGroup.Wait()</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// pkg/scheduler/actions/allocate/allocate.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(alloc *Action)</span></span> Execute(ssn *framework.Session) {</span><br><span class="line">    <span class="comment">// Scheduler 负责 Pod 调度</span></span><br><span class="line">    <span class="keyword">for</span> _, task := <span class="keyword">range</span> tasks {</span><br><span class="line">        <span class="comment">// 调度决策和绑定</span></span><br><span class="line">        ssn.Bind(task, node)</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h2 id="3-2-深入分析：API-Server-层面的争用"><a href="#3-2-深入分析：API-Server-层面的争用" class="headerlink" title="3.2 深入分析：API-Server 层面的争用"></a>3.2 深入分析：API-Server 层面的争用</h2><p>那么争用发生在哪里？进一步分析会发现，这两个组件在完成各自的操作后，都需要将结果（创建 Pod / 更新 Pod 状态）提交到 <strong>K8s API-Server</strong>，并由其完成后续的 etcd 写入等操作。当两者同时操作一个 Pod 对象时，就会触发 K8s 的乐观锁机制。一个组件的写请求会因为 <code>resourceVersion</code> 不匹配而失败，返回 <code>409 Conflict</code> 错误，进而必须重试。大量的并发、冲突与重试，最终在宏观上表现为“一个工作、另一个等待”的交替执行现象。<strong>真正的争用就发生在这里</strong>。</p>
<p>换言之，我们观察到的卡顿，是两大批对 K8s API-Server 的请求（<code>CREATE</code> 请求和 <code>SCHEDULE</code> 更新请求）排队与失败并重试导致的宏观表现。</p>
<h3 id="3-2-1-CREATE-请求流"><a href="#3-2-1-CREATE-请求流" class="headerlink" title="3.2.1 CREATE 请求流"></a>3.2.1 CREATE 请求流</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Controller 创建 Pod 的请求流</span></span><br><span class="line">JobController.syncJob() </span><br><span class="line">  → kubeClient.CoreV1().Pods().Create() </span><br><span class="line">    → kube-apiserver </span><br><span class="line">      → etcd write</span><br></pre></td></tr></table></figure></div>

<h3 id="3-2-2-SCHEDULE-请求流"><a href="#3-2-2-SCHEDULE-请求流" class="headerlink" title="3.2.2 SCHEDULE 请求流"></a>3.2.2 SCHEDULE 请求流</h3><div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Scheduler 调度 Pod 的请求流</span></span><br><span class="line">VolcanoScheduler.allocate() </span><br><span class="line">  → ssn.Bind() </span><br><span class="line">    → kubeClient.CoreV1().Pods().Update() </span><br><span class="line">      → kube-apiserver </span><br><span class="line">        → etcd write</span><br></pre></td></tr></table></figure></div>

<h2 id="3-3-排队与重试机制分析"><a href="#3-3-排队与重试机制分析" class="headerlink" title="3.3 排队与重试机制分析"></a>3.3 排队与重试机制分析</h2><p>那排队与重试为什么会导致如此泾渭分明的“交替卡顿”呢？这就需要结合我们在上一篇博客中分析的<strong>协程阻塞模型</strong>。</p>
<h3 id="3-3-1-Job-数量对请求模式的影响"><a href="#3-3-1-Job-数量对请求模式的影响" class="headerlink" title="3.3.1 Job 数量对请求模式的影响"></a>3.3.1 Job 数量对请求模式的影响</h3><p>仔细分析上述三种层次的现象，其间唯一的区别是 Job 数量。Job 数量多时，会导致：</p>
<ol>
<li><strong>请求碎片化</strong>：当 Job 数量多时，原本一次性的 10000 个 Pod <code>CREATE</code> 请求，被切割成了许多个小批次的请求段；</li>
<li><strong>争用与插队</strong>：在这些 <code>CREATE</code> 请求的小段之间，存在着时间空隙。Scheduler 发送的 <code>SCHEDULE</code>（Pod Update）请求就会“见缝插针”，填满这些空隙。这就导致了 API-Server 的请求队列中，呈现出一段 <code>CREATE</code>、一段 <code>SCHEDULE</code> 交替进行的局面。当 <code>SCHEDULE</code> 请求占据队列时，<code>CREATE</code> 请求就会排队阻塞，反之亦然。</li>
</ol>
<p>因此，在不同 Job 数量下会有不同的请求模式</p>
<p><strong>Job 数量少时</strong>：</p>
<ul>
<li>所有 Pod 的 <code>CREATE</code> 请求（共 10K）可以在很短时间内同时被发送到 API-Server</li>
<li>由于 <code>SCHEDULE</code> 需要的时间比 <code>CREATE</code> 更多，因此后续 <code>SCHEDULE</code> 请求陆陆续续被发送到 API-Server 时 <code>CREATE</code> 已经几乎完成</li>
<li>不会产生二者间的争用</li>
</ul>
<p><strong>Job 数量多时</strong>：</p>
<ul>
<li>Pod 的 <code>CREATE</code> 请求断断续续被发送到 API-Server</li>
<li>此后 <code>SCHEDULE</code> 请求也陆陆续续被发送到 API-Server</li>
<li>由于 Pod 的多批 <code>CREATE</code> 请求间存在时间空隙，导致出现某些时刻 <code>SCHEDULE</code> 占满而使得 <code>CREATE</code> 排队阻塞</li>
</ul>
<h3 id="3-3-2-协程阻塞的放大效应"><a href="#3-3-2-协程阻塞的放大效应" class="headerlink" title="3.3.2 协程阻塞的放大效应"></a>3.3.2 协程阻塞的放大效应</h3><p>简单回顾一下：</p>
<blockquote>
<p>Controller 是以 Job 为粒度进行处理的，一个 worker 协程会等待一个 Job 内的所有 Pod 创建完成后，才会开始处理下一个 Job。</p>
</blockquote>
<p>在此过程中，由于 Controller 每个协程会等待一个 Job 完成后再进行下一个 Job 的处理，因此一旦一个 Job 中某些 Pod 被阻塞，就会产生放大效应导致整个协程阻塞，使得阻塞现象更加严重。</p>
<p>而一系列同属一个 Job 的 Pod 资源变更后将会对同一个 PodGroup 甚至 Job 进行资源更新，导致 <code>409 Conflict</code> 错误也会在一段时间内连续出现，使得表现出“突停”现象。</p>
<div class="code-container" data-rel="Go"><figure class="iseeu highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pkg/controllers/job/job_controller_actions.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *jobcontroller)</span></span> syncJob(jobInfo *apis.JobInfo, updateStatus state.UpdateStatusFn) <span class="type">error</span> {</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    waitCreationGroup := sync.WaitGroup{}</span><br><span class="line">    <span class="comment">// 收集所有需要创建的 Pod</span></span><br><span class="line">    <span class="keyword">for</span> _, ts := <span class="keyword">range</span> job.Spec.Tasks {</span><br><span class="line">        <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="type">int</span>(ts.Replicas); i++ {</span><br><span class="line">            <span class="comment">// ...</span></span><br><span class="line">            waitCreationGroup.Add(<span class="number">1</span>)</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 并发创建 Pod</span></span><br><span class="line">    <span class="keyword">for</span> taskName, podToCreateEachTask := <span class="keyword">range</span> podToCreate {</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(taskName <span class="type">string</span>, podToCreateEachTask []*v1.Pod)</span></span> {</span><br><span class="line">            <span class="keyword">for</span> _, pod := <span class="keyword">range</span> podToCreateEachTask {</span><br><span class="line">                <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(pod *v1.Pod)</span></span> {</span><br><span class="line">                    <span class="keyword">defer</span> waitCreationGroup.Done()</span><br><span class="line">                    <span class="comment">// API-Server 调用</span></span><br><span class="line">                    newPod, err := cc.kubeClient.CoreV1().Pods(pod.Namespace).Create(context.TODO(), pod, metav1.CreateOptions{})</span><br><span class="line">                }(pod)</span><br><span class="line">            }</span><br><span class="line">        }(taskName, podToCreateEachTask)</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ⚠️ 关键阻塞点：等待所有 Pod 创建完成</span></span><br><span class="line">    waitCreationGroup.Wait()</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h2 id="3-4-CREATE-本身成为瓶颈的情况"><a href="#3-4-CREATE-本身成为瓶颈的情况" class="headerlink" title="3.4 CREATE 本身成为瓶颈的情况"></a>3.4 CREATE 本身成为瓶颈的情况</h2><p>此外还有一个因素，随着 Job 数量变多，<code>CREATE</code> 过程中 Controller 用于处理 Job 的计算量越来越大，速度也会变得越来越慢并成为瓶颈，这种情况下则无需争用分析，<code>CREATE</code> 本身就是瓶颈，对应上述benchmark-1（10K×1）。</p>
<h2 id="3-5-小结"><a href="#3-5-小结" class="headerlink" title="3.5 小结"></a>3.5 小结</h2><p>目前根据 “关键发现： <code>CREATE</code> 和 <code>SCHEDULE</code> 不会同时卡顿” 推断 vc-controller-manager 和 vc-scheduler 之间存在某种类型资源的争用，但暂未有更直接的证据，后续还将进一步分析。</p>
<p>但在此之外，有一个更根本的问题值得我们继续思考：“卡顿”问题如果能够被解决（即 <code>CREATE</code> 效率更高、不会“阻塞” <code>SCHEDULE</code>），整体效率就能更高吗？从后续实验会发现，并不一定。</p>
<h1 id="4️⃣-协程数优化实验：反直觉的结果"><a href="#4️⃣-协程数优化实验：反直觉的结果" class="headerlink" title="4️⃣ 协程数优化实验：反直觉的结果"></a>4️⃣ 协程数优化实验：反直觉的结果</h1><p>前期我们猜想协程数<code>--worker-threads</code> 是很重要的参数，并且猜想协程越多越能够并行、效率越高，但实验发现并非如此。</p>
<ol>
<li>“协程数” 与 “<code>CREATE</code> 效率” 非线性相关关系，也就是不是“协程越多越好”。</li>
<li>“<code>CREATE</code> 效率” 与 “整体效率” 非线性相关关系，也就是不是“<code>CERATE</code> 效率越快越好”。</li>
</ol>
<h2 id="4-1-实验设计"><a href="#4-1-实验设计" class="headerlink" title="4.1 实验设计"></a>4.1 实验设计</h2><p><strong>实验环境说明</strong>：</p>
<ul>
<li>协程数分别为：1、5、10、25、50、100、150、200、400、600</li>
<li>Job 和 Pod 组合分别为：10000×1、5000×2、2000×5、1000×10、500×20、200×50、100×100、50×200、20×500、1×10000</li>
<li>统计从测试开始到最后一个 <code>CREATE</code> 和 <code>SCHEDULE</code> 完成时间</li>
<li>计划每种配置下都重复执行 3 次，但由于时间问题目前某些配置还只有 2 或 1 次</li>
</ul>
<h2 id="4-2-实验结果分析"><a href="#4-2-实验结果分析" class="headerlink" title="4.2 实验结果分析"></a>4.2 实验结果分析</h2><p>实验得出了两个关键结论：</p>
<ul>
<li>在相同协程数下，随着 Job 数的增加，<code>CREATE</code> 用时整体提高。</li>
<li>在相同 Job 数下，随着 Controller 协程的增加，<code>CREATE</code> 用时呈现出明显的类似 <strong>“V”字型</strong>：先下降，后提高。</li>
</ul>
<h3 id="4-2-1-相同协程数下，Job-数增加的影响"><a href="#4-2-1-相同协程数下，Job-数增加的影响" class="headerlink" title="4.2.1 相同协程数下，Job 数增加的影响"></a>4.2.1 相同协程数下，Job 数增加的影响</h3><p>在相同协程数下，随着 Job 数的增加，<code>CREATE</code> 用时整体提高。这验证了我们前面的分析：</p>
<ol>
<li>Job 数量越多，Controller 用于处理 Job 的计算量越来越大</li>
<li>Job 数量越多，<code>CREATE</code> 请求被切割得越细，与 <code>SCHEDULE</code> 请求的争用越严重。</li>
</ol>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/5-more-worker-threads/summary/scale_performance_trends.png?raw=true" alt="在相同协程数下，不同 Job 数结果"><figcaption>在相同协程数下，不同 Job 数结果</figcaption></figure></p>
<h3 id="4-2-2-相同-Job-数下，协程数增加的影响"><a href="#4-2-2-相同-Job-数下，协程数增加的影响" class="headerlink" title="4.2.2 相同 Job 数下，协程数增加的影响"></a>4.2.2 相同 Job 数下，协程数增加的影响</h3><p>在相同 Job 数下，随着 Controller 协程的增加，<code>CREATE</code> 用时先下降后提高（类似 V 字型）。</p>
<p><strong>用时“先下降”（V 型左侧）的原因</strong>：</p>
<ul>
<li>协程数过少时，瓶颈在 API-Server 通信和远程 etcd 的 IO</li>
<li>计算资源未被充分利用，少量协程快速完成计算后发送 <code>CREATE</code> 请求、此后协程阻塞</li>
<li>此时协程数增加可以充分利用计算资源，消除等待通信/IO 的气泡时间</li>
</ul>
<p><strong>用时“后提高”（V 型右侧）的原因</strong>：</p>
<ul>
<li>协程数过多时，瓶颈在计算资源本身 + 加剧跨 Job 的 Pod 排队阻塞</li>
<li>大量协程已充分利用所有计算资源，此时跨 Job 的 Pod 排队竞争且公平地依次创建</li>
<li>一个 Job 内最后几个 Pod 阻塞整个 Job，导致突变情况更为严重</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/5-more-worker-threads/summary/worker_threads_trends.png?raw=true" alt="在相同 Job 数下，不同协程数结果"><figcaption>在相同 Job 数下，不同协程数结果</figcaption></figure></p>
<h2 id="4-3-实验结论"><a href="#4-3-实验结论" class="headerlink" title="4.3 实验结论"></a>4.3 实验结论</h2><p>协程数优化存在一个<strong>最优值</strong>，既不能太少（无法充分利用计算资源），也不能太多（加剧 API-Server 争用）。这个最优值需要根据具体的 Job 数量和 Pod 数量来动态调整。</p>
<h1 id="5️⃣-解决思路：从争用角度思考"><a href="#5️⃣-解决思路：从争用角度思考" class="headerlink" title="5️⃣ 解决思路：从争用角度思考"></a>5️⃣ 解决思路：从争用角度思考</h1><h2 id="5-1-问题本质重新认识"><a href="#5-1-问题本质重新认识" class="headerlink" title="5.1 问题本质重新认识"></a>5.1 问题本质重新认识</h2><p>基于以上分析我们会发现，减小卡顿其实并不是”治本”。<br>即使我们通过调优让 <code>CREATE</code> 阶段飞速完成，这些 Pod 依然要等待缓慢的 <code>SCHEDULE</code> 阶段，总时间相差无几，甚至可能因为前期资源占用过猛而变得更长。（例如下图<code>100x100</code>、<code>500x20</code>，调整协程后 <code>CREATE</code> 更快完成，但<code>SCHEDULE</code>完成时间反而更长）</p>
<ul>
<li>从全局最优的角度看，<strong>让 <code>CREATE</code> 和 <code>SCHEDULE</code> 的速率接近，实现一种动态平衡，可能是更好的选择</strong>。</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://github.com/Freshwlnd/image/blob/blog/kube-scheduling-perf-image/5-more-worker-threads/summary/create_vs_schedule_comparison.png?raw=true" alt="在相同 Job 数下，不同协程数结果2"><figcaption>在相同 Job 数下，不同协程数结果2</figcaption></figure></p>
<h2 id="5-2-根本解决方案"><a href="#5-2-根本解决方案" class="headerlink" title="5.2 根本解决方案"></a>5.2 根本解决方案</h2><p>如果想要彻底解决这个问题，可能需要对 Volcano 的整个架构进行比较大的修改，实现 <code>CREATE</code> 和 <code>SCHEDULE</code> 的合理配比、速率接近。可能需要：</p>
<ol>
<li><strong>调整 API-Server 的策略</strong>：实现更智能的请求排队和优先级机制</li>
<li><strong>调整 Controller 和 Scheduler 之间的联动速率调整</strong>：实现动态的速率匹配</li>
<li><strong>引入异步处理机制</strong>：将同步的批处理改为异步处理</li>
</ol>
<h2 id="5-3-短期优化方案"><a href="#5-3-短期优化方案" class="headerlink" title="5.3 短期优化方案"></a>5.3 短期优化方案</h2><p>在有限时间内，可以考虑以下优化方向：（囊括前期总结的几项内容）</p>
<ol>
<li><strong>调整协程数</strong>：根据 Job 数量和 Pod 数量动态调整最优协程数</li>
<li><strong>设置合适的 webhook timeout</strong>：避免超时导致的请求重试和性能下降</li>
<li><strong>优化 webhook 效率</strong>：参考 <a href="/2025/08/24/k8s/k8s-scheduler-performance-volcano-hypothesis-verification/" title="前面的分析">前面的分析</a>，将必要的校验功能转移到 Controller 或 K8s CRD（使用 CEL） 中。</li>
</ol>
<h1 id="6️⃣-小结"><a href="#6️⃣-小结" class="headerlink" title="6️⃣ 小结"></a>6️⃣ 小结</h1><p>截至目前，我们已经分析了几项特定的结论，并提出了一些解决方案（解决方案如上所述）。</p>
<p>【结论】</p>
<ol>
<li>Job数量对性能影响极大，Jobs数量越多性能越差。</li>
<li>Jobs多时，CREATE/SCHEDULE 存在“卡顿”现象。但卡顿只是表象，本质很可能是资源争用导致的轮替；除此之外，不一定要把卡顿消除、而是应该让CREATE和SCHEDULE的卡顿速率保持一致。</li>
<li>除此之外，webhook本身对性能的影响仍然比较大，需要优化。</li>
</ol>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://github.com/volcano-sh/volcano">[1] Volcano GitHub 仓库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/">[2] Volcano 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/">[3] Kubernetes API Server 设计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/architecture/controller/">[4] Kubernetes 控制器模式<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/actions/">[5] Volcano 调度器 Actions<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/kube-scheduler/">[6] Kubernetes 调度器<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/architecture/">[7] Volcano 架构设计<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/">[8] Kubernetes Webhook 机制<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>调度器</tag>
        <tag>性能优化</tag>
        <tag>Volcano</tag>
        <tag>批处理</tag>
        <tag>API-Server</tag>
        <tag>争用分析</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云原生批调度实战：Volcano 安装与初试</title>
    <url>/2025/06/22/k8s/k8s-volcano-install/</url>
    <content><![CDATA[<blockquote>
<p>本系列《云原生批调度实战：Volcano 深度解析》计划分为以下几篇，点击查看其它内容。</p>
<ol>
<li><a href="/2025/05/26/k8s/k8s-volcano-1/" title="云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点">云原生批调度实战：Volcano 深度解析（一）批处理背景需求与Volcano特点</a></li>
<li><a href="/2025/05/27/k8s/k8s-volcano-2/" title="云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态">云原生批调度实战：Volcano 深度解析（二）Volcano调度流程与调度状态</a></li>
<li><a href="/2025/06/22/k8s/k8s-volcano-install/" title="云原生批调度实战：Volcano 安装与初试">云原生批调度实战：Volcano 安装与初试</a></li>
<li><a href="/2025/08/25/k8s/k8s-volcano-core-flow/" title="云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计">云原生批调度实战：Volcano 深度解析（三）核心流程解析与架构设计</a></li>
<li><a href="/2025/08/26/k8s/k8s-volcano-create-analysis/" title="云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析">云原生批调度实战：Volcano 深度解析（四）Webhook 机制深度解析</a></li>
<li><a href="/2025/09/04/k8s/k8s-volcano-create-schedule-contention-analysis/" title="云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验">云原生批调度实战：Volcano 深度解析（五）CREATE/SCHEDULE 阶段“卡顿”现象解析与协程数优化实验</a>
</li>
</ol>
</blockquote>
<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在 Kubernetes 集群中，原生调度器主要针对在线服务设计，采用”先到先得”的调度策略。然而，在实际生产环境中，我们经常需要处理大规模批处理作业，这些作业具有资源需求大、运行时间长、依赖关系复杂等特点。原生调度器在处理这类作业时往往力不从心，无法满足复杂的调度需求。</p>
<p>Volcano 作为 Kubernetes 的批处理调度系统，正是为了解决这些问题而生。它提供了作业管理、队列管理、资源预留等高级特性，特别适合 AI 训练、大数据处理等场景。本文将首先对 Volcano 进行深入调研，了解其设计理念和业界应用情况；然后详细介绍安装部署过程，为后续的调度功能测试和源码研究打下基础。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><h2 id="1-Volcano-的提出背景"><a href="#1-Volcano-的提出背景" class="headerlink" title="1. Volcano 的提出背景"></a>1. Volcano 的提出背景</h2><p>根据 CNCF 官方博客<a href="#refer-anchor-1"><sup>[1]</sup></a>的介绍，Volcano 项目最初由华为云发起，旨在解决 Kubernetes 在批处理作业调度方面的不足。原生 Kubernetes 调度器存在以下局限性：</p>
<ol>
<li><p>资源调度策略：</p>
<ul>
<li>原生调度器采用”先到先得”的调度策略，无法满足批处理作业的复杂需求</li>
<li>不支持作业优先级和公平性调度，可能导致资源分配不均衡</li>
<li>缺乏对批处理作业特性的考虑，如作业依赖关系、资源预留等</li>
</ul>
</li>
<li><p>作业管理能力：</p>
<ul>
<li>不支持作业级别的资源管理，难以实现作业间的资源隔离</li>
<li>缺乏作业依赖关系处理，无法保证作业按正确顺序执行</li>
<li>不支持作业队列管理，难以实现多租户场景下的资源分配</li>
</ul>
</li>
<li><p>资源利用效率：</p>
<ul>
<li>无法进行资源预留和抢占，可能导致关键作业无法及时执行</li>
<li>缺乏对集群整体资源利用率的优化，资源利用率可能较低</li>
<li>不支持跨作业的资源平衡，可能导致资源碎片化</li>
</ul>
</li>
</ol>
<h2 id="2-Volcano-的业界地位"><a href="#2-Volcano-的业界地位" class="headerlink" title="2. Volcano 的业界地位"></a>2. Volcano 的业界地位</h2><p>根据 GitHub 仓库<a href="#refer-anchor-1"><sup>[2]</sup></a>和 CNCF 项目状态<a href="#refer-anchor-1"><sup>[3]</sup></a>：</p>
<ol>
<li><p>项目背景：</p>
<ul>
<li>由华为云开源并贡献给 CNCF</li>
<li>2020 年 4 月成为 CNCF 沙箱项目</li>
<li>2021 年 7 月升级为 CNCF 孵化项目</li>
<li>被阿里云、腾讯云等多家云服务提供商采用</li>
</ul>
</li>
<li><p>应用范围：</p>
<ul>
<li>广泛应用于 AI 训练场景，如 TensorFlow、PyTorch 等框架</li>
<li>被用于大规模数据处理，如 Spark、Flink 等应用</li>
<li>在科学计算领域有重要应用，如基因测序、气象模拟等</li>
</ul>
</li>
<li><p>社区活跃度：</p>
<ul>
<li>GitHub 星数超过 3.5k</li>
<li>有超过 100 位贡献者</li>
<li>每月有稳定的版本更新</li>
<li>有活跃的 Slack 社区和邮件列表</li>
</ul>
</li>
</ol>
<h2 id="3-离线作业的特殊性"><a href="#3-离线作业的特殊性" class="headerlink" title="3. 离线作业的特殊性"></a>3. 离线作业的特殊性</h2><p>根据 Kubernetes 官方文档<a href="#refer-anchor-1"><sup>[4]</sup></a>和 Volcano 技术博客<a href="#refer-anchor-1"><sup>[5]</sup></a>：</p>
<ol>
<li><p>资源需求特征：</p>
<ul>
<li>资源需求量大：单个作业可能需要多个节点的资源</li>
<li>运行时间长：从几分钟到数天不等</li>
<li>对资源利用率要求高：需要最大化资源利用效率</li>
</ul>
</li>
<li><p>调度需求：</p>
<ul>
<li>需要支持作业优先级：确保重要作业优先执行</li>
<li>需要处理作业依赖关系：保证作业按正确顺序执行</li>
<li>需要支持资源预留和抢占：确保关键作业能够及时执行</li>
</ul>
</li>
<li><p>原生调度器的不足：</p>
<ul>
<li>无法处理作业间的依赖关系：可能导致作业执行顺序错误</li>
<li>缺乏对作业优先级的支持：无法保证重要作业优先执行</li>
<li>资源调度策略过于简单：无法满足复杂的调度需求</li>
<li>无法进行跨作业的资源优化：可能导致资源利用率低下</li>
</ul>
</li>
</ol>
<h1 id="🧠思路"><a href="#🧠思路" class="headerlink" title="🧠思路"></a>🧠思路</h1><ol>
<li>调研 Volcano 的基本情况</li>
<li>安装部署 Volcano</li>
<li>配置测试环境</li>
<li>进行功能测试</li>
</ol>
<h1 id="🔨解决"><a href="#🔨解决" class="headerlink" title="🔨解决"></a>🔨解决</h1><h2 id="0-安装-Helm"><a href="#0-安装-Helm" class="headerlink" title="0. 安装 Helm"></a>0. 安装 Helm</h2><h3 id="0-1-Helm-简介"><a href="#0-1-Helm-简介" class="headerlink" title="0.1 Helm 简介"></a>0.1 Helm 简介</h3><p>Helm 是 Kubernetes 的包管理工具，类似于 Linux 的 apt、yum 等包管理器。它可以帮助我们：</p>
<ul>
<li>简化 Kubernetes 应用的部署和管理</li>
<li>实现应用配置的版本控制</li>
<li>方便地分享和复用应用配置</li>
<li>管理应用依赖关系</li>
</ul>
<h3 id="0-2-安装-Helm"><a href="#0-2-安装-Helm" class="headerlink" title="0.2 安装 Helm"></a>0.2 安装 Helm</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下载 Helm 安装脚本</span></span><br><span class="line">curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加执行权限</span></span><br><span class="line"><span class="built_in">chmod</span> 700 get_helm.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行安装脚本</span></span><br><span class="line">./get_helm.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证安装</span></span><br><span class="line">helm version</span><br></pre></td></tr></table></figure></div>

<h3 id="1-3-配置-Helm-仓库"><a href="#1-3-配置-Helm-仓库" class="headerlink" title="1.3 配置 Helm 仓库"></a>1.3 配置 Helm 仓库</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 添加各个仓库</span></span><br><span class="line">helm repo add stable https://charts.helm.sh/stable</span><br><span class="line">helm repo add aliyun https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</span><br><span class="line">helm repo add azure https://mirror.azure.cn/kubernetes/charts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新仓库信息</span></span><br><span class="line">helm repo update</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看已添加的仓库</span></span><br><span class="line">helm repo list</span><br></pre></td></tr></table></figure></div>

<h2 id="1-安装-Volcano"><a href="#1-安装-Volcano" class="headerlink" title="1. 安装 Volcano"></a>1. 安装 Volcano</h2><p>注意：如果要使用 kwok 进行模拟，则需要先安装 Volcano 后再启动 kwok。否则会被 kwok 变为假请求而无法安装。</p>
<h3 id="1-1-使用-Helm-安装"><a href="#1-1-使用-Helm-安装" class="headerlink" title="1.1 使用 Helm 安装"></a>1.1 使用 Helm 安装</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 添加 Helm 仓库</span></span><br><span class="line">helm repo add volcano-sh https://volcano-sh.github.io/helm-charts</span><br><span class="line">helm repo update</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 Volcano</span></span><br><span class="line">helm install volcano volcano-sh/volcano -n volcano-system --create-namespace</span><br></pre></td></tr></table></figure></div>

<h3 id="1-2-通过-YAML-文件安装"><a href="#1-2-通过-YAML-文件安装" class="headerlink" title="1.2 通过 YAML 文件安装"></a>1.2 通过 YAML 文件安装</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">curl -fsSL -o volcano-development.yaml https://raw.githubusercontent.com/volcano-sh/volcano/master/installer/volcano-development.yaml</span><br><span class="line"><span class="comment"># 为避免镜像拉取问题，可使用 DaoCloud 代理，在文件中所有image名前加上 m.daocloud.io/ 即可</span></span><br><span class="line"><span class="comment"># 若有多个文件要修改，则可以使用 `find ./files -type f -exec sed -i 's/image: /image: m.daocloud.io\//g' {} +`</span></span><br><span class="line">sed -i <span class="string">'s/image: /image: m.daocloud.io\//g'</span> volcano-development.yaml</span><br><span class="line">kubectl apply -f volcano-development.yaml</span><br></pre></td></tr></table></figure></div>

<h3 id="1-3-验证安装"><a href="#1-3-验证安装" class="headerlink" title="1.3 验证安装"></a>1.3 验证安装</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查 Pod 状态</span></span><br><span class="line">kubectl get pods -n volcano-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查调度器状态</span></span><br><span class="line">kubectl get pods -n volcano-system -l app=volcano-scheduler</span><br></pre></td></tr></table></figure></div>

<h2 id="2-配置-Volcano"><a href="#2-配置-Volcano" class="headerlink" title="2. 配置 Volcano"></a>2. 配置 Volcano</h2><h3 id="2-1-创建队列"><a href="#2-1-创建队列" class="headerlink" title="2.1 创建队列"></a>2.1 创建队列</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><figcaption><span>queue.yaml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">scheduling.volcano.sh/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Queue</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-queue</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">priority:</span> <span class="number">100</span></span><br><span class="line">  <span class="attr">reclaimable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># weight字段仅用于proportion插件</span></span><br><span class="line">  <span class="attr">weight:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f queue.yaml</span><br><span class="line">kubectl get queue</span><br></pre></td></tr></table></figure></div>

<h3 id="2-2-创建-PodGroup"><a href="#2-2-创建-PodGroup" class="headerlink" title="2.2 创建 PodGroup"></a>2.2 创建 PodGroup</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><figcaption><span>podgroup.yaml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">scheduling.volcano.sh/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PodGroup</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-podgroup</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">minMember:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">queue:</span> <span class="string">test-queue</span></span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f podgroup.yaml</span><br><span class="line">kubectl get podgroup</span><br></pre></td></tr></table></figure></div>

<h2 id="3-测试调度功能"><a href="#3-测试调度功能" class="headerlink" title="3. 测试调度功能"></a>3. 测试调度功能</h2><h3 id="3-1-创建测试作业"><a href="#3-1-创建测试作业" class="headerlink" title="3.1 创建测试作业"></a>3.1 创建测试作业</h3><div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><figcaption><span>vcjob-quickstart.yaml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch.volcano.sh/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">quickstart-job</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">minAvailable:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">schedulerName:</span> <span class="string">volcano</span></span><br><span class="line">  <span class="comment"># 如果省略 'queue' 字段，将使用 'default' 队列。</span></span><br><span class="line">  <span class="attr">queue:</span> <span class="string">test-queue</span></span><br><span class="line">  <span class="attr">policies:</span></span><br><span class="line">    <span class="comment"># 如果Pod失败（例如，由于应用程序错误），则重启整个作业。</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">event:</span> <span class="string">PodFailed</span></span><br><span class="line">      <span class="attr">action:</span> <span class="string">RestartJob</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">completion-task</span></span><br><span class="line">      <span class="attr">policies:</span></span><br><span class="line">      <span class="comment"># 当此特定任务成功完成时，将整个作业标记为"完成"。</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">event:</span> <span class="string">TaskCompleted</span></span><br><span class="line">        <span class="attr">action:</span> <span class="string">CompleteJob</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">command:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">sh</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">'echo "Job is running and will complete!"; sleep 100; echo "Job done!"'</span></span><br><span class="line">              <span class="attr">image:</span> <span class="string">m.daocloud.io/docker.io/library/busybox:latest</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">busybox-container</span></span><br><span class="line">              <span class="attr">resources:</span></span><br><span class="line">                <span class="attr">requests:</span></span><br><span class="line">                  <span class="attr">cpu:</span> <span class="number">1</span></span><br><span class="line">                <span class="attr">limits:</span></span><br><span class="line">                  <span class="attr">cpu:</span> <span class="number">1</span></span><br><span class="line">          <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure></div>

<h3 id="3-2-验证调度结果"><a href="#3-2-验证调度结果" class="headerlink" title="3.2 验证调度结果"></a>3.2 验证调度结果</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看作业状态</span></span><br><span class="line">$ kubectl get vcjob quickstart-job -oyaml</span><br><span class="line"><span class="comment"># 会看到类似以下输出（时间戳和 UID 会不同）</span></span><br><span class="line">……</span><br><span class="line">status:</span><br><span class="line">  conditions:</span><br><span class="line">  - lastTransitionTime: <span class="string">"2025-05-28T08:39:22Z"</span></span><br><span class="line">    status: Pending</span><br><span class="line">  - lastTransitionTime: <span class="string">"2025-05-28T08:39:23Z"</span></span><br><span class="line">    status: Pending</span><br><span class="line">  - lastTransitionTime: <span class="string">"2025-05-28T08:39:27Z"</span></span><br><span class="line">    status: Pending</span><br><span class="line">  - lastTransitionTime: <span class="string">"2025-05-28T08:39:28Z"</span></span><br><span class="line">    status: Pending</span><br><span class="line">  - lastTransitionTime: <span class="string">"2025-05-28T08:39:30Z"</span></span><br><span class="line">    status: Running</span><br><span class="line">  minAvailable: 3</span><br><span class="line">  running: 3</span><br><span class="line">  state:</span><br><span class="line">    lastTransitionTime: <span class="string">"2025-05-28T08:39:30Z"</span></span><br><span class="line">    phase: Running</span><br><span class="line">  taskStatusCount:</span><br><span class="line">    completion-task:</span><br><span class="line">      phase:</span><br><span class="line">        Running: 3</span><br><span class="line">……</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看 Pod 状态</span></span><br><span class="line">$ kubectl get pods -l volcano.sh/job-name=quickstart-job</span><br><span class="line"><span class="comment"># 最初 Pod 将处于 Running 状态。大约100秒后，busybox 容器将退出，Pod 的状态将变为 Completed。</span></span><br><span class="line">NAME                               READY   STATUS      RESTARTS   AGE</span><br><span class="line">quickstart-job-completion-task-0   0/1     Completed   0          3m59s</span><br><span class="line">quickstart-job-completion-task-1   0/1     Completed   0          3m59s</span><br><span class="line">quickstart-job-completion-task-2   0/1     Completed   0          3m59s</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 一旦 Pod 完成，VolcanoJob 中的 TaskCompleted 策略将触发 CompleteJob 操作，这会将 VolcanoJob 的阶段转换为 Completed</span></span><br><span class="line"><span class="comment"># 查看作业状态</span></span><br><span class="line">$ kubectl get vcjob quickstart-job -oyaml</span><br><span class="line"><span class="comment"># 会看到类似以下输出（时间戳和 UID 会不同）</span></span><br><span class="line">……</span><br><span class="line">status:</span><br><span class="line">……</span><br><span class="line">  minAvailable: 3</span><br><span class="line">  runningDuration: 1m49s</span><br><span class="line">  state:</span><br><span class="line">    lastTransitionTime: <span class="string">"2025-05-28T08:41:11Z"</span></span><br><span class="line">    phase: Completed</span><br><span class="line">  version: 3</span><br></pre></td></tr></table></figure></div>

<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.cncf.io/blog/2021/02/26/volcano-collision-between-containers-and-batch-computing/">[1] CNCF 官方博客：Volcano 项目介绍<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://github.com/volcano-sh/volcano">[2] Volcano GitHub 仓库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.cncf.io/projects/volcano/">[3] CNCF 项目状态<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/docs/concepts/workloads/controllers/job/">[4] Kubernetes 批处理作业文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/">[5] Volcano 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://github.com/kubernetes-sigs/kwok/discussions/981">[6] Kwok Discussion<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://blog.csdn.net/gitblog_00033/article/details/139876727">[7] Volcano 开源项目安装与配置指南<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/installation/">[8] Volcano 安装<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://volcano.sh/zh/docs/tutorials/">[9] Volcano 快速开始<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>调度器</tag>
        <tag>Volcano</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】Kubernetes Webhook入门：准入控制机制与性能瓶颈分析</title>
    <url>/2025/07/08/k8s/k8s-webhook/</url>
    <content><![CDATA[<!-- > 本系列《Kubernetes深度解析》计划分为以下几篇，点击查看其它内容。 -->
<!-- > 1. <a href="/2025/07/08/k8s/k8s-webhook/" title="Kubernetes Webhook入门：准入控制机制与性能瓶颈分析">Kubernetes Webhook入门：准入控制机制与性能瓶颈分析</a> -->
<!-- > 2. （待续）Kubernetes调度器性能优化实践 -->
<!-- > 3. （待续）大规模集群资源管理策略 -->
<!-- > 4. （待续）云原生架构设计最佳实践 -->

<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在<a href="/2025/06/26/k8s/k8s-scheduler-performance-video/" title="调度器性能对比分析">调度器性能对比分析</a>中，我们发现Webhook可能在大规模情况下成为Volcano创建Job的限制因素。为了深入理解这一现象，本文将从Webhook的基本概念出发，系统梳理其在Kubernetes生态系统中的作用机制和性能影响。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>在调度器性能测试中，我们发现了一个有趣的现象：Volcano调度器在大量Job创建时会出现阶段性阻塞，其中一个可能的原因是Webhook QPS限制。这引发了我们对Webhook机制的深入思考：</p>
<h3 id="核心问题"><a href="#核心问题" class="headerlink" title="核心问题"></a>核心问题</h3><ol>
<li><strong>大背景</strong>：Webhook的起源是什么？为什么Kubernetes需要这种机制？</li>
<li><strong>小背景</strong>：Webhook在K8s/Volcano中是如何应用的？</li>
<li><strong>出发点</strong>：在K8s中应用Webhook时是否有什么参数存在限制，如跟<code>--kube-api-qps</code>有什么关系？为什么要设计这种限制？</li>
<li><strong>挑战</strong>：什么情况下会成为瓶颈限制性能？</li>
</ol>
<h1 id="🧠问题回答"><a href="#🧠问题回答" class="headerlink" title="🧠问题回答"></a>🧠问题回答</h1><h2 id="问题一：Webhook的起源是什么？"><a href="#问题一：Webhook的起源是什么？" class="headerlink" title="问题一：Webhook的起源是什么？"></a>问题一：Webhook的起源是什么？</h2><h3 id="Webhook概念的起源"><a href="#Webhook概念的起源" class="headerlink" title="Webhook概念的起源"></a>Webhook概念的起源</h3><p><strong>Webhook</strong>一词最早出现在2007年，由Jeff Lindsay提出<a href="#refer-anchor-1"><sup>[1]</sup></a>。它描述了一种”反向API调用”的机制，即服务器在特定事件发生时主动向客户端发送HTTP请求，而不是客户端主动轮询服务器。</p>
<h3 id="什么是Webhook？一个简单的比喻"><a href="#什么是Webhook？一个简单的比喻" class="headerlink" title="什么是Webhook？一个简单的比喻"></a>什么是Webhook？一个简单的比喻</h3><p>想象一下<strong>闹钟</strong>的工作原理<a href="#refer-anchor-7"><sup>[7]</sup></a>：</p>
<blockquote>
<p>你在手机上定了一个明天早上6点的闹钟（注册webhook），当时间来到第二天早上6点时，手机闹钟响起（触发webhook），你就会被叫醒（你的服务器收到通知并执行相应操作）。</p>
</blockquote>
<p><strong>Webhook</strong>就是这样一种”反向通知”机制：</p>
<ul>
<li><strong>传统方式</strong>：你每隔几分钟就问一次”有新消息吗？”（周期性拉取）</li>
<li><strong>Webhook方式</strong>：有新消息时，系统主动告诉你”有新消息了！”（触发式推送）</li>
</ul>
<h3 id="Webhook在不同场景下的应用"><a href="#Webhook在不同场景下的应用" class="headerlink" title="Webhook在不同场景下的应用"></a>Webhook在不同场景下的应用</h3><h4 id="1-传统应用场景（事件驱动）"><a href="#1-传统应用场景（事件驱动）" class="headerlink" title="1. 传统应用场景（事件驱动）"></a>1. 传统应用场景（事件驱动）</h4><ul>
<li><strong>钉钉机器人</strong>：当有重要事件发生时，钉钉主动向你的webhook地址发送消息</li>
<li><strong>支付系统</strong>：支付成功后，支付平台主动通知商家系统</li>
<li><strong>GitHub代码推送</strong>：代码推送后，GitHub主动通知CI/CD系统</li>
</ul>
<h4 id="2-Kubernetes应用场景（请求拦截）"><a href="#2-Kubernetes应用场景（请求拦截）" class="headerlink" title="2. Kubernetes应用场景（请求拦截）"></a>2. Kubernetes应用场景（请求拦截）</h4><ul>
<li><strong>准入控制</strong>：当用户创建Pod时，API服务器主动调用Webhook进行检查</li>
<li><strong>资源验证</strong>：验证Pod是否符合集群的安全策略</li>
<li><strong>资源修改</strong>：给Pod添加默认标签或注解</li>
</ul>
<h3 id="在Kubernetes中的应用"><a href="#在Kubernetes中的应用" class="headerlink" title="在Kubernetes中的应用"></a>在Kubernetes中的应用</h3><p>在Kubernetes中，Webhook被用作<strong>准入控制器（Admission Controller）</strong>的一种实现方式<a href="#refer-anchor-2"><sup>[2]</sup></a>。准入控制器是Kubernetes API服务器的一个插件机制，用于在资源创建、修改或删除之前进行拦截和处理。</p>
<h3 id="为什么需要Webhook？"><a href="#为什么需要Webhook？" class="headerlink" title="为什么需要Webhook？"></a>为什么需要Webhook？</h3><p>想象一下<strong>海关检查</strong>的工作<a href="#refer-anchor-8"><sup>[8]</sup></a>：</p>
<blockquote>
<p>当有货物要进入国家时，海关会检查：</p>
<ul>
<li>这个货物符合进口规定吗？（验证）</li>
<li>需要添加标签或修改包装吗？（修改）</li>
<li>有安全隐患吗？（安全验证）</li>
</ul>
</blockquote>
<p>Kubernetes的Webhook就像这个海关：</p>
<ol>
<li><strong>扩展性需求</strong>：Kubernetes需要支持各种自定义的验证和修改逻辑</li>
<li><strong>动态配置</strong>：Webhook可以在不重启API服务器的情况下动态添加新的验证规则</li>
<li><strong>外部集成</strong>：允许外部系统参与Kubernetes的资源管理决策</li>
<li><strong>安全增强</strong>：提供额外的安全验证层</li>
</ol>
<h3 id="为什么K8s下的Webhook和其他场景的Webhook看起来似乎不一样？"><a href="#为什么K8s下的Webhook和其他场景的Webhook看起来似乎不一样？" class="headerlink" title="为什么K8s下的Webhook和其他场景的Webhook看起来似乎不一样？"></a>为什么K8s下的Webhook和其他场景的Webhook看起来似乎不一样？</h3><p><strong>关键理解</strong>：Webhook的本质都是<strong>HTTP回调机制</strong>，区别在于<strong>触发时机</strong>和<strong>处理方式</strong>：</p>
<table>
<thead>
<tr>
<th>场景</th>
<th>触发时机</th>
<th>处理方式</th>
<th>目的</th>
</tr>
</thead>
<tbody><tr>
<td><strong>传统应用</strong></td>
<td>事件发生时</td>
<td>异步通知</td>
<td>推送信息</td>
</tr>
<tr>
<td><strong>Kubernetes</strong></td>
<td>请求到达时</td>
<td>同步拦截</td>
<td>验证/修改</td>
</tr>
</tbody></table>
<p><strong>相同点</strong>：</p>
<ul>
<li>都是基于HTTP的回调机制（触发式推送而非周期性拉取）</li>
<li>都是服务器主动调用外部服务</li>
<li>都支持自定义处理逻辑</li>
</ul>
<p><strong>不同点</strong>：</p>
<ul>
<li><strong>触发条件</strong>：事件驱动 vs 请求驱动</li>
<li><strong>处理方式</strong>：异步推送 vs 同步拦截</li>
<li><strong>响应要求</strong>：无响应要求 vs 必须返回结果</li>
</ul>
<h2 id="问题二：Webhook在K8s-Volcano中是如何应用的？"><a href="#问题二：Webhook在K8s-Volcano中是如何应用的？" class="headerlink" title="问题二：Webhook在K8s/Volcano中是如何应用的？"></a>问题二：Webhook在K8s/Volcano中是如何应用的？</h2><h3 id="Kubernetes中的Webhook类型"><a href="#Kubernetes中的Webhook类型" class="headerlink" title="Kubernetes中的Webhook类型"></a>Kubernetes中的Webhook类型</h3><h4 id="1-验证性Webhook（Validating-Webhook）"><a href="#1-验证性Webhook（Validating-Webhook）" class="headerlink" title="1. 验证性Webhook（Validating Webhook）"></a>1. 验证性Webhook（Validating Webhook）</h4><ul>
<li><strong>作用</strong>：验证资源是否符合特定规则</li>
<li><strong>时机</strong>：在资源被持久化到etcd之前</li>
<li><strong>结果</strong>：允许或拒绝请求</li>
</ul>
<h4 id="2-修改性Webhook（Mutating-Webhook）"><a href="#2-修改性Webhook（Mutating-Webhook）" class="headerlink" title="2. 修改性Webhook（Mutating Webhook）"></a>2. 修改性Webhook（Mutating Webhook）</h4><ul>
<li><strong>作用</strong>：修改资源内容</li>
<li><strong>时机</strong>：在验证性Webhook之前</li>
<li><strong>结果</strong>：返回修改后的资源</li>
</ul>
<h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">用户创建Pod → API服务器接收请求 → 修改性Webhook → 验证性Webhook → 持久化到etcd</span><br></pre></td></tr></table></figure></div>

<p><strong>具体例子</strong>：</p>
<ol>
<li>用户提交一个Pod创建请求</li>
<li>API服务器收到请求后，先调用修改性Webhook</li>
<li>修改性Webhook可能会给Pod添加默认标签</li>
<li>然后调用验证性Webhook检查Pod是否符合规则</li>
<li>如果验证通过，Pod被保存到etcd；如果失败，请求被拒绝</li>
</ol>
<h2 id="问题三：Webhook的QPS限制机制"><a href="#问题三：Webhook的QPS限制机制" class="headerlink" title="问题三：Webhook的QPS限制机制"></a>问题三：Webhook的QPS限制机制</h2><h3 id="QPS限制参数"><a href="#QPS限制参数" class="headerlink" title="QPS限制参数"></a>QPS限制参数</h3><h4 id="1-kube-api-qps"><a href="#1-kube-api-qps" class="headerlink" title="1. --kube-api-qps"></a>1. <code>--kube-api-qps</code></h4><ul>
<li><strong>含义</strong>：API服务器向Webhook服务发送请求的速率限制</li>
<li><strong>默认值</strong>：通常为50 QPS</li>
<li><strong>作用范围</strong>：所有Webhook请求的总和</li>
</ul>
<h4 id="2-kube-api-burst"><a href="#2-kube-api-burst" class="headerlink" title="2. --kube-api-burst"></a>2. <code>--kube-api-burst</code></h4><ul>
<li><strong>含义</strong>：突发请求的最大数量</li>
<li><strong>默认值</strong>：通常为100</li>
<li><strong>作用</strong>：允许短时间的突发流量</li>
</ul>
<h3 id="与-kube-api-qps的关系"><a href="#与-kube-api-qps的关系" class="headerlink" title="与--kube-api-qps的关系"></a>与<code>--kube-api-qps</code>的关系</h3><p><strong>关系说明</strong>：</p>
<ul>
<li><code>--kube-api-qps</code>控制API服务器向所有外部服务（包括Webhook）发送请求的速率</li>
<li>Webhook请求也受到这个限制的约束</li>
<li>当Webhook服务响应慢时，会占用更多的QPS配额</li>
</ul>
<h3 id="为什么设计这种限制？"><a href="#为什么设计这种限制？" class="headerlink" title="为什么设计这种限制？"></a>为什么设计这种限制？</h3><h4 id="1-保护API服务器"><a href="#1-保护API服务器" class="headerlink" title="1. 保护API服务器"></a>1. 保护API服务器</h4><ul>
<li>防止Webhook服务过载影响API服务器性能</li>
<li>避免资源耗尽导致系统崩溃</li>
</ul>
<h4 id="2-公平性保证"><a href="#2-公平性保证" class="headerlink" title="2. 公平性保证"></a>2. 公平性保证</h4><ul>
<li>确保不同Webhook服务获得公平的处理机会</li>
<li>防止单个Webhook占用过多资源</li>
</ul>
<h2 id="问题四：什么情况下会成为瓶颈？"><a href="#问题四：什么情况下会成为瓶颈？" class="headerlink" title="问题四：什么情况下会成为瓶颈？"></a>问题四：什么情况下会成为瓶颈？</h2><h3 id="瓶颈场景分析"><a href="#瓶颈场景分析" class="headerlink" title="瓶颈场景分析"></a>瓶颈场景分析</h3><h4 id="1-大规模Job创建"><a href="#1-大规模Job创建" class="headerlink" title="1. 大规模Job创建"></a>1. 大规模Job创建</h4><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">场景：同时创建1000个Job，每个Job包含100个Pod</span><br><span class="line">影响：需要调用100,000次Webhook</span><br><span class="line">瓶颈：Webhook QPS限制导致请求排队</span><br></pre></td></tr></table></figure></div>

<h4 id="2-Webhook服务响应慢"><a href="#2-Webhook服务响应慢" class="headerlink" title="2. Webhook服务响应慢"></a>2. Webhook服务响应慢</h4><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">场景：Webhook服务处理单个请求需要100ms</span><br><span class="line">影响：即使QPS限制为50，实际吞吐量可能只有10 QPS</span><br><span class="line">瓶颈：Webhook服务成为性能瓶颈</span><br></pre></td></tr></table></figure></div>

<h4 id="3-复杂的验证逻辑"><a href="#3-复杂的验证逻辑" class="headerlink" title="3. 复杂的验证逻辑"></a>3. 复杂的验证逻辑</h4><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">场景：Webhook需要查询外部数据库进行验证</span><br><span class="line">影响：每次验证都需要网络调用，增加延迟</span><br><span class="line">瓶颈：网络延迟和外部服务响应时间</span><br></pre></td></tr></table></figure></div>

<h3 id="生活中的类比"><a href="#生活中的类比" class="headerlink" title="生活中的类比"></a>生活中的类比</h3><p>想象一下<strong>银行柜台</strong>的场景<a href="#refer-anchor-9"><sup>[9]</sup></a>：</p>
<blockquote>
<p>银行有10个柜台，每个柜台每分钟最多处理2个客户（QPS限制）。</p>
<ul>
<li>正常情况下：客户排队，柜台按顺序处理</li>
<li>高峰期：大量客户同时到达，柜台处理不过来，排队时间变长</li>
<li>柜台效率低：即使有10个柜台，如果每个客户处理时间很长，整体处理能力也会下降</li>
</ul>
</blockquote>
<p>Webhook的瓶颈就像这个银行柜台：</p>
<ul>
<li><strong>QPS限制</strong>：就像柜台数量有限</li>
<li><strong>处理时间</strong>：就像每个客户的处理时间</li>
<li><strong>排队等待</strong>：就像客户在银行排队</li>
</ul>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><p>目前仅有粗浅地了解，接下来会进一步开展后续研究，例如：</p>
<ol>
<li><p><strong>Webhook最佳实践</strong></p>
<ul>
<li>性能优化策略</li>
<li>错误处理机制</li>
<li>监控和告警</li>
</ul>
</li>
<li><p><strong>调度器集成</strong></p>
<ul>
<li>Volcano Webhook实现细节</li>
<li>其他调度器的Webhook使用</li>
<li>性能对比分析</li>
</ul>
</li>
<li><p><strong>大规模集群优化</strong></p>
<ul>
<li>Webhook在高并发场景下的表现</li>
<li>瓶颈识别和解决方案</li>
<li>最佳配置参数</li>
</ul>
</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E9%92%A9%E5%AD%90">[1] Webhook - Wikipedia<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/">[2] Kubernetes 中的准入控制 - 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://github.com/volcano-sh/volcano/tree/master/pkg/webhooks">[3] Volcano Webhook Implementation - GitHub<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/concepts/cluster-administration/admission-webhooks-good-practices/">[4] Admission Webhook 良好实践 - Kubernetes官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/webhook/">[5] Webhook Mode - Kubernetes官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/">[6] Kubernetes API Server 参数 - 官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://juejin.cn/post/7437727364082040871">[7] 什么是Webhook？工作原理？如何实现？缺点？ - 掘金<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://zhuanlan.zhihu.com/p/606844215">[8] 详细介绍一下webhook技术 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://blog.csdn.net/m0_71808387/article/details/140469408">[9] Webhook 是什么？详解其工作原理 - CSDN<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.redhat.com/zh-cn/topics/automation-and-management/shenmeshi-webhook">[10] 什么是 Webhook？ - RedHat<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.cnblogs.com/keep-live/articles/16544143.html">[11] kubernetes的webhook开发 - 博客园<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>Webhook</tag>
        <tag>准入控制</tag>
        <tag>调度器</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】【业界系统】kro简介——初识Kube Resource Orchestrator</title>
    <url>/2025/03/24/k8s/kro/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>对于GSOC中一个与我课题相关的开源项目——KRO，我感到非常好奇。<br>因此本文介绍了KRO（Kube Resource Orchestrator），它旨在简化Kubernetes API和资源管理，通过引入自定义资源 <strong>ResourceGraphDefinition</strong>，将Kubernetes部署及其依赖项封装到单个API中，支持自定义终端用户界面。<br>此外，本文简单探讨了KRO的需求、核心原理、运作方式以及性能评估课题，并分享了我在调研过程中的思路和反思。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><p>最近GSOC<a href="#refer-anchor-1"><sup>[1]</sup></a>开始进入申请阶段了，在浏览相关组织及题目时，发现有个看起来和我的课题调度编排很相关的开源项目——KRO<a href="#refer-anchor-2"><sup>[2]</sup></a>。因此首先特意调研一下该项目具体是用于做什么的、如何使用。<br>其次，具体看了看KRO今年的几个题目<a href="#refer-anchor-3"><sup>[3]</sup></a>，和调度编排本身没什么相关，主要是做一些外围完善工作，例如指标收集、IDE集成、验证和生成测试案例、性能评估。虽然与课题相关性比较小，但可以借此机会更深入地了解kro，尤其是对于性能评估课题，感觉很适合用于深入实践和理解。因此其次是对性能评估问题进行分析，对其中关键名词进行解析。</p>
<h1 id="🧠思路"><a href="#🧠思路" class="headerlink" title="🧠思路"></a>🧠思路</h1><ol>
<li>调研KRO基础信息，了解用于做什么、如何使用、典型场景。</li>
<li>解析KRO性能评估课题。</li>
</ol>
<h1 id="🔨解决"><a href="#🔨解决" class="headerlink" title="🔨解决"></a>🔨解决</h1><h2 id="KRO基础信息"><a href="#KRO基础信息" class="headerlink" title="KRO基础信息"></a>KRO基础信息</h2><p>KRO（Kube Resource Orchestrator，读作 “crow”）<a href="#refer-anchor-4"><sup>[4,5]</sup></a>是一个开源项目，由谷歌云、亚马逊云科技和微软 Azure 联合。该项目试图对 Kubernetes 资源的分组和部署方式进行标准化，旨在简化 Kubernetes API 和资源管理，使平台团队可以更轻松地部署工作负载。<br>整体来说，确实是个很小众的项目，国内相关博客都很难找到。</p>
<h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><p>Kubernetes 没有提供一种可供<strong>平台团队</strong>使用的原生方法，让他们能够<strong>创建自定义资源</strong>组供开发团队使用，许多组织都是使用 Helm 或 Kustomize 等客户端模板工具，或构建自己的自定义 Kubernetes 控制器。事实证明，这些方法往往维护成本高昂，非专业人员难以有效使用。<a href="#refer-anchor-5"><sup>[5]</sup></a></p>
<blockquote>
<p>有了 kro，你就可以将应用程序及其依赖项组合成单个资源，方便终端用户使用。<br>—— Abdelfettah Sghiouar 和 Nic Slattery</p>
</blockquote>
<h3 id="核心原理"><a href="#核心原理" class="headerlink" title="核心原理"></a>核心原理</h3><p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://static001.geekbang.org/wechat/images/85/85afab6f4b7a3232749fae162e999e9b.jpg"
                      alt="图1"
                ><figcaption>图1</figcaption></figure></p>
<p>Kro 的核心创新是引入了 自定义资源 <strong>ResourceGraphDefinition</strong>。Kro 将 Kubernetes 部署及其依赖项都封装到了单个 API 中，支持自定义终端用户界面，仅暴露供非平台工程师使用的参数。这种屏蔽隐藏了 Kubernetes 和云提供商 API 端点的复杂性，那在部署上下文中并没有用处。（好抽象，和CRD有什么区别？）<a href="#refer-anchor-5"><sup>[5]</sup></a></p>
<ul>
<li>具体来说，使用kro，可以轻松地配置新的自定义API，这些API可以创建一组Kubernetes<strong>对象</strong>以及它们之间的<strong>逻辑操作</strong>。<a href="#refer-anchor-4"><sup>[4]</sup></a><ul>
<li>kro利用CEL（通用表达式语言）进行<strong>逻辑操作</strong>，该语言与Kubernetes webhooks使用的相同语言。</li>
<li>使用CEL表达式，可以轻松地将<strong>值</strong>从一个对象<strong>传递</strong>到另一个对象，并将<strong>条件</strong>包含到您的自定义API定义中。</li>
<li>基于CEL表达式，kro自动计算<strong>创建对象的顺序</strong>。</li>
<li>可以为API规范中的字段定义默认值，简化最终用户的流程，然后最终用户可以毫不费力地调用这些自定义API来创建分组资源。<br>（还得是官方文档说得清楚，简单的报道说得过于抽象了）</li>
</ul>
</li>
</ul>
<h3 id="运作方式"><a href="#运作方式" class="headerlink" title="运作方式"></a>运作方式</h3><h4 id="开发者界面"><a href="#开发者界面" class="headerlink" title="开发者界面"></a>开发者界面</h4><p>当最终用户使用自定义API将YAML规范应用于集群时，API会在集群内创建一组资源。</p>
<ul>
<li>这些资源可以包括原生Kubernetes资源和集群中安装的任何自定义资源定义（CRD）。</li>
<li>其中一些资源可能会在集群之外创建额外的资源。<br>如下图所示，开发人员调用自定义API，该API创建了部署、入口、服务帐户、普罗米修斯监视器、IAM角色、IAM策略和亚马逊S3桶等资源。这使得开发人员能够以标准化和简化的方式轻松管理和部署他们的应用程序。<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://kro.run/assets/images/KRO-Dev-Interface-fd5678326238378842cdac2fc5861848.png"
                      alt="图2"
                ><figcaption>图2</figcaption></figure><h4 id="资源图定义"><a href="#资源图定义" class="headerlink" title="资源图定义"></a>资源图定义</h4>当团队在集群中安装Kro时，它会安装一个名为ResourceGraphDefinition（RG）的自定义资源定义（CRD）。平台、安全和合规团队可以通过为ResourceGraphDefinition CRD定义自定义资源来协作创建自定义API。<br>在下图描述的示例中，平台团队创建了一个具有任意名称“应用程序堆栈”的RG，该RG封装了必要的资源，以及任何其他逻辑、抽象和安全最佳实践。当RGD应用于集群时，会创建一个新的ApplicationStack API，并可供开发人员与之交互。开发人员不再需要直接管理底层基础设施的复杂性，因为自定义API处理所需资源的部署和配置。<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://kro.run/assets/images/KRO-Platform-Team-b03b6c07257680295eebfd9f61dc22c5.png"
                      alt="图3"
                ><figcaption>图3</figcaption></figure><h4 id="资源图定义实例"><a href="#资源图定义实例" class="headerlink" title="资源图定义实例"></a>资源图定义实例</h4>开发人员团队可以创建应用程序堆栈的多个实例，每个实例都根据其特定要求量身定制。<br>如下图所示，开发团队A和开发团队B都实例化了自己的应用程序堆栈。</li>
<li>虽然基础资源相似，但开发团队A选择利用Ingress选项将他们的服务暴露在外部，而开发团队B选择将他们的服务保留在集群内部。</li>
<li>这种灵活性允许每个开发团队根据其特定要求自定义其应用程序堆栈。<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://kro.run/assets/images/KRO-Instance-3ca3c95acf4a6b41a3cc2563ac2acbcb.png"
                      alt="图4"
                ><figcaption>图4</figcaption></figure></li>
</ul>
<h2 id="KRO性能评估课题解析"><a href="#KRO性能评估课题解析" class="headerlink" title="KRO性能评估课题解析"></a>KRO性能评估课题解析</h2><p>详情见下回分解～</p>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><p>由于资料较少，调研基础博客后还是没太理解KRO的意义。光看字面意思，感觉CRD完全可以替代，无法理解KRO和CRD之间有什么区别？<br>好在还是让自己不要偷工减料，去看了英文主页原文，发现主页已经讲得很清楚了。KRO比CRD多的是多个组件之间的逻辑串联关系。<br>未来会进一步调研<a href="#refer-anchor-6">[6]</a>，看看具体案例中如何使用KRO；以及结合本次调研结果，进一步分析GSOC中的性能评估课题。</p>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://summerofcode.withgoogle.com/" >[1] Google Summer of Code<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link"   href="https://summerofcode.withgoogle.com/programs/2025/organizations/kro-kube-resource-orchestrator" >[2] 2025 Program - kro | Kube Resource Orchestrator: Simplify Kubernetes API and resource management.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link"   href="https://github.com/kro-run/kro/issues/288" >[3] GSoC 2025 Project Ideas for kro<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link"   href="https://github.com/kro-run/kro" >[4] kro | Kube Resource Orchestrator<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-5"></div>

<p><a class="link"   href="https://www.infoq.cn/article/3e5BZcY6oRKDByH8Z5IB" >[5] 云计算巨头合作开发全新 Kubernetes 资源管理工具<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-6"></div>

<p><a class="link"   href="https://thenewstack.io/kubernetes-gets-a-new-resource-orchestrator-in-the-form-of-kro/" >[6] Kubernetes Gets a New Resource Orchestrator in the Form of Kro<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>业界现状</category>
      </categories>
      <tags>
        <tag>工具整理</tag>
        <tag>视频</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】云计算集群调度数据集整理</title>
    <url>/2025/06/09/k8s/scheduler-datasets/</url>
    <content><![CDATA[<h1 id="🎯简介"><a href="#🎯简介" class="headerlink" title="🎯简介"></a>🎯简介</h1><p>在云计算集群管理领域，高质量的数据集对于算法研究、性能优化和系统设计至关重要。本文整理了三个具有代表性的数据集：阿里巴巴的集群数据集、谷歌的集群数据集，以及字节跳动最新发布的VM碎片重调度数据集。这些数据集各有特色，为不同场景下的集群调度研究提供了宝贵的数据支持。</p>
<h1 id="🌍背景"><a href="#🌍背景" class="headerlink" title="🌍背景"></a>🌍背景</h1><p>随着云计算的快速发展，集群调度系统面临着越来越复杂的挑战：</p>
<ol>
<li>资源利用率优化</li>
<li>碎片处理</li>
<li>性能优化</li>
<li>成本控制</li>
<li>在离线混合部署优化</li>
</ol>
<p>为了应对这些挑战，研究人员需要真实的生产环境数据来验证和优化他们的算法。本文介绍的三个数据集分别来自不同的场景，能够满足不同研究需求。</p>
<h1 id="📊数据集介绍"><a href="#📊数据集介绍" class="headerlink" title="📊数据集介绍"></a>📊数据集介绍</h1><h2 id="1-字节跳动-VM碎片重调度数据集-EuroSys’25"><a href="#1-字节跳动-VM碎片重调度数据集-EuroSys’25" class="headerlink" title="1. 字节跳动 VM碎片重调度数据集 (EuroSys’25)"></a>1. 字节跳动 VM碎片重调度数据集 (EuroSys’25)</h2><h3 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h3><p>这是字节跳动最新发布的数据集，主要用于研究VM碎片重调度优化问题。该数据集支持深度强化学习等现代算法的研究。</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><ul>
<li>VM碎片重调度优化研究</li>
<li>深度强化学习算法验证</li>
</ul>
<h3 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h3><p>数据集包含多个子集（<code>L</code>、<code>M</code>、<code>M_medium</code>、<code>M_small</code>、<code>multi</code>），每个子集都包含训练集、测试集和执行集。数据以JSON格式存储，包含以下主要信息：</p>
<ul>
<li>集群信息（cluster_list）</li>
<li>主机信息（host_info）</li>
<li>VM类型信息（vm_type_info）</li>
<li>VM实例信息（vm_instance）</li>
<li>其他需求（other_requirement）</li>
</ul>
<h3 id="数据案例"><a href="#数据案例" class="headerlink" title="数据案例"></a>数据案例</h3><div class="code-container" data-rel="Json"><figure class="iseeu highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">    <span class="attr">"cluster_list"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">{</span></span><br><span class="line">            <span class="attr">"cluster_name"</span><span class="punctuation">:</span> <span class="string">"b04-dpdk-g1"</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">"host_info"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="punctuation">{</span></span><br><span class="line">                    <span class="attr">"node_id"</span><span class="punctuation">:</span> <span class="string">"host-3ts0t92p7u4e8i4mqozp"</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">"status"</span><span class="punctuation">:</span> <span class="string">"ACTIVE"</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">"node_cpu"</span><span class="punctuation">:</span> <span class="number">88</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">"node_mem_mb"</span><span class="punctuation">:</span> <span class="number">368776.0</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">"numa"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="punctuation">{</span></span><br><span class="line">                            <span class="attr">"node"</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">"total_cpu"</span><span class="punctuation">:</span> <span class="number">44</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">"free_cpu"</span><span class="punctuation">:</span> <span class="number">6.0</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">"memory_huge_total_mb"</span><span class="punctuation">:</span> <span class="number">184388.0</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">"memory_huge_free_mb"</span><span class="punctuation">:</span> <span class="number">28740.0</span></span><br><span class="line">                        <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">                        ...</span><br><span class="line">                    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">"rack_id"</span><span class="punctuation">:</span> <span class="number">14</span></span><br><span class="line">                <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">                ...</span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">"vm_type_info"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="punctuation">{</span></span><br><span class="line">                    <span class="attr">"vm_type"</span><span class="punctuation">:</span> <span class="string">"ecs.g1.2xlarge"</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">"flavor_limit"</span><span class="punctuation">:</span> <span class="number">362</span></span><br><span class="line">                <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">                ...</span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">"vm_instance"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="punctuation">{</span></span><br><span class="line">                    <span class="attr">"instance_id"</span><span class="punctuation">:</span> <span class="string">"i-b5oy384o4ffwak4csmr2"</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">"instance_type"</span><span class="punctuation">:</span> <span class="string">"ecs.g1.2xlarge"</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">"host_id"</span><span class="punctuation">:</span> <span class="string">"host-3ts0t92p7u4e8i4mqozp"</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">"numa"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="punctuation">{</span></span><br><span class="line">                            <span class="attr">"node"</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">"cpu"</span><span class="punctuation">:</span> <span class="number">8</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">"mem_mb"</span><span class="punctuation">:</span> <span class="number">32768.0</span></span><br><span class="line">                        <span class="punctuation">}</span></span><br><span class="line">                    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">"allow_migration"</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">                <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">                ...</span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">"other_requirement"</span><span class="punctuation">:</span> <span class="punctuation">{</span></span><br><span class="line">                <span class="attr">"deployment_set"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="punctuation">{</span></span><br><span class="line">                        <span class="attr">"granularity"</span><span class="punctuation">:</span> <span class="string">"host"</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">"data"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="string">"vm_647"</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">"vm_1011"</span><span class="punctuation">,</span></span><br><span class="line">                            ...</span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">                    ...</span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">}</span></span><br><span class="line">        <span class="punctuation">}</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"vm_type_list"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">{</span></span><br><span class="line">            <span class="attr">"vm_type"</span><span class="punctuation">:</span> <span class="string">"ecs.g1.xlarge"</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">"request_cpu"</span><span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">"request_mem_mb"</span><span class="punctuation">:</span> <span class="number">16384.0</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">"numa"</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">"expected_newly_created_num"</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">"weight"</span><span class="punctuation">:</span> <span class="number">0.0</span></span><br><span class="line">        <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">        ...</span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"general_requirement"</span><span class="punctuation">:</span> <span class="punctuation">{</span></span><br><span class="line">        <span class="attr">"optimization_objective"</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"maximum_migration_each_batch"</span><span class="punctuation">:</span> <span class="number">1000</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"maximum_migration"</span><span class="punctuation">:</span> <span class="number">10000</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"maximum_time"</span><span class="punctuation">:</span> <span class="number">600</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"available_zone"</span><span class="punctuation">:</span> <span class="string">"cn-beijing-a"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"family_type"</span><span class="punctuation">:</span> <span class="string">"ecs.g1"</span></span><br><span class="line">    <span class="punctuation">}</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></table></figure></div>

<h3 id="获取方式"><a href="#获取方式" class="headerlink" title="获取方式"></a>获取方式</h3><ul>
<li>论文链接：<a class="link" href="https://dl.acm.org/doi/10.1145/3689031.3717476">Towards VM Rescheduling Optimization Through Deep Reinforcement Learning<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>数据集：<a class="link" href="https://drive.google.com/drive/folders/1PfRo1cVwuhH30XhsE2Np3xqJn2GpX5qy">Google Drive<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>代码仓库：<a class="link" href="https://github.com/zhykoties/VMR2L_eurosys">GitHub<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<h2 id="2-阿里巴巴集群数据集"><a href="#2-阿里巴巴集群数据集" class="headerlink" title="2. 阿里巴巴集群数据集"></a>2. 阿里巴巴集群数据集</h2><h3 id="数据集概述-1"><a href="#数据集概述-1" class="headerlink" title="数据集概述"></a>数据集概述</h3><p>该数据集记录了约4000台机器在8天内的运行情况，包含6个主要数据表。</p>
<h3 id="适用场景-1"><a href="#适用场景-1" class="headerlink" title="适用场景"></a>适用场景</h3><ul>
<li>传统调度算法研究</li>
<li>资源利用率分析</li>
<li>在线服务和离线作业混合调度</li>
<li>集群性能分析</li>
</ul>
<h3 id="数据表说明"><a href="#数据表说明" class="headerlink" title="数据表说明"></a>数据表说明</h3><ol>
<li><code>machine_meta.csv</code>：机器元信息和事件信息</li>
<li><code>machine_usage.csv</code>：机器资源使用情况</li>
<li><code>container_meta.csv</code>：容器元信息和事件信息</li>
<li><code>container_usage.csv</code>：容器资源使用情况</li>
<li><code>batch_instance.csv</code>：批处理作业实例信息</li>
<li><code>batch_task.csv</code>：批处理作业任务信息</li>
</ol>
<h3 id="数据特点"><a href="#数据特点" class="headerlink" title="数据特点"></a>数据特点</h3><ul>
<li>时间戳以秒为单位</li>
<li>内存和磁盘大小进行了归一化处理（[0, 100]范围）</li>
<li>支持在线服务和离线作业分析</li>
</ul>
<h3 id="数据案例-1"><a href="#数据案例-1" class="headerlink" title="数据案例"></a>数据案例</h3><p>有表格的具体说明位于<a href=".alibaba-dataset/clusterdata/cluster-trace-v2018/schema.txt">schema</a>。展示如下：</p>
<p><strong>常见字段的一些解释。</strong></p>
<ul>
<li><p><code>time_stamp</code>、<code>start_time</code> 和 <code>end_time</code>：表中的这些字段都以 “<code>秒</code>“为单位，数字是实际时间与跟踪采样周期开始时间之差。采样周期的起始时间为 <code>0</code>。</p>
</li>
<li><p>出于保密原因，我们对<code>内存大小</code>和<code>磁盘大小</code>等一些值进行了<strong>归一化处理</strong>，并在 [0, 100] 之间对这些字段进行了重新缩放。不过，也有一些无效值会被设置为-1 或 101。</p>
</li>
</ul>
<h3 id="machine-meta-csv"><a href="#machine-meta-csv" class="headerlink" title="machine_meta.csv"></a><code>machine_meta.csv</code></h3><table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>标签</th>
<th>注释</th>
</tr>
</thead>
<tbody><tr>
<td>machine_id</td>
<td>string</td>
<td></td>
<td>机器唯一标识符 uid</td>
</tr>
<tr>
<td>time_stamp</td>
<td>bigint</td>
<td></td>
<td>时间戳，单位为秒</td>
</tr>
<tr>
<td>failure_domain_1</td>
<td>bigint</td>
<td></td>
<td>容器故障域的第一级</td>
</tr>
<tr>
<td>failure_domain_2</td>
<td>string</td>
<td></td>
<td>容器故障域的第二级</td>
</tr>
<tr>
<td>cpu_num</td>
<td>bigint</td>
<td></td>
<td>机器上的CPU数量</td>
</tr>
<tr>
<td>mem_size</td>
<td>bigint</td>
<td></td>
<td>归一化后的内存大小，范围[0, 100]</td>
</tr>
<tr>
<td>status</td>
<td>string</td>
<td></td>
<td>机器状态</td>
</tr>
</tbody></table>
<ul>
<li>关于failure_domain_1：我们有多级故障域，在这个版本的日志中提供了两个。对于任何需要容错的应用程序，其实例应该分布在多个故障域中。这是一个枚举值。</li>
</ul>
<h3 id="machine-usage-csv"><a href="#machine-usage-csv" class="headerlink" title="machine_usage.csv"></a><code>machine_usage.csv</code></h3><table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>标签</th>
<th>注释</th>
</tr>
</thead>
<tbody><tr>
<td>machine_id</td>
<td>string</td>
<td></td>
<td>机器唯一标识符 uid</td>
</tr>
<tr>
<td>time_stamp</td>
<td>double</td>
<td></td>
<td>时间戳，单位为秒</td>
</tr>
<tr>
<td>cpu_util_percent</td>
<td>bigint</td>
<td></td>
<td>CPU使用率，范围[0, 100]</td>
</tr>
<tr>
<td>mem_util_percent</td>
<td>bigint</td>
<td></td>
<td>内存使用率，范围[0, 100]</td>
</tr>
<tr>
<td>mem_gps</td>
<td>double</td>
<td></td>
<td>归一化后的内存带宽，范围[0, 100]</td>
</tr>
<tr>
<td>mkpi</td>
<td>bigint</td>
<td></td>
<td>每千条指令的缓存未命中数</td>
</tr>
<tr>
<td>net_in</td>
<td>double</td>
<td></td>
<td>归一化后的入站网络流量，范围[0, 100]</td>
</tr>
<tr>
<td>net_out</td>
<td>double</td>
<td></td>
<td>归一化后的出站网络流量，范围[0, 100]</td>
</tr>
<tr>
<td>disk_io_percent</td>
<td>double</td>
<td></td>
<td>磁盘IO使用率，范围[0, 100]，异常值为-1或101</td>
</tr>
</tbody></table>
<h3 id="container-meta-csv"><a href="#container-meta-csv" class="headerlink" title="container_meta.csv"></a><code>container_meta.csv</code></h3><table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>标签</th>
<th>注释</th>
</tr>
</thead>
<tbody><tr>
<td>container_id</td>
<td>string</td>
<td></td>
<td>容器唯一标识符 uid</td>
</tr>
<tr>
<td>machine_id</td>
<td>string</td>
<td></td>
<td>容器所在主机的唯一标识符 uid</td>
</tr>
<tr>
<td>time_stamp</td>
<td>bigint</td>
<td></td>
<td>时间戳，单位为秒</td>
</tr>
<tr>
<td>app_du</td>
<td>string</td>
<td></td>
<td>同一应用组的容器共享相同的app_du值</td>
</tr>
<tr>
<td>status</td>
<td>string</td>
<td></td>
<td>容器状态</td>
</tr>
<tr>
<td>cpu_request</td>
<td>bigint</td>
<td></td>
<td>CPU请求量，100表示1核</td>
</tr>
<tr>
<td>cpu_limit</td>
<td>bigint</td>
<td></td>
<td>CPU限制量，100表示1核</td>
</tr>
<tr>
<td>mem_size</td>
<td>double</td>
<td></td>
<td>归一化后的内存大小，范围[0, 100]</td>
</tr>
</tbody></table>
<ul>
<li>关于 app_du：属于同一部署单元的容器提供一种服务，通常情况下，它们应分布在不同的故障域中</li>
</ul>
<h3 id="container-usage-csv"><a href="#container-usage-csv" class="headerlink" title="container_usage.csv"></a><code>container_usage.csv</code></h3><table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>标签</th>
<th>注释</th>
</tr>
</thead>
<tbody><tr>
<td>container_id</td>
<td>string</td>
<td></td>
<td>容器唯一标识符 uid</td>
</tr>
<tr>
<td>machine_id</td>
<td>string</td>
<td></td>
<td>容器所在主机的唯一标识符 uid</td>
</tr>
<tr>
<td>time_stamp</td>
<td>double</td>
<td></td>
<td>时间戳，单位为秒</td>
</tr>
<tr>
<td>cpu_util_percent</td>
<td>bigint</td>
<td></td>
<td>CPU使用率，范围[0, 100]</td>
</tr>
<tr>
<td>mem_util_percent</td>
<td>bigint</td>
<td></td>
<td>内存使用率，范围[0, 100]</td>
</tr>
<tr>
<td>cpi</td>
<td>double</td>
<td></td>
<td>每条指令的周期数</td>
</tr>
<tr>
<td>mem_gps</td>
<td>double</td>
<td></td>
<td>归一化后的内存带宽，范围[0, 100]</td>
</tr>
<tr>
<td>mpki</td>
<td>bigint</td>
<td></td>
<td>每千条指令的内存访问未命中数</td>
</tr>
<tr>
<td>net_in</td>
<td>double</td>
<td></td>
<td>归一化后的入站网络流量，范围[0, 100]</td>
</tr>
<tr>
<td>net_out</td>
<td>double</td>
<td></td>
<td>归一化后的出站网络流量，范围[0, 100]</td>
</tr>
<tr>
<td>disk_io_percent</td>
<td>double</td>
<td></td>
<td>磁盘IO使用率，范围[0, 100]，异常值为-1或101</td>
</tr>
</tbody></table>
<h3 id="batch-task-csv"><a href="#batch-task-csv" class="headerlink" title="batch_task.csv"></a><code>batch_task.csv</code></h3><table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>标签</th>
<th>注释</th>
</tr>
</thead>
<tbody><tr>
<td>task_name</td>
<td>string</td>
<td></td>
<td>任务名称，在每个作业job内唯一</td>
</tr>
<tr>
<td>instance_num</td>
<td>bigint</td>
<td></td>
<td>实例数量</td>
</tr>
<tr>
<td>job_name</td>
<td>string</td>
<td></td>
<td>作业名称</td>
</tr>
<tr>
<td>task_type</td>
<td>string</td>
<td></td>
<td>任务类型</td>
</tr>
<tr>
<td>status</td>
<td>string</td>
<td></td>
<td>任务状态</td>
</tr>
<tr>
<td>start_time</td>
<td>bigint</td>
<td></td>
<td>任务开始时间</td>
</tr>
<tr>
<td>end_time</td>
<td>bigint</td>
<td></td>
<td>任务结束时间</td>
</tr>
<tr>
<td>plan_cpu</td>
<td>double</td>
<td></td>
<td>任务所需的CPU数量，100表示1核</td>
</tr>
<tr>
<td>plan_mem</td>
<td>double</td>
<td></td>
<td>归一化后的内存大小，范围[0, 100]</td>
</tr>
</tbody></table>
<ul>
<li>Task name 表示 DAG 信息，请参阅批处理工作负载的说明</li>
</ul>
<h3 id="batch-instance-csv"><a href="#batch-instance-csv" class="headerlink" title="batch_instance.csv"></a><code>batch_instance.csv</code></h3><table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>标签</th>
<th>注释</th>
</tr>
</thead>
<tbody><tr>
<td>instance_name</td>
<td>string</td>
<td></td>
<td>实例名称</td>
</tr>
<tr>
<td>task_name</td>
<td>string</td>
<td></td>
<td>实例所属的任务名称</td>
</tr>
<tr>
<td>job_name</td>
<td>string</td>
<td></td>
<td>实例所属的作业名称</td>
</tr>
<tr>
<td>task_type</td>
<td>string</td>
<td></td>
<td>任务类型</td>
</tr>
<tr>
<td>status</td>
<td>string</td>
<td></td>
<td>实例状态</td>
</tr>
<tr>
<td>start_time</td>
<td>bigint</td>
<td></td>
<td>实例开始时间</td>
</tr>
<tr>
<td>end_time</td>
<td>bigint</td>
<td></td>
<td>实例结束时间</td>
</tr>
<tr>
<td>machine_id</td>
<td>string</td>
<td></td>
<td>实例所在机器的唯一标识符</td>
</tr>
<tr>
<td>seq_no</td>
<td>bigint</td>
<td></td>
<td>实例的序列号</td>
</tr>
<tr>
<td>total_seq_no</td>
<td>bigint</td>
<td></td>
<td>实例的总序列号</td>
</tr>
<tr>
<td>cpu_avg</td>
<td>double</td>
<td></td>
<td>实例平均CPU使用率，100表示1核</td>
</tr>
<tr>
<td>cpu_max</td>
<td>double</td>
<td></td>
<td>实例最大CPU使用率，100表示1核</td>
</tr>
<tr>
<td>mem_avg</td>
<td>double</td>
<td></td>
<td>实例平均内存使用率（归一化）</td>
</tr>
<tr>
<td>mem_max</td>
<td>double</td>
<td></td>
<td>实例最大内存使用率（归一化，范围[0, 100]）</td>
</tr>
</tbody></table>
<ul>
<li>Task name 在 job 中是统一的；注意 Task name 表示 DAG 信息，请参阅批处理工作负载的说明</li>
<li>共有 12 种类型，其中只有部分类型有 DAG 信息</li>
</ul>
<h3 id="获取方式-1"><a href="#获取方式-1" class="headerlink" title="获取方式"></a>获取方式</h3><ul>
<li>GitHub仓库：<a class="link" href="https://github.com/alibaba/clusterdata/blob/master/cluster-trace-v2018/trace_2018.md">alibaba/clusterdata<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<h2 id="3-谷歌集群数据集"><a href="#3-谷歌集群数据集" class="headerlink" title="3. 谷歌集群数据集"></a>3. 谷歌集群数据集</h2><h3 id="数据集概述-2"><a href="#数据集概述-2" class="headerlink" title="数据集概述"></a>数据集概述</h3><p>该数据集提供了2019年5月期间8个不同Borg cells的信息，数据量约2.4TiB（压缩后）。</p>
<ul>
<li>数据集包含多个文件<code>clusterdata_2011_1</code>、<code>clusterdata_2019_a</code>、<code>clusterdata_2019_b</code>、……、<code>clusterdata_2019_h</code></li>
<li>每个文件中包含多张表<code>collection_events</code>、<code>instance_events</code>、<code>instance_usage</code>、<code>machine_attributes</code>、<code>machine_events</code>。其中<code>collection</code>和<code>instance</code>的关系，类似于<code>job</code>和<code>task</code>的关系。</li>
</ul>
<h3 id="适用场景-2"><a href="#适用场景-2" class="headerlink" title="适用场景"></a>适用场景</h3><ul>
<li>MapReduce等分布式框架研究</li>
<li>大规模集群调度优化</li>
<li>资源分配策略研究</li>
<li>作业依赖关系分析</li>
</ul>
<h3 id="数据特点-1"><a href="#数据特点-1" class="headerlink" title="数据特点"></a>数据特点</h3><ul>
<li>每5分钟的CPU使用信息直方图</li>
<li>资源分配集（alloc sets）信息</li>
<li>作业级父信息（job-parent information）</li>
<li>支持MapReduce等分布式计算框架分析</li>
<li>侧重于资源请求和使用情况，不包含有关终端用户end users、其数据或存储系统和其他服务的访问模式的信息</li>
</ul>
<h3 id="获取方式-2"><a href="#获取方式-2" class="headerlink" title="获取方式"></a>获取方式</h3><ul>
<li>通过<a class="link" href="https://console.cloud.google.com/bigquery">Google BigQuery<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>访问，获取方式参考<a class="link" href="https://stackoverflow.com/questions/62058162/how-to-load-google-clusterdata-2019-traces-in-bigquery-console">博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>如下：<ol>
<li>点击”<code>+添加数据</code>“ / “<code>+ Add Data</code>“</li>
<li>点击”<code>按名称为项目加星标</code>“/“<code>Star a project by name</code>“</li>
<li>输入名称”<code>google.com:google-cluster-data</code>“</li>
<li>点击”<code>加星标</code>“/“<code>star</code>“</li>
</ol>
</li>
<li>数据集文档：<a class="link" href="https://drive.google.com/file/d/10r6cnJ5cJ89fPWCgj7j4LtLBqYN9RiI9/view">Google cluster-usage traces v3<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>示例分析代码：<a class="link" href="https://www.kaggle.com/datasets/derrickmwiti/google-2019-cluster-sample/code">Kaggle<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="📝参考文献"><a href="#📝参考文献" class="headerlink" title="📝参考文献"></a>📝参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://dl.acm.org/doi/10.1145/3689031.3717476">[1] Xianzhong Ding, Yunkai Zhang, Binbin Chen, Donghao Ying, Tieying Zhang, Jianjun Chen, Lei Zhang, Alberto Cerpa, and Wan Du. 2025. Towards VM Rescheduling Optimization Through Deep Reinforcement Learning. In Proceedings of the Twentieth European Conference on Computer Systems (EuroSys ‘25). Association for Computing Machinery, New York, NY, USA, 686–701.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://drive.google.com/drive/folders/1PfRo1cVwuhH30XhsE2Np3xqJn2GpX5qy">[2] VMR2L Dataset<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://github.com/alibaba/clusterdata/blob/master/cluster-trace-v2018/trace_2018.md">[3] Alibaba Cluster Data<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://console.cloud.google.com/bigquery">[4] Google Cluster Data<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://drive.google.com/file/d/10r6cnJ5cJ89fPWCgj7j4LtLBqYN9RiI9/view">[5] Google Cluster Usage Traces v3<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.kaggle.com/datasets/derrickmwiti/google-2019-cluster-sample/code">[6] Google Cluster Data Analysis Example<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>数据集</tag>
        <tag>集群调度</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】YARN 与 Mesos 调度架构深度解析：两级式与单体式的本质区别</title>
    <url>/2025/06/04/k8s/scheduler-yarn-vs-mesos/</url>
    <content><![CDATA[<h1 id="💡-前言"><a href="#💡-前言" class="headerlink" title="💡 前言"></a>💡 前言</h1><p>在阅读阿里 Fuxi 2.0<a href="#refer-anchor-1"><sup>[1]</sup></a>、字节 Godel<a href="#refer-anchor-1"><sup>[2,3]</sup></a> 等业界先进调度器架构论文时，常会遇到“两级式”调度的概念。初看之下，容易将其理解为“任务调度与资源管理”两级，似乎是将实时问题拆分为<strong>长周期（资源管理）</strong>和<strong>短周期（任务调度）</strong>。但深入分析后会发现，这种理解存在矛盾：如 Fuxi2.0、Godel 等主流调度器只负责资源管理，还需要由计算框架的 Application Master 负责任务调度，按上述理解也应该被视为“两级式”，但实际上它们并未被归类为“两级式”。那么，“两级式”到底指什么？YARN 和 Mesos 的本质区别又在哪里？</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://miro.medium.com/v2/resize:fit:557/0*uolfGPoVJ270Vqcg.png" alt="图1：典型调度架构"><figcaption>图1：典型调度架构</figcaption></figure></p>
<h1 id="核心结论"><a href="#核心结论" class="headerlink" title="核心结论"></a>核心结论</h1><p>经过认真调研后，得出的结论：单体式、两级式及状态共享式，是面向“资源管理”领域的分类，与“任务管理”无关。</p>
<p>具体案例：</p>
<ul>
<li><strong>两级式调度</strong>（以 Mesos 为代表）：所有资源管理与调度由两层调度器完成，第一级进行资源粗分筛选，第二级进行资源细分分配。任务管理则由各自的 ApplicationMaster 或 Executor 负责。</li>
<li><strong>单体式调度</strong>（以 YARN 为代表）：所有资源管理与调度均由 YARN 统一完成。任务管理则由 Application Master 负责，包括任务拆分、请求和执行，不涉及资源调度。</li>
</ul>
<h1 id="详细分析"><a href="#详细分析" class="headerlink" title="详细分析"></a>详细分析</h1><h2 id="“两级式”初印象与常见误区"><a href="#“两级式”初印象与常见误区" class="headerlink" title="“两级式”初印象与常见误区"></a>“两级式”初印象与常见误区</h2><p>对“两级式”的初印象是“任务调度和资源管理”两级，有一种把实时问题拆分成<strong>长周期（资源管理）</strong>和<strong>短周期（任务调度）</strong>两级的错觉。</p>
<h2 id="矛盾所在"><a href="#矛盾所在" class="headerlink" title="矛盾所在"></a>矛盾所在</h2><p>但按照以上这种理解，则有一个矛盾无法解释：被分类为“状态共享式”的Fuxi2.0、Godel等主流调度器，本身只负责“资源管理”，还是需要和计算框架中的“ApplicationMaster（负责任务调度）”进行对接；按上述理解，他们也是“两级式”，但实际上却并没有被分类为“两级式”。</p>
<p>根据下文，看起来阿里巴巴论文 Fuxi 2.0<a href="#refer-anchor-1"><sup>[1]</sup></a> 仍然是一个两级式架构：先调度资源（Fuxi 2.0负责）、再在资源上调度任务（其他计算框架的ApplicationMaster负责）。</p>
<p>原文摘录：状态共享架构具有向后兼容性和用户无感性，可以直接和原 Application Master 对接，后者无需进行修改。且后者负责应用级调度。</p>
<blockquote>
<p>The shared-state architecture is a neat design that also satisfies our two hard constraints given in §1 (backward compatibility and seamless user transparency). First, interactions between application masters, worker agents and schedulers would require little change. An application master still talks to only one scheduler and performs application-level scheduling on a pool of committed resources. …<br>共享状态架构是一种巧妙的设计，它还能满足我们在第 1 节中提出的两个硬约束条件（向后兼容性和用户无感性）。首先，应用程序主程序 application masters、工作代理 worker agents 和调度器 schedulers 之间的交互几乎不需要改变。每个 application master 仍然只与一个 scheduler 对话，并在已承诺的资源池上执行应用级调度。…</p>
</blockquote>
<h2 id="调研解释"><a href="#调研解释" class="headerlink" title="调研解释"></a>调研解释</h2><p>那么两级式架构到底如何理解？</p>
<h3 id="阿里论文原文分析"><a href="#阿里论文原文分析" class="headerlink" title="阿里论文原文分析"></a>阿里论文原文分析</h3><p>进一步对阿里 Fuxi 2.0<a href="#refer-anchor-1"><sup>[1]</sup></a> 论文进行具体阅读，找寻线索。原文摘录：</p>
<blockquote>
<p>Due to the rapid growth in our businesses in recent years, we have faced serious challenges in scaling our scheduler, which is <strong>a centralized architecture similar to YARN [44]</strong>, as there have been substantially more tasks and machines in our clusters. Today, the size of some of our clusters is close to 100k machines and the average task submission rate is about 40k tasks/sec (and considerably higher in some months). This scale simply exceeds a single scheduler’s capacity and an upgrade to a distributed scheduler architecture is inevitable.<br>由于近年来我们的业务快速增长，我们在扩展我们的调度程序（<strong>与 YARN [44] 类似的集中式架构</strong>）时面临严峻挑战，因为我们集群中的任务和机器数量大幅增加。如今，我们一些集群的规模已接近 10 万台机器，平均任务提交率约为每秒 4 万个任务（某些月份甚至更高）。这种规模已经超出了单个调度程序的能力，升级到分布式调度程序架构势在必行。</p>
</blockquote>
<blockquote>
<p>Our previous cluster scheduler follows a typical master-worker architecture [44]. A single master manages all the resources in a cluster and handles all the scheduling work. Each worker machine has an agent process, which sends the latest status of the worker via heart-beat messages to the master. The master receives jobs submitted by users and then places each job in its corresponding quota group [26]（脚注2）. The cluster operator configures a quota group to specify the minimum and maximum amounts of resources the group can acquire. In particular, when the cluster is overloaded, resources have to be divided among all the groups by weighted fairness (based on their quotas).<br>我们之前的集群调度器遵循典型的主从架构[44]。单个主节点管理集群中的所有资源并处理所有调度工作。每个工作节点都有一个代理进程，通过心跳消息将工作节点的最新状态发送给主节点。主节点接收用户提交的任务，然后将每个任务放置在其对应的配额组[26]（脚注2）中。集群管理员配置配额组以指定该组可以获取的最小和最大资源量。特别是，当集群过载时，必须通过加权公平（基于其配额）将资源在所有组之间分配。<br>脚注2：Jobs belong to projects and projects are assigned resource quotas according to their budgets. A quota group can be considered as a virtual cluster.<br>脚注2：作业属于项目，项目根据其预算分配资源配额。配额组可以被视为一个虚拟集群。</p>
</blockquote>
<blockquote>
<p>In recent years, the scale of our cluster has significantly increased and a single cluster can have 100k machines. Statically partitioning a large cluster is not an option because there are some extremely large jobs from critical projects and a large cluster is required to ensure that these large jobs and a large number of daily production jobs can be both processed without extended delay. There are also important technical reasons (e.g., resource fragmentation [45], limited visibility [39]) and business factors (e.g., projects need to access the data of other projects in the same business unit that stores its data in a single cluster for operational and management reasons), which require scheduling over an entire large cluster rather than breaking it down into smaller ones.<br>近年来，我们的集群规模显著扩大，单个集群可拥有 10 万台机器。对大型集群进行静态分区是不可取的，因为有一些来自关键项目的超大型作业，需要一个大型集群来确保这些大型作业和大量日常生产作业都能得到处理，而不会出现长时间的延迟。还有一些重要的技术原因（如资源分散[45]、可视性有限[39]）和业务因素（如项目需要访问同一业务部门中其他项目的数据，而该业务部门出于运营和管理原因将其数据存储在单个集群中），都要求在整个大型集群上进行调度，而不是将其分解成更小的集群。</p>
</blockquote>
<blockquote>
<p>However, the previous monolithic single-master architecture could not handle the scale of the current clusters in Alibaba. First, the 10x larger number of machines requires a larger time gap between two consecutive heart-beat messages from a worker to the master so that the master, which is on the critical path of all decisions, would not be overloaded. But a larger gap is more likely to leave idle machines unused for a longer period of time during the gap. Second, the significantly larger number of tasks simply exceeds the capability of a single scheduler. Specifically, our previous scheduler could only handle task submission rates in the range of a few thousand tasks per second, but the average task submission rate is 40K/sec (and the peak is 61K/sec) for the 30 days in Figure 1a.<br>然而，以前的单机单主架构无法应对阿里巴巴目前的集群规模。首先，由于机器数量增加了 10 倍，因此需要在工人向主控端连续发送两条心跳消息之间留出更大的时间间隔，这样处于所有决策关键路径上的主控端才不会超负荷。但更大的时间间隔更有可能使闲置机器在间隔期间有更长的闲置时间。其次，大量的任务根本无法满足单个调度程序的需求。具体来说，我们之前的调度程序只能处理每秒几千个任务的提交率，但图 1a 中 30 天的平均任务提交率为 40K/秒（峰值为 61K/秒）。</p>
</blockquote>
<blockquote>
<p>Omega [39] proposed the shared-state scheduler architecture as described in §1. This architecture addresses the limitations in monolithic, two-level, and static partitioning approaches, respectively. First, each scheduler in the shared-state architecture can run a different scheduling strategy programmed in separate code bases for different types of jobs, as to avoid the software engineering difficulties of maintaining all strategies in one code base and using multi-threading for solving head-of-line blocking in monolithic architecture. Second, each scheduler has a global view of the cluster, thus solving the problem of limited visibility in <strong>two-level schedulers such as Mesos [25].</strong> This allows global policies (e.g., fairness and priority) to be implemented. Third, each scheduler can assign tasks to any machine in the cluster instead of a fixed subset of partitions, which reduces resource fragmentation in statically partitioned clusters and achieves higher utilization [45].<br>Omega [39]提出了第 1 节所述的共享状态调度器架构。该架构分别解决了单片、双层和静态分区方法的局限性。首先，共享状态架构中的每个调度器可针对不同类型的作业运行不同的调度策略，这些策略在不同的代码库中编程，从而避免了在单片架构中将所有策略维护在一个代码库中以及使用多线程解决行头阻塞的软件工程难题。其次，每个调度器都有集群的全局视图，从而解决了 <strong>Mesos [25] 等两级调度器</strong>的有限可见性问题。这使得全局策略（如公平性和优先级）得以实施。第三，每个调度器可以将任务分配给集群中的任何一台机器，而不是固定的分区子集，这就减少了静态分区集群中的资源碎片化，实现了更高的利用率[45]。</p>
</blockquote>
<p>上述内容中，可以得到两个结论：</p>
<ol>
<li>提到的单体式代表为 YARN（这与 Google 的 Omega 调度器论文中一致。而在字节 Godel 调度器论文中将 YARN 视为两级式，个人认为这是有误的）。</li>
<li>提到的两级式调度器代表为 Mesos。</li>
</ol>
<h3 id="代表性架构细化调研"><a href="#代表性架构细化调研" class="headerlink" title="代表性架构细化调研"></a>代表性架构细化调研</h3><p>对于上述两个结论，进一步通过调研相关资料，分析 Mesos （两级式代表）和 YARN （单体式代表，但也有论文将其视为两级式）的具体调度流程：</p>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://img.draven.co/mesos-architecture-diagram-2021-03-20-16162121718200.png" alt="图2：Mesos架构图"><figcaption>图2：Mesos架构图</figcaption></figure></p>
<h4 id="Mesos介绍"><a href="#Mesos介绍" class="headerlink" title="Mesos介绍"></a>Mesos介绍</h4><ul>
<li><strong>总体出发点</strong>：根据相关博客<a href="#refer-anchor-1"><sup>[4]</sup></a>，Mesos想取代的是静态分区集群。其“两级式”是仅在资源层面调度的“两级”（Mesos Master + Framework Scheduler，后者由各框架额外实现），任务层面调度（如任务分解、多任务间数据传输等）还是依靠各框架原本的任务调度器（Application Master 及 Executor）。</li>
<li><strong>整体流程</strong>：具体来说，如上图2所示，Mesos Master（第一级调度）会筛选出一部分资源给 Framework Scheduler 框架调度器（HadoopScheduler、MPIScheduler，第二级调度器），框架的调度器进行从中选择具体资源调度。</li>
<li><strong>具体流程</strong>：根据具体解析文章<a href="#refer-anchor-1"><sup>[5,6,7]</sup></a>第二、四篇文章，更具体的流程如下图3。<ol>
<li>各 Node（Mesos Slave） 上报，有一块“空闲资源”；同时 Application Framework 有一堆作业排队等待（来自各框架 Application Master）。</li>
<li>Mesos Master 第一级调度：根据自定义目标（论文中实现了两种默认插件，一个使用max-min fairness公平性为目标，一个使用预设的绝对优先级strict priorities为目标）筛选作业（此外需要补充一点，和目前主流K8s调度架构不太一样，这一级是资源找作业、而非作业找资源），按优先级向筛选出的 Framework 发起邀约。</li>
<li>Framework Scheduler 第二级调度：根据邀约信息，决定是否接收资源邀约、以及要将哪个作业调度到哪个服务器上。</li>
</ol>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://atts.w3cschool.cn/attachments/image/cimg/2015-07-31_55bb145cb9d3b.jpg" alt="图3：Mesos案例流程图"><figcaption>图3：Mesos案例流程图</figcaption></figure></p>
<h4 id="YARN介绍"><a href="#YARN介绍" class="headerlink" title="YARN介绍"></a>YARN介绍</h4><p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://www.qubole.com/wp-content/uploads/2018/04/image4.png" alt="图4：HADOOP演进图"><figcaption>图4：HADOOP演进图</figcaption></figure></p>
<ul>
<li><strong>背景</strong>：根据相关博客<a href="#refer-anchor-1"><sup>[8,9]</sup></a>，如上图4所示，YARN (Yet Another Resource Negotiator) 是 Hadoop1.0 到 2.0 升级后的产物，是 Hadoop1.0 中的<strong>资源管理模块被独立出来</strong>的结果。在 Hadoop2.0 中除了 YARN 还有专门的 Application Master。</li>
<li><strong>总体出发点</strong>：如背景所述，将资源调度和任务调度拆分为两个模块 YARN 和 Application Master。Application Master 只是 YARN 的一个 Application，可以理解为一个业务进程（参考知乎回答<a href="#refer-anchor-1"><sup>[10]</sup></a>的评论区），不参与调度、只参与任务发起和执行。</li>
<li><strong>具体流程</strong>：只有 Yarn Resource Manager 一个组件在调度，Application Master 不参与调度、只参与拆分需求和执行任务，更具体的流程如下图5。<ol>
<li>Application Client 发起请求（多阶段工作流）；同时 Node Manager 持续通过心跳状态进行上报。</li>
<li>YARN Resource Manager 收到请求后直接调度，在第一个调度决策位置创建容器，并启动 Application Master。</li>
<li>Application Master 在容器中拆分作业为任务请求，变成新的请求发起方（如第1步），发起请求。</li>
<li>YARN Resource Manager 收到请求后继续调度，将调度决策告知 Application Master，Application Master 在对应位置运行后续任务。</li>
</ol>
</li>
</ul>
<p><figure class="image-caption"><img lazyload="" src="/images/loading.svg" data-src="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif" alt="图5：YARN架构及流图"><figcaption>图5：YARN架构及流图</figcaption></figure></p>
<h1 id="总结与趣闻"><a href="#总结与趣闻" class="headerlink" title="总结与趣闻"></a>总结与趣闻</h1><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>两级式中，两层调度器都是进行资源管理，第一层粗分、第二层细分。<br>如果把任务管理也算进来，其实可以视为三级式。</p>
<p>具体来说：</p>
<ol>
<li>Mesos 是两级式架构。所有资源管理与调度由两层调度器完成。第一级是粗筛，将一批符合要求的资源提供给各框架做选择；第二级是具体调度，决定要用哪些资源执行作业。后续还会有任务管理器（Application Master 或 Executor）负责拆分任务、执行任务。</li>
<li>YARN 是单体式架构。所有资源管理与调度均由 YARN 统一完成。任务管理则由 Application Master 负责，包括任务拆分、请求和执行（类似 Mesos 中的 Executor），这部分不涉及资源调度。</li>
</ol>
<p>另一个角度<a href="#refer-anchor-1"><sup>[8]</sup></a>：Mesos 和 Yarn 资源分配粒度不同。</p>
<ol>
<li>Mesos Master 只负责为计算框架粗粒度筛选一批资源，具体的细粒度资源分配计算框架侧（Framework Scheduler）实现。这两者共同组成了“两级式”调度。</li>
<li>Yarn 则直接全权负责细粒度资源分配。</li>
</ol>
<h2 id="趣闻1"><a href="#趣闻1" class="headerlink" title="趣闻1"></a>趣闻1</h2><p>补充一点有意思的故事1<a href="#refer-anchor-1"><sup>[11]</sup></a>：</p>
<ol>
<li>Borg(google) 很早就在谷歌内部使用，但在 2015 年才公布。其中混部和超卖的思想到十几年后的现在才被业界系统开始探索。</li>
<li>Mesos(Twitter) 2012 年发布，当年红极一时，后来被 K8s 替代。</li>
<li>YARN(Apache) 2013 年发布。</li>
</ol>
<h2 id="趣闻2"><a href="#趣闻2" class="headerlink" title="趣闻2"></a>趣闻2</h2><p>补充另一个有意思的故事2<a href="#refer-anchor-1"><sup>[10,12]</sup></a>：Spark 早期是为了推广 Mesos 而产生的，这也是它名字的由来，不过后来反而是 Spark 火起来了……</p>
<ol>
<li>2009 年，Apache Spark（以下简称 Spark）诞生于加州大学伯克利分校（University of California, Berkeley）AMP 实验室，2013 年被捐献给 Apache 基金会。</li>
<li>实际上，Spark 的创始团队本来是为了开发集群管理框架 Apache Mesos（以下简称Mesos）。Mesos 开发完成后，需要一个基于 Mesos 的产品运行在上面以验证 Mesos 的各种功能，于是他们接着开发了 Spark。Spark有火花、鼓舞之意，创始团队希望用 Spark 来证明在 Mesos 上从零开始创造一个项目非常简单。</li>
<li>如今，Spark 已经成为大数据分析领域绝对的王者，而 Mesos 反而没有那么有名，真可谓无心插柳柳成荫。</li>
</ol>
<h2 id="趣闻3"><a href="#趣闻3" class="headerlink" title="趣闻3"></a>趣闻3</h2><p>关于 YARN 起名的一些引申<a href="#refer-anchor-1"><sup>[10]</sup></a>：</p>
<ol>
<li>YARN 的全称是 “Yet Another Resource Negotiator”，意思是“另一种资源调度器”，这种命名和“有间客栈”这种可谓是异曲同工之妙。</li>
<li>以前 Java 有一个项目编译工具，叫做 Ant，他的命名也是类似的，叫做 “Another Neat Tool”的缩写，翻译过来是”另一种整理工具“。</li>
</ol>
<h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>通过对 YARN 与 Mesos 两种主流调度架构的深入剖析，可以看出，两级式与单体式的本质区别在于资源调度权力的分层与集中。理解这些架构的设计思想与演进脉络，有助于我们更好地把握大规模集群调度系统的未来发展方向。</p>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.usenix.org/conference/atc21/presentation/feng-yihui">[1] Feng, Yihui, et al. “Scaling large production clusters with partitioned synchronization.” 2021 USENIX Annual Technical Conference (USENIX ATC 21). 2021.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://github.com/kubewharf/godel-scheduler">[2] Github - Gödel Unified Scheduling System<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://dl.acm.org/doi/10.1145/3620678.3624663">[3] Wu Xiang, Yakun Li, Yuquan Ren, Fan Jiang, Chaohui Xin, Varun Gupta, Chao Xiang, Xinyi Song, Meng Liu, Bing Li, Kaiyang Shao, Chen Xu, Wei Shao, Yuqi Fu, Wilson Wang, Cong Xu, Wei Xu, Caixue Lin, Rui Shi, and Yuming Liang. 2023. Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance. In Proceedings of the 2023 ACM Symposium on Cloud Computing (SoCC ‘23). Association for Computing Machinery, New York, NY, USA, 308–323.<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://draveness.me/papers-mesos/">[4] 集群管理系统 Mesos 的设计原理 · NSDI ‘11<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://m.w3cschool.cn/uisnsi/e4t3pozt.html">[5] 深入浅出Mesos（二）：Mesos的体系结构和工作流<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://m.w3cschool.cn/uisnsi/yo2jgozt.html">[6] 深入浅出Mesos（四）：Mesos的资源分配<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.cnblogs.com/sdifens/p/11350859.html">[7] 博客园 - mesos（分布式资源管理器）<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.jianshu.com/p/a4ba843b09cc">[8] 简书 - Yarn与Mesos<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://www.cnblogs.com/liuwd/p/10856829.html">[9] 博客园 - Yarn和mesos区别<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://zhuanlan.zhihu.com/p/54192454">[10] 知乎 - 深入浅出 Hadoop YARN<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://blog.csdn.net/Kaiyang_Shao/article/details/89926352">[11] CSDN - Borg/Mesos/Yarn三大主流资源管理与调度系统对比<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" href="https://cloud.tencent.com/developer/article/1559995">[12] 腾讯云 - Hadoop Spark Kylin…你知道大数据框架名字背后的故事吗？<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>调度器</tag>
        <tag>YARN</tag>
        <tag>Mesos</tag>
      </tags>
  </entry>
  <entry>
    <title>【C++】结构化绑定（Structured Binding）详解</title>
    <url>/2025/03/31/program_language/cpp/cpp-structured-binding/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>在C++中，结构化绑定（Structured Binding）是一种简洁优雅的语法糖，允许开发者直接解构复杂类型的返回值，例如<code>std::pair</code>或<code>std::tuple</code>，从而使代码更易读、更易维护。本文将详细介绍这种语法的专业名词、引入版本、拓展用法以及类似的语法糖。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><p>在使用C++时，常常需要处理返回值为<code>std::pair</code>或<code>std::tuple</code>的函数。传统方法需要显式声明类型并通过<code>std::get</code>访问元素，这种方式既冗长又不直观。例如：</p>
<div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line">std::pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt; result = <span class="built_in">func</span>();</span><br><span class="line"><span class="type">int</span> x = result.first;</span><br><span class="line"><span class="type">int</span> y = result.second;</span><br></pre></td></tr></table></figure></div>

<p>C++17引入了结构化绑定语法，使得我们可以直接使用<code>[x, y] = func()</code>来解构返回值，极大地提升了代码的可读性和简洁性。</p>
<h1 id="🧠思路"><a href="#🧠思路" class="headerlink" title="🧠思路"></a>🧠思路</h1><ol>
<li>了解结构化绑定的专业名词及其引入版本。</li>
<li>探讨结构化绑定的常见用法及拓展场景。</li>
<li>介绍其他类似的语法糖，帮助开发者编写更优雅的代码。</li>
</ol>
<h1 id="🔨解决"><a href="#🔨解决" class="headerlink" title="🔨解决"></a>🔨解决</h1><h2 id="什么是结构化绑定？"><a href="#什么是结构化绑定？" class="headerlink" title="什么是结构化绑定？"></a>什么是结构化绑定？</h2><p>结构化绑定（Structured Binding）是C++17引入的一种语法糖，是指在一次声明中同时引入多个变量，同时绑定初始化表达式的各个子对象的语法形式。<a href="#refer-anchor-4"><sup>[4]</sup></a></p>
<p>结构化绑定声明使用auto来声明多个变量，所有变量都必须用中括号括起来。</p>
<p>允许开发者将复杂类型（如<code>std::pair</code>、<code>std::tuple</code>或用户自定义结构体）的成员解构为多个变量。其语法形式允许开发者直接将返回值的成员绑定到局部变量中，而无需显式声明类型或调用特定方法。</p>
<p>其语法形式如下：</p>
<div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line">cv-<span class="keyword">auto</span>+引用 [变量<span class="number">1</span>, 变量<span class="number">2</span>, ... 变量n ] = 初始化表达式;</span><br><span class="line">cv-<span class="keyword">auto</span>+引用 [变量<span class="number">1</span>, 变量<span class="number">2</span>, ... 变量n ] (初始化表达式);</span><br><span class="line">cv-<span class="keyword">auto</span>+引用 [变量<span class="number">1</span>, 变量<span class="number">2</span>, ... 变量n ] &#123;初始化表达式&#125;;</span><br><span class="line"><span class="comment">// 这里 cv-auto+引用 包含 auto, auto const, auto &amp;, auto&amp;&amp; 等等形式</span></span><br></pre></td></tr></table></figure></div>

<p>在这里，<code>[x, y]</code>会自动绑定到<code>func()</code>返回的<code>std::pair</code>的两个成员。</p>
<hr>
<h2 id="结构化绑定的引入版本"><a href="#结构化绑定的引入版本" class="headerlink" title="结构化绑定的引入版本"></a>结构化绑定的引入版本</h2><p>结构化绑定是从 <strong>C++17</strong> 开始引入的。要使用这一特性，请确保你的编译器支持C++17或更高版本，并在编译时添加<code>-std=c++17</code>选项。例如：</p>
<div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line">g++ -std=c+<span class="number">+17</span> -o main main.cpp</span><br></pre></td></tr></table></figure></div>

<hr>
<h2 id="常见用法"><a href="#常见用法" class="headerlink" title="常见用法"></a>常见用法</h2><h3 id="1-解构std-pair或std-tuple"><a href="#1-解构std-pair或std-tuple" class="headerlink" title="1. 解构std::pair或std::tuple"></a>1. 解构<code>std::pair</code>或<code>std::tuple</code></h3><p>结构化绑定可以直接解构<code>std::pair</code>或<code>std::tuple</code>，避免显式调用方法访问其成员。</p>
<div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;tuple&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">std::pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt; <span class="title">func</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="number">1</span>, <span class="number">2</span>&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> [x, y] = <span class="built_in">func</span>();</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;x: &quot;</span> &lt;&lt; x &lt;&lt; <span class="string">&quot;, y: &quot;</span> &lt;&lt; y &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    std::tuple&lt;<span class="type">int</span>, <span class="type">double</span>, std::string&gt; t = &#123;<span class="number">42</span>, <span class="number">3.14</span>, <span class="string">&quot;Hello&quot;</span>&#125;;</span><br><span class="line">    <span class="keyword">auto</span> [a, b, c] = t;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;a: &quot;</span> &lt;&lt; a &lt;&lt; <span class="string">&quot;, b: &quot;</span> &lt;&lt; b &lt;&lt; <span class="string">&quot;, c: &quot;</span> &lt;&lt; c &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="2-解构用户自定义结构体"><a href="#2-解构用户自定义结构体" class="headerlink" title="2. 解构用户自定义结构体"></a>2. 解构用户自定义结构体</h3><p>如果结构体的成员是<code>public</code>，可以直接使用结构化绑定来解构。</p>
<div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Point</span> &#123;</span><br><span class="line">    <span class="type">int</span> x;</span><br><span class="line">    <span class="type">int</span> y;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Point p = &#123;<span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">auto</span> [x, y] = p;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;x: &quot;</span> &lt;&lt; x &lt;&lt; <span class="string">&quot;, y: &quot;</span> &lt;&lt; y &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="3-遍历std-map或std-unordered-map"><a href="#3-遍历std-map或std-unordered-map" class="headerlink" title="3. 遍历std::map或std::unordered_map"></a>3. 遍历<code>std::map</code>或<code>std::unordered_map</code></h3><p>结构化绑定可以简化对键值对容器的遍历，使代码更加简洁。</p>
<div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;map&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::map&lt;std::string, <span class="type">int</span>&gt; m = &#123;&#123;<span class="string">&quot;Alice&quot;</span>, <span class="number">25</span>&#125;, &#123;<span class="string">&quot;Bob&quot;</span>, <span class="number">30</span>&#125;&#125;;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [key, value] : m) &#123;</span><br><span class="line">        std::cout &lt;&lt; key &lt;&lt; <span class="string">&quot;: &quot;</span> &lt;&lt; value &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<hr>
<h2 id="拓展用法"><a href="#拓展用法" class="headerlink" title="拓展用法"></a>拓展用法</h2><h3 id="1-与范围for循环结合"><a href="#1-与范围for循环结合" class="headerlink" title="1. 与范围for循环结合"></a>1. 与范围<code>for</code>循环结合</h3><p>结构化绑定可以与范围<code>for</code>循环结合，简化对容器中复杂类型的遍历。</p>
<div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::vector&lt;std::pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt;&gt; v = &#123;&#123;<span class="number">1</span>, <span class="number">2</span>&#125;, &#123;<span class="number">3</span>, <span class="number">4</span>&#125;, &#123;<span class="number">5</span>, <span class="number">6</span>&#125;&#125;;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [x, y] : v) &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;x: &quot;</span> &lt;&lt; x &lt;&lt; <span class="string">&quot;, y: &quot;</span> &lt;&lt; y &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="2-解构数组"><a href="#2-解构数组" class="headerlink" title="2. 解构数组"></a>2. 解构数组</h3><p>结构化绑定也支持解构数组，允许开发者直接将数组的元素绑定到多个变量。</p>
<div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> arr[<span class="number">3</span>] = &#123;<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>&#125;;</span><br><span class="line">    <span class="keyword">auto</span> [a, b, c] = arr;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;a: &quot;</span> &lt;&lt; a &lt;&lt; <span class="string">&quot;, b: &quot;</span> &lt;&lt; b &lt;&lt; <span class="string">&quot;, c: &quot;</span> &lt;&lt; c &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<hr>
<h2 id="类似的语法糖"><a href="#类似的语法糖" class="headerlink" title="类似的语法糖"></a>类似的语法糖</h2><h3 id="1-auto关键字"><a href="#1-auto关键字" class="headerlink" title="1. auto关键字"></a>1. <code>auto</code>关键字</h3><p><code>auto</code>是C++11引入的语法糖，用于自动推导变量类型。例如：</p>
<div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> x = <span class="number">42</span>; <span class="comment">// 自动推导为 int</span></span><br></pre></td></tr></table></figure></div>

<h3 id="2-范围for循环"><a href="#2-范围for循环" class="headerlink" title="2. 范围for循环"></a>2. 范围<code>for</code>循环</h3><p>C++11引入了范围<code>for</code>循环，用于简化容器的遍历：</p>
<div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; v = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> x : v) &#123;</span><br><span class="line">        std::cout &lt;&lt; x &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="3-初始化列表"><a href="#3-初始化列表" class="headerlink" title="3. 初始化列表"></a>3. 初始化列表</h3><p>C++11引入了初始化列表语法，简化了容器的初始化：</p>
<div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; v = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;; <span class="comment">// 使用初始化列表</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<hr>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><p>结构化绑定是C++17引入的一项重要特性，它极大地简化了对复杂类型的解构操作，使代码更加简洁和易读。在实际开发中，合理使用结构化绑定和其他语法糖（如<code>auto</code>、范围<code>for</code>循环）可以显著提升代码的可维护性和开发效率。</p>
<p>未来有空时，还会继续整理其它有意思的语法糖<a href="#refer-anchor-5"><sup>[5]</sup></a>的用法。</p>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://en.cppreference.com/w/cpp/language/structured_binding" >[1] C++17 Structured Bindings<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>  </p>
<div id="refer-anchor-2"></div>

<p><a class="link"   href="https://en.cppreference.com/w/cpp/17" >[2] C++17 Features<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>  </p>
<div id="refer-anchor-3"></div>

<p><a class="link"   href="https://www.packtpub.com/product/modern-c-programming-cookbook-second-edition/9781839211966" >[3] Modern C++ Programming Cookbook<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link"   href="https://blog.csdn.net/zwvista/article/details/78111346" >[4] C++17尝鲜：结构化绑定声明（Structured Binding Declaration）<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link"   href="https://www.luogu.com.cn/article/l86yn4aw" >[5] 从 C++98 到 C++20，寻觅甜甜的语法糖们<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>编程语言</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>结构化绑定</tag>
        <tag>语法糖</tag>
      </tags>
  </entry>
  <entry>
    <title>Lua 数据类型</title>
    <url>/2018/11/02/program_language/Lua/Lua-DataType/</url>
    <content><![CDATA[<h1 id="Lua-数据类型"><a href="#Lua-数据类型" class="headerlink" title="Lua 数据类型"></a>Lua 数据类型</h1><table>
<thead>
<tr>
<th align="left">数据类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">nil</td>
<td>这个最简单，只有值nil属于该类，表示一个无效值（在条件表达式中相当于false）。</td>
</tr>
<tr>
<td align="left">boolean</td>
<td>包含两个值：false和true。</td>
</tr>
<tr>
<td align="left">number</td>
<td>表示双精度类型的实浮点数</td>
</tr>
<tr>
<td align="left">string</td>
<td>字符串由一对双引号或单引号来表示</td>
</tr>
<tr>
<td align="left">function</td>
<td>由 C 或 Lua 编写的函数</td>
</tr>
<tr>
<td align="left">userdata&nbsp;&nbsp;&nbsp;</td>
<td>表示任意存储在变量中的C数据结构</td>
</tr>
<tr>
<td align="left">thread</td>
<td>表示执行的独立线路，用于执行协同程序</td>
</tr>
<tr>
<td align="left">table</td>
<td>Lua 中的表（table）其实是一个”关联数组”（associative arrays），数组的索引可以是数字或者是字符串。在 Lua 里，table 的创建是通过”构造表达式”来完成，最简单构造表达式是{}，用来创建一个空表。</td>
</tr>
</tbody></table>
<hr>
<h2 id="nil"><a href="#nil" class="headerlink" title="nil"></a>nil</h2><ul>
<li>nil 类型表示一种没有任何有效值，它只有一个值 – nil</li>
<li>对于全局变量和 table，nil 还有一个”删除”作用，给全局变量或者 table 表里的变量赋一个 nil 值，等同于把它们删掉.</li>
</ul>
<hr>
<h2 id="boolean"><a href="#boolean" class="headerlink" title="boolean"></a>boolean</h2><ul>
<li>boolean 类型只有两个可选值：true（真） 和 false（假）</li>
<li>Lua 把 false 和 nil 看作是”假”，其他的都为”真”:</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">if false or nil then</span><br><span class="line">    print(&quot;至少有一个是 true&quot;)</span><br><span class="line">else</span><br><span class="line">    print(&quot;false 和 nil 都为 false!&quot;)</span><br><span class="line">end</span><br></pre></td></tr></table></figure></div>

<p> *<em>以上代码执行结果如下</em></p>
 <div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">false 和 nil 都为 false!</span><br><span class="line">[Finished in 0.0s]</span><br></pre></td></tr></table></figure></div>

<hr>
<h2 id="number"><a href="#number" class="headerlink" title="number"></a>number</h2><ul>
<li>Lua 默认只有一种 number 类型 – double（双精度）类型（默认类型可以修改 luaconf.h 里的定义）</li>
</ul>
<hr>
<h2 id="string"><a href="#string" class="headerlink" title="string"></a>string</h2><ul>
<li>字符串由一对双引号或单引号来表示。</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">string1 = &quot;this is string1&quot;</span><br><span class="line">string2 = &#x27;this is string2&#x27;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>也可以用 2 个方括号 “[[]]” 来表示”一块”字符串。</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">html = [[</span><br><span class="line">There are many words</span><br><span class="line">]]</span><br></pre></td></tr></table></figure></div>

<ul>
<li>在对一个数字字符串上进行算术操作时，Lua 会尝试将这个数字字符串转成一个数字，如：</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; print(&quot;2&quot; + 6)</span><br><span class="line">8.0</span><br><span class="line">&gt; print(&quot;2&quot; + &quot;6&quot;)</span><br><span class="line">8.0</span><br><span class="line">&gt; print(&quot;2 + 6&quot;)</span><br><span class="line">2 + 6</span><br><span class="line">&gt; print(&quot;-2e2&quot; * &quot;6&quot;)</span><br><span class="line">-1200.0</span><br></pre></td></tr></table></figure></div>

<ul>
<li>字符串连接使用的是 .. ，如：</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; print(&quot;a&quot; .. &#x27;b&#x27;)</span><br><span class="line">ab</span><br><span class="line">&gt; print(157 .. 428)</span><br><span class="line">157428</span><br></pre></td></tr></table></figure></div>

<ul>
<li>使用 # 来计算字符串的长度，放在字符串前面，如：</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; len = &quot;https://freshwlnd.github.io/&quot;</span><br><span class="line">&gt; print(#len)</span><br><span class="line">28</span><br></pre></td></tr></table></figure></div>

<hr>
<h2 id="table"><a href="#table" class="headerlink" title="table"></a>table</h2><ul>
<li>在 Lua 里，table 的创建是通过”构造表达式”来完成，最简单构造表达式是{}，用来创建一个空表。也可以在表里添加一些数据，直接初始化表:</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- 创建一个空的 table</span><br><span class="line">table1 = &#123;&#125;</span><br><span class="line">table2 = &#123;&#x27;a&#x27;&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>Lua 中的表（table）其实是一个”关联数组”（associative arrays），数组的索引可以是数字或者是字符串:</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- table.lua</span><br><span class="line"></span><br><span class="line">-- 1</span><br><span class="line">table1 = &#123;1,3,4,5,6&#125;</span><br><span class="line">print(table1[3])</span><br><span class="line">print()</span><br><span class="line"></span><br><span class="line">-- 2</span><br><span class="line">table2 = &#123;&#125;</span><br><span class="line">table2[&#x27;a&#x27;] = &#x27;b&#x27;</span><br><span class="line">table2[1] = 2</span><br><span class="line">for k,v in pairs(table2) do</span><br><span class="line">	print(k..&#x27; : &#x27;..v)</span><br><span class="line">end</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<ul>
<li>脚本执行结果为：</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">4</span><br><span class="line"></span><br><span class="line">1 : 2</span><br><span class="line">a : b</span><br><span class="line">[Finished in 0.0s]</span><br></pre></td></tr></table></figure></div>

<ul>
<li>不同于其他语言的数组把 0 作为数组的初始索引，在 Lua 里表的默认初始索引一般以 1 开始:</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- table.lua</span><br><span class="line"></span><br><span class="line">table = &#123;1,2,3,4,5&#125;</span><br><span class="line">for k,v in pairs(table) do</span><br><span class="line">	print(k..&#x27; : &#x27;..v)</span><br><span class="line">end</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<ul>
<li>脚本执行结果为：</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">1 : 1</span><br><span class="line">2 : 2</span><br><span class="line">3 : 3</span><br><span class="line">4 : 4</span><br><span class="line">5 : 5</span><br><span class="line">[Finished in 0.0s]</span><br></pre></td></tr></table></figure></div>

<ul>
<li>table 不会固定长度大小，有新数据添加时 table 长度会自动增长，没初始的 table 都是 nil:</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- table.lua</span><br><span class="line"></span><br><span class="line">table = &#123;&#125;</span><br><span class="line">table[1] = &#x27;a&#x27;</span><br><span class="line">table[2] = &#x27;b&#x27;</span><br><span class="line">for i=1,3 do</span><br><span class="line">	print(table[i])</span><br><span class="line">end</span><br></pre></td></tr></table></figure></div>

<ul>
<li>脚本执行结果为：</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">a</span><br><span class="line">b</span><br><span class="line">nil</span><br><span class="line">[Finished in 0.0s]</span><br></pre></td></tr></table></figure></div>

<hr>
<h2 id="function"><a href="#function" class="headerlink" title="function"></a>function</h2><ul>
<li>在 Lua 中，函数是被看作是”第一类值（First-Class Value）”，函数可以存在变量里:</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- function.lua</span><br><span class="line">function factorial1(n)</span><br><span class="line">    if n == 0 then</span><br><span class="line">        return 1</span><br><span class="line">    else</span><br><span class="line">        return n * factorial1(n - 1)</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">print(factorial1(5))</span><br><span class="line">factorial2 = factorial1</span><br><span class="line">print(factorial2(5))</span><br></pre></td></tr></table></figure></div>

<ul>
<li>脚本执行结果为：</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">120</span><br><span class="line">120</span><br><span class="line">[Finished in 0.0s]</span><br></pre></td></tr></table></figure></div>

<ul>
<li>function 可以以匿名函数（anonymous function）的方式通过参数传递:</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- function2.lua</span><br><span class="line">function testFun(tab,fun)</span><br><span class="line">    for k ,v in pairs(tab) do</span><br><span class="line">        print(fun(k,v));</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tab=&#123;key1=&quot;val1&quot;,key2=&quot;val2&quot;&#125;;</span><br><span class="line">testFun(tab,</span><br><span class="line">function(key,val)--匿名函数</span><br><span class="line">    return key..&quot;=&quot;..val;</span><br><span class="line">end</span><br><span class="line">);</span><br></pre></td></tr></table></figure></div>

<ul>
<li>脚本执行结果为：</li>
</ul>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">key1=val1</span><br><span class="line">key2=val2</span><br><span class="line">[Finished in 0.0s]</span><br></pre></td></tr></table></figure></div>


<hr>
<h2 id="userdata（自定义类型）"><a href="#userdata（自定义类型）" class="headerlink" title="userdata（自定义类型）"></a>userdata（自定义类型）</h2><ul>
<li>userdata 是一种用户自定义数据，用于表示一种由应用程序或 C/C++ 语言库所创建的类型，可以将任意 C/C++ 的任意数据类型的数据（通常是 struct 和 指针）存储到 Lua 变量中调用。</li>
</ul>
<hr>
<blockquote>
<p>在最后，必须感谢<a href="www.runoob.com">菜鸟教程</a>的教程</p>
</blockquote>
]]></content>
      <categories>
        <category>技术</category>
        <category>编程语言</category>
        <category>Lua</category>
      </categories>
      <tags>
        <tag>Lua</tag>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title>【集群】K3s简介，与K8s的区别</title>
    <url>/2025/03/25/k8s/k8s-vs-k3s/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><p>本文将介绍K3s和K8s的基本概念，并详细探讨它们之间的区别。K3s是K8s的精简版，专为边缘计算和资源受限的环境设计。通过本文，你将了解K3s的特点、优势以及它与K8s的主要区别。</p>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><p>最近在了解一些云边协同系统，回忆起曾经调研时得知边缘端广泛采用的管理平台是K3s，也大致知道K3s是K8s的精简版，但一直不知道具体有什么区别。因此现在整理一下K3s的简介、K3s和K8s的区别。</p>
<h1 id="🧠思路"><a href="#🧠思路" class="headerlink" title="🧠思路"></a>🧠思路</h1><ol>
<li>介绍K3s和K8s的基本概念。</li>
<li>探讨K3s的特点和优势。</li>
<li>比较K3s和K8s的主要区别。</li>
<li>总结K3s在边缘计算中的应用场景。</li>
</ol>
<h1 id="🔨解决"><a href="#🔨解决" class="headerlink" title="🔨解决"></a>🔨解决</h1><h2 id="K3s简介"><a href="#K3s简介" class="headerlink" title="K3s简介"></a>K3s简介</h2><p>K3s是由Rancher Labs开发的轻量级Kubernetes(K8s)发行版，专为资源受限的环境和边缘计算设计，针对边缘计算、物联网等场景进行了高度优化。<br>K3s 经过专门设计，即使在最小的硬件环境中也能良好运行。<a href="#refer-anchor-4"><sup>[4]</sup></a></p>
<ul>
<li>K3s 提供了一个小于 60MB 的单个二进制文件。这个轻量级可执行文件包含了启动完全功能的 Kubernetes 集群所需的一切。</li>
<li>通过放弃非必要的 Kubernetes 功能（如云服务提供商集成和非 CSI 3 存储提供商），实现了这个小巧的二进制文件大小。</li>
<li>利用 Go 语言的 goroutines 6，将各个 Kubernetes 组件从单个入口点运行起来。</li>
</ul>
<h3 id="为什么叫-K3s"><a href="#为什么叫-K3s" class="headerlink" title="为什么叫 K3s?"></a>为什么叫 K3s?</h3><p>希望安装的 Kubernetes 在内存占用方面只是一半的大小。Kubernetes 是一个 10 个字母的单词，简写为 K8s。所以，有 Kubernetes 一半大的东西就是一个 5 个字母的单词，简写为 K3s。K3s 没有全称，也没有官方的发音。<a href="#refer-anchor-3"><sup>[3]</sup></a></p>
<h3 id="K3s的特点"><a href="#K3s的特点" class="headerlink" title="K3s的特点"></a>K3s的特点</h3><p>简单来说，K3s的特点体现在：</p>
<ul>
<li><strong>轻量级</strong>：K3s移除了许多不常用的Kubernetes组件，如内置的云提供商支持和存储驱动程序，减少了资源占用。</li>
<li><strong>易于安装</strong>：K3s提供了一键安装脚本，使其在各种环境中快速部署。</li>
<li><strong>内置SQLite</strong>：K3s默认使用SQLite作为数据存储，进一步减少了资源需求。</li>
</ul>
<p>具体来说，K3s有以下增强功能：</p>
<h4 id="控制"><a href="#控制" class="headerlink" title="控制"></a>控制</h4><ul>
<li><strong>最大程度减轻了外部依赖性：</strong>K3s 仅需要操作系统的内核 kernel 和 cgroup 挂载。这意味着你不需要安装很多额外的软件，K3s 就能正常工作。<ul>
<li>K3s 软件包需要的依赖项都被打包在 K3s 中，减少了对外部组件的依赖。包括：<ul>
<li>containerd</li>
<li>Flannel</li>
<li>CoreDNS</li>
<li>CNI</li>
<li>主机实用程序（iptables、socat 等）</li>
<li>Ingress controller（Traefik）</li>
<li>嵌入式服务负载均衡器（service load balancer）</li>
<li>嵌入式网络策略控制器（network policy controller）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h4><ul>
<li><strong>轻量级存储后端：</strong>K3s 默认使用基于 SQLite3 的轻量级存储后端作为默认存储机制，进一步减少了资源需求。同时支持使用 etcd3、MySQL 和 PostgreSQL 作为存储机制。</li>
</ul>
<h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><ul>
<li><strong>打包为单个二进制文件：</strong>K3s 将所有 Kubernetes control-plane 组件操作封装在一个单独的二进制文件和进程中，使其更易于分发和管理。</li>
<li><strong>封装在简单的启动程序中：</strong>通过该启动程序处理很多复杂的 TLS 和选项，使得 K3s 的安装和配置更加简便。</li>
<li><strong>所有组件都封装在单个二进制文件和进程中：</strong>这使得 K3s 具有自动化和管理包括证书分发在内的复杂集群操作的能力。</li>
</ul>
<h4 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h4><ul>
<li><strong>默认情况下是安全的：</strong>对轻量级环境有合理的默认值，确保在资源受限的环境中也能安全运行。</li>
</ul>
<h4 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h4><ul>
<li><strong>添加了简单但功能强大的batteries-included功能：</strong> K3s 自带了一些常用的功能和工具，就像买一个玩具时，电池已经包含在内，不需要额外购买，这些功能让 K3s 更加易用和强大。例如：<ul>
<li>本地存储提供程序</li>
<li>服务负载均衡器</li>
<li>Helm controller：Helm 是 Kubernetes 的包管理工具，类似于 Linux 系统中的 apt 或 yum。Helm controller 是一个自动化工具，可以帮助你在 Kubernetes 集群中安装和管理 Helm 包。它自动化了 Helm 包的安装和管理，允许用户定义、安装和升级复杂的 Kubernetes 应用。Helm controller 使得在 K3s 中使用 Helm 更加方便和高效。</li>
<li>Traefik Ingress controller：Traefik 是一个现代的反向代理和负载均衡器。Ingress controller 是 Kubernetes 中的一个组件，用于管理外部访问到集群内服务的流量。Ingress controller 负责处理 HTTP 和 HTTPS 请求，并将它们路由到集群内的相应服务。Traefik Ingress controller 就是使用 Traefik 来管理这些流量。Traefik 提供了强大的功能和灵活性，使得流量管理更加高效和可靠。</li>
</ul>
</li>
</ul>
<h2 id="K8s简介"><a href="#K8s简介" class="headerlink" title="K8s简介"></a>K8s简介</h2><p>K8s（Kubernetes）是一个开源的容器编排平台，用于自动化容器化应用的部署、扩展和管理。K8s由Google开发，并由CNCF（云原生计算基金会）维护。K8s提供了强大的功能和灵活性，适用于各种规模的生产环境。K8s帮助塑造了现代编排的定义。该系统包括了部署和运行容器化系统所需的一切。<br>Kubernetes 提供了部署容器并在多个主机上进行扩展的所有所需工具。Kubernetes 集群中的每台主机被称为一个节点，节点由 Kubernetes 控制平面管理。它会将你的容器调度到空闲节点上，管理网络和存储并提供与之交互的 API。</p>
<h3 id="K8s的特点"><a href="#K8s的特点" class="headerlink" title="K8s的特点"></a>K8s的特点</h3><ul>
<li><strong>强大的功能</strong>：K8s提供了丰富的功能，如自动扩展、负载均衡、滚动更新和回滚等。</li>
<li><strong>广泛的生态系统</strong>：K8s拥有庞大的社区和生态系统，提供了大量的插件和工具。</li>
<li><strong>高可用性</strong>：K8s支持多主节点和多工作节点的集群架构，提供高可用性和容错能力。</li>
</ul>
<h2 id="K3s和K8s的主要区别"><a href="#K3s和K8s的主要区别" class="headerlink" title="K3s和K8s的主要区别"></a>K3s和K8s的主要区别</h2><p>简单来说，二者区别如下：</p>
<ol>
<li><strong>安装和配置</strong>：K3s提供了一键安装脚本，简化了安装和配置过程。K8s的安装和配置相对复杂，需要更多的步骤和配置。</li>
<li><strong>资源占用</strong>：K3s移除了许多不常用的组件，减少了内存和CPU的使用，使其能够在资源受限的环境中运行。K8s则提供了更强大的功能和灵活性，但需要更多的资源。</li>
<li><strong>数据存储</strong>：K3s默认使用SQLite作为数据存储，进一步减少了资源需求。K8s则使用etcd作为数据存储，提供更高的性能和可靠性。</li>
<li><strong>架构支持</strong>：K3s支持ARM架构，使其能够在Raspberry Pi等设备上运行。K8s主要支持x86架构，但也可以通过额外配置支持ARM架构。</li>
</ol>
<p>更具体地，主要区别在于安装和配置（部署升级方式）、资源占用、数据存储、速度以及安全方面：</p>
<h3 id="安装和配置（部署升级方式）"><a href="#安装和配置（部署升级方式）" class="headerlink" title="安装和配置（部署升级方式）"></a>安装和配置（部署升级方式）</h3><p>通常情况下，相比 K8s，K3s 更容易部署和维护。轻量级的二进制文件让你可以用一个命令启动所有的 Kubernetes 控制平面组件。而要启动官方的 Kubernetes 集群则需要更多的时间和步骤，并且可能更难维护。<br>K3s 提供了更简单、无需干预的体验。K8s 下虽然使用 Kubeadm 的升级同样也相对简单，但需要运行更多的命令。这增加了升级过程中出错的可能性。而使用 K3s，你只需调用安装脚本并等待集群更新即可。</p>
<h4 id="K3s"><a href="#K3s" class="headerlink" title="K3s"></a>K3s</h4><ul>
<li>对于初始部署，以下命令可以启动并运行一个 K3s 集群： <div class="code-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">$ curl -sFL https://get.k3s.io | sh -</span><br></pre></td></tr></table></figure></div></li>
<li>官方的安装脚本会下载二进制文件并注册一个系统服务，该系统服务会在进程终止或主机重新启动时自动启动 K3s。它还配置了 Kubernetes 实用工具，包括 kubectl CLI。在新的机器上运行脚本后，你应该能够在几秒钟内与你的集群进行交互。</li>
<li>对于升级，K3s 提供简化的集群升级体验。你只需再次运行安装脚本即可下载最新版本并自动完成升级。在每个节点上重复执行此命令将使你的集群升级到最新的稳定版本，无需任何手动干预。</li>
</ul>
<h4 id="K8s"><a href="#K8s" class="headerlink" title="K8s"></a>K8s</h4><ul>
<li>对于初始部署，K8s 的部署过程比较复杂。Kubernetes 项目提供了各个组件的下载，比如：API server、controller manager 和 scheduler。你需要成功部署每个组件来创建你的控制平面。然后，你还需要在每个工作节点上安装 kubelet。</li>
<li>通过 kubeadm 工具，可以简化 Kubernetes 安装。在使用 kubeadm 之前，你需要安装一个容器运行时，比如 containerd 4。然后，你可以运行以下命令在你的主机上初始化 Kubernetes 控制平面：<div class="code-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">$ kubeadm init</span><br></pre></td></tr></table></figure></div></li>
<li>初始化完成后，系统会告诉你运行下一步需要做什么：<div class="code-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">$ <span class="built_in">sudo</span> <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">$ <span class="built_in">sudo</span> <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure></div></li>
<li>此后，你还需要手动选择并安装一个 Pod 网络插件，这样你的 Pod 才能相互通信。完成安装后，就可以向集群中添加节点并使用集群了。</li>
<li>对于升级，使用 kubeadm 创建的 K8s 集群进行升级需要执行几个额外的步骤。你需要获取最新版本的 kubeadm，接下来使用 kubeadm 升级你的控制平面，最后升级每个工作节点上的 kubelet 和 kubectl。</li>
</ul>
<h3 id="资源占用"><a href="#资源占用" class="headerlink" title="资源占用"></a>资源占用</h3><ul>
<li><p><strong>K3s</strong>: K3s 可以在 1C 512MB 的设备上运行，K3s 二进制文件大小不到 60 MB，并且不需要外部依赖。</p>
</li>
<li><p><strong>K8s</strong>: 使用 kubeadm 创建的 K8s 集群具有更高的资源需求。文档建议至少有两个空闲的 CPU 核和 2 GB 的内存。控制平面组件的增加开销意味着需要更多的硬件资源才能达到相同的结果。这在云上部署集群时可能会增加成本。</p>
</li>
</ul>
<p>K3s 是资源受限环境的优先选择。这是该项目的核心关注领域。请记住，<em>虽然 K3s 可以运行在 512 MB 内存的设备上，但并不推荐这样，因为你需要给应用程序预留运行空间。</em></p>
<h3 id="数据存储及其它组件"><a href="#数据存储及其它组件" class="headerlink" title="数据存储及其它组件"></a>数据存储及其它组件</h3><p>K8s 和 K3s 打包了不同的组件来实现 Kubernetes 的架构。</p>
<ul>
<li>其中最大的变化之一就是控制平面使用的数据存储：上游 Kubernetes 使用 etcd，而 K3s 选择使用内置的 SQLite 数据库。这通常提高了性能并减小了二进制文件的大小，但可能不适用于大规模集群。如果需要，K3s 也可以连接到外部的 etcd 或使用 K3s 内置的 etcd 数据存储，以及其他基于 SQL 的数据库，如 MySQL 和 PostgreSQL。</li>
<li>标准的 Kubernetes 发行版<strong>只包括控制平面所需的组件</strong>。K3s 还<strong>内置了常用的生态工具</strong>，比如：kubectl。<ul>
<li>K3s <strong>集成了 Helm 支持</strong>，可以通过将 Helm Chart 表示为集群中的 HelmChart 对象来部署 Helm Chart。然而，上游 Kubernetes 不理解 Helm；你需要单独安装 Helm CLI 并使用其命令来安装你的 Chart。</li>
<li>K8s 和 K3s 都<strong>使用 containerd 作为默认的容器运行时</strong>，但这可以进行定制。K3s 还包含了其他几个来自社区的组件，包括用于 Pod 网络的 flannel 以及作为入口控制器和内置负载均衡器的 Traefik。Kubernetes 让你自己选择和安装这些工具，而 K3s 则内置了我们常用的工具。</li>
</ul>
</li>
</ul>
<p>当你不想花太多的时间成本去学习 K8s 各个组件作用时，K3s 是更好的选择。它可以启动一个功能完整的集群，并且可用于生产。</p>
<h3 id="速度"><a href="#速度" class="headerlink" title="速度"></a>速度</h3><ul>
<li>在等效硬件上部署的 K8s 集群和 K3s 集群应该可以以相似的性能运行你的容器，因为它们使用相同的 containerd 运行时。</li>
<li>然而，K3s 非常轻巧，它安装和启动控制平面的速度要比 K8s 快得多。<ul>
<li>相比之下，上游的 Kubernetes 可能需要几分钟才能启动（而 K3s 通常在一分钟内可用）。</li>
<li>这使得 K3s 更适合于临时的集群，例如本地开发和测试环境。你可以快速启动一个集群，使用后再将 K3s 关闭。</li>
</ul>
</li>
</ul>
<h3 id="安全-1"><a href="#安全-1" class="headerlink" title="安全"></a>安全</h3><ul>
<li>K3s 在设计上是安全的，并提供了一个最小的攻击面。所有组件都打包在一个二进制文件中，减少的依赖关系使得安全漏洞的出现可能性较小。</li>
<li>这并不意味着 K8s 是不安全的。Kubernetes 已成为最受欢迎的开源项目之一，被全球各大公司采用。它经过定期审查，以确保集群受到攻击的保护。</li>
</ul>
<p>无论你使用哪种解决方案，你都应该在安装后加强集群的安全保护。K3s 和 Kubernetes 都有自己的安全建议，用于创建安全的集群。</p>
<h2 id="K3s在边缘计算中的应用场景"><a href="#K3s在边缘计算中的应用场景" class="headerlink" title="K3s在边缘计算中的应用场景"></a>K3s在边缘计算中的应用场景</h2><p>K3s由于其轻量级和易于安装的特点，非常适合在边缘计算和资源受限的环境中使用。以下是一些典型的应用场景：</p>
<ul>
<li><strong>物联网（IoT）</strong>：K3s可以在Raspberry Pi等低功耗设备上运行，适用于物联网设备的管理和编排。</li>
<li><strong>边缘计算</strong>：K3s可以在边缘节点上部署，提供本地计算和存储能力，减少数据传输延迟。</li>
<li><strong>开发和测试</strong>：K3s的轻量级和易于安装的特点，使其非常适合用于开发和测试环境。</li>
</ul>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><p>通过此次调研，我对K3s和K8s有了更深入的了解。K3s作为K8s的精简版，专为资源受限的环境和边缘计算设计，具有轻量级、易于安装和ARM支持等特点。虽然K3s在功能上不如K8s强大，但在特定场景下，K3s提供了更高的效率和灵活性。</p>
<p>在未来的工作中，我将继续关注K3s和K8s的发展，并尝试将它们应用到实际项目中。</p>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://k3s.io/" >[1] K3s官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link"   href="https://kubernetes.io/" >[2] Kubernetes官方文档<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link"   href="https://docs.rancher.cn/docs/k3s/_index/" >[3] Rancher Labs博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link"   href="https://forums.rancher.cn/t/k3s-vs-k8s/2704" >[4] K3s vs K8s：轻量级和全功能的对决<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-5"></div>

<p><a class="link"   href="https://juejin.cn/post/7321634253909721142" >[5] 选择K3s还是K8s?<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>业界现状</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>边缘计算</tag>
        <tag>K8s</tag>
        <tag>K3s</tag>
      </tags>
  </entry>
  <entry>
    <title>【开源】发布 Jar 包到 Maven Central Repository，上传 javadoc</title>
    <url>/2023/08/17/program_language/java/java-maven-center/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><ul>
<li>模拟器终于到了阶段一收尾，整理一下如何将开发的项目发布成为大家都能调用的包。</li>
<li>本文大部分来源于网上博客<a href="#refer-anchor-1"><sup>[1]</sup></a><a href="#refer-anchor-2"><sup>[2]</sup></a>，如有侵权（也许）请联系我。基本都是搬运，欢迎大家支持原作者。</li>
</ul>
<h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><h2 id="📚-流程目录"><a href="#📚-流程目录" class="headerlink" title="📚 流程目录"></a>📚 流程目录</h2><ol>
<li>注册</li>
<li>创建项目</li>
<li>java项目配置</li>
<li>上传、验证、发布</li>
<li>等待审核</li>
</ol>
<h2 id="1️⃣-注册"><a href="#1️⃣-注册" class="headerlink" title="1️⃣ 注册"></a>1️⃣ 注册</h2><ul>
<li><p>Maven Central 网站并不提供注册的功能，需要到 Sonatype 网站上进行注册。</p>
</li>
<li><p>而 Sonatype 网站也没有直接提供一个注册链接，真正的注册入口在 <a class="link"   href="https://issues.sonatype.org/secure/Signup!default.jspa" >issues tracker<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 上。</p>
</li>
<li><p>（密码要求真的很严格）<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Freshwlnd/image/blob/blog/issues-tracker.jpg?raw=true"
                      alt="密码要求"
                ><figcaption>密码要求</figcaption></figure></p>
</li>
</ul>
<h2 id="2️⃣-创建项目"><a href="#2️⃣-创建项目" class="headerlink" title="2️⃣ 创建项目"></a>2️⃣ 创建项目</h2><ul>
<li>根据提示创建 issue（我私自翻译为项目，感觉比较贴切）</li>
</ul>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://p.sda1.dev/12/3148bbc32e51cbc8c21a41229d2699ec/1692279570549.jpg"
                      alt="创建 issue"
                ><figcaption>创建 issue</figcaption></figure></p>
<ul>
<li>在 Sonatype 中 <a class="link"   href="https://issues.sonatype.org/secure/CreateIssue.jspa?issuetype=21&pid=10134" >创建<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 新项目。<ul>
<li>根据弹出框的提示，填写概要、描述、GroupId、Project URL、SCM url 以及你在 jira 上的用户名。创建完毕后，会被自动跳转到该 issue 的详情页并分配一个唯一的ID，如：OSSRH-33944。余下的时间只需要等待，一般在两个工作日之内，Sonatype 的工作人员就会着手处理，然后他会在该 issue 底下的评论区留言。</li>
<li><font color='red'>由于项目仍在开发中，尚处于私有状态，暂未进行这一步，等 javadoc 及一系列修改完成后再进行相关操作。</font></li>
</ul>
</li>
</ul>
<h2 id="3️⃣-java项目配置"><a href="#3️⃣-java项目配置" class="headerlink" title="3️⃣ java项目配置"></a>3️⃣ java项目配置</h2><ul>
<li>下一步需要在java项目中进行一些必要的配置，包括：验证域名、jar、sourcesJar、javadocJar 以及对这些产物的 signing（签名）。</li>
</ul>
<h3 id="3-1-密钥生成"><a href="#3-1-密钥生成" class="headerlink" title="3.1 密钥生成"></a>3.1 密钥生成</h3><ul>
<li>使用 gpg 进行加密和签名，mac 下参考<a href="#refer-anchor-3">[3]</a>使用 homebrew 直接安装<code>brew install gpg</code>，win 下参考<a href="#refer-anchor-2">[2]</a>在<a class="link"   href="https://www.gpg4win.org/" >Gpg4win - Secure email and file encryption with GnuPG for Windows 官网<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>下载，根据参考文档<a href="#refer-anchor-2">[2]</a><a href="#refer-anchor-3">[3]</a>分别生成并上传密钥。</li>
</ul>
<h3 id="3-2-Maven-Config-配置"><a href="#3-2-Maven-Config-配置" class="headerlink" title="3.2 Maven Config 配置"></a>3.2 Maven Config 配置</h3><ul>
<li>在setting.xml中添加如下配置</li>
</ul>
<ol>
<li>放在servers里面<div class="code-container" data-rel="Xml"><figure class="iseeu highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">server</span>&gt;</span></span><br><span class="line">      	<span class="tag">&lt;<span class="name">id</span>&gt;</span>ossrh<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">      	<span class="tag">&lt;<span class="name">username</span>&gt;</span>你的issues.sonatype.org账号<span class="tag">&lt;/<span class="name">username</span>&gt;</span></span><br><span class="line">      	<span class="tag">&lt;<span class="name">password</span>&gt;</span>你的issues.sonatype.org密码<span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">server</span>&gt;</span></span><br></pre></td></tr></table></figure></div></li>
<li>放在profiles里面<div class="code-container" data-rel="Xml"><figure class="iseeu highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">profile</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">id</span>&gt;</span>ossrh<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">activation</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">activeByDefault</span>&gt;</span>true<span class="tag">&lt;/<span class="name">activeByDefault</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">activation</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--这里填你安装的GnuPG位置--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">gpg.executable</span>&gt;</span>H:\GnuPG\bin\gpg.exe<span class="tag">&lt;/<span class="name">gpg.executable</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">gpg.passphrase</span>&gt;</span>刚才你生成密钥时输入的密码，不是指纹！！！<span class="tag">&lt;/<span class="name">gpg.passphrase</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--这里填你秘钥在磁盘上的位置,可通过上面步骤的 gpg --list-keys找到--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">gpg.homedir</span>&gt;</span>C:\Users\30398\AppData\Roaming\gnupg<span class="tag">&lt;/<span class="name">gpg.homedir</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">profile</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

</li>
</ol>
<h3 id="3-3-pom-xml-配置"><a href="#3-3-pom-xml-配置" class="headerlink" title="3.3 pom.xml 配置"></a>3.3 pom.xml 配置</h3><div class="code-container" data-rel="Xml"><figure class="iseeu highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span> <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">relativePath</span>/&gt;</span> <span class="comment">&lt;!-- lookup parent from repository --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>自己写<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>自己写<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.6.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>KaTool<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>这里你自己写<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- https://mvnrepository.com/artifact/com.qiniu/qiniu-java-sdk --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.reporting.outputEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.reporting.outputEncoding</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--注意一定要和jdk版本对应，建议1.8，版本太高可能会出现TreeMap的异常--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">                  ......</span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--项目地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url</span>&gt;</span>例子：https://github.com/Karosown/KaTool<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--开发者信息--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">developers</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">developer</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>Karos<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>Karos<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">email</span>&gt;</span>mail@wzl1.top<span class="tag">&lt;/<span class="name">email</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">roles</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">role</span>&gt;</span>Developer<span class="tag">&lt;/<span class="name">role</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">roles</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">timezone</span>&gt;</span>+8<span class="tag">&lt;/<span class="name">timezone</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">developer</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">developers</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--开源协议...--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">licenses</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">license</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>Apache License, Version 2.0<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://www.apache.org/licenses/LICENSE-2.0.txt<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">distribution</span>&gt;</span>repo<span class="tag">&lt;/<span class="name">distribution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">comments</span>&gt;</span>A business-friendly OSS license<span class="tag">&lt;/<span class="name">comments</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">license</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">licenses</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--项目在github或其它托管平台的地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scm</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">connection</span>&gt;</span>例子：https://github.com/Karosown/KaTool.git<span class="tag">&lt;/<span class="name">connection</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">developerConnection</span>&gt;</span>例子：scm:git:ssh://git@github.com:Karosown/KaTool.git<span class="tag">&lt;/<span class="name">developerConnection</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>例子：https://github.com/Karosown/KaTool/tree/master  分支一定要带上，当时没带上找<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">scm</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-source-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">id</span>&gt;</span>attach-sources<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>jar-no-fork<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-javadoc-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">additionalJOptions</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">additionalJOption</span>&gt;</span>-Xdoclint:none<span class="tag">&lt;/<span class="name">additionalJOption</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">additionalJOptions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">id</span>&gt;</span>attach-javadocs<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>jar<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-gpg-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">id</span>&gt;</span>sign-artifacts<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>verify<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>sign<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">distributionManagement</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">snapshotRepository</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>ossrh<span class="tag">&lt;/<span class="name">id</span>&gt;</span>            <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://s01.oss.sonatype.org/content/repositories/snapshots<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">snapshotRepository</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>ossrh<span class="tag">&lt;/<span class="name">id</span>&gt;</span>            <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://s01.oss.sonatype.org/service/local/staging/deploy/maven2/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">distributionManagement</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<h3 id="3-4-生成相关组件"><a href="#3-4-生成相关组件" class="headerlink" title="3.4 生成相关组件"></a>3.4 生成相关组件</h3><ul>
<li>运行 mvn deploy，输入创建密钥时的密码。（以下图片来源于<a href="#refer-anchor-2">[2]</a>）<br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Freshwlnd/image/blob/blog/java1.png?raw=true"
                      alt="运行 mvn deploy"
                ><figcaption>运行 mvn deploy</figcaption></figure><br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Freshwlnd/image/blob/blog/java2.png?raw=true"
                      alt="输入密码"
                ><figcaption>输入密码</figcaption></figure><br><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Freshwlnd/image/blob/blog/java3.png?raw=true"
                      alt="创建成功"
                ><figcaption>创建成功</figcaption></figure></li>
</ul>
<h2 id="4️⃣-上传、验证、发布"><a href="#4️⃣-上传、验证、发布" class="headerlink" title="4️⃣ 上传、验证、发布"></a>4️⃣ 上传、验证、发布</h2><h2 id="5️⃣-等待审核"><a href="#5️⃣-等待审核" class="headerlink" title="5️⃣ 等待审核"></a>5️⃣ 等待审核</h2><h1 id="待完成内容"><a href="#待完成内容" class="headerlink" title="待完成内容"></a>待完成内容</h1><ol>
<li>确定项目相关信息，包括： <code>概要</code>,<code>Group Id</code>及<code>pom.xml</code>中的信息。</li>
<li>创建 issue 并填写信息。</li>
<li>配置密钥。</li>
<li>上传。</li>
</ol>
<h1 id="x1f5fa-参考"><a href="#x1f5fa-参考" class="headerlink" title="&#x1f5fa;参考"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://cloud.tencent.com/developer/article/1188461" >[1] 如何发布Jar包到Maven Central Repository<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link"   href="https://cloud.tencent.com/developer/article/2212153" >[2] 如何上传自己的项目到Maven中央仓库<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link"   href="https://juejin.cn/post/7047440793920864287" >[3] M1 Mac 配置 GPG<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link"   href="https://blog.csdn.net/zhu19774279/article/details/49813303" >[4] 如何编译maven工程得到jar、sources、javadoc并上传至Sonatype Nexus OSS<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>【Spring】java 单体式应用微服务拆分过程 bug 修复：Json Parse Error</title>
    <url>/2023/08/25/program_language/java/java-spring-bug-json-parse-error/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><ul>
<li><p>将单体式 Spring 应用拆分为微服务式应用过程中，遇到了一系列有关 Spring 框架的问题，将修复过程及相关问题信息分析过程记录下来，便于以后解决同类问题，也顺便提高自己对 Spring 框架的理解。</p>
</li>
<li><p>前期还遇到循环引用导致 JSON 序列化失败、Serialize 类序列化失败等问题，暂未记录下来，未来有机会再回顾并补充相关记录。</p>
</li>
</ul>
<h1 id="🧠问题1️⃣——JSON-parse-error"><a href="#🧠问题1️⃣——JSON-parse-error" class="headerlink" title="🧠问题1️⃣——JSON parse error"></a>🧠问题1️⃣——JSON parse error</h1><ul>
<li>共出现三类报错，分别对应 Spring Framework <code>org.springframework.data.domain</code> 包中的 <code>Pageable</code>、<code>PageRequest</code>、<code>Sort</code>三个类。</li>
</ul>
<h2 id="✏️问题描述"><a href="#✏️问题描述" class="headerlink" title="✏️问题描述"></a>✏️问题描述</h2><ul>
<li><p>上述三个类是用于处理数据分页和排序的关键类。其中：</p>
<ul>
<li><p> <code>Pageable</code> 接口定义了处理分页信息的通用方法，<code>PageRequest</code> 是它的默认实现之一，提供了一个便捷的方式来构造分页请求。<code>Sort</code> 类用于定义数据的排序规则，可以用于单独的查询，也可以与<code>Pageable</code> 一起使用以实现在分页基础上的排序。在数据库查询中，通常会将Pageable和Sort对象传递给查询方法，以指定分页和排序规则，从而从数据库中检索特定范围的数据，并按指定的顺序排列。</p>
</li>
<li><p>具体而言：</p>
<ul>
<li><p><code>org.springframework.data.domain.Pageable</code>：</p>
<ul>
<li>Pageable接口是用于定义数据分页信息的接口。它允许用户指定要检索的页码、每页的数据量以及排序规则。通常用于在数据库查询中限制结果集大小并实现分页功能。</li>
</ul>
</li>
<li><p><code>org.springframework.data.domain.PageRequest</code>：</p>
<ul>
<li>PageRequest是Pageable接口的默认实现之一。它提供了一个简便的方法来创建分页请求。用户可以通过构造函数传递页码、每页数据量和排序规则来创建一个PageRequest对象，然后将其用作查询方法的参数。</li>
</ul>
</li>
<li><p><code>org.springframework.data.domain.Sort</code>：</p>
<ul>
<li>Sort类用于指定数据排序规则。它允许用户定义一个或多个排序条件，包括属性名和排序方向（升序或降序）。在数据库查询中，Sort对象可以与Pageable一起使用，以便在分页的基础上对数据进行排序。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="🤔问题分析"><a href="#🤔问题分析" class="headerlink" title="🤔问题分析"></a>🤔问题分析</h3><ul>
<li><p>本项目迁移至微服务过程中，一个变为远程调用的函数使用了 <code>Pageable</code> 作为函数参数。</p>
</li>
<li><p>在远程调用时，先将相应参数转化为 JSON 格式数据，再将 JSON 数据转换为相应对象。</p>
<ul>
<li>经过简单分析得知，问题源于将 JSON 数据转换为对象时出现错误，具体来说， JSON 解析器无法构造 <code>Pageable</code> 实例，因为找不到适合的构造函数或者创造者方法，或者可能需要添加/启用类型信息。（最常见的报错提示缺乏无参构造函数）</li>
</ul>
</li>
<li><p>先展示一下报错信息，再介绍我所尝试的几种解决方案。</p>
</li>
</ul>
<h3 id="ℹ️报错信息-1"><a href="#ℹ️报错信息-1" class="headerlink" title="ℹ️报错信息 1"></a>ℹ️报错信息 1</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Cannot construct instance of `org.springframework.data.domain.Pageable` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information; nested exception is com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `org.springframework.data.domain.Pageable` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information at [Source: java.io.PushbackInputStream@11b5cfbc; line: 1, column: 59] (through reference chain: com.raysmond.blog.common.models.PostParams[&quot;pageRequest&quot;])</span><br></pre></td></tr></table></figure></div>

<h3 id="ℹ️报错信息-2"><a href="#ℹ️报错信息-2" class="headerlink" title="ℹ️报错信息 2"></a>ℹ️报错信息 2</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Can not construct instance of `org.springframework.data.domain.PageRequest``: no suitable constructor found, can not deserialize from Object value (missing default constructor or creator, or perhaps need to add/enable type information?); nested exception is com.fasterxml.jackson.databind.JsonMappingException: Can not construct instance of org.springframework.data.domain.PageRequest: no suitable constructor found, can not deserialize from Object value (missing default constructor or creator, or perhaps need to add/enable type information?) at [Source: java.io.PushbackInputStream@72267439; line: 1, column: 60] (through reference chain: com.raysmond.blog.common.models.PostParams[\&quot;pageRequest\&quot;])&quot;,&quot;path&quot;:&quot;/PostRepositoryController/error/general&quot;&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="🛠️相关尝试及解决方案"><a href="#🛠️相关尝试及解决方案" class="headerlink" title="🛠️相关尝试及解决方案"></a>🛠️相关尝试及解决方案</h2><h3 id="🔨尝试方法1️⃣——封装基础类"><a href="#🔨尝试方法1️⃣——封装基础类" class="headerlink" title="🔨尝试方法1️⃣——封装基础类"></a>🔨尝试方法1️⃣——封装基础类</h3><ul>
<li><p>根据提示可知，缺乏无参构造函数。而基础包中的代码是只读的无法修改，因此采用封装的方式，参考<a href="#refer-anchor-1">[1]</a><a href="#refer-anchor-2">[2]</a>实现一个继承基础类的新类，和基础类相比仅仅多了一个无参构造函数。</p>
</li>
<li><p>以 PageRequest 为例，查看源码后构造新类如下：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">package com.raysmond.blog.common.models;</span><br><span class="line"></span><br><span class="line">import org.springframework.data.domain.Sort;</span><br><span class="line">import org.springframework.data.domain.Sort.Direction;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">public class PageRequest extends org.springframework.data.domain.PageRequest &#123;</span><br><span class="line"></span><br><span class="line">    public PageRequest() &#123;</span><br><span class="line">        super(1, 1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public PageRequest(int page, int size) &#123;</span><br><span class="line">        super(page, size);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public PageRequest(int page, int size, Direction direction, String... properties) &#123;</span><br><span class="line">        super(page, size, direction, properties);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public PageRequest(int page, int size, Sort sort) &#123;</span><br><span class="line">        super(page, size, sort);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
<li><p>实现后，将所有地方的使用的基础类替换为新类，一个简单的方法是查找替换：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">import com.raysmond.blog.common.models.PageRequest;</span><br><span class="line">// import org.springframework.data.domain.PageRequest;</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>修改后似乎解决了该问题，但出现了第二个错误问题——404。因此尝试使用其他解决方案。</p>
</li>
</ul>
<h3 id="🔨尝试方法2️⃣——启用-Jackson-配置"><a href="#🔨尝试方法2️⃣——启用-Jackson-配置" class="headerlink" title="🔨尝试方法2️⃣——启用 Jackson 配置"></a>🔨尝试方法2️⃣——启用 Jackson 配置</h3><ul>
<li><p>最开始就看到这种方法<a href="#refer-anchor-2"><sup>[2]</sup></a>，但在 application.yaml 中配置时发现对应配置项无法找到，因此搁置。后来检索 <code>Sort</code> 类的问题时再次调研到更细致的配置方法<a href="#refer-anchor-4"><sup>[4]</sup></a>。</p>
</li>
<li><p>具体如下：</p>
<ul>
<li><p>配置项（在 <code>application</code> 文件中配置）：</p>
<div class="code-container" data-rel="Yml"><figure class="iseeu highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">feign.autoconfiguration.jackson.enabled=true</span></span><br></pre></td></tr></table></figure></div>
</li>
<li><p>导入包：</p>
<div class="code-container" data-rel="Gradle"><figure class="iseeu highlight gradle"><table><tr><td class="code"><pre><span class="line"># gradle</span><br><span class="line"><span class="keyword">compile</span> <span class="string">&#x27;org.springframework.cloud:spring-cloud-openfeign-core:+&#x27;</span></span><br></pre></td></tr></table></figure></div>
<div class="code-container" data-rel="Xml"><figure class="iseeu highlight xml"><table><tr><td class="code"><pre><span class="line"># maven</span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-openfeign-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span>    # 根据需要修改</span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>
</li>
</ul>
</li>
<li><p>同样，导入后报错消失，但仍然出现第二个错误问题—— 404 问题。（😵‍💫晕倒）</p>
</li>
<li><p>暂且认为是解决了一个问题的第一阶段，先尝试解决第二阶段。</p>
</li>
</ul>
<h1 id="🧠问题2️⃣——404-Not-Found"><a href="#🧠问题2️⃣——404-Not-Found" class="headerlink" title="🧠问题2️⃣——404 Not Found"></a>🧠问题2️⃣——404 Not Found</h1><h2 id="✏️问题描述-1"><a href="#✏️问题描述-1" class="headerlink" title="✏️问题描述"></a>✏️问题描述</h2><ul>
<li>如上所述，当 jackson 不再报错后，开始出现 404 问题，主要信息为<code>Content type &#39;application/json;charset=UTF-8&#39; not supported</code>。</li>
</ul>
<h3 id="ℹ️报错信息"><a href="#ℹ️报错信息" class="headerlink" title="ℹ️报错信息"></a>ℹ️报错信息</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">feign.FeignException: status 404 reading PostRepositoryRealClient#findAllByPostTypeAndPostStatusAndDeleted(PostParams); </span><br><span class="line">content: &#123;</span><br><span class="line">    status: 404,</span><br><span class="line">    error: Not Found,</span><br><span class="line">    exception: org.springframework.web.HttpMediaTypeNotSupportedException,</span><br><span class="line">    message:org.springframework.web.HttpMediaTypeNotSupportedException: Content type &#x27;application/json;charset=UTF-8&#x27; not supported</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>


<h3 id="🤔问题分析-1"><a href="#🤔问题分析-1" class="headerlink" title="🤔问题分析"></a>🤔问题分析</h3><ul>
<li><p>这个错误表明<strong>服务器不支持传入的Content-Type</strong>，该Content-Type是application/json;charset=UTF-8。</p>
<ul>
<li>这可能是因为：<ul>
<li>服务器端的接口没有正确配置以处理JSON格式的请求，</li>
<li>或者可能是由于请求的Content-Type与服务器端接口的期望不匹配。</li>
</ul>
</li>
</ul>
</li>
<li><p>由于报错分析过于简单，有点无从下手，检索了一系列文章也没看出个所以然。因此考虑第一步骤为获取更多信息：</p>
<h3 id="💾尝试方法1️⃣——获取更多信息"><a href="#💾尝试方法1️⃣——获取更多信息" class="headerlink" title="💾尝试方法1️⃣——获取更多信息"></a>💾尝试方法1️⃣——获取更多信息</h3></li>
<li><p>首先分别测试每个被调用者，看到底是哪个接口开始出错：</p>
<ul>
<li><em>发现 Edge 的 检查-&gt;网络控制器 中有类似于 Postman 的工具，正好用于测试。</em></li>
<li>进行相应测试后发现问题还是出在接收端反序列化上。</li>
</ul>
</li>
<li><p>进行一系列检索后，发现一个相关解答。</p>
</li>
</ul>
<h3 id="💭问题原因"><a href="#💭问题原因" class="headerlink" title="💭问题原因"></a>💭问题原因</h3><ul>
<li>来源于<a href="#refer-anchor-5">[5]</a>，对于不支持的类型，会报错<code>Content type &#39;application/json;charset=UTF-8&#39; not supported</code>，含义实际上是无法解析 json 数据。<ul>
<li>理论上我们已经进行了相关配置，不应该出现该问题。只能怀疑是 spring 版本过低导致的 bug。</li>
<li>然而如果要升级 spring 只会消耗更多时间精力，因此暂不考虑该方案。</li>
</ul>
</li>
<li>进一步地，<a href="#refer-anchor-5">[5]</a>中导入相关包后仍然报错，根据其报错可以更深了解 spring 这部分原理。<ul>
<li>spring需要使用方法TypeFactory.type(class)进行解析，当jackson mapper中没有实现方法则会报错。</li>
</ul>
</li>
</ul>
<h1 id="🧠最终方案——曲线救国"><a href="#🧠最终方案——曲线救国" class="headerlink" title="🧠最终方案——曲线救国"></a>🧠最终方案——曲线救国</h1><ul>
<li>之前排查过程中其实看到一套方案，但这种方案无法触及当前问题的本质，出于对问题本质的好奇一直没有采用。<ul>
<li>然而现在已经耗费了太多时间在这个问题上，只能先曲线救国一下了。</li>
</ul>
</li>
<li>方案如下：<blockquote>
<p>使用默认支持的参数格式：<br>  Spring Data通常会根据请求的参数自动解析分页和排序信息，而无需将它们作为JSON对象传递。例如，在使用Spring MVC时，您可以直接将页码、每页大小和排序参数添加到URL中，Spring Data会自动解析这些参数并应用于查询。这样可以避免直接将分页对象作为JSON传递，从而避免反序列化问题。wd</p>
</blockquote>
</li>
</ul>
<h2 id="🔨解决方法1️⃣——传递重要参数"><a href="#🔨解决方法1️⃣——传递重要参数" class="headerlink" title="🔨解决方法1️⃣——传递重要参数"></a>🔨解决方法1️⃣——传递重要参数</h2><ul>
<li>本项目下使用<code>PageRequest</code>作为<code>Pageable</code>的实现类，其创建方式如下：<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="title class_">PageRequest</span>(page, pageSize, Sort.Direction.DESC, <span class="string">&quot;createdAt&quot;</span>)</span><br></pre></td></tr></table></figure></div></li>
<li>显然，只要将各个参数传递后重新创建对象即可，因此实现以下 DTO：<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PostParams</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> PostType postType;</span><br><span class="line">    <span class="keyword">private</span> PostStatus postStatus;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">boolean</span> isNullPageRequest;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> page=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> size=<span class="number">5</span>;</span><br><span class="line">    <span class="keyword">private</span> String sortDirection=<span class="string">&quot;DESC&quot;</span>;</span><br><span class="line">    List&lt;String&gt; properties= <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;String&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Boolean deleted;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">PostParams</span><span class="params">(PostType postType, PostStatus postStatus, Pageable pageRequest, Boolean deleted)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.postType = postType;</span><br><span class="line">        <span class="built_in">this</span>.postStatus = postStatus;</span><br><span class="line">        setPageRequest(pageRequest);</span><br><span class="line">        <span class="built_in">this</span>.deleted = deleted;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">PostParams</span><span class="params">(PostType postType, PostStatus postStatus, Boolean deleted)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.postType = postType;</span><br><span class="line">        <span class="built_in">this</span>.postStatus = postStatus;</span><br><span class="line">        setPageRequest(<span class="literal">null</span>);</span><br><span class="line">        <span class="built_in">this</span>.deleted = deleted;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setPageRequest</span><span class="params">(Pageable pageRequest)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(pageRequest==<span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="built_in">this</span>.isNullPageRequest = <span class="literal">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.isNullPageRequest = <span class="literal">false</span>;</span><br><span class="line">            <span class="built_in">this</span>.page = pageRequest.getPageNumber();</span><br><span class="line">            <span class="built_in">this</span>.size = pageRequest.getPageSize();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Pageable <span class="title function_">getPageRequest</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">PageRequest</span>(<span class="built_in">this</span>.page, <span class="built_in">this</span>.size, Sort.Direction.fromString(<span class="built_in">this</span>.sortDirection), <span class="built_in">this</span>.properties.toArray(<span class="keyword">new</span> <span class="title class_">String</span>[<span class="built_in">this</span>.properties.size()]));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
<li><del>不得不吐槽一下，Sort 的设计太反人类了，确实是不想让人获取其中的对象（也可能是什么设计模式？）</del>。</li>
<li>进一步地，在所有接口上封装一层函数以使用 <code>PostParams</code> 对象作为中介即可。</li>
</ul>
<h1 id="🧠问题3️⃣——后续JSON-parse-error（Page）"><a href="#🧠问题3️⃣——后续JSON-parse-error（Page）" class="headerlink" title="🧠问题3️⃣——后续JSON parse error（Page）"></a>🧠问题3️⃣——后续JSON parse error（Page）</h1><h2 id="✏️问题描述-2"><a href="#✏️问题描述-2" class="headerlink" title="✏️问题描述"></a>✏️问题描述</h2><ul>
<li>后续调用函数并返回<code>org.springframework.data.domain.Page</code>类时出现反序列化报错，在此进行记录。</li>
<li>上述类是 <code>Spring Data JPA</code> 提供的一个分页对象，可以通过它来方便地实现数据分页操作。</li>
</ul>
<h3 id="ℹ️报错信息-1-1"><a href="#ℹ️报错信息-1-1" class="headerlink" title="ℹ️报错信息 1"></a>ℹ️报错信息 1</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">org.springframework.web.util.NestedServletException: Request processing failed; nested exception is feign.codec.DecodeException: JSON parse error: Cannot construct instance of `org.springframework.data.domain.Page` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information; nested exception is com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `org.springframework.data.domain.Page` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information\n at [Source: java.io.PushbackInputStream@3448ee37; line: 1, column: 1]</span><br></pre></td></tr></table></figure></div>

<h3 id="🤔问题分析-2"><a href="#🤔问题分析-2" class="headerlink" title="🤔问题分析"></a>🤔问题分析</h3><ul>
<li>根据报错信息可以了解，在反序列化时先创造空 <code>Page</code> 对象，但由于其是抽象类且没有默认构造函数，因此导致报错。</li>
<li>根据[前文相关信息](### 🔨尝试方法2️⃣——启用 Jackson 配置)进行项目配置后仍然无法解决，暂未尝试进行 Page 实现类的自定义封装，先尝试配置方便的 FeignConfiguration。</li>
</ul>
<h2 id="🛠️相关尝试及解决方案-1"><a href="#🛠️相关尝试及解决方案-1" class="headerlink" title="🛠️相关尝试及解决方案"></a>🛠️相关尝试及解决方案</h2><h3 id="🔨尝试方法1️⃣——FeignConfiguration"><a href="#🔨尝试方法1️⃣——FeignConfiguration" class="headerlink" title="🔨尝试方法1️⃣——FeignConfiguration"></a>🔨尝试方法1️⃣——FeignConfiguration</h3><ul>
<li>根据相关资料<a href="#refer-anchor-6"><sup>[6]</sup></a>，创建一个新类<code>FeignConfigurationFactory</code>（暂时还不知道原理，先亦步亦趋）<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.databind.Module;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.openfeign.support.PageJacksonModule;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.openfeign.support.SortJacksonModule;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FeignConfigurationFactory</span> &#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> Module <span class="title function_">pageJacksonModule</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">PageJacksonModule</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h4 id="版本报错"><a href="#版本报错" class="headerlink" title="版本报错"></a>版本报错</h4><ul>
<li><p>运行后报错：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">java: 无法访问org.springframework.cloud.openfeign.support.PageJacksonModule</span><br><span class="line">  错误的类文件: /Users/freshwind/.gradle/caches/modules-2/files-2.1/org.springframework.cloud/spring-cloud-openfeign-core/4.0.4/30883d013fe1586e06e9f995020124ba6202a317/spring-cloud-openfeign-core-4.0.4.jar!/org/springframework/cloud/openfeign/support/PageJacksonModule.class</span><br><span class="line">    类文件具有错误的版本 61.0, 应为 52.0</span><br><span class="line">    请删除该文件或确保该文件位于正确的类路径子目录中。</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>查询相关资料<a href="#refer-anchor-7"><sup>[7]</sup></a>，判断是多个依赖发生冲突。即多个包都引用了<code>org/springframework.cloud:spring-cloud-openfeign-core</code>并且引用的是不同版本。</p>
</li>
<li><p>在使用 Gradle 管理时，执行<code>gradle dependencies</code>查看依赖路径</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">+--- org.springframework.cloud:spring-cloud-openfeign-core:+ -&gt; 4.0.4</span><br><span class="line">|    +--- org.springframework.boot:spring-boot-autoconfigure:3.0.9 -&gt; 1.5.9.RELEASE (*)</span><br><span class="line">|    +--- org.springframework.boot:spring-boot-starter-aop:3.0.9 -&gt; 1.5.9.RELEASE (*)</span><br><span class="line">|    +--- io.github.openfeign.form:feign-form-spring:3.8.0</span><br><span class="line">|    |    +--- io.github.openfeign.form:feign-form:3.8.0</span><br><span class="line">|    |    |    \--- org.slf4j:slf4j-api:1.7.26 -&gt; 1.7.25</span><br><span class="line">|    |    +--- org.springframework:spring-web:5.1.5.RELEASE -&gt; 4.3.13.RELEASE (*)</span><br><span class="line">|    |    \--- org.slf4j:slf4j-api:1.7.26 -&gt; 1.7.25</span><br><span class="line">|    \--- commons-fileupload:commons-fileupload:1.5</span><br><span class="line">|         \--- commons-io:commons-io:2.11.0</span><br></pre></td></tr></table></figure></div></li>
<li><p>其中<code>spring-cloud-openfeign-core:4.0.4</code>与报错信息对得上，可以看见下面<code>org.springframework.boot:spring-boot-autoconfigure</code>和<code>org.springframework.boot:spring-boot-starter-aop</code>都被强制更新了版本，因此怀疑是<code>spring-cloud-openfeign-core</code>版本问题，尝试降低<code>spring-cloud-openfeign-core</code>版本：</p>
<ul>
<li>根据版本资料<a href="#refer-anchor-8"><sup>[8]</sup></a>逐个降低版本，直到无冲突产生。（但换到最低支持的版本仍然有冲突）</li>
<li>同时发现前文已有<code>compile(&#39;org.springframework.cloud:spring-cloud-starter-openfeign&#39;)</code>，可能已包含<code>spring-cloud-openfeign-core</code>，因此考虑删除该处。</li>
</ul>
</li>
<li><p>后续根据相关资料<a href="#refer-anchor-9"><sup>[9]</sup></a>，判断确实是 spring 组件与 java 之间的版本问题，java 1.8 无法与 spring boot 3.0 及以上版本兼容，需换成 java17。（当然此处选择了降低 spring 版本）。</p>
</li>
<li><p>调整版本后最后的报错为：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">Caused by: java.lang.ClassCastException: java.lang.ClassNotFoundException cannot be cast to [Ljava.lang.Object;</span><br><span class="line">	at org.springframework.boot.context.properties.EnableConfigurationPropertiesImportSelector.selectImports(EnableConfigurationPropertiesImportSelector.java:54)</span><br><span class="line">	at org.springframework.context.annotation.ConfigurationClassParser.processImports(ConfigurationClassParser.java:586)</span><br><span class="line">	... 21 common frames omitted</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>经过了一系列尝试后（一晚上的努力）仍然失败，放弃该方案❌</p>
</li>
</ul>
<h3 id="🔨尝试方法2️⃣——Page实现类"><a href="#🔨尝试方法2️⃣——Page实现类" class="headerlink" title="🔨尝试方法2️⃣——Page实现类"></a>🔨尝试方法2️⃣——Page实现类</h3><ul>
<li><p>根据[前文相关信息](### 🔨尝试方法2️⃣——启用 Jackson 配置)尝试进行 Page 实现类的自定义封装。</p>
<ol>
<li><p>构建以下 <code>RestPage</code> 类继承 <code>Page</code> 的默认实现类 <code>PageImpl</code>，设置相应构造函数及 json 配置。</p>
<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.annotation.JsonCreator;</span><br><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.annotation.JsonIgnoreProperties;</span><br><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.annotation.JsonProperty;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.domain.Page;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.domain.PageImpl;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.domain.PageRequest;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="meta">@JsonIgnoreProperties(ignoreUnknown = true, value = &#123;&quot;pageable&quot;&#125;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RestPage</span>&lt;T&gt; <span class="keyword">extends</span> <span class="title class_">PageImpl</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="meta">@JsonCreator(mode = JsonCreator.Mode.PROPERTIES)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">RestPage</span><span class="params">(<span class="meta">@JsonProperty(&quot;content&quot;)</span> List&lt;T&gt; content,</span></span><br><span class="line"><span class="params">                    <span class="meta">@JsonProperty(&quot;number&quot;)</span> <span class="type">int</span> page,</span></span><br><span class="line"><span class="params">                    <span class="meta">@JsonProperty(&quot;size&quot;)</span> <span class="type">int</span> size,</span></span><br><span class="line"><span class="params">                    <span class="meta">@JsonProperty(&quot;totalElements&quot;)</span> <span class="type">long</span> total)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>(content, <span class="keyword">new</span> <span class="title class_">PageRequest</span>(page, size), total);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">RestPage</span><span class="params">(Page&lt;T&gt; page)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>(page.getContent(), <span class="keyword">new</span> <span class="title class_">PageRequest</span>(page.getNumber(), page.getSize()), page.getTotalPages());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>将相应 FeignClient 及 被调用类函数中涉及的 <code>Page</code> 类替换为 <code>RestPage</code> 类，例如：</p>
<ul>
<li>原代码：<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// FeignClient</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/findByTag&quot;, method = RequestMethod.POST)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line">Page&lt;Post&gt; <span class="title function_">findByTag</span><span class="params">(<span class="meta">@RequestBody</span> PostParams postPrams)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 被调用类</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/findByTag&quot;, method = RequestMethod.POST)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line">Page&lt;Post&gt; <span class="title function_">findByTag</span><span class="params">(<span class="meta">@RequestBody</span> PostParams postPrams)</span> &#123;</span><br><span class="line">  <span class="type">String</span> <span class="variable">tag</span> <span class="operator">=</span> postPrams.getTag();</span><br><span class="line">  <span class="type">Pageable</span> <span class="variable">pageable</span> <span class="operator">=</span> postPrams.getPageRequest();</span><br><span class="line">  <span class="keyword">return</span> postRepository.findByTag(tag, pageable);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
</li>
</ul>
</li>
</ol>
<ul>
<li>修改后代码：<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// FeignClient</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/findByTag&quot;, method = RequestMethod.POST)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line">RestPage&lt;Post&gt; <span class="title function_">findByTag</span><span class="params">(<span class="meta">@RequestBody</span> PostParams postPrams)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 被调用类</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/findByTag&quot;, method = RequestMethod.POST)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line">RestPage&lt;Post&gt; <span class="title function_">findByTag</span><span class="params">(<span class="meta">@RequestBody</span> PostParams postPrams)</span> &#123;</span><br><span class="line">  <span class="type">String</span> <span class="variable">tag</span> <span class="operator">=</span> postPrams.getTag();</span><br><span class="line">  <span class="type">Pageable</span> <span class="variable">pageable</span> <span class="operator">=</span> postPrams.getPageRequest();</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RestPage</span>&lt;Post&gt;(postRepository.findByTag(tag, pageable));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
</li>
</ul>
</li>
<li><p>终于成功···</p>
</li>
</ul>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><ul>
<li>对于环境配置的问题总是会花很长时间，一方面是因为这类问题往往涉及复杂的框架，有大片知识盲区，另一方面也受我个人思路影响。<ul>
<li>第一个“问题”是好奇心，好奇心过重导致我更希望将所有问题的根源都摸清楚。实际上这种状态确实是人类所需要的，但我的问题在于“遇到较大困难时，既磨磨蹭蹭不能往前推进，又拖拖拉拉不肯放弃”。在本次情况中，实际上早就知道可以“曲线救国”，但始终没有把那条路放到面上考虑，而是沉浸在“我在攻克难题”的虚假幻想中。</li>
<li>第二个问题是过于自信、过于浮躁，主要体现在明明梳理不清思路，却也不愿意花费一些时间写下来（当然最后还是写了，否则也没有这篇博客了）。记录的好处实在是有点太多了，既能帮助捋清思路，又能提高工作成就感进而提高专注度，还能将坑分享给大家节省大家时间（一个人一分钟，四十个人是不是四十分钟了？[doge]）</li>
</ul>
</li>
</ul>
<h1 id="🚧ToDoList（也许会补上）"><a href="#🚧ToDoList（也许会补上）" class="headerlink" title="🚧ToDoList（也许会补上）"></a>🚧ToDoList（也许会补上）</h1><ol>
<li><input disabled="" type="checkbox"> Spring 框架基础原理</li>
<li><input disabled="" type="checkbox"> Jackson 组件原理及相关注解作用</li>
<li><input checked="" disabled="" type="checkbox"> <a href="#">Post not found: program_language/java-spring-bug-4xx 到底为啥报4xx相关错误</a></li>
<li><input checked="" disabled="" type="checkbox"> <a href="#">Post not found: program_language/java-spring-bug-json-infinite-recursion json循环引用报错</a></li>
<li><input disabled="" type="checkbox"> Serialize Json 报错</li>
</ol>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。（如果你发现了本问题的核心原因，一定要告诉我！）</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://blog.csdn.net/qq_22899021/article/details/83380108" >[1] JSON parse error: Can not construct instance of org.springframework.data.domain.Page<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a href="https://stackoverflow.com/questions/55965523/error-during-deserialization-of-pageimpl-cannot-construct-instance-of-org-spr">[2] Error during Deserialization of PageImpl : Cannot construct instance of <code>org.springframework.data.domain.PageImpl</code></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link"   href="https://stackoverflow.com/questions/30974286/com-fasterxml-jackson-databind-jsonmappingexception-can-not-deserialize-instanc" >[3] com.fasterxml.jackson.databind.JsonMappingException: Can not deserialize instance of org.springframework.data.domain.Sort out of START_ARRAY token<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link"   href="https://stackoverflow.com/questions/63924863/jackson-with-feign-cant-deserialized-springs-org-springframework-data-domain-s" >[4] Jackson with Feign can’t deserialized Spring’s org.springframework.data.domain.Sort<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-5"></div>

<p><a class="link"   href="https://www.weizhixi.com/article/5.html" >[5] springmvc接收参数异常application/json not supported<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-6"></div>

<p><a href="https://blog.csdn.net/hadues/article/details/130985415">[6] Cannot construct instance of <code>org.springframework.data.domain.Page</code> (no Creators, like default const</a></p>
<div id="refer-anchor-7"></div>

<p><a class="link"   href="https://www.jianshu.com/p/82de510b40b9" >[7] Gradle 依赖&amp;解决依赖冲突<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-8"></div>

<p><a class="link"   href="https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-openfeign-core" >[8] Spring Cloud OpenFeign Core<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-9"></div>

<p><a class="link"   href="https://www.jb51.net/article/272985.htm" >[9] 解决Springboot启动报错:类文件具有错误的版本61.0,应为 52.0<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境检修</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title>【Spring】java 单体式应用微服务拆分过程 bug 修复：Json Infinite Recursion</title>
    <url>/2023/08/27/program_language/java/java-spring-bug-json-infinite-recursion/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><ul>
<li><p>将单体式 Spring 应用拆分为微服务式应用过程中，遇到了一系列有关 Spring 框架的问题，将修复过程及相关问题信息分析过程记录下来，便于以后解决同类问题，也顺便提高自己对 Spring 框架的理解。</p>
</li>
<li><p>前期还遇到Serialize 类序列化失败等问题，暂未记录下来，未来有机会再回顾并补充相关记录。</p>
</li>
</ul>
<h1 id="🧠问题1️⃣——Json-Infinite-Recursion"><a href="#🧠问题1️⃣——Json-Infinite-Recursion" class="headerlink" title="🧠问题1️⃣——Json Infinite Recursion"></a>🧠问题1️⃣——Json Infinite Recursion</h1><h2 id="✏️问题描述"><a href="#✏️问题描述" class="headerlink" title="✏️问题描述"></a>✏️问题描述</h2><ul>
<li>项目中涉及多个循环引用的类，例如最典型的 <code>Post</code> 和 <code>User</code>，代码如下所示：</li>
</ul>
<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Post</span> {</span><br><span class="line">    <span class="meta">@ManyToOne</span></span><br><span class="line">    <span class="keyword">private</span> User user;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> {</span><br><span class="line">    <span class="meta">@OneToMany(fetch = FetchType.LAZY, mappedBy = "user", cascade = CascadeType.REMOVE)</span></span><br><span class="line">    <span class="keyword">private</span> Collection&lt;Post&gt; posts = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<ul>
<li>问题也很明显，当压缩为 JSON 格式数据时，不断循环引用导致出错。</li>
</ul>
<h3 id="ℹ️报错信息"><a href="#ℹ️报错信息" class="headerlink" title="ℹ️报错信息"></a>ℹ️报错信息</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">feign.codec.EncodeException: Could not write JSON: Infinite recursion (StackOverflowError); nested exception is com.fasterxml.jackson.databind.JsonMappingException: Infinite recursion (StackOverflowError) (through reference chain: com.raysmond.blog.common.models.User["post"]-&gt;com.raysmond.blog.common.models.Post["seoData"]-&gt;com.raysmond.blog.common.models.User["post"]-&gt;com.raysmond.blog.common.models.Post["seoData"]-&gt;...)</span><br></pre></td></tr></table></figure></div>

<h2 id="🔨解决方法1️⃣——-JsonIgnore"><a href="#🔨解决方法1️⃣——-JsonIgnore" class="headerlink" title="🔨解决方法1️⃣——@JsonIgnore"></a>🔨解决方法1️⃣——@JsonIgnore</h2><ul>
<li>算是比较粗鲁的方法。</li>
<li><code>@JsonIgnore</code> 能够在 JSON 序列化时将一些属性忽略<a href="#refer-anchor-1"><sup>[1]</sup></a>，从而避免循环引用。<ul>
<li>具体而言，将注解标记在属性或者方法上，序列化生成的 JSON 数据中将不包含该属性，反序列化时也不会读取该属性。</li>
<li>示例：<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Post</span> {</span><br><span class="line">    <span class="meta">@ManyToOne</span></span><br><span class="line">    <span class="keyword">private</span> User user;  <span class="comment">// 保持正常</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> {</span><br><span class="line">    <span class="meta">@OneToMany(fetch = FetchType.LAZY, mappedBy = "user", cascade = CascadeType.REMOVE)</span></span><br><span class="line">    <span class="meta">@JsonIgnore</span>         <span class="comment">// 序列化时忽略</span></span><br><span class="line">    <span class="keyword">private</span> Collection&lt;Post&gt; posts = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
</li>
</ul>
<h2 id="🔨解决方法2️⃣——-JsonManagedReference-和-JsonBackReference"><a href="#🔨解决方法2️⃣——-JsonManagedReference-和-JsonBackReference" class="headerlink" title="🔨解决方法2️⃣——@JsonManagedReference 和 @JsonBackReference"></a>🔨解决方法2️⃣——@JsonManagedReference 和 @JsonBackReference</h2><ul>
<li><p>比上一种更合理的方法，不影响数据内容。</p>
</li>
<li><p>通过将循环引用关系双方中的一方不序列化，来避免出现无限循环，使 Jackson 正常工作。<a href="#refer-anchor-2"><sup>[2]</sup></a><a href="#refer-anchor-3"><sup>[3]</sup></a></p>
</li>
<li><p>因此，Jackson 会获取引用的前向部分（被标记了 @JsonManagedReference 注解的部分），并将其转换为类似 json 的存储格式；这就是正常 marshalling 过程。然后，Jackson 会查找引用的后向部分（被标记了 @JsonBackReference 注解的部分），不对其进行序列化，这部分关系将在前向引用的反序列化（解Marshalling）过程中正常重新构建，不影响使用。</p>
<ul>
<li><em>marshalling可译作集结、结集、编码、编组、编集、安整、数据打包、列集等，是计算机科学中把一个对象的内存表示变换为适合存储或发送的数据格式的过程。典型用于数据必须在一个程序的两个部分之间移动，或者必须从一个程序移动到另一个程序。Marshalling类似于序列化，可用于一个对象与一个远程对象通信。</em></li>
<li>示例：<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Post</span> {</span><br><span class="line">    <span class="meta">@ManyToOne</span></span><br><span class="line">    <span class="meta">@JsonManagedReference</span></span><br><span class="line">    <span class="keyword">private</span> User user;  <span class="comment">// 保持正常</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> {</span><br><span class="line">    <span class="meta">@OneToMany(fetch = FetchType.LAZY, mappedBy = "user", cascade = CascadeType.REMOVE)</span></span><br><span class="line">    <span class="meta">@JsonBackReference</span>  <span class="comment">// 序列化时忽略</span></span><br><span class="line">    <span class="keyword">private</span> Collection&lt;Post&gt; posts = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
</li>
</ul>
</li>
<li><p>⚠️注：仅对 OneToMany 或 OneToOne 情况适用，ManyToMany 下不适用。</p>
</li>
</ul>
<h2 id="🔨解决方法3️⃣——-JsonIdentityInfo"><a href="#🔨解决方法3️⃣——-JsonIdentityInfo" class="headerlink" title="🔨解决方法3️⃣——@JsonIdentityInfo"></a>🔨解决方法3️⃣——@JsonIdentityInfo</h2><ul>
<li><p>最简单的一种方法（个人认为），因为不用手动设定父子关系，仅需给整个类进行注解标记即可。</p>
</li>
<li><p>使 Jackson 只在第一次遇到时序列化为完整的对象，之后再遇到同一个对象，都以对象的标识符 ID（或其他属性）代替。这样就不会序列化每个对象都 “扫描 “一次，在多个相互关联的对象之间形成链式循环时非常有用（例如：订单 -&gt; 订单行 -&gt; 用户 -&gt; 订单，如此反复）。<a href="#refer-anchor-2"><sup>[2]</sup></a></p>
<ul>
<li>@JsonIdentityInfo 相关参数定义<a href="#refer-anchor-3"><sup>[3]</sup></a><div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> JsonIdentityInfo</span><br><span class="line">{</span><br><span class="line">    <span class="comment">// Object ID 的 JSON 属性名</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">property</span><span class="params">()</span> <span class="keyword">default</span> <span class="string">"@id"</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Object ID 的生成器</span></span><br><span class="line">    <span class="keyword">public</span> Class&lt;? <span class="keyword">extends</span> <span class="title class_">ObjectIdGenerator</span>&lt;?&gt;&gt; generator();</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 将 Object ID 解析回对象的解析器</span></span><br><span class="line">    <span class="keyword">public</span> Class&lt;? <span class="keyword">extends</span> <span class="title class_">ObjectIdResolver</span>&gt; resolver() <span class="keyword">default</span> SimpleObjectIdResolver.class;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Class&lt;?&gt; scope() <span class="keyword">default</span> Object.class;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div></li>
<li>示例：<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@JsonIdentityInfo(generator = ObjectIdGenerators.PropertyGenerator.class, property = "id", scope = Post.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Post</span> {</span><br><span class="line">    <span class="meta">@ManyToOne</span></span><br><span class="line">    <span class="meta">@JsonManagedReference</span></span><br><span class="line">    <span class="keyword">private</span> User user;  <span class="comment">// 保持正常</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@JsonIdentityInfo(generator = ObjectIdGenerators.PropertyGenerator.class, property = "id", scope = User.class)</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> {</span><br><span class="line">    <span class="meta">@OneToMany(fetch = FetchType.LAZY, mappedBy = "user", cascade = CascadeType.REMOVE)</span></span><br><span class="line">    <span class="meta">@JsonBackReference</span>  <span class="comment">// 序列化时忽略</span></span><br><span class="line">    <span class="keyword">private</span> Collection&lt;Post&gt; posts = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
</li>
</ul>
</li>
<li><p>⚠️注：</p>
<ul>
<li>后续发现当同一个对象被传输两次及以上时，会报错：<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">Failed to read HTTP message: org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Already had POJO for id</span><br></pre></td></tr></table></figure></div></li>
</ul>
</li>
<li><p>根据相关回答<a href="#refer-anchor-5"><sup>[5]</sup></a>，问题出在同一个变量出现两次：</p>
<blockquote>
<p>The problem is that Jackson fails becouse the same entity is present two times.<br>The solution is send only the plain ID in the second instance, not wrapped in object.</p>
</blockquote>
</li>
<li><p>由于没想好如何跟他一样在第二次传输时修改传输内容，最终选择采用<a href="#%F0%9F%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%951%EF%B8%8F%E2%83%A3jsonignore">第一种方案</a>。</p>
</li>
<li><p>另外，发现一篇非常全面的好文<a href="#refer-anchor-6"><sup>[6]</sup></a>，里面包含了各种有关 Jackson 序列化的小知识。</p>
</li>
</ul>
<h1 id="🚧ToDoList（也许会补上）"><a href="#🚧ToDoList（也许会补上）" class="headerlink" title="🚧ToDoList（也许会补上）"></a>🚧ToDoList（也许会补上）</h1><ol>
<li><input disabled="" type="checkbox"> Spring 框架基础原理</li>
<li><input disabled="" type="checkbox"> Jackson 组件原理及相关注解作用</li>
<li><input checked="" disabled="" type="checkbox"> <a href="#">Post not found: program_language/java-spring-bug-4xx 到底为啥报4xx相关错误</a></li>
<li><input checked="" disabled="" type="checkbox"> <a href="#">Post not found: program_language/java-spring-bug-json-infinite-recursion json循环引用报错</a></li>
<li><input disabled="" type="checkbox"> Serialize Json 报错</li>
</ol>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://blog.csdn.net/liliang_11676/article/details/80209994">[1] 注解@JsonIgnore的使用方法及其效果<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link" href="https://stackoverflow.com/questions/3325387/infinite-recursion-with-jackson-json-and-hibernate-jpa-issue">[2] Infinite Recursion with Jackson JSON and Hibernate JPA issue<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link" href="https://cloud.tencent.com/developer/article/1711806">[3] Jackson 的 JsonManagedReference 和 JsonBackReference 注解<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link" href="https://blog.csdn.net/qq_20919883/article/details/117256836">[4] @JsonIdentityInfo 处理循环引用<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-5"></div>

<p><a class="link" href="https://stackoverflow.com/questions/42558927/serializing-already-had-pojo-for-id-java-lang-string">[5] Serializing Already had POJO for id (java.lang.String)<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-6"></div>

<p><a class="link" href="https://lanlan2017.github.io/JavaReadingNotes/c7a15d1f/">[6] 14.5 使用Jackson序列化为JSON_XML_MessagePack<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境检修</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title>【Spring】java 单体式应用微服务拆分过程 bug 修复：泛型函数</title>
    <url>/2023/09/08/program_language/java/java-spring-feign-generic/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><ul>
<li>将单体式 Spring 应用拆分为微服务式应用过程中，遇到了一系列有关 Spring 框架的问题，将修复过程及相关问题信息分析过程记录下来，便于以后解决同类问题，也顺便提高自己对 Spring 框架的理解。</li>
</ul>
<h1 id="🧠问题"><a href="#🧠问题" class="headerlink" title="🧠问题"></a>🧠问题</h1><ul>
<li><p>存在一个泛型函数，其输入参数和返回值都是泛型：</p>
<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping("/DTOUtil")</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DTOUtil</span> {</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">ModelMapper</span> <span class="variable">MAPPER</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> ModelMapper <span class="title function_">getMapper</span><span class="params">()</span> {</span><br><span class="line">        <span class="keyword">if</span> (MAPPER == <span class="literal">null</span>) {</span><br><span class="line">            MAPPER = <span class="keyword">new</span> <span class="title class_">ModelMapper</span>();</span><br><span class="line">            MAPPER.getConfiguration().setMatchingStrategy(MatchingStrategies.STRICT);</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> MAPPER;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping(value = "/map", method = RequestMethod.POST)</span></span><br><span class="line">    <span class="meta">@ResponseBody</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;S, T&gt; T <span class="title function_">map</span><span class="params">(<span class="meta">@RequestBody</span> DTORequestParams&lt;S, T&gt; dtoRequestParams)</span> {</span><br><span class="line">        <span class="type">S</span> <span class="variable">source</span> <span class="operator">=</span> dtoRequestParams.getSource();</span><br><span class="line">        Class&lt;T&gt; targetClass = dtoRequestParams.getTargetClass();</span><br><span class="line">        <span class="keyword">return</span> getMapper().map(source, targetClass);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>当使用 feign 进行远程调用时，会报以下错误：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">Caused by: feign.FeignException: status 400 reading DTOUtilRealClient#map(DTORequestParams); content:</span><br><span class="line">{"timestamp":1694347613202,"status":400,"error":"Bad Request","exception":"org.springframework.http.converter.HttpMessageNotReadableException","message":"Bad Request","path":"/DTOUtil/map"}</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h2 id="📚信息搜集"><a href="#📚信息搜集" class="headerlink" title="📚信息搜集"></a>📚信息搜集</h2><h3 id="泛型原理-1"><a href="#泛型原理-1" class="headerlink" title="泛型原理[1]"></a>泛型原理<a href="#refer-anchor-1"><sup>[1]</sup></a></h3><ul>
<li><p>泛型的本质是对类型进行参数化，在代码逻辑不关注具体的数据类型时使用。例如：实现一个通用的排序算法，此时关注的是算法本身，而非排序的对象的类型。</p>
</li>
<li><p>基本原理：</p>
<ul>
<li>泛型本质是将数据类型参数化，它通过擦除的方式来实现。<ul>
<li>声明了泛型的 .java 源代码，在编译生成 .class 文件之后，泛型相关的信息就消失了。可以认为，源代码中泛型相关的信息，就是提供给编译器用的。泛型信息对 Java 编译器可以见，对 Java 虚拟机不可见。</li>
</ul>
</li>
<li>Java 编译器通过如下方式实现擦除：<ul>
<li>用 Object 或者界定类型替代泛型，产生的字节码中只包含了原始的类，接口和方法；</li>
<li>在恰当的位置插入强制转换代码来确保类型安全；</li>
<li>在继承了泛型类或接口的类中插入桥接方法来保留多态性。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Feign与泛型"><a href="#Feign与泛型" class="headerlink" title="Feign与泛型"></a>Feign与泛型</h3><ul>
<li><p>个人分析：</p>
<ul>
<li>基于上一节<a href="#%E6%B3%9B%E5%9E%8B%E5%8E%9F%E7%90%861">原理</a>，在源码编译后泛型相关信息就已经被翻译为具体类型。<ul>
<li>因此当被调用的泛型类被单独封装在一个微服务中时，编译器无法推断应当翻译为什么类（每个微服务单独编译，不知道会被谁调用）。</li>
<li>这种情况下似乎只能放弃使用泛型类，而是增加更具体的接口。考虑增加一个转换器类作为中介来进行类型的转换。</li>
</ul>
</li>
</ul>
</li>
<li><p>经过广泛调研，看到多个“当返回值为泛型数据”<a href="#refer-anchor-2"><sup>[2]</sup></a><a href="#refer-anchor-3"><sup>[3]</sup></a>的解决方案，猜测“当参数为泛型数据”的被调用泛型类是无法实现的。</p>
</li>
</ul>
<h1 id="🔨解决"><a href="#🔨解决" class="headerlink" title="🔨解决"></a>🔨解决</h1><ul>
<li>通过增加中介转换类实现推理。</li>
<li>（非常不优雅，但从原理分析似乎也很合理，只是代码很丑）</li>
<li>（如果有其他优雅的方案，欢迎在留言区告诉我）</li>
</ul>
<h1 id="🏥反思"><a href="#🏥反思" class="headerlink" title="🏥反思"></a>🏥反思</h1><ol>
<li>黑猫白猫，能抓耗子就是好猫。和花一周找一个优雅的方案相比（甚至可能一周也找不到），用一个稍显粗鲁的方案也不失为某种意义上的“优雅”。</li>
</ol>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link" href="https://github.com/freshwlnd/">动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="🗺参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">🗺</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link" href="https://www.cnblogs.com/robothy/p/13949788.html">[1] Java 中泛型的实现原理<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link" href="https://blog.csdn.net/qq_39609993/article/details/113653231">[2] FeignClient使用泛型接收数据<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link" href="https://www.bedebug.com/archives/openfeign">[3] Feign 踩坑指南 (接口返回泛型设置属性为null)<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境检修</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title>【Python 进阶】yield 关键词</title>
    <url>/2023/09/13/program_language/python/py-yield/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><ul>
<li>写小脚本中的读取文件模块时，copilot 推荐了一段带有 yield 的代码，突然意识到对 Python 的一些进阶用法很不熟悉，正好基于相关资料<br><a href="#refer-anchor-1"><sup>[1]</sup></a><a href="#refer-anchor-2"><sup>[2]</sup></a>进行总结。</li>
</ul>
<h1 id="🖼️背景"><a href="#🖼️背景" class="headerlink" title="🖼️背景"></a>🖼️背景</h1><ul>
<li>当我们需要用到一组数据时，一种简单的方案是把它们<strong>全部提前生成/读入</strong>，保存在列表变量，存储在内存中。</li>
<li>这种方案的一个明显缺点是：内存占用过大。<ul>
<li>在日常使用中可能不会造成什么明显后果，但当涉及的数据过多时就会对性能产生很大影响。</li>
<li>尤其是面对未知大小的文件，直接读入会导致不可预测的内存占用。</li>
</ul>
</li>
</ul>
<h2 id="案例——生成斐波那契数列"><a href="#案例——生成斐波那契数列" class="headerlink" title="案例——生成斐波那契数列"></a>案例——生成斐波那契数列</h2><div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 简单方案</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fibonacci</span>(<span class="params"><span class="built_in">max</span></span>): </span><br><span class="line">    n, a, b = <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span> </span><br><span class="line">    L = [] </span><br><span class="line">    <span class="keyword">while</span> n &lt; <span class="built_in">max</span>: </span><br><span class="line">        L.append(b) </span><br><span class="line">        a, b = b, a + b </span><br><span class="line">        n = n + <span class="number">1</span> </span><br><span class="line">    <span class="keyword">return</span> L</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> fibonacci(<span class="number">1000</span>): </span><br><span class="line">    <span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure></div>

<h1 id="🧠解决思路：延迟生成"><a href="#🧠解决思路：延迟生成" class="headerlink" title="🧠解决思路：延迟生成"></a>🧠解决思路：延迟生成</h1><ul>
<li>数据之间可能存在一些逻辑关系，例如：<ul>
<li>斐波那契数列中，前两个数产生第三个数</li>
<li>文件读取时，前一行数据的下一个位置是后一行数据的开头</li>
</ul>
</li>
<li>我们可以用<strong>记录数据之间的逻辑关系</strong>来代替<strong>记录具体数据</strong>，更进一步地，仅当需要时才通过<strong>之前的数据</strong>及<strong>逻辑关系</strong>获得所需数据，也就是<strong>将数据的生成/读入过程延迟到数据被需要的时候</strong>。</li>
</ul>
<h1 id="🔨解决方案-1️⃣：迭代器"><a href="#🔨解决方案-1️⃣：迭代器" class="headerlink" title="🔨解决方案 1️⃣：迭代器"></a>🔨解决方案 1️⃣：迭代器</h1><ul>
<li>将上文中 <code>fibonacci</code> 函数改造为一个使用迭代器的类，迭代器不断生成下一个数。<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 迭代器方案</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Fibonacci</span>: </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, <span class="built_in">max</span></span>): </span><br><span class="line">        <span class="variable language_">self</span>.<span class="built_in">max</span> = <span class="built_in">max</span> </span><br><span class="line">        <span class="variable language_">self</span>.n, <span class="variable language_">self</span>.a, <span class="variable language_">self</span>.b = <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span> </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>): </span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span> </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>): </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.n &lt; <span class="variable language_">self</span>.<span class="built_in">max</span>: </span><br><span class="line">            r = <span class="variable language_">self</span>.b </span><br><span class="line">            <span class="variable language_">self</span>.a, <span class="variable language_">self</span>.b = <span class="variable language_">self</span>.b, <span class="variable language_">self</span>.a + <span class="variable language_">self</span>.b </span><br><span class="line">            <span class="variable language_">self</span>.n = <span class="variable language_">self</span>.n + <span class="number">1</span> </span><br><span class="line">            <span class="keyword">return</span> r </span><br><span class="line">        <span class="keyword">raise</span> StopIteration()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> Fibonacci(<span class="number">1000</span>): </span><br><span class="line">    <span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure></div></li>
<li>很显然，这种方案带来的一个问题是复杂的代码格式，需要多写很多配置，不够优雅。</li>
</ul>
<h1 id="🔨解决方案-2️⃣：yield"><a href="#🔨解决方案-2️⃣：yield" class="headerlink" title="🔨解决方案 2️⃣：yield"></a>🔨解决方案 2️⃣：yield</h1><ul>
<li>使用 yield 关键字，可以很优雅地使函数成为一个生成器 generator。</li>
<li>看起来 <code>fibonacci</code> 函数仍然是个普通函数，但其返回值实际上是一个迭代器。（非常优雅）<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># yield方案</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fibonacci</span>(<span class="params"><span class="built_in">max</span></span>): </span><br><span class="line">    n, a, b = <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span> </span><br><span class="line">    <span class="keyword">while</span> n &lt; <span class="built_in">max</span>: </span><br><span class="line">        <span class="keyword">yield</span> b </span><br><span class="line">        a, b = b, a + b </span><br><span class="line">        n = n + <span class="number">1</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> fibonacci(<span class="number">1000</span>): </span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line">f = fibonacci(<span class="number">10</span>) <span class="comment"># f 是一个迭代器，由生成器返回生成</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">next</span>(f), end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        sys.exit()</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h1 id="💡原理"><a href="#💡原理" class="headerlink" title="💡原理"></a>💡原理</h1><ul>
<li>根据直观理解，yield 关键词和 return 关键词类似，能够返回一个东西。猜测可能是解释器看到 yield 时返回一个迭代器，并将相关代码赋给该迭代器。</li>
<li>感兴趣的小伙伴可以根据相关资料<a href="#refer-anchor-3"><sup>[3]</sup></a>理解一下底层原理。</li>
</ul>
<hr>
<hr>
<ul>
<li>希望这篇博客对你有帮助！如果你有任何问题或需要进一步的帮助，请随时提问。</li>
<li>如果你喜欢这篇文章，欢迎<a class="link"   href="https://github.com/freshwlnd/" >动动小手<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>给我一个follow或star。</li>
</ul>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://www.runoob.com/python3/python3-iterator-generator.html" >[1] Python3 迭代器与生成器<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link"   href="https://www.runoob.com/w3cnote/python-yield-used-analysis.html" >[2] Python yield 使用浅析<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link"   href="https://cloud.tencent.com/developer/article/1115799" >[3] 深度详解 Python yield与实现<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>进阶</tag>
      </tags>
  </entry>
  <entry>
    <title>【Spring】java 单体式应用微服务拆分过程 bug 修复：4xx 系列</title>
    <url>/2023/08/27/program_language/java/java-spring-bug-4xx/</url>
    <content><![CDATA[<h1 id="💡简介"><a href="#💡简介" class="headerlink" title="💡简介"></a>💡简介</h1><ul>
<li><p>将单体式 Spring 应用拆分为微服务式应用过程中，遇到了一系列有关 Spring 框架的问题，将修复过程及相关问题信息分析过程记录下来，便于以后解决同类问题，也顺便提高自己对 Spring 框架的理解。</p>
</li>
<li><p>前期还遇到Serialize 类序列化失败等问题，暂未记录下来，未来有机会再回顾并补充相关记录。</p>
</li>
<li><p>陆续修了几个 bug，最终都落到了 4xx 问题上。该类问题较难处理，主要是由于问题信息不够细致，很有可能报错内容与真实问题存在偏差。</p>
</li>
</ul>
<h1 id="🔨辅助工具1️⃣——接口测试脚本（自制Postman平替）"><a href="#🔨辅助工具1️⃣——接口测试脚本（自制Postman平替）" class="headerlink" title="🔨辅助工具1️⃣——接口测试脚本（自制Postman平替）"></a>🔨辅助工具1️⃣——接口测试脚本（自制Postman平替）</h1><ul>
<li>为了精准定位问题，希望找到一个工具进行各个中间接口的测试，然而 postman 要下载（未来也许会去下）并且听说长得也不太好看，尝试了下 Edge 自带的网络控制台也不太好用（主要是数据格式不确定该如何设计），因此还是决定自己写一个小脚本。（如果你有什么推荐也欢迎在评论区告诉我）</li>
<li>仅需要基础功能：<ol>
<li>指定接口（目标 URL）</li>
<li>指定请求类型（POST、GET 等）</li>
<li>指定类型参数（RequestParam、body 等）</li>
</ol>
</li>
<li>脚本如下：<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python3</span></span><br><span class="line"><span class="comment"># -*- encoding: utf-8 -*-</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">@File    :   apiTest.py</span></span><br><span class="line"><span class="string">@Time    :   2023/08/26</span></span><br><span class="line"><span class="string">@Author  :   Yuehao.Xu</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一个请求函数，能够设定目标接口、请求类型、参数、请求头等，并返回请求结果</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">request</span>(<span class="params">url, method, datas=<span class="literal">None</span>, params=<span class="literal">None</span>, headers=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">return</span> requests.request(method=method, url=url, data=datas, params=params, headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">testURL</span>():</span><br><span class="line">    url = <span class="string">&quot;&quot;</span></span><br><span class="line">    method = <span class="string">&quot;POST&quot;</span></span><br><span class="line">    datas = &#123;</span><br><span class="line">        <span class="string">&quot;username&quot;</span>: <span class="string">&quot;admin&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&quot;k&quot;</span>: <span class="string">&quot;v&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    headers = &#123;<span class="string">&#x27;content-type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span>&#125;</span><br><span class="line">    res = request(url, method, datas=json.dumps(datas), params=params, headers=headers)</span><br><span class="line">    <span class="built_in">print</span>(res.text)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    testURL()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></div>


</li>
</ul>
<h1 id="🧠问题1️⃣——404"><a href="#🧠问题1️⃣——404" class="headerlink" title="🧠问题1️⃣——404"></a>🧠问题1️⃣——404</h1><h2 id="✏️问题描述"><a href="#✏️问题描述" class="headerlink" title="✏️问题描述"></a>✏️问题描述</h2><ul>
<li>前期修复 Jackson 相关问题费尽心力，当 jackson 不再报错后，开始出现两类 404 问题。<ul>
<li>第一类主要信息为<code>Content type &#39;application/json;charset=UTF-8&#39; not supported</code>。</li>
<li>第二类信息很少<code>feign.FeignException: status 404 reading xx#xx(xx); content: &#123;&quot;timestamp&quot;:xx,&quot;status&quot;:404,&quot;error&quot;:&quot;Not Found&quot;,&quot;message&quot;:&quot;Not Found&quot;,&quot;path&quot;:&quot;xx&quot;&#125;</code></li>
</ul>
</li>
</ul>
<h3 id="ℹ️报错信息1️⃣"><a href="#ℹ️报错信息1️⃣" class="headerlink" title="ℹ️报错信息1️⃣"></a>ℹ️报错信息1️⃣</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">feign.FeignException: status 404 reading PostRepositoryRealClient#findAllByPostTypeAndPostStatusAndDeleted(PostParams); </span><br><span class="line">content: &#123;</span><br><span class="line">    status: 404,</span><br><span class="line">    error: Not Found,</span><br><span class="line">    exception: org.springframework.web.HttpMediaTypeNotSupportedException,</span><br><span class="line">    message:org.springframework.web.HttpMediaTypeNotSupportedException: Content type &#x27;application/json;charset=UTF-8&#x27; not supported</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="ℹ️报错信息2️⃣"><a href="#ℹ️报错信息2️⃣" class="headerlink" title="ℹ️报错信息2️⃣"></a>ℹ️报错信息2️⃣</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">feign.FeignException: status 404 reading xx#xx(xx); </span><br><span class="line">content:</span><br><span class="line">&#123;</span><br><span class="line">	&quot;status&quot;:404,</span><br><span class="line">	&quot;error&quot;:&quot;Not Found&quot;,</span><br><span class="line">	&quot;message&quot;:&quot;Not Found&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="🛠️相关尝试及解决方案"><a href="#🛠️相关尝试及解决方案" class="headerlink" title="🛠️相关尝试及解决方案"></a>🛠️相关尝试及解决方案</h2><h3 id="📚问题分析"><a href="#📚问题分析" class="headerlink" title="📚问题分析"></a>📚问题分析</h3><ul>
<li>第一类问题：可能导致的原因很多，本次是由于 json 反序列化失败导致的，具体排查方法可见<a href="#%F0%9F%A7%A0%E9%97%AE%E9%A2%983%EF%B8%8F%E2%83%A3400">下文</a>。</li>
<li>第二类问题：<ul>
<li>经过断点排查，发现原因如下：<ul>
<li><code>Spring MVC</code>前置处理器 <code>org.springframework.web.servlet.DispatcherServlet</code>在 handle 处理完成后，会获得一个<code>ModelAndView</code>类对象<code>mv</code>，交由 <code>processDispatchResult</code> 方法进行响应处理。</li>
<li>此时若被调用函数未加<code>@ResponseBody</code>，则<code>mv</code>不为<code>null</code>，则会调用<code>render(mv, request, response);</code>进行处理，其中会将<code>ModelAndView</code>转为<code>View</code>类型的对象<code>view</code>。</li>
<li>而当返回值不代表页面（不存在于 View 列表中）时，该转换过程则会报错，并返回<code>404</code>。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="🔨解决方案"><a href="#🔨解决方案" class="headerlink" title="🔨解决方案"></a>🔨解决方案</h3><ul>
<li><p>第二类问题：</p>
<ul>
<li>基于以上分析，在所有函数前标记注解<code>@ResponseBody</code>即可。（哪怕返回值类型是<code>void</code>。怎么觉得不太自然？）</li>
</ul>
</li>
<li><p>⚠️注：</p>
<ul>
<li>目前的解决方法还未触及根本，如 <code>ModelAndView</code>是什么？实际工程中如何区分需要<code>View</code>和不需要<code>View</code>的请求？</li>
</ul>
</li>
</ul>
<h1 id="🧠问题2️⃣——415"><a href="#🧠问题2️⃣——415" class="headerlink" title="🧠问题2️⃣——415"></a>🧠问题2️⃣——415</h1><h2 id="✏️问题描述-1"><a href="#✏️问题描述-1" class="headerlink" title="✏️问题描述"></a>✏️问题描述</h2><ul>
<li><p>随着不断断点排查，缩小范围，排查后发现以下函数接收不到请求：</p>
<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RequestMapping(value = &quot;/findAllByPostTypeAndPostStatusAndDeleted&quot;, method = RequestMethod.POST)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line">Page&lt;Post&gt; <span class="title function_">findAllByPostTypeAndPostStatusAndDeleted</span><span class="params">(<span class="meta">@RequestBody</span> PostParams postPrams)</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>调整日志等级为 DEBUG，尽可能查看更多信息。<em>（DEBUG 等级下比较烦的是信息太多了，难以检索关键信息，只能耐着性子仔细看看）</em></p>
</li>
<li><p>看到以下几条报错信息，简单检索之后开始分析：</p>
</li>
</ul>
<h3 id="ℹ️报错信息1️⃣-1"><a href="#ℹ️报错信息1️⃣-1" class="headerlink" title="ℹ️报错信息1️⃣"></a>ℹ️报错信息1️⃣</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">org.springframework.web.util.NestedServletException: Request processing failed; </span><br><span class="line">    nested exception is feign.FeignException: status 415 reading PostRepositoryRealClient#findAllByPostTypeAndPostStatusAndDeleted(PostParams); </span><br><span class="line">content: &#123;</span><br><span class="line">    &quot;status&quot;:415,</span><br><span class="line">    &quot;error&quot;:&quot;Unsupported Media Type&quot;,</span><br><span class="line">    &quot;exception&quot;:&quot;org.springframework.web.HttpMediaTypeNotSupportedException&quot;,</span><br><span class="line">    &quot;message&quot;:&quot;Unsupported Media Type&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="ℹ️报错信息2️⃣-1"><a href="#ℹ️报错信息2️⃣-1" class="headerlink" title="ℹ️报错信息2️⃣"></a>ℹ️报错信息2️⃣</h3><ul>
<li>（额外发现一条 WARNING）<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">WARN  o.s.h.c.j.MappingJackson2HttpMessageConverter - Failed to evaluate Jackson deserialization for type [[simple type, class com.raysmond.blog.common.models.PostParams]]: java.lang.NullPointerException</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h3 id="ℹ️报错信息3️⃣——DEBUG-日志"><a href="#ℹ️报错信息3️⃣——DEBUG-日志" class="headerlink" title="ℹ️报错信息3️⃣——DEBUG 日志"></a>ℹ️报错信息3️⃣——DEBUG 日志</h3><ul>
<li>（DEBUG日志很多，在这里也稍微记录一下分析过程，方便下次分析）</li>
<li>（很长，暂且记录下来）（不知道有没有可以自行选择是否展示代码的功能，比如不想展示的时候点一下按钮就缩起来）<ul>
<li>更新：原来这叫代码折叠<a href="#refer-anchor-2"><sup>[2]</sup></a>，已进行更新，点击下面文字展开代码</li>
</ul>
</li>
</ul>
<ol>
<li>首先接收到请求，输出信息<details>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">2023-08-xx xx:xx:xx.xxx [qtp237594516-48] DEBUG o.e.jetty.server.HttpChannel - REQUEST for //localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted on HttpChannelOverHttp@487628e&#123;r=1,c=false,a=IDLE,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;</span><br><span class="line">POST //localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted HTTP/1.1</span><br><span class="line">Host: localhost:8051</span><br><span class="line">User-Agent: python-requests/2.25.1</span><br><span class="line">Accept-Encoding: gzip, deflate</span><br><span class="line">Accept: */*</span><br><span class="line">Connection: keep-alive</span><br><span class="line">Content-Type: application/json</span><br><span class="line">Content-Length: 192</span><br><span class="line">...</span><br></pre></td></tr></table></figure></div>
</details>


</li>
</ol>
<ol start="2">
<li><p>其次进行一系列匹配，确认是否是相关资源的访问或用户登录登出的请求（下面举一个例子）</p>
<details>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">2023-08-xx xx:xx:xx.xxx [qtp237594516-48] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/css/**&#x27;]</span><br><span class="line">2023-08-xx xx:xx:xx.xxx [qtp237594516-48] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Checking match of request : &#x27;/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27;; against &#x27;/css/**&#x27;</span><br><span class="line">...</span><br><span class="line">2023-08-xx xx:xx:xx.xxx [qtp237594516-48] DEBUG o.s.s.w.a.i.FilterSecurityInterceptor - Authorization successful</span><br><span class="line">2023-08-xx xx:xx:xx.xxx [qtp237594516-48] DEBUG o.s.s.w.a.i.FilterSecurityInterceptor - RunAsManager did not change Authentication object</span><br><span class="line">2023-08-xx xx:xx:xx.xxx [qtp237594516-48] DEBUG o.s.s.web.FilterChainProxy - /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted reached end of additional filter chain; proceeding with original chain</span><br><span class="line">...</span><br></pre></td></tr></table></figure></div>
</details>
</li>
<li><p>找到对应函数，并解析参数<font color='red'>（ 此处有一个小疑问：JPA EntityManager、jetty 分别是干什么的？ ）</font></p>
<details>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">2023-08-28 23:36:15.512 [qtp237594516-48] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Returning cached instance of singleton bean &#x27;postRepositoryController&#x27;</span><br><span class="line">2023-08-28 23:36:15.514 [qtp237594516-48] DEBUG o.s.o.j.s.OpenEntityManagerInViewInterceptor - Opening JPA EntityManager in OpenEntityManagerInViewInterceptor</span><br><span class="line">2023-08-28 23:36:15.536 [qtp237594516-48] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2d95e62f[p=HttpParser&#123;s=CONTENT,0 of 192&#125;,g=HttpGenerator@d670640&#123;s=START&#125;]=&gt;HttpChannelOverHttp@487628e&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;&lt;-SocketChannelEndPoint@719a7db0&#123;/0:0:0:0:0:0:0:1:62012&lt;-&gt;/0:0:0:0:0:0:0:1:8051,OPEN,fill=-,flush=-,to=78/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2d95e62f[p=HttpParser&#123;s=CONTENT,0 of 192&#125;,g=HttpGenerator@d670640&#123;s=START&#125;]=&gt;HttpChannelOverHttp@487628e&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; parse HeapByteBuffer@45ff047e[p=264,l=456,c=8192,r=192]=&#123;POST /PostReposit...Length: 192\r\n\r\n&lt;&lt;&lt;&#123;&quot;tag&quot;: &quot;null&quot;, &quot;...eted&quot;: &quot;false&quot;&#125;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125; &#123;&#125;</span><br><span class="line">2023-08-28 23:36:15.536 [qtp237594516-48] DEBUG o.eclipse.jetty.http.HttpParser - parseNext s=CONTENT HeapByteBuffer@45ff047e[p=264,l=456,c=8192,r=192]=&#123;POST /PostReposit...Length: 192\r\n\r\n&lt;&lt;&lt;&#123;&quot;tag&quot;: &quot;null&quot;, &quot;...eted&quot;: &quot;false&quot;&#125;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;</span><br><span class="line">2023-08-28 23:36:15.537 [qtp237594516-48] DEBUG o.e.jetty.server.HttpChannel - HttpChannelOverHttp@487628e&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; onContent Content@2f24f2eb&#123;HeapByteBufferR@203ca537[p=264,l=456,c=8192,r=192]=&#123;POST /PostReposit...Length: 192\r\n\r\n&lt;&lt;&lt;&#123;&quot;tag&quot;: &quot;null&quot;, &quot;...eted&quot;: &quot;false&quot;&#125;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;&#125;</span><br><span class="line">2023-08-28 23:36:15.537 [qtp237594516-48] DEBUG o.eclipse.jetty.server.HttpInput - HttpInputOverHTTP@4925bcd[c=0,q=0,[0]=null,s=STREAM] addContent Content@2f24f2eb&#123;HeapByteBufferR@203ca537[p=264,l=456,c=8192,r=192]=&#123;POST /PostReposit...Length: 192\r\n\r\n&lt;&lt;&lt;&#123;&quot;tag&quot;: &quot;null&quot;, &quot;...eted&quot;: &quot;false&quot;&#125;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;&#125;</span><br><span class="line">2023-08-28 23:36:15.537 [qtp237594516-48] DEBUG o.eclipse.jetty.http.HttpParser - CONTENT --&gt; END</span><br><span class="line">2023-08-28 23:36:15.537 [qtp237594516-48] DEBUG o.e.jetty.server.HttpChannel - HttpChannelOverHttp@487628e&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; onContentComplete</span><br><span class="line">2023-08-28 23:36:15.537 [qtp237594516-48] DEBUG o.e.jetty.server.HttpChannel - HttpChannelOverHttp@487628e&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; onRequestComplete</span><br><span class="line">2023-08-28 23:36:15.537 [qtp237594516-48] DEBUG o.eclipse.jetty.server.HttpInput - HttpInputOverHTTP@4925bcd[c=0,q=1,[0]=EOF,s=STREAM] addContent EOF</span><br></pre></td></tr></table></figure></div>
</details>
</li>
<li><p>开始处理相关信息，并出现上述 报错信息2️⃣，</p>
<details>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">2023-08-28 23:36:15.537 [qtp237594516-48] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2d95e62f[p=HttpParser&#123;s=END,192 of 192&#125;,g=HttpGenerator@d670640&#123;s=START&#125;]=&gt;HttpChannelOverHttp@487628e&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;&lt;-SocketChannelEndPoint@719a7db0&#123;/0:0:0:0:0:0:0:1:62012&lt;-&gt;/0:0:0:0:0:0:0:1:8051,OPEN,fill=-,flush=-,to=79/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2d95e62f[p=HttpParser&#123;s=END,192 of 192&#125;,g=HttpGenerator@d670640&#123;s=START&#125;]=&gt;HttpChannelOverHttp@487628e&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; parsed false HttpParser&#123;s=END,192 of 192&#125;</span><br><span class="line">2023-08-28 23:36:15.537 [qtp237594516-48] DEBUG o.eclipse.jetty.server.HttpInput - HttpInputOverHTTP@4925bcd[c=1,q=1,[0]=EOF,s=STREAM] read 1 from Content@2f24f2eb&#123;HeapByteBufferR@203ca537[p=265,l=456,c=8192,r=191]=&#123;POST /PostReposit...ength: 192\r\n\r\n&#123;&lt;&lt;&lt;&quot;tag&quot;: &quot;null&quot;, &quot;p...eted&quot;: &quot;false&quot;&#125;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;&#125;</span><br><span class="line">2023-08-28 23:36:15.548 [qtp237594516-48] WARN  o.s.h.c.j.MappingJackson2HttpMessageConverter - Failed to evaluate Jackson deserialization for type [[simple type, class com.raysmond.blog.common.models.PostParams]]</span><br></pre></td></tr></table></figure></div>
</details></li>
<li><p>下面是更细致的报错信息</p>
<details>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">java.lang.NullPointerException: null</span><br><span class="line">	at com.fasterxml.jackson.databind.jsontype.impl.SubTypeValidator.validateSubType(SubTypeValidator.java:84)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory._validateSubType(BeanDeserializerFactory.java:867)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.createBeanDeserializer(BeanDeserializerFactory.java:143)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer2(DeserializerCache.java:403)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer(DeserializerCache.java:349)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:264)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)</span><br><span class="line">	at com.fasterxml.jackson.databind.DeserializationContext.findNonContextualValueDeserializer(DeserializationContext.java:466)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:479)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:293)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.DeserializerCache.hasValueDeserializerFor(DeserializerCache.java:191)</span><br><span class="line">	at com.fasterxml.jackson.databind.DeserializationContext.hasValueDeserializerFor(DeserializationContext.java:421)</span><br><span class="line">	at com.fasterxml.jackson.databind.ObjectMapper.canDeserialize(ObjectMapper.java:2729)</span><br><span class="line">	at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.canRead(AbstractJackson2HttpMessageConverter.java:159)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodArgumentResolver.readWithMessageConverters(AbstractMessageConverterMethodArgumentResolver.java:195)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.readWithMessageConverters(RequestResponseBodyMethodProcessor.java:150)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.resolveArgument(RequestResponseBodyMethodProcessor.java:128)</span><br><span class="line">	at org.springframework.web.method.support.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:121)</span><br><span class="line">	at org.springframework.web.method.support.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:158)</span><br><span class="line">	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:128)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)</span><br><span class="line">	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)</span><br><span class="line">	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)</span><br><span class="line">	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)</span><br><span class="line">	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)</span><br><span class="line">	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:841)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1650)</span><br><span class="line">	at org.eclipse.jetty.websocket.server.WebSocketUpgradeFilter.doFilter(WebSocketUpgradeFilter.java:206)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317)</span><br><span class="line">	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)</span><br><span class="line">	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177)</span><br><span class="line">	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347)</span><br><span class="line">	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)</span><br><span class="line">	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)</span><br><span class="line">	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:190)</span><br><span class="line">	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:188)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1253)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:168)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)</span><br><span class="line">	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:166)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1155)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)</span><br><span class="line">	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)</span><br><span class="line">	at org.eclipse.jetty.server.Server.handle(Server.java:561)</span><br><span class="line">	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:334)</span><br><span class="line">	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)</span><br><span class="line">	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:279)</span><br><span class="line">	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:104)</span><br><span class="line">	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:124)</span><br><span class="line">	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:679)</span><br><span class="line">	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:597)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:748)</span><br></pre></td></tr></table></figure></div>
</details>
</li>
<li><p>再往后就出现了报错信息，之后就是我们在前端所看到的报错信息</p>
<details>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">2023-08-28 23:36:15.551 [qtp237594516-48] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Returning cached instance of singleton bean &#x27;exceptionHandlerController&#x27;</span><br><span class="line">2023-08-28 23:36:15.554 [qtp237594516-48] DEBUG o.s.s.w.c.HttpSessionSecurityContextRepository - SecurityContext is empty or contents are anonymous - context will not be stored in HttpSession.</span><br><span class="line">2023-08-28 23:36:15.554 [qtp237594516-48] DEBUG o.e.j.s.ErrorPageErrorHandler - getErrorPage(POST /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted) =&gt; error_page=/error (from global default)</span><br><span class="line">2023-08-28 23:36:15.555 [qtp237594516-48] DEBUG o.e.j.s.handler.ErrorHandler - error page dispatch /error-&gt;Dispatcher@0x6c792fdb&#123;null,/error&#125;</span><br><span class="line">2023-08-28 23:36:15.556 [qtp237594516-48] DEBUG o.e.j.s.handler.ContextHandler - scope /||/error @ o.s.b.c.e.j.JettyEmbeddedWebAppContext@79c2bc34&#123;/,[file:///private/var/folders/sg/fcqtq3fx50b9tfz0jmw8jh3m0000gq/T/jetty-docbase.8645957883152335123.8051/, jar:file:/Users/freshwind/.gradle/caches/modules-2/files-2.1/org.webjars/jquery/2.1.1/dd89e356066869550b5509c4370f995ad6698d9a/jquery-2.1.1.jar!/META-INF/resources, jar:file:/Users/freshwind/.gradle/caches/modules-2/files-2.1/org.webjars/bootstrap/3.2.0/aadbf822539bc170014701382cff887094c4c3df/bootstrap-3.2.0.jar!/META-INF/resources, jar:file:/Users/freshwind/.gradle/caches/modules-2/files-2.1/org.webjars/font-awesome/4.7.0/ae86dfacae19ede1910de53f38a573215256646b/font-awesome-4.7.0.jar!/META-INF/resources, jar:file:/Users/freshwind/.gradle/caches/modules-2/files-2.1/org.webjars/ace/1.2.8/dea95ef85f17e404c3930ce0618585d64ac93568/ace-1.2.8.jar!/META-INF/resources],AVAILABLE&#125;</span><br><span class="line">2023-08-28 23:36:15.556 [qtp237594516-48] DEBUG o.e.j.s.handler.ContextHandler - context=||/error @ o.s.b.c.e.j.JettyEmbeddedWebAppContext@79c2bc34&#123;/,[file:///private/var/folders/sg/fcqtq3fx50b9tfz0jmw8jh3m0000gq/T/jetty-docbase.8645957883152335123.8051/, jar:file:/Users/freshwind/.gradle/caches/modules-2/files-2.1/org.webjars/jquery/2.1.1/dd89e356066869550b5509c4370f995ad6698d9a/jquery-2.1.1.jar!/META-INF/resources, jar:file:/Users/freshwind/.gradle/caches/modules-2/files-2.1/org.webjars/bootstrap/3.2.0/aadbf822539bc170014701382cff887094c4c3df/bootstrap-3.2.0.jar!/META-INF/resources, jar:file:/Users/freshwind/.gradle/caches/modules-2/files-2.1/org.webjars/font-awesome/4.7.0/ae86dfacae19ede1910de53f38a573215256646b/font-awesome-4.7.0.jar!/META-INF/resources, jar:file:/Users/freshwind/.gradle/caches/modules-2/files-2.1/org.webjars/ace/1.2.8/dea95ef85f17e404c3930ce0618585d64ac93568/ace-1.2.8.jar!/META-INF/resources],AVAILABLE&#125;</span><br><span class="line">2023-08-28 23:36:15.556 [qtp237594516-48] DEBUG org.eclipse.jetty.server.session - sessionHandler=org.eclipse.jetty.server.session.SessionHandler2006081398==dftMaxIdleSec=1800</span><br><span class="line">2023-08-28 23:36:15.556 [qtp237594516-48] DEBUG org.eclipse.jetty.server.session - session=null</span><br><span class="line">2023-08-28 23:36:15.556 [qtp237594516-48] DEBUG o.e.jetty.servlet.ServletHandler - servlet |/error|null -&gt; dispatcherServlet@7ef5559e==org.springframework.web.servlet.DispatcherServlet,jsp=null,order=-1,inst=true</span><br><span class="line">2023-08-28 23:36:15.556 [qtp237594516-48] DEBUG o.e.jetty.servlet.ServletHandler - chain=null</span><br><span class="line">2023-08-28 23:36:15.558 [qtp237594516-48] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Returning cached instance of singleton bean &#x27;basicErrorController&#x27;</span><br><span class="line">2023-08-28 23:36:15.574 [qtp237594516-48] DEBUG o.e.jetty.server.HttpChannel - sendResponse info=null content=DirectByteBuffer@3d1f33c7[p=0,l=257,c=32768,r=257]=&#123;&lt;&lt;&lt;&#123;&quot;timestamp&quot;:1693...tusAndDeleted&quot;&#125;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125; complete=false committing=true callback=Blocker@244f040d&#123;null&#125;</span><br><span class="line">2023-08-28 23:36:15.574 [qtp237594516-48] DEBUG o.e.jetty.server.HttpChannel - COMMIT for /error on HttpChannelOverHttp@487628e&#123;r=1,c=true,a=DISPATCHED,uri=//localhost:8051/error&#125;</span><br><span class="line">415 null HTTP/1.1</span><br><span class="line">Date: Mon, 28 Aug 2023 15:36:15 GMT</span><br><span class="line">X-Content-Type-Options: nosniff</span><br><span class="line">X-XSS-Protection: 1; mode=block</span><br><span class="line">Pragma: no-cache</span><br><span class="line">X-Frame-Options: DENY</span><br><span class="line">Content-Type: application/json;charset=utf-8</span><br></pre></td></tr></table></figure></div>
</details>

</li>
</ol>
<h2 id="🛠️相关尝试及解决方案-1"><a href="#🛠️相关尝试及解决方案-1" class="headerlink" title="🛠️相关尝试及解决方案"></a>🛠️相关尝试及解决方案</h2><h3 id="🔍简单检索信息"><a href="#🔍简单检索信息" class="headerlink" title="🔍简单检索信息"></a>🔍简单检索信息</h3><ul>
<li>HTTP请求415错误 – 不支持的媒体类型(Unsupported media type)<a href="#refer-anchor-1"><sup>[1]</sup></a></li>
<li>通常可以检查以下情况：<ol>
<li>检查你的 http 请求头信息，比如 因为 User-Agent 被服务器设置拒绝请求了；</li>
</ol>
<ul>
<li>比如你写的的爬虫，就很有可能因为没有伪装成浏览器，被拒绝请求</li>
</ul>
<ol start="2">
<li>检查你的 http 请求方法，以及服务器端的设置</li>
</ol>
<ul>
<li>比如：有一个强制用 post 请求的接口，你是否使用了非 post 请求</li>
</ul>
<ol start="3">
<li>post 请求参数设置，必须为 json 格式</li>
</ol>
</li>
</ul>
<h3 id="📚问题分析-1"><a href="#📚问题分析-1" class="headerlink" title="📚问题分析"></a>📚问题分析</h3><ul>
<li><p>根据相关信息，推测大概率是所传输数据无法解析问题。根据相关信息，优先检查如何解决<a href="#%E2%84%B9%EF%B8%8F%E6%8A%A5%E9%94%99%E4%BF%A1%E6%81%AF2%EF%B8%8F%E2%83%A3">报错信息2️⃣</a>。</p>
<ul>
<li>经过简单检索，发现似乎没有相关信息，因此决定基于报错信息查看源码，理解报错原因。</li>
</ul>
</li>
<li><p>首先从报错信息<code>at com.fasterxml.jackson.databind.ObjectMapper.canDeserialize(ObjectMapper.java:2729)</code>定位到 ObjectMapper，查看相关逻辑。</p>
<ul>
<li>根据报错信息一步步找到<code>com/fasterxml/jackson/databind/jsontype/impl/SubTypeValidator.java:84</code>，相关函数代码如下：<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">validateSubType</span><span class="params">(DeserializationContext ctxt, JavaType type)</span> <span class="keyword">throws</span> JsonMappingException</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// There are certain nasty classes that could cause problems, mostly</span></span><br><span class="line">    <span class="comment">// via default typing -- catch them here.</span></span><br><span class="line">    <span class="keyword">final</span> Class&lt;?&gt; raw = type.getRawClass();</span><br><span class="line">    <span class="type">String</span> <span class="variable">full</span> <span class="operator">=</span> raw.getName();</span><br><span class="line"></span><br><span class="line">    main_check:</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (_cfgIllegalClassNames.contains(full)) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 18-Dec-2017, tatu: As per [databind#1855], need bit more sophisticated handling</span></span><br><span class="line">        <span class="comment">//    for some Spring framework types</span></span><br><span class="line">        <span class="keyword">if</span> (full.startsWith(PREFIX_STRING)) &#123;</span><br><span class="line">            <span class="keyword">for</span> (Class&lt;?&gt; cls = raw; cls != Object.class; cls = cls.getSuperclass()) &#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> cls.getSimpleName();</span><br><span class="line">                <span class="comment">// looking for &quot;AbstractBeanFactoryPointcutAdvisor&quot; but no point to allow any is there?</span></span><br><span class="line">                <span class="keyword">if</span> (<span class="string">&quot;AbstractPointcutAdvisor&quot;</span>.equals(name)</span><br><span class="line">                        <span class="comment">// ditto  for &quot;FileSystemXmlApplicationContext&quot;: block all ApplicationContexts</span></span><br><span class="line">                        || <span class="string">&quot;AbstractApplicationContext&quot;</span>.equals(name)) &#123;</span><br><span class="line">                    <span class="keyword">break</span> main_check;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125; <span class="keyword">while</span> (<span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">throw</span> JsonMappingException.from(ctxt,</span><br><span class="line">            String.format(<span class="string">&quot;Illegal type (%s) to deserialize: prevented for security reasons&quot;</span>, full));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
</ul>
</li>
<li><p>在其中的<code>for (Class&lt;?&gt; cls = raw; cls != Object.class; cls = cls.getSuperclass()) </code>循环中，如果当前<code>cls</code>为<code>interface</code>接口类（在本次测试中<code>cls</code>为<code>org.springframework.data.domain.Pageable</code>接口），则经过<code>cls = cls.getSuperclass()</code>语句后会使得<code>cls==null</code>。</p>
</li>
<li><p>检索该语句，发现 GitHub 上有人提过该 bug<a href="#refer-anchor-3"><sup>[3]</sup></a>。（此时在心里猜测可能是版本问题，因为前文中查看<code>ObjectMapper.java</code>文件并增加断点后发现同时存在 2.8.11 和 2.9.2 两个版本的同名文件）</p>
</li>
<li><p>根据 Github 讨论结果：<code>Fix included in 2.8.11.1 / 2.9.4</code>，尝试清除所有现有包并更新到最新版本。</p>
</li>
</ul>
<h3 id="🔨尝试方案1️⃣——清除所有包并更新到最新版本"><a href="#🔨尝试方案1️⃣——清除所有包并更新到最新版本" class="headerlink" title="🔨尝试方案1️⃣——清除所有包并更新到最新版本"></a>🔨尝试方案1️⃣——清除所有包并更新到最新版本</h3><ul>
<li>检查 <code>build.gradle</code> 发现使用的版本为 2.8.11，看来确实是版本问题。修改为以下内容：（Maven 采用相应的修改方式，只需确保版本更新即可）<div class="code-container" data-rel="Gradle"><figure class="iseeu highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="keyword">dependencies</span> &#123;</span><br><span class="line">	...</span><br><span class="line">	<span class="keyword">compile</span> <span class="keyword">group</span>: <span class="string">&#x27;com.fasterxml.jackson.core&#x27;</span>, name: <span class="string">&#x27;jackson-databind&#x27;</span>, version: <span class="string">&#x27;+&#x27;</span></span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
<li>保险起见，可以彻底清理 gradle 缓存（后续发现这里清理不彻底可能导致存在问题）（以下为 mac 版本）<a href="#refer-anchor-5"><sup>[5]</sup></a>：<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">./gradlew --stop</span><br><span class="line"><span class="built_in">rm</span> -rf ~/.gradle/caches/</span><br></pre></td></tr></table></figure></div></li>
<li>重新加载包（例如在 idea 下点击 reload 按钮）</li>
<li>静静等待…（吐槽一下，gradle 每次加载太久了）</li>
<li><em>发现自己的 build.gradle 文件格式乱得一塌糊涂，另立一个 flag⛳️，有空补一篇 gradle 的基础知识</em></li>
<li>结果：功夫不负有心人，变成 <code>400 Bad Requests</code> 了。</li>
</ul>
<h1 id="🧠问题3️⃣——400"><a href="#🧠问题3️⃣——400" class="headerlink" title="🧠问题3️⃣——400"></a>🧠问题3️⃣——400</h1><h2 id="✏️问题描述-2"><a href="#✏️问题描述-2" class="headerlink" title="✏️问题描述"></a>✏️问题描述</h2><ul>
<li>前期修复后，开始出现 400 问题，主要信息为<code>Bad Request</code>（相当于啥也没有）。</li>
</ul>
<h3 id="ℹ️报错信息1️⃣-2"><a href="#ℹ️报错信息1️⃣-2" class="headerlink" title="ℹ️报错信息1️⃣"></a>ℹ️报错信息1️⃣</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">content: &#123;</span><br><span class="line">	&quot;status&quot;:400,</span><br><span class="line">	&quot;error&quot;:&quot;Bad Request&quot;,</span><br><span class="line">	&quot;exception&quot;: &quot;org.springframework.http.converter.HttpMessageNotReadableException&quot;,</span><br><span class="line">	&quot;message&quot;:&quot;Bad Request&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>


<h3 id="ℹ️报错信息2️⃣——DEBUG-日志"><a href="#ℹ️报错信息2️⃣——DEBUG-日志" class="headerlink" title="ℹ️报错信息2️⃣——DEBUG 日志"></a>ℹ️报错信息2️⃣——DEBUG 日志</h3><ul>
<li>同样，仔细检查日志，以下隐去一些重复的不重要部分</li>
</ul>
<ol>
<li><p>首先接收到请求，输出信息</p>
<details>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">POST //localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted HTTP/1.1</span><br><span class="line">Host: localhost:8051</span><br><span class="line">User-Agent: python-requests/2.31.0</span><br><span class="line">Accept-Encoding: gzip, deflate, br</span><br><span class="line">Accept: */*</span><br><span class="line">Connection: keep-alive</span><br><span class="line">Content-Type: application/json</span><br><span class="line">Content-Length: 191</span><br></pre></td></tr></table></figure></div>
</details>
</li>
<li><p>其次进行一系列匹配，确认是否是相关资源的访问或用户登录登出的请求</p>
</li>
</ol>
<ul>
<li>其中有一部分之前没注意到的，是进行身份认证<detail>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">2023-08-30 18:13:24.851 [qtp1307131613-30] DEBUG o.s.s.w.a.i.FilterSecurityInterceptor - Secure object: FilterInvocation: URL: /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted; Attributes: [permitAll]</span><br><span class="line">2023-08-30 18:13:24.851 [qtp1307131613-30] DEBUG o.s.s.w.a.i.FilterSecurityInterceptor - Previously Authenticated: org.springframework.security.authentication.AnonymousAuthenticationToken@9055c2bc: Principal: anonymousUser; Credentials: [PROTECTED]; Authenticated: true; Details: org.springframework.security.web.authentication.WebAuthenticationDetails@b364: RemoteIpAddress: 0:0:0:0:0:0:0:1; SessionId: null; Granted Authorities: ROLE_ANONYMOUS</span><br><span class="line">2023-08-30 18:13:24.856 [qtp1307131613-30] DEBUG o.s.s.a.vote.AffirmativeBased - Voter: org.springframework.security.web.access.expression.WebExpressionVoter@4251b99a, returned: 1</span><br><span class="line">2023-08-30 18:13:24.856 [qtp1307131613-30] DEBUG o.s.s.w.a.i.FilterSecurityInterceptor - Authorization successful</span><br><span class="line">2023-08-30 18:13:24.856 [qtp1307131613-30] DEBUG o.s.s.w.a.i.FilterSecurityInterceptor - RunAsManager did not change Authentication object</span><br><span class="line">2023-08-30 18:13:24.856 [qtp1307131613-30] DEBUG o.s.s.web.FilterChainProxy - /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted reached end of additional filter chain; proceeding with original chain</span><br></pre></td></tr></table></figure></div>
</detail>
</li>
</ul>
<ol start="3">
<li><p>找到对应函数，并解析参数</p>
<detail>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">2023-08-30 18:13:24.856 [qtp1307131613-30] DEBUG o.e.jetty.servlet.ServletHandler - call filter Jetty_WebSocketUpgradeFilter</span><br><span class="line">2023-08-30 18:13:24.859 [qtp1307131613-30] DEBUG o.e.jetty.servlet.ServletHandler - call servlet dispatcherServlet@7ef5559e==org.springframework.web.servlet.DispatcherServlet,jsp=null,order=-1,inst=true</span><br><span class="line">2023-08-30 18:13:24.869 [qtp1307131613-30] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Returning cached instance of singleton bean &#x27;postRepositoryController&#x27;</span><br><span class="line">2023-08-30 18:13:24.869 [qtp1307131613-30] DEBUG o.s.o.j.s.OpenEntityManagerInViewInterceptor - Opening JPA EntityManager in OpenEntityManagerInViewInterceptor</span><br><span class="line">2023-08-30 18:13:24.879 [qtp1307131613-30] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@5a00b8c9[p=HttpParser&#123;s=CONTENT,0 of 191&#125;,g=HttpGenerator@648f8367&#123;s=START&#125;]=&gt;HttpChannelOverHttp@4c618052&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;&lt;-SocketChannelEndPoint@6e51a4e4&#123;/0:0:0:0:0:0:0:1:55642&lt;-&gt;/0:0:0:0:0:0:0:1:8051,OPEN,fill=-,flush=-,to=40/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@5a00b8c9[p=HttpParser&#123;s=CONTENT,0 of 191&#125;,g=HttpGenerator@648f8367&#123;s=START&#125;]=&gt;HttpChannelOverHttp@4c618052&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; parse HeapByteBuffer@60d27582[p=268,l=459,c=8192,r=191]=&#123;POST /PostReposit...Length: 191\r\n\r\n&lt;&lt;&lt;&#123;&quot;tag&quot;: &quot;tag&quot;, &quot;p...eted&quot;: &quot;false&quot;&#125;&gt;&gt;&gt;gnoreCase&quot;:false,...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125; &#123;&#125;</span><br><span class="line">2023-08-30 18:13:24.879 [qtp1307131613-30] DEBUG o.eclipse.jetty.http.HttpParser - parseNext s=CONTENT HeapByteBuffer@60d27582[p=268,l=459,c=8192,r=191]=&#123;POST /PostReposit...Length: 191\r\n\r\n&lt;&lt;&lt;&#123;&quot;tag&quot;: &quot;tag&quot;, &quot;p...eted&quot;: &quot;false&quot;&#125;&gt;&gt;&gt;gnoreCase&quot;:false,...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;</span><br><span class="line">2023-08-30 18:13:24.879 [qtp1307131613-30] DEBUG o.e.jetty.server.HttpChannel - HttpChannelOverHttp@4c618052&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; onContent Content@68dfa4ee&#123;HeapByteBufferR@70d39629[p=268,l=459,c=8192,r=191]=&#123;POST /PostReposit...Length: 191\r\n\r\n&lt;&lt;&lt;&#123;&quot;tag&quot;: &quot;tag&quot;, &quot;p...eted&quot;: &quot;false&quot;&#125;&gt;&gt;&gt;gnoreCase&quot;:false,...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;&#125;</span><br><span class="line">2023-08-30 18:13:24.879 [qtp1307131613-30] DEBUG o.eclipse.jetty.server.HttpInput - HttpInputOverHTTP@33d91dcb[c=0,q=0,[0]=null,s=STREAM] addContent Content@68dfa4ee&#123;HeapByteBufferR@70d39629[p=268,l=459,c=8192,r=191]=&#123;POST /PostReposit...Length: 191\r\n\r\n&lt;&lt;&lt;&#123;&quot;tag&quot;: &quot;tag&quot;, &quot;p...eted&quot;: &quot;false&quot;&#125;&gt;&gt;&gt;gnoreCase&quot;:false,...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;&#125;</span><br><span class="line">2023-08-30 18:13:24.879 [qtp1307131613-30] DEBUG o.eclipse.jetty.http.HttpParser - CONTENT --&gt; END</span><br><span class="line">2023-08-30 18:13:24.879 [qtp1307131613-30] DEBUG o.e.jetty.server.HttpChannel - HttpChannelOverHttp@4c618052&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; onContentComplete</span><br><span class="line">2023-08-30 18:13:24.879 [qtp1307131613-30] DEBUG o.e.jetty.server.HttpChannel - HttpChannelOverHttp@4c618052&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; onRequestComplete</span><br><span class="line">2023-08-30 18:13:24.879 [qtp1307131613-30] DEBUG o.eclipse.jetty.server.HttpInput - HttpInputOverHTTP@33d91dcb[c=0,q=1,[0]=EOF,s=STREAM] addContent EOF</span><br><span class="line">2023-08-30 18:13:24.880 [qtp1307131613-30] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@5a00b8c9[p=HttpParser&#123;s=END,191 of 191&#125;,g=HttpGenerator@648f8367&#123;s=START&#125;]=&gt;HttpChannelOverHttp@4c618052&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;&lt;-SocketChannelEndPoint@6e51a4e4&#123;/0:0:0:0:0:0:0:1:55642&lt;-&gt;/0:0:0:0:0:0:0:1:8051,OPEN,fill=-,flush=-,to=41/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@5a00b8c9[p=HttpParser&#123;s=END,191 of 191&#125;,g=HttpGenerator@648f8367&#123;s=START&#125;]=&gt;HttpChannelOverHttp@4c618052&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; parsed false HttpParser&#123;s=END,191 of 191&#125;</span><br><span class="line">2023-08-30 18:13:24.880 [qtp1307131613-30] DEBUG o.eclipse.jetty.server.HttpInput - HttpInputOverHTTP@33d91dcb[c=1,q=1,[0]=EOF,s=STREAM] read 1 from Content@68dfa4ee&#123;HeapByteBufferR@70d39629[p=269,l=459,c=8192,r=190]=&#123;POST /PostReposit...ength: 191\r\n\r\n&#123;&lt;&lt;&lt;&quot;tag&quot;: &quot;tag&quot;, &quot;po...eted&quot;: &quot;false&quot;&#125;&gt;&gt;&gt;gnoreCase&quot;:false,...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;&#125;</span><br><span class="line">2023-08-30 18:13:24.880 [qtp1307131613-30] DEBUG o.eclipse.jetty.server.HttpInput - HttpInputOverHTTP@33d91dcb[c=191,q=1,[0]=EOF,s=STREAM] read 190 from Content@68dfa4ee&#123;HeapByteBufferR@70d39629[p=459,l=459,c=8192,r=0]=&#123;POST /PostReposit...eted&quot;: &quot;false&quot;&#125;&lt;&lt;&lt;&gt;&gt;&gt;gnoreCase&quot;:false,...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;&#125;</span><br><span class="line">2023-08-30 18:13:24.881 [qtp1307131613-30] DEBUG o.e.jetty.server.HttpConnection - releaseRequestBuffer HttpConnection@5a00b8c9[p=HttpParser&#123;s=END,191 of 191&#125;,g=HttpGenerator@648f8367&#123;s=START&#125;]=&gt;HttpChannelOverHttp@4c618052&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;&lt;-SocketChannelEndPoint@6e51a4e4&#123;/0:0:0:0:0:0:0:1:55642&lt;-&gt;/0:0:0:0:0:0:0:1:8051,OPEN,fill=-,flush=-,to=41/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@5a00b8c9[p=HttpParser&#123;s=END,191 of 191&#125;,g=HttpGenerator@648f8367&#123;s=START&#125;]=&gt;HttpChannelOverHttp@4c618052&#123;r=1,c=false,a=DISPATCHED,uri=//localhost:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;</span><br><span class="line">2023-08-30 18:13:24.884 [qtp1307131613-30] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Returning cached instance of singleton bean &#x27;exceptionHandlerController&#x27;</span><br><span class="line">2023-08-30 18:13:24.886 [qtp1307131613-30] DEBUG o.s.s.w.c.HttpSessionSecurityContextRepository - SecurityContext is empty or contents are anonymous - context will not be stored in HttpSession.</span><br></pre></td></tr></table></figure></div>
</detail>
</li>
<li><p>这里比较棘手，突然就开始错误处理，并未说明是什么原因</p>
<detail>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">2023-08-30 18:13:24.886 [qtp1307131613-30] DEBUG o.e.j.s.ErrorPageErrorHandler - getErrorPage(POST /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted) =&gt; error_page=/error (from global default)</span><br><span class="line">2023-08-30 18:13:24.887 [qtp1307131613-30] DEBUG o.e.j.s.handler.ErrorHandler - error page dispatch /error-&gt;Dispatcher@0x30bd8073&#123;null,/error&#125;</span><br><span class="line">2023-08-30 18:13:24.887 [qtp1307131613-30] DEBUG o.e.j.s.handler.ContextHandler - scope /||/error @ o.s.b.c.e.j.JettyEmbeddedWebAppContext@15c1b543&#123;/,[file:///private/var/folders/sg/fcqtq3fx50b9tfz0jmw8jh3m0000gq/T/jetty-docbase.986210962886620735.8051/],AVAILABLE&#125;</span><br><span class="line">2023-08-30 18:13:24.887 [qtp1307131613-30] DEBUG o.e.j.s.handler.ContextHandler - context=||/error @ o.s.b.c.e.j.JettyEmbeddedWebAppContext@15c1b543&#123;/,[file:///private/var/folders/sg/fcqtq3fx50b9tfz0jmw8jh3m0000gq/T/jetty-docbase.986210962886620735.8051/],AVAILABLE&#125;</span><br><span class="line">2023-08-30 18:13:24.887 [qtp1307131613-30] DEBUG org.eclipse.jetty.server.session - sessionHandler=org.eclipse.jetty.server.session.SessionHandler596984576==dftMaxIdleSec=1800</span><br><span class="line">2023-08-30 18:13:24.887 [qtp1307131613-30] DEBUG org.eclipse.jetty.server.session - session=null</span><br><span class="line">2023-08-30 18:13:24.887 [qtp1307131613-30] DEBUG o.e.jetty.servlet.ServletHandler - servlet |/error|null -&gt; dispatcherServlet@7ef5559e==org.springframework.web.servlet.DispatcherServlet,jsp=null,order=-1,inst=true</span><br><span class="line">2023-08-30 18:13:24.887 [qtp1307131613-30] DEBUG o.e.jetty.servlet.ServletHandler - chain=null</span><br><span class="line">2023-08-30 18:13:24.888 [qtp1307131613-30] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Returning cached instance of singleton bean &#x27;basicErrorController&#x27;</span><br><span class="line">2023-08-30 18:13:24.900 [qtp1307131613-30] DEBUG o.e.jetty.server.HttpChannel - sendResponse info=null content=DirectByteBuffer@4a6a174d[p=0,l=243,c=32768,r=243]=&#123;&lt;&lt;&lt;&#123;&quot;timestamp&quot;:1693...tusAndDeleted&quot;&#125;&gt;&gt;&gt;tus 500 reading P...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125; complete=false committing=true callback=Blocker@49de1203&#123;null&#125;</span><br><span class="line">2023-08-30 18:13:24.901 [qtp1307131613-30] DEBUG o.e.jetty.server.HttpChannel - COMMIT for /error on HttpChannelOverHttp@4c618052&#123;r=1,c=true,a=DISPATCHED,uri=//localhost:8051/error&#125;</span><br><span class="line">400 null HTTP/1.1</span><br><span class="line">Date: Wed, 30 Aug 2023 10:13:24 GMT</span><br><span class="line">X-Content-Type-Options: nosniff</span><br><span class="line">X-XSS-Protection: 1; mode=block</span><br><span class="line">Pragma: no-cache</span><br><span class="line">X-Frame-Options: DENY</span><br><span class="line">Content-Type: application/json;charset=utf-8</span><br><span class="line">\</span><br><span class="line">2023-08-30 18:13:24.901 [qtp1307131613-30] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@329269b6[PROCESSING][i=HTTP/1.1&#123;s=400,h=6,cl=-1&#125;,cb=org.eclipse.jetty.server.HttpChannel$CommitCallback@6e70c98f] generate: NEED_HEADER (null,[p=0,l=243,c=32768,r=243],false)@START</span><br><span class="line">2023-08-30 18:13:24.901 [qtp1307131613-30] DEBUG o.e.jetty.http.HttpGenerator - generateHeaders HTTP/1.1&#123;s=400,h=6,cl=-1&#125; last=false content=DirectByteBuffer@4a6a174d[p=0,l=243,c=32768,r=243]=&#123;&lt;&lt;&lt;&#123;&quot;timestamp&quot;:1693...tusAndDeleted&quot;&#125;&gt;&gt;&gt;tus 500 reading P...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;</span><br><span class="line">2023-08-30 18:13:24.901 [qtp1307131613-30] DEBUG o.e.jetty.http.HttpGenerator - Date: Wed, 30 Aug 2023 10:13:24 GMT</span><br><span class="line">X-Content-Type-Options: nosniff</span><br><span class="line">X-XSS-Protection: 1; mode=block</span><br><span class="line">Pragma: no-cache</span><br><span class="line">X-Frame-Options: DENY</span><br><span class="line">Content-Type: application/json;charset=utf-8</span><br></pre></td></tr></table></figure></div>
</detail>

</li>
</ol>
<h2 id="🛠️相关尝试及解决方案-2"><a href="#🛠️相关尝试及解决方案-2" class="headerlink" title="🛠️相关尝试及解决方案"></a>🛠️相关尝试及解决方案</h2><h3 id="🔍简单检索信息-1"><a href="#🔍简单检索信息-1" class="headerlink" title="🔍简单检索信息"></a>🔍简单检索信息</h3><ul>
<li><p>Spring MVC : 400 错误是怎么发生的 ?<a href="#refer-anchor-4"><sup>[4]</sup></a></p>
</li>
<li><p><code>Spring MVC</code>前置处理器 <code>org.springframework.web.servlet.DispatcherServlet</code> 处理一个请求时，会在<code>doDispatch</code>方法中尝试捕获 <code>handler</code> 匹配过程， <code>handler adapter</code> 匹配过程和 <code>handler</code> 执行过程中的异常，该异常记做 <code>dispatchException</code>。</p>
</li>
<li><p>具体来说，对请求处理的主体流程可以简单地理解为两个步骤：</p>
<ol>
<li>寻找 <code>handler</code> 并执行以处理请求（<code>request</code>）。细分为以下几个方面：<ul>
<li>目标 <code>handler</code> <strong>匹配</strong>过程，</li>
<li>目标 <code>handler adapter</code> <strong>匹配</strong>过程，</li>
<li>目标 <code>handler</code> <strong>执行</strong>过程，</li>
<li>成功处理结果记录到 <code>ModelAndView mv</code>，</li>
<li>异常捕获并记录到 <code>Exception dispatchException</code></li>
</ul>
</li>
<li>加工handler请求处理结果做出响应（<code>response</code>）</li>
</ol>
</li>
<li><p>其中步骤 2 由 <code>processDispatchResult</code> 方法完成。</p>
</li>
<li><p>若捕获到异常，将调用 <code>processHandlerException</code> 来将异常转换成 <code>ModelAndView</code>。对于常见的 <code>HTTP</code> 状态码，可能对应多种异常。</p>
<ul>
<li>在本问题中所出现的<code>400 Bad Request</code>可能对应： <code>Servlet</code> 请求参数缺失、 <code>Servlet</code> 请求处理过程中的绑定异常 、类型不匹配、<code>HTTP</code> 消息不可读、<code>Spring</code>验证框架中的绑定异常等。</li>
</ul>
</li>
<li><p>补充：</p>
<ul>
<li>对于参数解析错误，一般都在<code>org.springframework.web.method.support.InvocableHandlerMethod</code>的<code>getMethodArgumentValues</code>方法下发生。</li>
</ul>
</li>
</ul>
<h3 id="📚问题分析-2"><a href="#📚问题分析-2" class="headerlink" title="📚问题分析"></a>📚问题分析</h3><ul>
<li><p>根据上述信息，找到<code>DispatcherServlet</code>类（位于<code>org.springframework.web.servlet.DispatcherServlet</code>）的<code>processDispatchResult</code>函数，通过断点截获来确定到底是哪种异常被转换成了<code>400 Bad Request</code>状态码。</p>
</li>
<li><p>果不其然，截获后发现了更准确的问题报错：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">JSON parse error: Cannot deserialize value of type `com.raysmond.blog.common.models.support.PostType` from String &quot;Post&quot;: value not one of declared Enum instance names: [POST, PAGE]</span><br><span class="line">JSON parse error: Cannot deserialize value of type `com.raysmond.blog.common.models.support.PostStatus` from String &quot;Published&quot;: value not one of declared Enum instance names: [DRAFT, PUBLISHED]</span><br></pre></td></tr></table></figure></div></li>
<li><p>显然是 Enum 类型变量初始化问题，明确问题后就能直接解决了。</p>
</li>
<li><p>直接调用该函数的 bug 成功解决，然而当通过另一个函数调用时又出现了错误，且所报错误如下（然而该问题所对应的代码已经被修改过了，因此猜测是文件缓存问题）：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">JSON parse error: Cannot construct instance of `org.springframework.data.domain.Pageable` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information</span><br></pre></td></tr></table></figure></div></li>
<li><p>经过细细的断点调试，发现 ObjectMapper.java 又存在两个版本 2.9.2 和 2.15.2，为排除该干扰，彻底清理 gradle 缓存<a href="#refer-anchor-5"><sup>[5]</sup></a>。</p>
</li>
<li><p>经过更细致地监控（全开 DEBUG 模式），获取以下复杂报错信息（但并没有获得什么更有价值的信息）：</p>
<detail></li>
</ul>
<ol>
<li><p>和 Eureka 通信</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">2023-09-02 18:57:40.145 [Eureka-JerseyClient-Conn-Cleaner2] DEBUG c.n.d.s.MonitoredConnectionManager - Closing connections idle longer than 30000 SECONDS</span><br><span class="line">2023-09-02 18:57:40.146 [Eureka-JerseyClient-Conn-Cleaner2] DEBUG c.n.d.shared.NamedConnectionPool - Closing connections idle longer than 30000 SECONDS</span><br><span class="line">2023-09-02 18:57:40.153 [Eureka-JerseyClient-Conn-Cleaner2] DEBUG c.n.d.s.MonitoredConnectionManager - Closing connections idle longer than -1 SECONDS</span><br><span class="line">2023-09-02 18:57:40.153 [Eureka-JerseyClient-Conn-Cleaner2] DEBUG c.n.d.shared.NamedConnectionPool - Closing connections idle longer than 0 SECONDS</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>获取请求</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">2023-09-02 18:57:40.168 [HikariPool-1 housekeeper] DEBUG c.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Pool stats (total=10, active=0, idle=10, waiting=0)</span><br><span class="line">2023-09-02 18:57:46.446 [qtp1864548849-44-acceptor-0@750e313c-ServerConnector@7de2bdc7&#123;HTTP/1.1,[http/1.1]&#125;&#123;0.0.0.0:8051&#125;] DEBUG o.e.jetty.io.ManagedSelector - Queued change org.eclipse.jetty.io.ManagedSelector$Accept@ec53d19 on org.eclipse.jetty.io.ManagedSelector@79753f20 id=0 keys=1 selected=0</span><br><span class="line">2023-09-02 18:57:46.447 [qtp1864548849-46] DEBUG o.e.jetty.io.ManagedSelector - Selector loop woken up from select, 0/1 selected</span><br><span class="line">2023-09-02 18:57:46.447 [qtp1864548849-46] DEBUG o.e.jetty.io.ManagedSelector - Running action org.eclipse.jetty.io.ManagedSelector$Accept@ec53d19</span><br><span class="line">2023-09-02 18:57:46.447 [qtp1864548849-46] DEBUG o.e.jetty.io.ManagedSelector - Queued change org.eclipse.jetty.io.ManagedSelector$CreateEndPoint@7184b93e on org.eclipse.jetty.io.ManagedSelector@79753f20 id=0 keys=2 selected=0</span><br><span class="line">2023-09-02 18:57:46.447 [qtp1864548849-46] DEBUG o.e.jetty.io.ManagedSelector - Running action org.eclipse.jetty.io.ManagedSelector$CreateEndPoint@7184b93e</span><br><span class="line">2023-09-02 18:57:46.447 [qtp1864548849-46] DEBUG org.eclipse.jetty.io.IdleTimeout - SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=0/30000&#125;&#123;io=0/0,kio=0,kro=0&#125;-&gt;&lt;null&gt; idle timeout check, elapsed: 0 ms, remaining: 30000 ms</span><br><span class="line">2023-09-02 18:57:46.448 [qtp1864548849-46] DEBUG o.e.jetty.io.AbstractEndPoint - onOpen SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=1/30000&#125;&#123;io=0/0,kio=0,kro=0&#125;-&gt;&lt;null&gt;</span><br><span class="line">2023-09-02 18:57:46.449 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - new HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125; -&gt; SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=2/30000&#125;&#123;io=0/0,kio=0,kro=0&#125;-&gt;&lt;null&gt;,null,HttpChannelState@5716ebbe&#123;s=IDLE a=NOT_ASYNC i=true r=IDLE w=false&#125;</span><br><span class="line">2023-09-02 18:57:46.449 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - New HTTP Connection HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=2/30000&#125;&#123;io=0/0,kio=0,kro=0&#125;-&gt;&lt;null&gt;</span><br><span class="line">2023-09-02 18:57:46.449 [qtp1864548849-46] DEBUG o.e.jetty.io.AbstractConnection - onOpen HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=2/30000&#125;&#123;io=0/0,kio=0,kro=0&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:46.449 [qtp1864548849-46] DEBUG o.e.jetty.io.AbstractConnection - fillInterested HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=2/30000&#125;&#123;io=0/0,kio=0,kro=0&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:46.450 [qtp1864548849-46] DEBUG o.eclipse.jetty.io.FillInterest - interested FillInterest@71e0a5e2&#123;AC.ReadCB@2b3e8dcc&#123;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=1/30000&#125;&#123;io=0/0,kio=0,kro=0&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;&#125;&#125;</span><br><span class="line">2023-09-02 18:57:46.450 [qtp1864548849-46] DEBUG o.e.jetty.io.ChannelEndPoint - changeInterests p=false 0-&gt;1 for SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=1/30000&#125;&#123;io=0/1,kio=0,kro=0&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:46.450 [qtp1864548849-46] DEBUG o.e.jetty.io.ManagedSelector - Queued change CEP:SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=1/30000&#125;&#123;io=0/1,kio=0,kro=0&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;:runUpdateKey:NON_BLOCKING on org.eclipse.jetty.io.ManagedSelector@79753f20 id=0 keys=2 selected=0</span><br><span class="line">2023-09-02 18:57:46.450 [qtp1864548849-46] DEBUG o.e.jetty.io.ManagedSelector - Created SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=1/30000&#125;&#123;io=0/1,kio=0,kro=0&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:46.451 [qtp1864548849-46] DEBUG o.e.jetty.io.ManagedSelector - Running action CEP:SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=1/30000&#125;&#123;io=0/1,kio=0,kro=0&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;:runUpdateKey:NON_BLOCKING</span><br><span class="line">2023-09-02 18:57:46.451 [qtp1864548849-46] DEBUG o.e.jetty.io.ChannelEndPoint - Key interests updated 0 -&gt; 1 on SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=2/30000&#125;&#123;io=1/1,kio=1,kro=0&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:46.451 [qtp1864548849-46] DEBUG o.e.jetty.io.ManagedSelector - Selector loop waiting on select</span><br><span class="line">2023-09-02 18:57:46.451 [qtp1864548849-46] DEBUG o.e.jetty.io.ManagedSelector - Selector loop woken up from select, 1/2 selected</span><br><span class="line">2023-09-02 18:57:46.451 [qtp1864548849-46] DEBUG o.e.jetty.io.ManagedSelector - selected sun.nio.ch.SelectionKeyImpl@48f41b4e SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=2/30000&#125;&#123;io=1/1,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125; </span><br><span class="line">2023-09-02 18:57:46.451 [qtp1864548849-46] DEBUG o.e.jetty.io.ChannelEndPoint - onSelected 1-&gt;0 r=true w=false for SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=2/30000&#125;&#123;io=1/0,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:46.451 [qtp1864548849-46] DEBUG o.e.jetty.io.ChannelEndPoint - task CEP:SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=2/30000&#125;&#123;io=1/0,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;:runFillable:BLOCKING</span><br><span class="line">2023-09-02 18:57:46.452 [qtp1864548849-46] DEBUG o.e.j.u.t.s.EatWhatYouKill - EatWhatYouKill@7b3489b7/SelectorProducer@33317d26/PRODUCING/org.eclipse.jetty.util.thread.ReservedThreadExecutor@2e46ffd5&#123;s=2,p=0&#125; t=CEP:SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=2/30000&#125;&#123;io=1/0,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;:runFillable:BLOCKING/BLOCKING</span><br><span class="line">2023-09-02 18:57:46.452 [qtp1864548849-46] DEBUG o.e.j.u.t.s.EatWhatYouKill - EatWhatYouKill@7b3489b7/SelectorProducer@33317d26/IDLE/org.eclipse.jetty.util.thread.ReservedThreadExecutor@2e46ffd5&#123;s=1,p=0&#125; EPC t=CEP:SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=3/30000&#125;&#123;io=1/0,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;:runFillable:BLOCKING</span><br><span class="line">2023-09-02 18:57:46.452 [qtp1864548849-50] DEBUG o.e.j.u.t.ReservedThreadExecutor - org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread@22afa967 woken up</span><br><span class="line">2023-09-02 18:57:46.452 [qtp1864548849-50] DEBUG o.e.j.u.t.s.EatWhatYouKill - EatWhatYouKill@7b3489b7/SelectorProducer@33317d26/IDLE/org.eclipse.jetty.util.thread.ReservedThreadExecutor@2e46ffd5&#123;s=1,p=0&#125; run</span><br><span class="line">2023-09-02 18:57:46.452 [qtp1864548849-46] DEBUG o.eclipse.jetty.io.FillInterest - fillable FillInterest@71e0a5e2&#123;AC.ReadCB@2b3e8dcc&#123;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=3/30000&#125;&#123;io=1/0,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;&#125;&#125;</span><br><span class="line">2023-09-02 18:57:46.452 [qtp1864548849-50] DEBUG o.e.j.u.t.s.EatWhatYouKill - EatWhatYouKill@7b3489b7/SelectorProducer@33317d26/IDLE/org.eclipse.jetty.util.thread.ReservedThreadExecutor@2e46ffd5&#123;s=1,p=0&#125; produce</span><br><span class="line">2023-09-02 18:57:46.458 [qtp1864548849-50] DEBUG o.e.jetty.io.ChannelEndPoint - Key interests updated 1 -&gt; 0 on SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=3/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:46.458 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=3/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125; onFillable enter HttpChannelState@5716ebbe&#123;s=IDLE a=NOT_ASYNC i=true r=IDLE w=false&#125; null</span><br><span class="line">2023-09-02 18:57:46.458 [qtp1864548849-50] DEBUG o.e.jetty.io.ManagedSelector - Selector loop waiting on select</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>初步处理请求信息</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">2023-09-02 18:57:46.464 [qtp1864548849-46] DEBUG o.e.jetty.io.ChannelEndPoint - filled 579 SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=12/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:46.466 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=2/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125; filled 579 HeapByteBuffer@77409e4b[p=0,l=579,c=8192,r=579]=&#123;&lt;&lt;&lt;POST /PostReposit...:5,&quot;offset&quot;:0&#125;&#125;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;</span><br><span class="line">2023-09-02 18:57:46.467 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=3/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of 0&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=0,c=false,a=IDLE,uri=null&#125; parse HeapByteBuffer@77409e4b[p=0,l=579,c=8192,r=579]=&#123;&lt;&lt;&lt;POST /PostReposit...:5,&quot;offset&quot;:0&#125;&#125;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125; &#123;&#125;</span><br><span class="line">2023-09-02 18:57:46.467 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - parseNext s=START HeapByteBuffer@77409e4b[p=0,l=579,c=8192,r=579]=&#123;&lt;&lt;&lt;POST /PostReposit...:5,&quot;offset&quot;:0&#125;&#125;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;</span><br><span class="line">2023-09-02 18:57:46.467 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - START --&gt; SPACE1</span><br><span class="line">2023-09-02 18:57:46.467 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - SPACE1 --&gt; URI</span><br><span class="line">2023-09-02 18:57:46.467 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - URI --&gt; SPACE2</span><br><span class="line">2023-09-02 18:57:46.467 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - SPACE2 --&gt; REQUEST_VERSION</span><br><span class="line">2023-09-02 18:57:46.467 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - REQUEST_VERSION --&gt; HEADER</span><br><span class="line">2023-09-02 18:57:46.467 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:null --&gt; VALUE</span><br><span class="line">2023-09-02 18:57:46.467 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:null --&gt; IN_VALUE</span><br><span class="line">2023-09-02 18:57:46.468 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:null --&gt; FIELD</span><br><span class="line">2023-09-02 18:57:46.468 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:null --&gt; VALUE</span><br><span class="line">2023-09-02 18:57:46.468 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:null --&gt; IN_VALUE</span><br><span class="line">2023-09-02 18:57:46.468 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:null --&gt; FIELD</span><br><span class="line">2023-09-02 18:57:46.468 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:null --&gt; VALUE</span><br><span class="line">2023-09-02 18:57:46.468 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:null --&gt; IN_VALUE</span><br><span class="line">2023-09-02 18:57:46.468 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:null --&gt; FIELD</span><br><span class="line">2023-09-02 18:57:46.468 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:Accept: */* --&gt; IN_VALUE</span><br><span class="line">2023-09-02 18:57:46.468 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:Accept: */* --&gt; FIELD</span><br><span class="line">2023-09-02 18:57:46.468 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:Content-Type: application/json --&gt; IN_VALUE</span><br><span class="line">2023-09-02 18:57:46.468 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:Content-Type: application/json --&gt; FIELD</span><br><span class="line">2023-09-02 18:57:46.468 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:Accept-Encoding: gzip --&gt; IN_VALUE</span><br><span class="line">2023-09-02 18:57:46.468 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER:Accept-Encoding: gzip --&gt; FIELD</span><br><span class="line">2023-09-02 18:57:46.468 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - HEADER --&gt; CONTENT</span><br><span class="line">2023-09-02 18:57:46.469 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - REQUEST for //100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted on HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;</span><br><span class="line">POST //100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted HTTP/1.1</span><br><span class="line">Host: 100.64.188.184:8051</span><br><span class="line">User-Agent: Java/1.8.0_271</span><br><span class="line">Content-Length: 351</span><br><span class="line">Accept: */*</span><br><span class="line">Content-Type: application/json</span><br><span class="line">Accept-Encoding: gzip</span><br><span class="line">2023-09-02 18:57:46.469 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=CONTENT,0 of 351&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=5/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=CONTENT,0 of 351&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; parsed true HttpParser&#123;s=CONTENT,0 of 351&#125;</span><br><span class="line">2023-09-02 18:57:46.469 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; handle //100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted </span><br><span class="line">2023-09-02 18:57:46.469 [qtp1864548849-46] DEBUG o.e.j.server.HttpChannelState - handling HttpChannelState@5716ebbe&#123;s=IDLE a=NOT_ASYNC i=true r=IDLE w=false&#125;</span><br><span class="line">2023-09-02 18:57:46.469 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=DISPATCHED,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; action DISPATCH</span><br><span class="line">2023-09-02 18:57:46.469 [qtp1864548849-46] DEBUG org.eclipse.jetty.server.Server - REQUEST POST /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted on HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=DISPATCHED,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;</span><br><span class="line">2023-09-02 18:57:46.470 [qtp1864548849-46] DEBUG o.e.j.s.handler.ContextHandler - scope null||/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted @ o.s.b.c.e.j.JettyEmbeddedWebAppContext@1d008e61&#123;/,[file:///private/var/folders/sg/fcqtq3fx50b9tfz0jmw8jh3m0000gq/T/jetty-docbase.8868443885322920717.8051/],AVAILABLE&#125;</span><br><span class="line">2023-09-02 18:57:46.470 [qtp1864548849-46] DEBUG o.e.j.s.handler.ContextHandler - context=||/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted @ o.s.b.c.e.j.JettyEmbeddedWebAppContext@1d008e61&#123;/,[file:///private/var/folders/sg/fcqtq3fx50b9tfz0jmw8jh3m0000gq/T/jetty-docbase.8868443885322920717.8051/],AVAILABLE&#125;</span><br><span class="line">2023-09-02 18:57:46.470 [qtp1864548849-46] DEBUG org.eclipse.jetty.server.session - sessionHandler=org.eclipse.jetty.server.session.SessionHandler421217482==dftMaxIdleSec=1800</span><br><span class="line">2023-09-02 18:57:46.470 [qtp1864548849-46] DEBUG org.eclipse.jetty.server.session - session=null</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>匹配请求</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">2023-09-02 18:57:46.470 [qtp1864548849-46] DEBUG o.e.jetty.servlet.ServletHandler - servlet |/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted|null -&gt; dispatcherServlet@7ef5559e==org.springframework.web.servlet.DispatcherServlet,jsp=null,order=-1,inst=true</span><br><span class="line">2023-09-02 18:57:46.470 [qtp1864548849-46] DEBUG o.e.jetty.servlet.ServletHandler - chain=characterEncodingFilter-&gt;hiddenHttpMethodFilter-&gt;httpPutFormContentFilter-&gt;requestContextFilter-&gt;springSecurityFilterChain-&gt;Jetty_WebSocketUpgradeFilter-&gt;dispatcherServlet@7ef5559e==org.springframework.web.servlet.DispatcherServlet,jsp=null,order=-1,inst=true</span><br><span class="line">2023-09-02 18:57:46.470 [qtp1864548849-46] DEBUG o.e.jetty.servlet.ServletHandler - call filter characterEncodingFilter</span><br><span class="line">2023-09-02 18:57:46.470 [qtp1864548849-46] DEBUG o.e.jetty.servlet.ServletHandler - call filter hiddenHttpMethodFilter</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.e.jetty.servlet.ServletHandler - call filter httpPutFormContentFilter</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.e.jetty.servlet.ServletHandler - call filter requestContextFilter</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.b.w.f.OrderedRequestContextFilter - Bound request context to thread: Request(POST //100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted)@114beb7b</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.e.jetty.servlet.ServletHandler - call filter springSecurityFilterChain</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/css/**&#x27;]</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Checking match of request : &#x27;/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27;; against &#x27;/css/**&#x27;</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/js/**&#x27;]</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Checking match of request : &#x27;/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27;; against &#x27;/js/**&#x27;</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/images/**&#x27;]</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Checking match of request : &#x27;/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27;; against &#x27;/images/**&#x27;</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/webjars/**&#x27;]</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Checking match of request : &#x27;/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27;; against &#x27;/webjars/**&#x27;</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/**/favicon.ico&#x27;]</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Checking match of request : &#x27;/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27;; against &#x27;/**/favicon.ico&#x27;</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/error&#x27;]</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Checking match of request : &#x27;/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27;; against &#x27;/error&#x27;</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - No matches found</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.web.FilterChainProxy - /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted at position 1 of 10 in additional filter chain; firing Filter: &#x27;WebAsyncManagerIntegrationFilter&#x27;</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.web.FilterChainProxy - /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted at position 2 of 10 in additional filter chain; firing Filter: &#x27;SecurityContextPersistenceFilter&#x27;</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.c.HttpSessionSecurityContextRepository - No HttpSession currently exists</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.w.c.HttpSessionSecurityContextRepository - No SecurityContext was available from the HttpSession: null. A new one will be created.</span><br><span class="line">2023-09-02 18:57:46.471 [qtp1864548849-46] DEBUG o.s.s.web.FilterChainProxy - /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted at position 3 of 10 in additional filter chain; firing Filter: &#x27;HeaderWriterFilter&#x27;</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.h.w.HstsHeaderWriter - Not injecting HSTS header since it did not match the requestMatcher org.springframework.security.web.header.writers.HstsHeaderWriter$SecureRequestMatcher@4325f834</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.web.FilterChainProxy - /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted at position 4 of 10 in additional filter chain; firing Filter: &#x27;LogoutFilter&#x27;</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/logout&#x27;, GET]</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Request &#x27;POST /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27; doesn&#x27;t match &#x27;GET /logout</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/logout&#x27;, POST]</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Checking match of request : &#x27;/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27;; against &#x27;/logout&#x27;</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/logout&#x27;, PUT]</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Request &#x27;POST /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27; doesn&#x27;t match &#x27;PUT /logout</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/logout&#x27;, DELETE]</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Request &#x27;POST /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27; doesn&#x27;t match &#x27;DELETE /logout</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - No matches found</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.web.FilterChainProxy - /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted at position 5 of 10 in additional filter chain; firing Filter: &#x27;RequestCacheAwareFilter&#x27;</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.web.FilterChainProxy - /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted at position 6 of 10 in additional filter chain; firing Filter: &#x27;SecurityContextHolderAwareRequestFilter&#x27;</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.web.FilterChainProxy - /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted at position 7 of 10 in additional filter chain; firing Filter: &#x27;AnonymousAuthenticationFilter&#x27;</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.a.AnonymousAuthenticationFilter - Populated SecurityContextHolder with anonymous token: &#x27;org.springframework.security.authentication.AnonymousAuthenticationToken@6faab5ec: Principal: anonymousUser; Credentials: [PROTECTED]; Authenticated: true; Details: org.springframework.security.web.authentication.WebAuthenticationDetails@ffffc434: RemoteIpAddress: 100.64.188.184; SessionId: null; Granted Authorities: ROLE_ANONYMOUS&#x27;</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.web.FilterChainProxy - /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted at position 8 of 10 in additional filter chain; firing Filter: &#x27;SessionManagementFilter&#x27;</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.web.FilterChainProxy - /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted at position 9 of 10 in additional filter chain; firing Filter: &#x27;ExceptionTranslationFilter&#x27;</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.web.FilterChainProxy - /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted at position 10 of 10 in additional filter chain; firing Filter: &#x27;FilterSecurityInterceptor&#x27;</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/logout&#x27;, GET]</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Request &#x27;POST /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27; doesn&#x27;t match &#x27;GET /logout</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/logout&#x27;, POST]</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Checking match of request : &#x27;/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27;; against &#x27;/logout&#x27;</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/logout&#x27;, PUT]</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Request &#x27;POST /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27; doesn&#x27;t match &#x27;PUT /logout</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - Trying to match using Ant [pattern=&#x27;/logout&#x27;, DELETE]</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.AntPathRequestMatcher - Request &#x27;POST /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#x27; doesn&#x27;t match &#x27;DELETE /logout</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.u.m.OrRequestMatcher - No matches found</span><br><span class="line">2023-09-02 18:57:46.472 [qtp1864548849-46] DEBUG o.s.s.w.a.i.FilterSecurityInterceptor - Secure object: FilterInvocation: URL: /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted; Attributes: [permitAll]</span><br><span class="line">2023-09-02 18:57:46.473 [qtp1864548849-46] DEBUG o.s.s.w.a.i.FilterSecurityInterceptor - Previously Authenticated: org.springframework.security.authentication.AnonymousAuthenticationToken@6faab5ec: Principal: anonymousUser; Credentials: [PROTECTED]; Authenticated: true; Details: org.springframework.security.web.authentication.WebAuthenticationDetails@ffffc434: RemoteIpAddress: 100.64.188.184; SessionId: null; Granted Authorities: ROLE_ANONYMOUS</span><br><span class="line">2023-09-02 18:57:46.473 [qtp1864548849-46] DEBUG o.s.s.a.vote.AffirmativeBased - Voter: org.springframework.security.web.access.expression.WebExpressionVoter@78ef6211, returned: 1</span><br><span class="line">2023-09-02 18:57:46.473 [qtp1864548849-46] DEBUG o.s.s.w.a.i.FilterSecurityInterceptor - Authorization successful</span><br><span class="line">2023-09-02 18:57:46.473 [qtp1864548849-46] DEBUG o.s.s.w.a.i.FilterSecurityInterceptor - RunAsManager did not change Authentication object</span><br><span class="line">2023-09-02 18:57:46.474 [qtp1864548849-46] DEBUG o.s.s.web.FilterChainProxy - /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted reached end of additional filter chain; proceeding with original chain</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>处理请求</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">2023-09-02 18:57:46.474 [qtp1864548849-46] DEBUG o.e.jetty.servlet.ServletHandler - call filter Jetty_WebSocketUpgradeFilter</span><br><span class="line">2023-09-02 18:57:46.474 [qtp1864548849-46] DEBUG o.e.jetty.servlet.ServletHandler - call servlet dispatcherServlet@7ef5559e==org.springframework.web.servlet.DispatcherServlet,jsp=null,order=-1,inst=true</span><br><span class="line">2023-09-02 18:57:46.474 [qtp1864548849-46] DEBUG o.s.w.servlet.DispatcherServlet - DispatcherServlet with name &#x27;dispatcherServlet&#x27; processing POST request for [/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted]</span><br><span class="line">2023-09-02 18:57:46.474 [qtp1864548849-46] DEBUG o.s.w.s.m.m.a.RequestMappingHandlerMapping - Looking up handler method for path /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted</span><br><span class="line">2023-09-02 18:57:46.475 [qtp1864548849-46] DEBUG o.s.w.s.m.m.a.RequestMappingHandlerMapping - Returning handler method [org.springframework.data.domain.Page&lt;com.raysmond.blog.common.models.Post&gt; com.raysmond.blog.microservice1.repositories.controllers.PostRepositoryController.findAllByPostTypeAndPostStatusAndDeleted(com.raysmond.blog.common.models.PostParams)]</span><br><span class="line">2023-09-02 18:57:46.475 [qtp1864548849-46] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Returning cached instance of singleton bean &#x27;postRepositoryController&#x27;</span><br><span class="line">2023-09-02 18:57:46.475 [qtp1864548849-46] DEBUG o.s.o.j.s.OpenEntityManagerInViewInterceptor - Opening JPA EntityManager in OpenEntityManagerInViewInterceptor</span><br><span class="line">2023-09-02 18:57:46.479 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=CONTENT,0 of 351&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=DISPATCHED,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=15/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=CONTENT,0 of 351&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=DISPATCHED,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; parse HeapByteBuffer@77409e4b[p=228,l=579,c=8192,r=351]=&#123;POST /PostReposit...oding: gzip\r\n\r\n&lt;&lt;&lt;&#123;&quot;tag&quot;:&quot;tag&quot;,&quot;pos...:5,&quot;offset&quot;:0&#125;&#125;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125; &#123;&#125;</span><br><span class="line">2023-09-02 18:57:46.479 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - parseNext s=CONTENT HeapByteBuffer@77409e4b[p=228,l=579,c=8192,r=351]=&#123;POST /PostReposit...oding: gzip\r\n\r\n&lt;&lt;&lt;&#123;&quot;tag&quot;:&quot;tag&quot;,&quot;pos...:5,&quot;offset&quot;:0&#125;&#125;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;</span><br><span class="line">2023-09-02 18:57:46.479 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=DISPATCHED,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; onContent Content@4e445473&#123;HeapByteBufferR@341ed4da[p=228,l=579,c=8192,r=351]=&#123;POST /PostReposit...oding: gzip\r\n\r\n&lt;&lt;&lt;&#123;&quot;tag&quot;:&quot;tag&quot;,&quot;pos...:5,&quot;offset&quot;:0&#125;&#125;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;&#125;</span><br><span class="line">2023-09-02 18:57:46.479 [qtp1864548849-46] DEBUG o.eclipse.jetty.server.HttpInput - HttpInputOverHTTP@4025a80e[c=0,q=0,[0]=null,s=STREAM] addContent Content@4e445473&#123;HeapByteBufferR@341ed4da[p=228,l=579,c=8192,r=351]=&#123;POST /PostReposit...oding: gzip\r\n\r\n&lt;&lt;&lt;&#123;&quot;tag&quot;:&quot;tag&quot;,&quot;pos...:5,&quot;offset&quot;:0&#125;&#125;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;&#125;</span><br><span class="line">2023-09-02 18:57:46.480 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - CONTENT --&gt; END</span><br><span class="line">2023-09-02 18:57:46.480 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=DISPATCHED,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; onContentComplete</span><br><span class="line">2023-09-02 18:57:46.480 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=DISPATCHED,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; onRequestComplete</span><br><span class="line">2023-09-02 18:57:46.480 [qtp1864548849-46] DEBUG o.eclipse.jetty.server.HttpInput - HttpInputOverHTTP@4025a80e[c=0,q=1,[0]=EOF,s=STREAM] addContent EOF</span><br><span class="line">2023-09-02 18:57:46.480 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=END,351 of 351&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=DISPATCHED,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=16/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=END,351 of 351&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=DISPATCHED,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; parsed false HttpParser&#123;s=END,351 of 351&#125;</span><br><span class="line">2023-09-02 18:57:46.480 [qtp1864548849-46] DEBUG o.eclipse.jetty.server.HttpInput - HttpInputOverHTTP@4025a80e[c=1,q=1,[0]=EOF,s=STREAM] read 1 from Content@4e445473&#123;HeapByteBufferR@341ed4da[p=229,l=579,c=8192,r=350]=&#123;POST /PostReposit...ding: gzip\r\n\r\n&#123;&lt;&lt;&lt;&quot;tag&quot;:&quot;tag&quot;,&quot;post...:5,&quot;offset&quot;:0&#125;&#125;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;&#125;</span><br><span class="line">2023-09-02 18:57:46.481 [qtp1864548849-46] DEBUG o.s.w.s.m.m.a.RequestResponseBodyMethodProcessor - Read [class com.raysmond.blog.common.models.PostParams] as &quot;application/json;charset=UTF-8&quot; with [org.springframework.http.converter.json.MappingJackson2HttpMessageConverter@f6e3b67]</span><br><span class="line">2023-09-02 18:57:46.481 [qtp1864548849-46] DEBUG o.eclipse.jetty.server.HttpInput - HttpInputOverHTTP@4025a80e[c=351,q=1,[0]=EOF,s=STREAM] read 350 from Content@4e445473&#123;HeapByteBufferR@341ed4da[p=579,l=579,c=8192,r=0]=&#123;POST /PostReposit...:5,&quot;offset&quot;:0&#125;&#125;&lt;&lt;&lt;&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;&#125;</span><br><span class="line">2023-09-02 18:57:46.481 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - releaseRequestBuffer HttpConnection@2b3e8dcc[p=HttpParser&#123;s=END,351 of 351&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=DISPATCHED,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=17/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=END,351 of 351&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=DISPATCHED,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>报错</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">2023-09-02 18:57:46.483 [qtp1864548849-46] DEBUG o.s.w.s.m.m.a.ServletInvocableHandlerMethod - Failed to resolve argument 0 of type &#x27;com.raysmond.blog.common.models.PostParams&#x27;</span><br><span class="line">org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Cannot construct instance of `org.springframework.data.domain.Pageable` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information; nested exception is com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `org.springframework.data.domain.Pageable` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information</span><br><span class="line"> at [Source: java.io.PushbackInputStream@e7b9342; line: 1, column: 179] (through reference chain: com.raysmond.blog.common.models.PostParams[&quot;pageRequest&quot;])</span><br><span class="line">	at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.readJavaType(AbstractJackson2HttpMessageConverter.java:238)</span><br><span class="line">	at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.read(AbstractJackson2HttpMessageConverter.java:223)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodArgumentResolver.readWithMessageConverters(AbstractMessageConverterMethodArgumentResolver.java:201)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.readWithMessageConverters(RequestResponseBodyMethodProcessor.java:150)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.resolveArgument(RequestResponseBodyMethodProcessor.java:128)</span><br><span class="line">	at org.springframework.web.method.support.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:121)</span><br><span class="line">	at org.springframework.web.method.support.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:158)</span><br><span class="line">	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:128)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)</span><br><span class="line">	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)</span><br><span class="line">	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)</span><br><span class="line">	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)</span><br><span class="line">	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)</span><br><span class="line">	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:841)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1650)</span><br><span class="line">	at org.eclipse.jetty.websocket.server.WebSocketUpgradeFilter.doFilter(WebSocketUpgradeFilter.java:206)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317)</span><br><span class="line">	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)</span><br><span class="line">	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177)</span><br><span class="line">	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347)</span><br><span class="line">	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)</span><br><span class="line">	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)</span><br><span class="line">	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:190)</span><br><span class="line">	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:188)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1253)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:168)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)</span><br><span class="line">	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:166)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1155)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)</span><br><span class="line">	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)</span><br><span class="line">	at org.eclipse.jetty.server.Server.handle(Server.java:561)</span><br><span class="line">	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:334)</span><br><span class="line">	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)</span><br><span class="line">	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:279)</span><br><span class="line">	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:104)</span><br><span class="line">	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:124)</span><br><span class="line">	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:247)</span><br><span class="line">	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:140)</span><br><span class="line">	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)</span><br><span class="line">	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:243)</span><br><span class="line">	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:679)</span><br><span class="line">	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:597)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:748)</span><br><span class="line">Caused by: com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `org.springframework.data.domain.Pageable` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information</span><br><span class="line"> at [Source: java.io.PushbackInputStream@e7b9342; line: 1, column: 179] (through reference chain: com.raysmond.blog.common.models.PostParams[&quot;pageRequest&quot;])</span><br><span class="line">	at com.fasterxml.jackson.databind.exc.InvalidDefinitionException.from(InvalidDefinitionException.java:67)</span><br><span class="line">	at com.fasterxml.jackson.databind.DeserializationContext.reportBadDefinition(DeserializationContext.java:1451)</span><br><span class="line">	at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1027)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserialize(AbstractDeserializer.java:265)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:519)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeWithErrorWrapping(BeanDeserializer.java:527)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeUsingPropertyBased(BeanDeserializer.java:448)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1265)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:325)</span><br><span class="line">	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:159)</span><br><span class="line">	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4001)</span><br><span class="line">	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3072)</span><br><span class="line">	at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.readJavaType(AbstractJackson2HttpMessageConverter.java:235)</span><br><span class="line">	... 91 common frames omitted</span><br><span class="line">2023-09-02 18:57:46.484 [qtp1864548849-46] DEBUG o.s.w.s.m.m.a.ExceptionHandlerExceptionResolver - Resolving exception from handler [org.springframework.data.domain.Page&lt;com.raysmond.blog.common.models.Post&gt; com.raysmond.blog.microservice1.repositories.controllers.PostRepositoryController.findAllByPostTypeAndPostStatusAndDeleted(com.raysmond.blog.common.models.PostParams)]: org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Cannot construct instance of `org.springframework.data.domain.Pageable` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information; nested exception is com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `org.springframework.data.domain.Pageable` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information</span><br><span class="line"> at [Source: java.io.PushbackInputStream@e7b9342; line: 1, column: 179] (through reference chain: com.raysmond.blog.common.models.PostParams[&quot;pageRequest&quot;])</span><br><span class="line">2023-09-02 18:57:46.484 [qtp1864548849-46] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Returning cached instance of singleton bean &#x27;exceptionHandlerController&#x27;</span><br><span class="line">2023-09-02 18:57:46.485 [qtp1864548849-46] DEBUG o.s.w.s.m.m.a.ExceptionHandlerExceptionResolver - Invoking @ExceptionHandler method: public org.springframework.web.servlet.ModelAndView com.raysmond.blog.microservice1.error.ExceptionHandlerController.exception(com.raysmond.blog.common.models.FakeHttpServletRequest,java.lang.Exception)</span><br><span class="line">2023-09-02 18:57:46.486 [qtp1864548849-46] WARN  o.s.w.s.m.m.a.ExceptionHandlerExceptionResolver - Failed to invoke @ExceptionHandler method: public org.springframework.web.servlet.ModelAndView com.raysmond.blog.microservice1.error.ExceptionHandlerController.exception(com.raysmond.blog.common.models.FakeHttpServletRequest,java.lang.Exception)</span><br><span class="line">java.lang.IllegalStateException: Could not resolve method parameter at index 0 in public org.springframework.web.servlet.ModelAndView com.raysmond.blog.microservice1.error.ExceptionHandlerController.exception(com.raysmond.blog.common.models.FakeHttpServletRequest,java.lang.Exception): No suitable resolver for argument 0 of type &#x27;com.raysmond.blog.common.models.FakeHttpServletRequest&#x27;</span><br><span class="line">	at org.springframework.web.method.support.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:172)</span><br><span class="line">	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:128)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)</span><br><span class="line">	at org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver.doResolveHandlerMethodException(ExceptionHandlerExceptionResolver.java:380)</span><br><span class="line">	at org.springframework.web.servlet.handler.AbstractHandlerMethodExceptionResolver.doResolveException(AbstractHandlerMethodExceptionResolver.java:59)</span><br><span class="line">	at org.springframework.web.servlet.handler.AbstractHandlerExceptionResolver.resolveException(AbstractHandlerExceptionResolver.java:136)</span><br><span class="line">	at org.springframework.web.servlet.handler.HandlerExceptionResolverComposite.resolveException(HandlerExceptionResolverComposite.java:76)</span><br><span class="line">	at org.springframework.web.servlet.DispatcherServlet.processHandlerException(DispatcherServlet.java:1222)</span><br><span class="line">	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1034)</span><br><span class="line">	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:984)</span><br><span class="line">	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)</span><br><span class="line">	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)</span><br><span class="line">	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)</span><br><span class="line">	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:841)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1650)</span><br><span class="line">	at org.eclipse.jetty.websocket.server.WebSocketUpgradeFilter.doFilter(WebSocketUpgradeFilter.java:206)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317)</span><br><span class="line">	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)</span><br><span class="line">	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214)</span><br><span class="line">	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177)</span><br><span class="line">	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347)</span><br><span class="line">	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)</span><br><span class="line">	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1637)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)</span><br><span class="line">	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)</span><br><span class="line">	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:190)</span><br><span class="line">	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:188)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1253)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:168)</span><br><span class="line">	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)</span><br><span class="line">	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:166)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1155)</span><br><span class="line">	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)</span><br><span class="line">	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)</span><br><span class="line">	at org.eclipse.jetty.server.Server.handle(Server.java:561)</span><br><span class="line">	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:334)</span><br><span class="line">	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)</span><br><span class="line">	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:279)</span><br><span class="line">	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:104)</span><br><span class="line">	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:124)</span><br><span class="line">	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:247)</span><br><span class="line">	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:140)</span><br><span class="line">	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)</span><br><span class="line">	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:243)</span><br><span class="line">	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:679)</span><br><span class="line">	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:597)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:748)</span><br><span class="line">2023-09-02 18:57:46.486 [qtp1864548849-46] DEBUG o.s.w.s.m.a.ResponseStatusExceptionResolver - Resolving exception from handler [org.springframework.data.domain.Page&lt;com.raysmond.blog.common.models.Post&gt; com.raysmond.blog.microservice1.repositories.controllers.PostRepositoryController.findAllByPostTypeAndPostStatusAndDeleted(com.raysmond.blog.common.models.PostParams)]: org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Cannot construct instance of `org.springframework.data.domain.Pageable` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information; nested exception is com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `org.springframework.data.domain.Pageable` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information</span><br><span class="line"> at [Source: java.io.PushbackInputStream@e7b9342; line: 1, column: 179] (through reference chain: com.raysmond.blog.common.models.PostParams[&quot;pageRequest&quot;])</span><br><span class="line">2023-09-02 18:57:46.486 [qtp1864548849-46] DEBUG o.s.w.s.m.s.DefaultHandlerExceptionResolver - Resolving exception from handler [org.springframework.data.domain.Page&lt;com.raysmond.blog.common.models.Post&gt; com.raysmond.blog.microservice1.repositories.controllers.PostRepositoryController.findAllByPostTypeAndPostStatusAndDeleted(com.raysmond.blog.common.models.PostParams)]: org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Cannot construct instance of `org.springframework.data.domain.Pageable` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information; nested exception is com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `org.springframework.data.domain.Pageable` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information</span><br><span class="line"> at [Source: java.io.PushbackInputStream@e7b9342; line: 1, column: 179] (through reference chain: com.raysmond.blog.common.models.PostParams[&quot;pageRequest&quot;])</span><br><span class="line">2023-09-02 18:57:46.486 [qtp1864548849-46] WARN  o.s.w.s.m.s.DefaultHandlerExceptionResolver - Failed to read HTTP message: org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Cannot construct instance of `org.springframework.data.domain.Pageable` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information; nested exception is com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `org.springframework.data.domain.Pageable` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information</span><br><span class="line"> at [Source: java.io.PushbackInputStream@e7b9342; line: 1, column: 179] (through reference chain: com.raysmond.blog.common.models.PostParams[&quot;pageRequest&quot;])</span><br><span class="line">2023-09-02 18:57:46.486 [qtp1864548849-46] DEBUG o.s.s.w.c.HttpSessionSecurityContextRepository - SecurityContext is empty or contents are anonymous - context will not be stored in HttpSession.</span><br><span class="line">2023-09-02 18:57:46.486 [qtp1864548849-46] DEBUG o.e.j.s.ErrorPageErrorHandler - getErrorPage(POST /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted) =&gt; error_page=/error (from global default)</span><br><span class="line">2023-09-02 18:57:46.486 [qtp1864548849-46] DEBUG o.e.j.s.handler.ErrorHandler - error page dispatch /error-&gt;Dispatcher@0x62f0a932&#123;null,/error&#125;</span><br><span class="line">2023-09-02 18:57:46.486 [qtp1864548849-46] DEBUG o.e.j.s.handler.ContextHandler - scope /||/error @ o.s.b.c.e.j.JettyEmbeddedWebAppContext@1d008e61&#123;/,[file:///private/var/folders/sg/fcqtq3fx50b9tfz0jmw8jh3m0000gq/T/jetty-docbase.8868443885322920717.8051/],AVAILABLE&#125;</span><br><span class="line">2023-09-02 18:57:46.486 [qtp1864548849-46] DEBUG o.e.j.s.handler.ContextHandler - context=||/error @ o.s.b.c.e.j.JettyEmbeddedWebAppContext@1d008e61&#123;/,[file:///private/var/folders/sg/fcqtq3fx50b9tfz0jmw8jh3m0000gq/T/jetty-docbase.8868443885322920717.8051/],AVAILABLE&#125;</span><br><span class="line">2023-09-02 18:57:46.486 [qtp1864548849-46] DEBUG org.eclipse.jetty.server.session - sessionHandler=org.eclipse.jetty.server.session.SessionHandler421217482==dftMaxIdleSec=1800</span><br><span class="line">2023-09-02 18:57:46.486 [qtp1864548849-46] DEBUG org.eclipse.jetty.server.session - session=null</span><br><span class="line">2023-09-02 18:57:46.486 [qtp1864548849-46] DEBUG o.e.jetty.servlet.ServletHandler - servlet |/error|null -&gt; dispatcherServlet@7ef5559e==org.springframework.web.servlet.DispatcherServlet,jsp=null,order=-1,inst=true</span><br><span class="line">2023-09-02 18:57:46.486 [qtp1864548849-46] DEBUG o.e.jetty.servlet.ServletHandler - chain=null</span><br><span class="line">2023-09-02 18:57:46.487 [qtp1864548849-46] DEBUG o.s.w.servlet.DispatcherServlet - DispatcherServlet with name &#x27;dispatcherServlet&#x27; processing POST request for [/error]</span><br><span class="line">2023-09-02 18:57:46.487 [qtp1864548849-46] DEBUG o.s.w.s.m.m.a.RequestMappingHandlerMapping - Looking up handler method for path /error</span><br><span class="line">2023-09-02 18:57:46.489 [qtp1864548849-46] DEBUG o.s.w.s.m.m.a.RequestMappingHandlerMapping - Returning handler method [public org.springframework.http.ResponseEntity&lt;java.util.Map&lt;java.lang.String, java.lang.Object&gt;&gt; org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)]</span><br><span class="line">2023-09-02 18:57:46.489 [qtp1864548849-46] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Returning cached instance of singleton bean &#x27;basicErrorController&#x27;</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - sendResponse info=null content=DirectByteBuffer@3c945af6[p=0,l=243,c=32768,r=243]=&#123;&lt;&lt;&lt;&#123;&quot;timestamp&quot;:1693...tusAndDeleted&quot;&#125;&gt;&gt;&gt;afdc977e4ff71f7e1...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125; complete=false committing=true callback=Blocker@208a09b2&#123;null&#125;</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - COMMIT for /error on HttpChannelOverHttp@38fffb8&#123;r=1,c=true,a=DISPATCHED,uri=//100.64.188.184:8051/error&#125;</span><br><span class="line">400 null HTTP/1.1</span><br><span class="line">Date: Sat, 02 Sep 2023 10:57:46 GMT</span><br><span class="line">X-Content-Type-Options: nosniff</span><br><span class="line">X-XSS-Protection: 1; mode=block</span><br><span class="line">Pragma: no-cache</span><br><span class="line">X-Frame-Options: DENY</span><br><span class="line">Content-Type: application/json;charset=utf-8</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@4d02b075[PROCESSING][i=HTTP/1.1&#123;s=400,h=6,cl=-1&#125;,cb=org.eclipse.jetty.server.HttpChannel$CommitCallback@1fb1cb14] generate: NEED_HEADER (null,[p=0,l=243,c=32768,r=243],false)@START</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.e.jetty.http.HttpGenerator - generateHeaders HTTP/1.1&#123;s=400,h=6,cl=-1&#125; last=false content=DirectByteBuffer@3c945af6[p=0,l=243,c=32768,r=243]=&#123;&lt;&lt;&lt;&#123;&quot;timestamp&quot;:1693...tusAndDeleted&quot;&#125;&gt;&gt;&gt;afdc977e4ff71f7e1...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.e.jetty.http.HttpGenerator - Date: Sat, 02 Sep 2023 10:57:46 GMT</span><br><span class="line">X-Content-Type-Options: nosniff</span><br><span class="line">X-XSS-Protection: 1; mode=block</span><br><span class="line">Pragma: no-cache</span><br><span class="line">X-Frame-Options: DENY</span><br><span class="line">Content-Type: application/json;charset=utf-8</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.e.jetty.http.HttpGenerator - CHUNKED_CONTENT</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@4d02b075[PROCESSING][i=HTTP/1.1&#123;s=400,h=6,cl=-1&#125;,cb=org.eclipse.jetty.server.HttpChannel$CommitCallback@1fb1cb14] generate: FLUSH ([p=0,l=250,c=8192,r=250],[p=0,l=243,c=32768,r=243],false)@COMMITTED</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.eclipse.jetty.io.WriteFlusher - write: WriteFlusher@786f58e9&#123;IDLE&#125;-&gt;null [HeapByteBuffer@77409e4b[p=0,l=250,c=8192,r=250]=&#123;&lt;&lt;&lt;HTTP/1.1 400 Bad ...chunked\r\n\r\nF3\r\n&gt;&gt;&gt;&quot;:&quot;POST&quot;,&quot;postSta...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;,DirectByteBuffer@3c945af6[p=0,l=243,c=32768,r=243]=&#123;&lt;&lt;&lt;&#123;&quot;timestamp&quot;:1693...tusAndDeleted&quot;&#125;&gt;&gt;&gt;afdc977e4ff71f7e1...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;]</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.eclipse.jetty.io.WriteFlusher - update WriteFlusher@786f58e9&#123;WRITING&#125;-&gt;null:IDLE--&gt;WRITING</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.e.jetty.io.ChannelEndPoint - flushed 493 SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=W,to=27/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=END,351 of 351&#125;,g=HttpGenerator@d6ee9c8&#123;s=COMMITTED&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=true,a=DISPATCHED,uri=//100.64.188.184:8051/error&#125;</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.eclipse.jetty.io.WriteFlusher - Flushed=true 250/250+1 WriteFlusher@786f58e9&#123;WRITING&#125;-&gt;null</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.eclipse.jetty.io.WriteFlusher - update WriteFlusher@786f58e9&#123;IDLE&#125;-&gt;null:WRITING--&gt;IDLE</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@4d02b075[PROCESSING][i=HTTP/1.1&#123;s=400,h=6,cl=-1&#125;,cb=org.eclipse.jetty.server.HttpChannel$CommitCallback@1fb1cb14] generate: DONE ([p=250,l=250,c=8192,r=0],[p=243,l=243,c=32768,r=0],false)@COMMITTED</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - sendResponse info=null content=HeapByteBuffer@367a5afc[p=0,l=0,c=0,r=0]=&#123;&lt;&lt;&lt;&gt;&gt;&gt;&#125; complete=false committing=false callback=Blocker@208a09b2&#123;null&#125;</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - sendResponse info=null content=HeapByteBuffer@367a5afc[p=0,l=0,c=0,r=0]=&#123;&lt;&lt;&lt;&gt;&gt;&gt;&#125; complete=false committing=false callback=Blocker@208a09b2&#123;null&#125;</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.s.w.s.m.m.a.HttpEntityMethodProcessor - Written [&#123;timestamp=Sat Sep 02 18:57:46 CST 2023, status=400, error=Bad Request, exception=org.springframework.http.converter.HttpMessageNotReadableException, message=Bad Request, path=/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;] as &quot;application/json&quot; using [org.springframework.http.converter.json.MappingJackson2HttpMessageConverter@f6e3b67]</span><br><span class="line">2023-09-02 18:57:46.491 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - sendResponse info=null content=HeapByteBuffer@367a5afc[p=0,l=0,c=0,r=0]=&#123;&lt;&lt;&lt;&gt;&gt;&gt;&#125; complete=false committing=false callback=Blocker@208a09b2&#123;null&#125;</span><br><span class="line">2023-09-02 18:57:46.492 [qtp1864548849-46] DEBUG o.s.w.servlet.DispatcherServlet - Null ModelAndView returned to DispatcherServlet with name &#x27;dispatcherServlet&#x27;: assuming HandlerAdapter completed request handling</span><br><span class="line">2023-09-02 18:57:46.492 [qtp1864548849-46] DEBUG o.s.w.servlet.DispatcherServlet - Successfully completed request</span><br><span class="line">2023-09-02 18:57:46.492 [qtp1864548849-46] DEBUG org.eclipse.jetty.server.session - FinalSession=null old_session_manager=org.eclipse.jetty.server.session.SessionHandler421217482==dftMaxIdleSec=1800 this=org.eclipse.jetty.server.session.SessionHandler421217482==dftMaxIdleSec=1800</span><br><span class="line">2023-09-02 18:57:46.492 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - sendResponse info=null content=HeapByteBuffer@367a5afc[p=0,l=0,c=0,r=0]=&#123;&lt;&lt;&lt;&gt;&gt;&gt;&#125; complete=true committing=false callback=Blocker@208a09b2&#123;null&#125;</span><br><span class="line">2023-09-02 18:57:46.492 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@4d02b075[PROCESSING][i=null,cb=Blocker@208a09b2&#123;null&#125;] generate: CONTINUE (null,[p=0,l=0,c=0,r=0],true)@COMPLETING</span><br><span class="line">2023-09-02 18:57:46.492 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@4d02b075[PROCESSING][i=null,cb=Blocker@208a09b2&#123;null&#125;] generate: NEED_CHUNK (null,[p=0,l=0,c=0,r=0],true)@COMPLETING</span><br><span class="line">2023-09-02 18:57:46.492 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@4d02b075[PROCESSING][i=null,cb=Blocker@208a09b2&#123;null&#125;] generate: FLUSH (null,[p=0,l=0,c=0,r=0],true)@COMPLETING</span><br><span class="line">2023-09-02 18:57:46.492 [qtp1864548849-46] DEBUG o.eclipse.jetty.io.WriteFlusher - write: WriteFlusher@786f58e9&#123;IDLE&#125;-&gt;null [HeapByteBuffer@24ce20e9[p=0,l=7,c=1024,r=7]=&#123;&lt;&lt;&lt;\r\n0\r\n\r\n&gt;&gt;&gt;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;]</span><br><span class="line">2023-09-02 18:57:46.492 [qtp1864548849-46] DEBUG o.eclipse.jetty.io.WriteFlusher - update WriteFlusher@786f58e9&#123;WRITING&#125;-&gt;null:IDLE--&gt;WRITING</span><br><span class="line">2023-09-02 18:57:46.492 [qtp1864548849-46] DEBUG o.e.jetty.io.ChannelEndPoint - flushed 7 SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=W,to=1/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=END,351 of 351&#125;,g=HttpGenerator@d6ee9c8&#123;s=COMPLETING&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=true,a=DISPATCHED,uri=//100.64.188.184:8051/error&#125;</span><br><span class="line">2023-09-02 18:57:46.492 [qtp1864548849-46] DEBUG o.eclipse.jetty.io.WriteFlusher - Flushed=true 7/7+0 WriteFlusher@786f58e9&#123;WRITING&#125;-&gt;null</span><br><span class="line">2023-09-02 18:57:46.492 [qtp1864548849-46] DEBUG o.eclipse.jetty.io.WriteFlusher - update WriteFlusher@786f58e9&#123;IDLE&#125;-&gt;null:WRITING--&gt;IDLE</span><br><span class="line">2023-09-02 18:57:46.492 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@4d02b075[PROCESSING][i=null,cb=Blocker@208a09b2&#123;null&#125;] generate: DONE (null,[p=0,l=0,c=0,r=0],true)@END</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.s.w.servlet.DispatcherServlet - Null ModelAndView returned to DispatcherServlet with name &#x27;dispatcherServlet&#x27;: assuming HandlerAdapter completed request handling</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.s.o.j.s.OpenEntityManagerInViewInterceptor - Closing JPA EntityManager in OpenEntityManagerInViewInterceptor</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.s.o.j.EntityManagerFactoryUtils - Closing JPA EntityManager</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.s.w.servlet.DispatcherServlet - Successfully completed request</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.s.s.w.a.ExceptionTranslationFilter - Chain processed normally</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.s.s.w.c.SecurityContextPersistenceFilter - SecurityContextHolder now cleared, as request processing completed</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.s.b.w.f.OrderedRequestContextFilter - Cleared thread-bound request context: Request[POST //100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted]@114beb7b</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG org.eclipse.jetty.server.session - FinalSession=null old_session_manager=null this=org.eclipse.jetty.server.session.SessionHandler421217482==dftMaxIdleSec=1800</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG org.eclipse.jetty.server.Server - handled=true async=false committed=true on HttpChannelOverHttp@38fffb8&#123;r=1,c=true,a=DISPATCHED,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125;</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.e.j.server.HttpChannelState - unhandle HttpChannelState@5716ebbe&#123;s=DISPATCHED a=NOT_ASYNC i=true r=IDLE w=false&#125;</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - HttpChannelOverHttp@38fffb8&#123;r=1,c=true,a=COMPLETING,uri=//100.64.188.184:8051/PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted&#125; action COMPLETE</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.e.j.server.HttpChannelState - onComplete HttpChannelState@5716ebbe&#123;s=COMPLETING a=NOT_ASYNC i=false r=IDLE w=false&#125;</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - COMPLETE for /PostRepositoryController/findAllByPostTypeAndPostStatusAndDeleted written=243</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.e.j.server.HttpChannelState - recycle HttpChannelState@5716ebbe&#123;s=COMPLETED a=NOT_ASYNC i=false r=IDLE w=false&#125;</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - reset HttpParser&#123;s=END,351 of 351&#125;</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - END --&gt; START</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpChannel - HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125; handle exit, result COMPLETE</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.e.jetty.io.ChannelEndPoint - filled 0 SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=1/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:46.493 [qtp1864548849-46] DEBUG o.e.jetty.io.ChannelEndPoint - filled 0 SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=1/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:46.494 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=2/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125; filled 0 HeapByteBuffer@77409e4b[p=0,l=0,c=8192,r=0]=&#123;&lt;&lt;&lt;&gt;&gt;&gt;HTTP/1.1 400 Bad ...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;</span><br><span class="line">2023-09-02 18:57:46.494 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=2/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125; parse HeapByteBuffer@77409e4b[p=0,l=0,c=8192,r=0]=&#123;&lt;&lt;&lt;&gt;&gt;&gt;HTTP/1.1 400 Bad ...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125; &#123;&#125;</span><br><span class="line">2023-09-02 18:57:46.494 [qtp1864548849-46] DEBUG o.eclipse.jetty.http.HttpParser - parseNext s=START HeapByteBuffer@77409e4b[p=0,l=0,c=8192,r=0]=&#123;&lt;&lt;&lt;&gt;&gt;&gt;HTTP/1.1 400 Bad ...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;</span><br><span class="line">2023-09-02 18:57:46.494 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=2/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125; parsed false HttpParser&#123;s=START,0 of -1&#125;</span><br><span class="line">2023-09-02 18:57:46.494 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - releaseRequestBuffer HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=2/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:46.494 [qtp1864548849-46] DEBUG o.e.jetty.io.AbstractConnection - fillInterested HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=2/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:46.494 [qtp1864548849-46] DEBUG o.eclipse.jetty.io.FillInterest - interested FillInterest@71e0a5e2&#123;AC.ReadCB@2b3e8dcc&#123;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=0/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&#125;&#125;</span><br><span class="line">2023-09-02 18:57:46.494 [qtp1864548849-46] DEBUG o.e.jetty.io.ChannelEndPoint - changeInterests p=false 0-&gt;1 for SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=0/30000&#125;&#123;io=0/1,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:46.494 [qtp1864548849-46] DEBUG o.e.jetty.io.ManagedSelector - Queued change CEP:SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=0/30000&#125;&#123;io=0/1,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;:runUpdateKey:NON_BLOCKING on org.eclipse.jetty.io.ManagedSelector@79753f20 id=0 keys=2 selected=0</span><br><span class="line">2023-09-02 18:57:46.494 [qtp1864548849-50] DEBUG o.e.jetty.io.ManagedSelector - Selector loop woken up from select, 0/2 selected</span><br><span class="line">2023-09-02 18:57:46.494 [qtp1864548849-50] DEBUG o.e.jetty.io.ManagedSelector - Running action CEP:SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=0/30000&#125;&#123;io=0/1,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;:runUpdateKey:NON_BLOCKING</span><br><span class="line">2023-09-02 18:57:46.495 [qtp1864548849-46] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=1/30000&#125;&#123;io=1/1,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125; onFillable exit HttpChannelState@5716ebbe&#123;s=IDLE a=NOT_ASYNC i=true r=IDLE w=false&#125; null</span><br><span class="line">2023-09-02 18:57:46.495 [qtp1864548849-46] DEBUG o.e.j.u.t.ReservedThreadExecutor - org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread@55e30b93 waiting</span><br><span class="line">2023-09-02 18:57:46.495 [qtp1864548849-50] DEBUG o.e.jetty.io.ChannelEndPoint - Key interests updated 0 -&gt; 1 on SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=1/30000&#125;&#123;io=1/1,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:46.495 [qtp1864548849-50] DEBUG o.e.jetty.io.ManagedSelector - Selector loop waiting on select</span><br><span class="line">2023-09-02 18:57:47.871 [Scheduler-1718325723] DEBUG org.eclipse.jetty.io.IdleTimeout - SocketChannelEndPoint@5f1948e0&#123;/100.64.188.184:55286&lt;-&gt;/100.64.188.184:8051,OSHUT,fill=FI,flush=-,to=30005/30000&#125;&#123;io=1/1,kio=1,kro=1&#125;-&gt;HttpConnection@1d737ae6[p=HttpParser&#123;s=CLOSE,0 of -1&#125;,g=HttpGenerator@22cb7ee&#123;s=START&#125;]=&gt;HttpChannelOverHttp@17faa56a&#123;r=1,c=false,a=IDLE,uri=null&#125; idle timeout check, elapsed: 30005 ms, remaining: -5 ms</span><br><span class="line">2023-09-02 18:57:47.871 [Scheduler-1718325723] DEBUG org.eclipse.jetty.io.IdleTimeout - SocketChannelEndPoint@5f1948e0&#123;/100.64.188.184:55286&lt;-&gt;/100.64.188.184:8051,OSHUT,fill=FI,flush=-,to=30005/30000&#125;&#123;io=1/1,kio=1,kro=1&#125;-&gt;HttpConnection@1d737ae6[p=HttpParser&#123;s=CLOSE,0 of -1&#125;,g=HttpGenerator@22cb7ee&#123;s=START&#125;]=&gt;HttpChannelOverHttp@17faa56a&#123;r=1,c=false,a=IDLE,uri=null&#125; idle timeout expired</span><br><span class="line">2023-09-02 18:57:47.871 [Scheduler-1718325723] DEBUG o.eclipse.jetty.io.FillInterest - onFail FillInterest@403f8334&#123;AC.ReadCB@1d737ae6&#123;HttpConnection@1d737ae6[p=HttpParser&#123;s=CLOSE,0 of -1&#125;,g=HttpGenerator@22cb7ee&#123;s=START&#125;]=&gt;HttpChannelOverHttp@17faa56a&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5f1948e0&#123;/100.64.188.184:55286&lt;-&gt;/100.64.188.184:8051,OSHUT,fill=FI,flush=-,to=30005/30000&#125;&#123;io=1/1,kio=1,kro=1&#125;-&gt;HttpConnection@1d737ae6[p=HttpParser&#123;s=CLOSE,0 of -1&#125;,g=HttpGenerator@22cb7ee&#123;s=START&#125;]=&gt;HttpChannelOverHttp@17faa56a&#123;r=1,c=false,a=IDLE,uri=null&#125;&#125;&#125; &#123;&#125;</span><br><span class="line">2023-09-02 18:57:47.871 [Scheduler-1718325723] DEBUG o.eclipse.jetty.http.HttpParser - close HttpParser&#123;s=CLOSE,0 of -1&#125;</span><br><span class="line">2023-09-02 18:57:47.871 [Scheduler-1718325723] DEBUG o.eclipse.jetty.http.HttpParser - CLOSE --&gt; CLOSE</span><br><span class="line">2023-09-02 18:57:47.871 [Scheduler-1718325723] DEBUG o.e.jetty.io.AbstractConnection - HttpConnection@1d737ae6[p=HttpParser&#123;s=CLOSE,0 of -1&#125;,g=HttpGenerator@22cb7ee&#123;s=START&#125;]=&gt;HttpChannelOverHttp@17faa56a&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5f1948e0&#123;/100.64.188.184:55286&lt;-&gt;/100.64.188.184:8051,OSHUT,fill=-,flush=-,to=30005/30000&#125;&#123;io=1/1,kio=1,kro=1&#125;-&gt;HttpConnection@1d737ae6[p=HttpParser&#123;s=CLOSE,0 of -1&#125;,g=HttpGenerator@22cb7ee&#123;s=START&#125;]=&gt;HttpChannelOverHttp@17faa56a&#123;r=1,c=false,a=IDLE,uri=null&#125; onFillInterestedFailed &#123;&#125;</span><br><span class="line">2023-09-02 18:57:47.872 [Scheduler-1718325723] DEBUG o.e.jetty.io.ChannelEndPoint - doClose SocketChannelEndPoint@5f1948e0&#123;/100.64.188.184:55286&lt;-&gt;/100.64.188.184:8051,CLOSED,fill=-,flush=-,to=30005/30000&#125;&#123;io=1/1,kio=1,kro=1&#125;-&gt;HttpConnection@1d737ae6[p=HttpParser&#123;s=CLOSE,0 of -1&#125;,g=HttpGenerator@22cb7ee&#123;s=START&#125;]=&gt;HttpChannelOverHttp@17faa56a&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:47.872 [Scheduler-1718325723] DEBUG o.eclipse.jetty.io.WriteFlusher - ignored: WriteFlusher@15c3409&#123;IDLE&#125;-&gt;null &#123;&#125;</span><br><span class="line">2023-09-02 18:57:47.872 [Scheduler-1718325723] DEBUG o.eclipse.jetty.io.FillInterest - onClose FillInterest@403f8334&#123;null&#125;</span><br><span class="line">2023-09-02 18:57:47.872 [Scheduler-1718325723] DEBUG o.e.jetty.io.ManagedSelector - Queued change org.eclipse.jetty.io.ManagedSelector$DestroyEndPoint@1a8ae631 on org.eclipse.jetty.io.ManagedSelector@79753f20 id=0 keys=2 selected=0</span><br><span class="line">2023-09-02 18:57:47.872 [Scheduler-1718325723] DEBUG o.eclipse.jetty.io.WriteFlusher - ignored: WriteFlusher@15c3409&#123;IDLE&#125;-&gt;null &#123;&#125;</span><br><span class="line">2023-09-02 18:57:47.872 [qtp1864548849-50] DEBUG o.e.jetty.io.ManagedSelector - Selector loop woken up from select, 0/1 selected</span><br><span class="line">2023-09-02 18:57:47.872 [Scheduler-1718325723] DEBUG o.e.jetty.io.AbstractEndPoint - Ignored idle endpoint SocketChannelEndPoint@5f1948e0&#123;/100.64.188.184:55286&lt;-&gt;/100.64.188.184:8051,CLOSED,fill=-,flush=-,to=30006/30000&#125;&#123;io=1/1,kio=-1,kro=-1&#125;-&gt;HttpConnection@1d737ae6[p=HttpParser&#123;s=CLOSE,0 of -1&#125;,g=HttpGenerator@22cb7ee&#123;s=START&#125;]=&gt;HttpChannelOverHttp@17faa56a&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:47.872 [qtp1864548849-50] DEBUG o.e.jetty.io.ManagedSelector - Running action org.eclipse.jetty.io.ManagedSelector$DestroyEndPoint@1a8ae631</span><br><span class="line">2023-09-02 18:57:47.872 [qtp1864548849-50] DEBUG o.e.jetty.io.ManagedSelector - Destroyed SocketChannelEndPoint@5f1948e0&#123;/100.64.188.184:55286&lt;-&gt;/100.64.188.184:8051,CLOSED,fill=-,flush=-,to=0/30000&#125;&#123;io=1/1,kio=-1,kro=-1&#125;-&gt;HttpConnection@1d737ae6[p=HttpParser&#123;s=CLOSE,0 of -1&#125;,g=HttpGenerator@22cb7ee&#123;s=START&#125;]=&gt;HttpChannelOverHttp@17faa56a&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:47.872 [qtp1864548849-50] DEBUG o.e.jetty.io.AbstractConnection - onClose HttpConnection@1d737ae6[p=HttpParser&#123;s=CLOSE,0 of -1&#125;,g=HttpGenerator@22cb7ee&#123;s=START&#125;]=&gt;HttpChannelOverHttp@17faa56a&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5f1948e0&#123;/100.64.188.184:55286&lt;-&gt;/100.64.188.184:8051,CLOSED,fill=-,flush=-,to=0/30000&#125;&#123;io=1/1,kio=-1,kro=-1&#125;-&gt;HttpConnection@1d737ae6[p=HttpParser&#123;s=CLOSE,0 of -1&#125;,g=HttpGenerator@22cb7ee&#123;s=START&#125;]=&gt;HttpChannelOverHttp@17faa56a&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:47.872 [qtp1864548849-50] DEBUG o.e.jetty.io.ManagedSelector - Selector loop waiting on select</span><br><span class="line">2023-09-02 18:57:51.503 [qtp1864548849-50] DEBUG o.e.jetty.io.ManagedSelector - Selector loop woken up from select, 1/1 selected</span><br><span class="line">2023-09-02 18:57:51.503 [qtp1864548849-50] DEBUG o.e.jetty.io.ManagedSelector - selected sun.nio.ch.SelectionKeyImpl@48f41b4e SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=5009/30000&#125;&#123;io=1/1,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125; </span><br><span class="line">2023-09-02 18:57:51.503 [qtp1864548849-50] DEBUG o.e.jetty.io.ChannelEndPoint - onSelected 1-&gt;0 r=true w=false for SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=5009/30000&#125;&#123;io=1/0,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:51.503 [qtp1864548849-50] DEBUG o.e.jetty.io.ChannelEndPoint - task CEP:SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=5009/30000&#125;&#123;io=1/0,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;:runFillable:BLOCKING</span><br><span class="line">2023-09-02 18:57:51.504 [qtp1864548849-50] DEBUG o.e.j.u.t.s.EatWhatYouKill - EatWhatYouKill@7b3489b7/SelectorProducer@33317d26/PRODUCING/org.eclipse.jetty.util.thread.ReservedThreadExecutor@2e46ffd5&#123;s=2,p=0&#125; t=CEP:SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=5009/30000&#125;&#123;io=1/0,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;:runFillable:BLOCKING/BLOCKING</span><br><span class="line">2023-09-02 18:57:51.504 [qtp1864548849-47] DEBUG o.e.j.u.t.ReservedThreadExecutor - org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread@6221fd5f woken up</span><br><span class="line">2023-09-02 18:57:51.504 [qtp1864548849-50] DEBUG o.e.j.u.t.s.EatWhatYouKill - EatWhatYouKill@7b3489b7/SelectorProducer@33317d26/IDLE/org.eclipse.jetty.util.thread.ReservedThreadExecutor@2e46ffd5&#123;s=1,p=0&#125; EPC t=CEP:SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=5010/30000&#125;&#123;io=1/0,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;:runFillable:BLOCKING</span><br><span class="line">2023-09-02 18:57:51.504 [qtp1864548849-50] DEBUG o.eclipse.jetty.io.FillInterest - fillable FillInterest@71e0a5e2&#123;AC.ReadCB@2b3e8dcc&#123;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=FI,flush=-,to=5010/30000&#125;&#123;io=1/0,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&#125;&#125;</span><br><span class="line">2023-09-02 18:57:51.504 [qtp1864548849-47] DEBUG o.e.j.u.t.s.EatWhatYouKill - EatWhatYouKill@7b3489b7/SelectorProducer@33317d26/IDLE/org.eclipse.jetty.util.thread.ReservedThreadExecutor@2e46ffd5&#123;s=1,p=0&#125; run</span><br><span class="line">2023-09-02 18:57:51.504 [qtp1864548849-47] DEBUG o.e.j.u.t.s.EatWhatYouKill - EatWhatYouKill@7b3489b7/SelectorProducer@33317d26/IDLE/org.eclipse.jetty.util.thread.ReservedThreadExecutor@2e46ffd5&#123;s=1,p=0&#125; produce</span><br><span class="line">2023-09-02 18:57:51.504 [qtp1864548849-50] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=5010/30000&#125;&#123;io=1/0,kio=1,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125; onFillable enter HttpChannelState@5716ebbe&#123;s=IDLE a=NOT_ASYNC i=true r=IDLE w=false&#125; null</span><br><span class="line">2023-09-02 18:57:51.505 [qtp1864548849-47] DEBUG o.e.jetty.io.ChannelEndPoint - Key interests updated 1 -&gt; 0 on SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=5010/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:51.505 [qtp1864548849-47] DEBUG o.e.jetty.io.ManagedSelector - Selector loop waiting on select</span><br><span class="line">2023-09-02 18:57:51.505 [qtp1864548849-50] DEBUG o.e.jetty.io.ChannelEndPoint - filled -1 SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,OPEN,fill=-,flush=-,to=5011/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:51.505 [qtp1864548849-50] DEBUG o.eclipse.jetty.http.HttpParser - atEOF HttpParser&#123;s=START,0 of -1&#125;</span><br><span class="line">2023-09-02 18:57:51.505 [qtp1864548849-50] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,ISHUT,fill=-,flush=-,to=5011/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125; filled -1 HeapByteBuffer@77409e4b[p=0,l=0,c=8192,r=0]=&#123;&lt;&lt;&lt;&gt;&gt;&gt;HTTP/1.1 400 Bad ...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;</span><br><span class="line">2023-09-02 18:57:51.505 [qtp1864548849-50] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,ISHUT,fill=-,flush=-,to=5011/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=START,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125; parse HeapByteBuffer@77409e4b[p=0,l=0,c=8192,r=0]=&#123;&lt;&lt;&lt;&gt;&gt;&gt;HTTP/1.1 400 Bad ...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125; &#123;&#125;</span><br><span class="line">2023-09-02 18:57:51.505 [qtp1864548849-50] DEBUG o.eclipse.jetty.http.HttpParser - parseNext s=START HeapByteBuffer@77409e4b[p=0,l=0,c=8192,r=0]=&#123;&lt;&lt;&lt;&gt;&gt;&gt;HTTP/1.1 400 Bad ...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&#125;</span><br><span class="line">2023-09-02 18:57:51.505 [qtp1864548849-50] DEBUG o.eclipse.jetty.http.HttpParser - START --&gt; CLOSED</span><br><span class="line">2023-09-02 18:57:51.505 [qtp1864548849-50] DEBUG o.e.jetty.io.ChannelEndPoint - doClose SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,CLOSED,fill=-,flush=-,to=5011/30000&#125;&#123;io=0/0,kio=0,kro=1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=CLOSED,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:51.505 [qtp1864548849-50] DEBUG o.eclipse.jetty.io.WriteFlusher - ignored: WriteFlusher@786f58e9&#123;IDLE&#125;-&gt;null &#123;&#125;</span><br><span class="line">2023-09-02 18:57:51.505 [qtp1864548849-50] DEBUG o.eclipse.jetty.io.FillInterest - onClose FillInterest@71e0a5e2&#123;null&#125;</span><br><span class="line">2023-09-02 18:57:51.505 [qtp1864548849-50] DEBUG o.e.jetty.io.ManagedSelector - Queued change org.eclipse.jetty.io.ManagedSelector$DestroyEndPoint@652feff5 on org.eclipse.jetty.io.ManagedSelector@79753f20 id=0 keys=1 selected=0</span><br><span class="line">2023-09-02 18:57:51.505 [qtp1864548849-47] DEBUG o.e.jetty.io.ManagedSelector - Selector loop woken up from select, 0/0 selected</span><br><span class="line">2023-09-02 18:57:51.505 [qtp1864548849-47] DEBUG o.e.jetty.io.ManagedSelector - Running action org.eclipse.jetty.io.ManagedSelector$DestroyEndPoint@652feff5</span><br><span class="line">2023-09-02 18:57:51.506 [qtp1864548849-47] DEBUG o.e.jetty.io.ManagedSelector - Destroyed SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,CLOSED,fill=-,flush=-,to=5011/30000&#125;&#123;io=0/0,kio=-1,kro=-1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=CLOSED,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:51.506 [qtp1864548849-50] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=CLOSED,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,CLOSED,fill=-,flush=-,to=5011/30000&#125;&#123;io=0/0,kio=-1,kro=-1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=CLOSED,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125; parsed false HttpParser&#123;s=CLOSED,0 of -1&#125;</span><br><span class="line">2023-09-02 18:57:51.506 [qtp1864548849-47] DEBUG o.e.jetty.io.AbstractConnection - onClose HttpConnection@2b3e8dcc[p=HttpParser&#123;s=CLOSED,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,CLOSED,fill=-,flush=-,to=5012/30000&#125;&#123;io=0/0,kio=-1,kro=-1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=CLOSED,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:51.506 [qtp1864548849-47] DEBUG o.e.jetty.io.ManagedSelector - Selector loop waiting on select</span><br><span class="line">2023-09-02 18:57:51.506 [qtp1864548849-50] DEBUG o.e.jetty.server.HttpConnection - releaseRequestBuffer HttpConnection@2b3e8dcc[p=HttpParser&#123;s=CLOSED,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,CLOSED,fill=-,flush=-,to=5012/30000&#125;&#123;io=0/0,kio=-1,kro=-1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=CLOSED,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;</span><br><span class="line">2023-09-02 18:57:51.506 [qtp1864548849-50] DEBUG o.e.jetty.server.HttpConnection - HttpConnection@2b3e8dcc[p=HttpParser&#123;s=CLOSED,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125;&lt;-SocketChannelEndPoint@5315f828&#123;/100.64.188.184:55553&lt;-&gt;/100.64.188.184:8051,CLOSED,fill=-,flush=-,to=5012/30000&#125;&#123;io=0/0,kio=-1,kro=-1&#125;-&gt;HttpConnection@2b3e8dcc[p=HttpParser&#123;s=CLOSED,0 of -1&#125;,g=HttpGenerator@d6ee9c8&#123;s=START&#125;]=&gt;HttpChannelOverHttp@38fffb8&#123;r=1,c=false,a=IDLE,uri=null&#125; onFillable exit HttpChannelState@5716ebbe&#123;s=IDLE a=NOT_ASYNC i=true r=IDLE w=false&#125; null</span><br><span class="line">2023-09-02 18:57:51.506 [qtp1864548849-50] DEBUG o.e.j.u.t.ReservedThreadExecutor - org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread@22afa967 waiting</span><br></pre></td></tr></table></figure></div>
</detail>
</li>
</ol>
<ul>
<li>通过断点监控，发现<code>com.fasterxml.jackson.databind.deser.BeanDeserializer</code>中函数<code>deserializeFromObject</code>解析输入参数时存在<code>pageRequest</code>参数（很奇怪），进而导致了以上报错，实际上不应该传递该参数。</li>
<li>根据前期排查，直接向 microservice1 发送 POST 请求时可以正常，而通过 microservice2 发送 POST 请求时会出现该问题，因此暂时判断问题出在 microservice2，对 microservice2 通过 <code>feignclient</code> 发送请求的过程进行断点排查+详细日志输出。</li>
<li>检索信息，查看 <code>feignclient</code> 端所传递信息情况，发现<code>com.fasterxml.jackson.databind.ObjectWriter</code>的<code>writeValue</code>函数导致转为 json 后的数据出现<code>pageRequest</code>参数。<ul>
<li>更具体地说，是在使用<code>com.fasterxml.jackson.databind.ser.DefaultSerializerProvider</code>的<code>serializeValue</code>函数中所获取的<code>JsonSerializer&lt;Object&gt;</code>类对象的属性存在<code>pageRequest</code>参数。<ul>
<li>至此，怀疑是因为在 PageParam 类中写了<code>getPageRequest</code>和<code>setPageReuqest</code>两个函数，进一步被<code>@Data</code>之类的注解自动识别为属性。</li>
</ul>
</li>
<li>首先进一步断点排查，查看<code>com.fasterxml.jackson.databind.ser.DefaultSerializerProvider</code>类的<code>findTypedValueSerializer</code>函数如何构建出错的<code>JsonSerializer&lt;Object&gt;</code>类对象。<ul>
<li>发现相关<code>JsonSerializer&lt;Object&gt;</code>类对象已经提前设定好，基本排除 <code>JsonSerialize</code> 问题。</li>
</ul>
</li>
<li>进一步检索 <code>@Data</code> 注解原理，发现似乎并无关联。</li>
<li>进一步检索 <code>Jackson</code> 对于 <code>getter</code> 函数的处理，发现果然存在问题，<code>Jackson</code> 会自动将存在 <code>getter</code> 函数的属性解析<a href="#refer-anchor-6"><sup>[6]</sup></a>。（你害我害得好苦啊）（太自动化了竟然也不是好事）</li>
</ul>
</li>
</ul>
<h3 id="🔨解决方案-1"><a href="#🔨解决方案-1" class="headerlink" title="🔨解决方案"></a>🔨解决方案</h3><ul>
<li>定位到问题后，解决就变得非常简单了。</li>
<li>在 <code>getter</code>、<code>setter</code> 函数上增加 <code>@JsonIgnore</code> 注解即可。</li>
<li>后续：问题转变为反序列化<code>org.springframework.data.domain.Page</code>失败，相关解决方案已补充至<a href="#">Post not found: program_language/java-spring-bug-json-parse-error 【Spring】java 单体式应用微服务拆分过程 bug 修复：Json Parse Error</a>。</li>
</ul>
<h3 id="📖知识补充——-JsonIgnore-注解"><a href="#📖知识补充——-JsonIgnore-注解" class="headerlink" title="📖知识补充——@JsonIgnore 注解"></a>📖知识补充——@JsonIgnore 注解</h3><ul>
<li>作用：<a href="#refer-anchor-7"><sup>[7]</sup></a><blockquote>
<p>Marker annotation that indicates that the annotated method or field is to be ignored by introspection-based serialization and deserialization functionality. That is, it should not be consider a “getter”, “setter” or “creator”.<br>标记注释，表示注释的方法或字段将被基于自检的序列化和反序列化功能忽略。也就是说，它不应被视为 “getter”、”setter “或 “creator”。</p>
</blockquote>
</li>
<li>本次发现的隐含小坑：<ul>
<li>此处暗示，<code>getter</code>、<code>setter</code>函数会影响 Json 序列化及反序列化结果。</li>
<li>当使用不想被序列化/反序列化的<code>getter</code>、<code>setter</code>函数时应当标注该注解。</li>
</ul>
</li>
</ul>
<h1 id="🧠问题4️⃣——400：Already-had-POJO-for-id"><a href="#🧠问题4️⃣——400：Already-had-POJO-for-id" class="headerlink" title="🧠问题4️⃣——400：Already had POJO for id"></a>🧠问题4️⃣——400：Already had POJO for id</h1><h2 id="✏️问题描述-3"><a href="#✏️问题描述-3" class="headerlink" title="✏️问题描述"></a>✏️问题描述</h2><ul>
<li>对于存在循环引用的对象，传参后出现<code>Already had POJO for id</code>报错。</li>
</ul>
<h3 id="ℹ️报错信息1️⃣-3"><a href="#ℹ️报错信息1️⃣-3" class="headerlink" title="ℹ️报错信息1️⃣"></a>ℹ️报错信息1️⃣</h3><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">Failed to read HTTP message: org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Already had POJO for id (java.lang.Long) [[ObjectId: key=1, type=com.fasterxml.jackson.databind.deser.impl.PropertyBasedObjectIdGenerator, scope=com.raysmond.blog.common.models.User]]</span><br></pre></td></tr></table></figure></div>

<h3 id="📚问题分析-3"><a href="#📚问题分析-3" class="headerlink" title="📚问题分析"></a>📚问题分析</h3><ul>
<li>根据前期相应方法，逐步断点，最后定位到报错源：</li>
</ul>
<ol>
<li><code>com.fasterxml.jackson.databind.deser.impl.ObjectIdValueProperty</code>的<code>deserializeSetAndReturn</code>方法希望将<code>ReadableObjectId</code>类型的变量<code>roid</code>与<code>Object</code>类型的变量<code>instance</code>进行绑定。<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">ReadableObjectId</span> <span class="variable">roid</span> <span class="operator">=</span> ctxt.findObjectId(id, _objectIdReader.generator, _objectIdReader.resolver);</span><br><span class="line">roid.bindItem(instance);</span><br></pre></td></tr></table></figure></div></li>
<li><code>com.fasterxml.jackson.databind.deser.impl.ReadableObjectId</code>的<code>bindItem</code>方法调用<code>_resolver</code>变量进行绑定。</li>
<li><code>com.fasterxml.jackson.annotation.SimpleObjectIdResolver</code>的<code>SimpleObjectIdResolver</code>方法进行最终绑定，代码如下：<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">bindItem</span><span class="params">(IdKey id, Object ob)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (_items == <span class="literal">null</span>) &#123;</span><br><span class="line">        _items = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;ObjectIdGenerator.IdKey,Object&gt;();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (_items.containsKey(id)) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;Already had POJO for id (&quot;</span> + id.key.getClass().getName() + <span class="string">&quot;) [&quot;</span> + id</span><br><span class="line">                + <span class="string">&quot;]&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    _items.put(id, ob);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
</ol>
<ul>
<li>思考逻辑，希望的逻辑是：先检索是否已经存在该 id 为 key 的对象，如果已存在则不再重新插入。<ul>
<li>基于该逻辑向前梳理，找“当 id 已存在时 spring 是如何处理的”。</li>
<li>逐步断点理解流程后突然意识到（受到<a href="#refer-anchor-8">[8]</a>修改 <code>generator</code> 参数的启发），所谓“解决循环引用”的过程，很可能是从标记了<code>@JsonIdentityInfo</code>注解的类开始，对其下每个被标记了该注解的属性对象用 id 代替。而我们的项目中定义了这样一个 DTO 类：<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PostUserParams</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Post post;</span><br><span class="line">    <span class="keyword">private</span> User user;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">PostUserParams</span><span class="params">(Post post, User user)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.post = post;</span><br><span class="line">        <span class="built_in">this</span>.user = user;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
<li>其中的 <code>post</code> 和 <code>user</code> 对象分别在两个<code>@JsonIdentityInfo</code>序列化过程中，而当<code>post</code>的子对象<code>post_user</code>与<code>user</code>相同时则会出现冲突（在两个序列化过程中出现相同，而非同一个序列化过程中出现相同）。</li>
<li>因此问题应当出在序列化过程而非反序列化过程。</li>
</ul>
</li>
</ul>
<h3 id="🔨解决方案-2"><a href="#🔨解决方案-2" class="headerlink" title="🔨解决方案"></a>🔨解决方案</h3><ul>
<li>一种思路是在序列化<code>user</code>的过程中识别该对象是否已被序列化过。</li>
<li>另一种思路是把<code>user</code>当做没出现过的对象，序列化成其他值。</li>
<li>前者还没想到怎么使用，后者尝试将<code>@JsonIdentityInfo</code>的<code>generator</code>参数改为<code>ObjectIdGenerators.IntSequenceGenerator.class</code>并删去<code>property</code>属性<a href="#refer-anchor-8"><sup>[8]</sup></a><a href="#refer-anchor-9"><sup>[9]</sup></a>。</li>
</ul>
<h3 id="📚相关知识补充"><a href="#📚相关知识补充" class="headerlink" title="📚相关知识补充"></a>📚相关知识补充</h3><ul>
<li>根据相关资料<a href="#refer-anchor-8"><sup>[8]</sup></a><a href="#refer-anchor-9"><sup>[9]</sup></a>及<code>com.fasterxml.jackson.annotation.ObjectIdGenerators</code>源码，<code>generator</code> 参数有以下几个选项：<ol>
<li><code>ObjectIdGenerators.IntSequenceGenerator</code>：<ul>
<li>Simple sequence-number based generator, which uses basic Java ints (starting with value 1) as Object Identifiers. </li>
<li>基于序列号的简单生成器，使用基本的 Java ints（从值 1 开始）作为对象标识符。</li>
</ul>
</li>
<li><code>ObjectIdGenerators.PropertyGenerator</code>：<ul>
<li>Abstract place-holder class which is used to denote case where Object Identifier to use comes from a POJO property (getter method or field). If so, value is written directly during serialization, and used as-is during deserialization. Actual implementation class is part of databind package. </li>
<li>抽象占位类，用于表示要使用的对象标识符来自 POJO 属性（获取方法或字段）的情况。如果是这样，值将在序列化过程中直接写入，并在反序列化过程中按原样使用。实际实现类是 databind 包的一部分。</li>
</ul>
</li>
<li><code>ObjectIdGenerators.StringIdGenerator</code> (since 2.7)：<ul>
<li>Implementation that will accept arbitrary (but unique) String Ids on deserialization, and (by default) use random UUID generation similar to ObjectIdGenerators.UUIDGenerator for generation ids.</li>
<li>This generator is most useful for cases where another system creates String Ids (of arbitrary structure, if any), and Jackson only needs to keep track of id-to-Object mapping. Generation also works, although if UUIDs are always used, ObjectIdGenerators.UUIDGenerator is a better match as it will also validate ids being used.</li>
<li>该实现将在反序列化时接受任意（但唯一）的字符串 Ids，并且（默认情况下）使用类似于 ObjectIdGenerators.UUIDGenerator 的随机 UUID 生成器生成 ID。</li>
<li>这种生成器最适用于其他系统创建字符串 Ids（任意结构，如果有的话），而 Jackson 只需要跟踪 id 到对象的映射的情况。尽管如果总是使用 UUID，ObjectIdGenerators.UUIDGenerator 也能发挥作用，但它也会验证正在使用的 id。</li>
</ul>
</li>
<li><code>ObjectIdGenerators.UUIDGenerator</code>：<ul>
<li>Implementation that just uses UUIDs as reliably unique identifiers: downside is that resulting String is 36 characters long.</li>
<li>One difference to other generators is that scope is always set as Object.class (regardless of arguments): this because UUIDs are globally unique, and scope has no meaning.</li>
<li>该实现只使用 UUID 作为可靠的唯一标识符：缺点是生成的字符串长达 36 个字符。</li>
<li>与其他生成器的一个不同之处是，scope 总是设置为 Object.class（与参数无关）：这是因为 UUID 是全局唯一的，而 scope 没有任何意义。</li>
</ul>
</li>
</ol>
</li>
</ul>
<h1 id="🤔思考"><a href="#🤔思考" class="headerlink" title="🤔思考"></a>🤔思考</h1><ul>
<li>排查 bug 的思路？<ul>
<li>根据前期 bug 排查，已经确定 microservice1 在接收到正常数据时能够正常运行，但后期排查时又不小心忽略了该结论，导致浪费大量时间排查 microservice1。</li>
<li>应该始终提醒自己从宏观层面回顾，之前获得了什么结论，现在需要证明/排除的是什么问题。</li>
</ul>
</li>
</ul>
<h1 id="🚧ToDoList（也许会补上）"><a href="#🚧ToDoList（也许会补上）" class="headerlink" title="🚧ToDoList（也许会补上）"></a>🚧ToDoList（也许会补上）</h1><ol>
<li><input disabled="" type="checkbox"> Spring 框架基础原理</li>
<li><input disabled="" type="checkbox"> Jackson 组件原理及相关注解作用</li>
<li><input checked="" disabled="" type="checkbox"> <a href="#">Post not found: program_language/java-spring-bug-4xx 到底为啥报4xx相关错误</a></li>
<li><input checked="" disabled="" type="checkbox"> <a href="#">Post not found: program_language/java-spring-bug-json-infinite-recursion json循环引用报错</a></li>
<li><input disabled="" type="checkbox"> Serialize Json 报错</li>
</ol>
<h1 id="x1f5fa-参考文献"><a href="#x1f5fa-参考文献" class="headerlink" title="&#x1f5fa;参考文献"></a><span class="emoji" alias="world_map" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5fa.png?v8">&#x1f5fa;</span>参考文献</h1><div id="refer-anchor-1"></div>

<p><a class="link"   href="https://www.cnblogs.com/cocoajin/p/3986204.html" >[1] HTTP请求415错误 – 不支持的媒体类型(Unsupported media type)<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-2"></div>

<p><a class="link"   href="https://huoyingwhw.com/2019/08/04/Markdown%E4%B8%AD%E6%8A%98%E5%8F%A0%E4%BB%A3%E7%A0%81%E7%9A%84%E6%96%B9%E6%B3%95/" >[2] Markdown中折叠代码的方法<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-3"></div>

<p><a class="link"   href="https://github.com/FasterXML/jackson-databind/issues/1872" >[3] NullPointerException in SubTypeValidator.validateSubType when validating Spring interface<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-4"></div>

<p><a class="link"   href="https://blog.csdn.net/andy_zhang2007/article/details/89297627" >[4] Spring MVC : 400 错误是怎么发生的 ?<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-5"></div>

<p><a class="link"   href="https://juejin.cn/s/%E6%B8%85%E9%99%A4gradle%E7%BC%93%E5%AD%98" >[5] 清除gradle缓存<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-6"></div>

<p><a class="link"   href="https://stackoverflow.com/questions/59191010/jackson-deserialization-behaviour-for-a-getter-without-property" >[6] Jackson deserialization behaviour for a getter without property<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-7"></div>

<p><a class="link"   href="https://fasterxml.github.io/jackson-annotations/javadoc/2.5/com/fasterxml/jackson/annotation/JsonIgnore.html" >[7] Annotation Type JsonIgnore<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-8"></div>

<p><a class="link"   href="https://www.cnblogs.com/rain144576/p/14565060.html" >[8] 公用技术——数据格式——JSON——Jackson类库——复杂对象<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div id="refer-anchor-9"></div>

<p><a href="https://fasterxml.github.io/jackson-annotations/javadoc/2.8/com/fasterxml/jackson/annotation/ObjectIdGenerator.html">[9] Class ObjectIdGenerator<T></a></p>
]]></content>
      <categories>
        <category>工程</category>
        <category>环境检修</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
</search>
